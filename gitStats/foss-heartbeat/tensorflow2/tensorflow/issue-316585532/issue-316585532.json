{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18774", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18774/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18774/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18774/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18774", "id": 316585532, "node_id": "MDU6SXNzdWUzMTY1ODU1MzI=", "number": 18774, "title": "mobilenet_v1_eval.py has a big bug?", "user": {"login": "GarryLau", "id": 14019923, "node_id": "MDQ6VXNlcjE0MDE5OTIz", "avatar_url": "https://avatars1.githubusercontent.com/u/14019923?v=4", "gravatar_id": "", "url": "https://api.github.com/users/GarryLau", "html_url": "https://github.com/GarryLau", "followers_url": "https://api.github.com/users/GarryLau/followers", "following_url": "https://api.github.com/users/GarryLau/following{/other_user}", "gists_url": "https://api.github.com/users/GarryLau/gists{/gist_id}", "starred_url": "https://api.github.com/users/GarryLau/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/GarryLau/subscriptions", "organizations_url": "https://api.github.com/users/GarryLau/orgs", "repos_url": "https://api.github.com/users/GarryLau/repos", "events_url": "https://api.github.com/users/GarryLau/events{/privacy}", "received_events_url": "https://api.github.com/users/GarryLau/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tatatodd", "id": 5453737, "node_id": "MDQ6VXNlcjU0NTM3Mzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/5453737?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tatatodd", "html_url": "https://github.com/tatatodd", "followers_url": "https://api.github.com/users/tatatodd/followers", "following_url": "https://api.github.com/users/tatatodd/following{/other_user}", "gists_url": "https://api.github.com/users/tatatodd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tatatodd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tatatodd/subscriptions", "organizations_url": "https://api.github.com/users/tatatodd/orgs", "repos_url": "https://api.github.com/users/tatatodd/repos", "events_url": "https://api.github.com/users/tatatodd/events{/privacy}", "received_events_url": "https://api.github.com/users/tatatodd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-04-22T14:53:19Z", "updated_at": "2018-11-21T18:59:35Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code</strong>:Yes</li>\n<li><strong>OS Platform and Distribution</strong>:Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from</strong>:binary(Anaconda)</li>\n<li><strong>TensorFlow version</strong>:1.7</li>\n<li><strong>Python version</strong>: Python 3.6.2</li>\n<li><strong>Bazel version</strong>:<br>\nBuild label: 0.11.1<br>\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Tue May 14 07:48:23 +50148 (1520362424903)<br>\nBuild timestamp: 1520362424903<br>\nBuild timestamp as int: 1520362424903</li>\n<li><strong>CUDA/cuDNN version</strong>:CUDA 9.0, cuDNN v7.0</li>\n<li><strong>GPU model and memory</strong>:GTX 1080Ti, 11GB</li>\n<li><strong>Exact command to reproduce</strong>:Just run mobilenet_v1_eval.py to evaluate the trained model, you will find the bug. If <strong>is_training=True you can get the right result</strong>.[The is_trainging are in mobilenet_v1.mobilenet_v1_arg_scope(is_training=True) and mobilenet_v1.mobilenet_v1(inputs, is_training=True) ]. <strong>Or remove \"slim.batch_norm\" in \"with slim.arg_scope([slim.batch_norm, slim.dropout],\" can also get the right result.</strong> \"with slim.arg_scope([slim.batch_norm, slim.dropout],\"  is in L362 of <a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py\">https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py</a></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Totally, I have two problems.<br>\n<strong>Firstly</strong>,<br>\nIn the mobilenet_v1_eval.py, yeah, it's eval not train. When is_training=False, you will not get a right result. When is_training=True, you can get a right answer. Obviously, it's wrong! I guess it's a big bug associate with batch norm, but I cannot figure it out. Someone knows that?<br>\nAttentation, the is_training is not the one in  flower_input(is_training=False), they are in mobilenet_v1.mobilenet_v1_arg_scope(is_training=True) and mobilenet_v1.mobilenet_v1(inputs, is_training=True). And <strong>flower_input() was a custom code referencing imagenet_input()</strong> in <a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py\">https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py</a></p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">build_model</span>():\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Build the mobilenet_v1 model for evaluation.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">  Returns:</span>\n<span class=\"pl-s\">    g: graph with rewrites after insertion of quantization ops and batch norm</span>\n<span class=\"pl-s\">    folding.</span>\n<span class=\"pl-s\">    eval_ops: eval ops for inference.</span>\n<span class=\"pl-s\">    variables_to_restore: List of variables to restore from checkpoint.</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span>\n  g <span class=\"pl-k\">=</span> tf.Graph()\n  <span class=\"pl-k\">with</span> g.as_default():\n    inputs, labels <span class=\"pl-k\">=</span> flower_input(<span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n    scope <span class=\"pl-k\">=</span> mobilenet_v1.mobilenet_v1_arg_scope(\n        <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>)\n    <span class=\"pl-k\">with</span> slim.arg_scope(scope):\n      logits, _ <span class=\"pl-k\">=</span> mobilenet_v1.mobilenet_v1(\n          inputs,\n          <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n          <span class=\"pl-v\">depth_multiplier</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.depth_multiplier,\n          <span class=\"pl-v\">num_classes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.num_classes)\n\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.quantize:\n      tf.contrib.quantize.create_eval_graph()\n\n    eval_ops <span class=\"pl-k\">=</span> metrics(logits, labels)\n\n  <span class=\"pl-k\">return</span> g, eval_ops</pre></div>\n<p><strong>Secondly</strong>,<br>\nI use export_eval_pbtxt() in the following to get the \"mobilenet_v1_eval.pbtxt\".</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">export_eval_pbtxt</span>():\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Export eval.pbtxt.<span class=\"pl-pds\">\"\"\"</span></span>\n  g <span class=\"pl-k\">=</span> tf.Graph()\n  <span class=\"pl-k\">with</span> g.as_default():\n    inputs <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>,<span class=\"pl-c1\">224</span>,<span class=\"pl-c1\">224</span>,<span class=\"pl-c1\">3</span>])\n    scope <span class=\"pl-k\">=</span> mobilenet_v1.mobilenet_v1_arg_scope(\n        <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">weight_decay</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.0</span>)\n    <span class=\"pl-k\">with</span> slim.arg_scope(scope):\n      logits, _ <span class=\"pl-k\">=</span> mobilenet_v1.mobilenet_v1(\n          inputs,\n          <span class=\"pl-v\">is_training</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>,\n          <span class=\"pl-v\">depth_multiplier</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.depth_multiplier,\n          <span class=\"pl-v\">num_classes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.num_classes)\n    eval_graph_file <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/home/lg/projects/mobilenet_v1_eval.pbtxt<span class=\"pl-pds\">'</span></span>\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n          <span class=\"pl-k\">with</span> <span class=\"pl-c1\">open</span>(eval_graph_file, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>w<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n            f.write(<span class=\"pl-c1\">str</span>(g.as_graph_def()))\n</pre></div>\n<p>Then, frozen the graph:</p>\n<div class=\"highlight highlight-source-python\"><pre>bazel<span class=\"pl-k\">-</span><span class=\"pl-c1\">bin</span><span class=\"pl-k\">/</span>tensorflow<span class=\"pl-k\">/</span>python<span class=\"pl-k\">/</span>tools<span class=\"pl-k\">/</span>freeze_graph  \\\n  <span class=\"pl-ii\">--</span>input_graph<span class=\"pl-k\">=</span><span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>lg<span class=\"pl-k\">/</span>projects<span class=\"pl-k\">/</span>mobilenet_v1_eval.pbtxt \\\n  <span class=\"pl-ii\">--</span>input_checkpoint<span class=\"pl-k\">=</span><span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>lg<span class=\"pl-k\">/</span>projects<span class=\"pl-k\">/</span>checkpoint<span class=\"pl-k\">/</span>model.ckpt<span class=\"pl-k\">-</span><span class=\"pl-c1\">20000</span> \\\n  <span class=\"pl-ii\">--</span>input_binary<span class=\"pl-k\">=</span>false \\\n  <span class=\"pl-ii\">--</span>output_graph<span class=\"pl-k\">=</span><span class=\"pl-k\">/</span>home<span class=\"pl-k\">/</span>lg<span class=\"pl-k\">/</span>projects<span class=\"pl-k\">/</span>frozen_mobilenet_v1_224.pb  \\\n  <span class=\"pl-ii\">--</span>output_node_names<span class=\"pl-k\">=</span>MobilenetV1<span class=\"pl-k\">/</span>Predictions<span class=\"pl-k\">/</span>Reshape_1  \\\n  <span class=\"pl-ii\">--</span>checkpoint_version<span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span></pre></div>\n<p>Then I use the frozen .pb file to classify an image, it won't get a right result, no matter you use is_training is True or False above to get the \"mobilenet_v1_eval.pbtxt\".<br>\nAnd the classify file is:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> absolute_import\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> division\n<span class=\"pl-k\">from</span> <span class=\"pl-c1\">__future__</span> <span class=\"pl-k\">import</span> print_function\n\n<span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> os.path\n<span class=\"pl-k\">import</span> re\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> tarfile\n\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">from</span> six.moves <span class=\"pl-k\">import</span> urllib\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">create_graph</span>():\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Creates a graph from saved GraphDef file and returns a saver.<span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Creates graph from saved graph_def.pb.</span>\n  <span class=\"pl-k\">with</span> tf.gfile.FastGFile(os.path.join(<span class=\"pl-c1\">FLAGS</span>.model_dir, <span class=\"pl-sr\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">'</span>/home/lg/projects/frozen_mobilenet_v1_224<span class=\"pl-c1\">.</span>pb<span class=\"pl-pds\">'</span></span>), <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>) <span class=\"pl-k\">as</span> f:\n    graph_def <span class=\"pl-k\">=</span> tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    _ <span class=\"pl-k\">=</span> tf.import_graph_def(graph_def,<span class=\"pl-v\">return_elements</span><span class=\"pl-k\">=</span>[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>MobilenetV1/Predictions/Reshape_1:0<span class=\"pl-pds\">'</span></span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>lg<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run_inference_on_image</span>(<span class=\"pl-smi\">image</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Runs inference on an image.</span>\n<span class=\"pl-s\">  Args:</span>\n<span class=\"pl-s\">    image: Image file name.</span>\n<span class=\"pl-s\">  Returns:</span>\n<span class=\"pl-s\">    Nothing</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span>\n  <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> tf.gfile.Exists(image):\n    tf.logging.fatal(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>File does not exist <span class=\"pl-c1\">%s</span><span class=\"pl-pds\">'</span></span>, image)\n\n  image_data <span class=\"pl-k\">=</span> tf.gfile.FastGFile(image, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>).read()\n  img_data_jpg <span class=\"pl-k\">=</span> tf.image.decode_jpeg(image_data) <span class=\"pl-c\"><span class=\"pl-c\">#</span>\u56fe\u50cf\u89e3\u7801  </span>\n  img_data_jpg <span class=\"pl-k\">=</span> tf.image.convert_image_dtype(img_data_jpg, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32) <span class=\"pl-c\"><span class=\"pl-c\">#</span>\u6539\u53d8\u56fe\u50cf\u6570\u636e\u7684\u7c7b\u578b</span>\n  img_data_jpg <span class=\"pl-k\">=</span> tf.image.resize_image_with_crop_or_pad(img_data_jpg,<span class=\"pl-c1\">224</span>,<span class=\"pl-c1\">224</span>)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Creates graph from saved GraphDef.</span>\n  create_graph()\n\n  <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    image_data <span class=\"pl-k\">=</span> img_data_jpg.eval().reshape(<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">224</span>,<span class=\"pl-c1\">224</span>,<span class=\"pl-c1\">3</span>)\n    softmax_tensor <span class=\"pl-k\">=</span> sess.graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lg/MobilenetV1/Predictions/Reshape_1:0<span class=\"pl-pds\">'</span></span>)\n    predictions <span class=\"pl-k\">=</span> sess.run(softmax_tensor, {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>lg/Placeholder:0<span class=\"pl-pds\">'</span></span>: image_data})\n    predictions <span class=\"pl-k\">=</span> np.squeeze(predictions)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>predictions: <span class=\"pl-pds\">'</span></span>,predictions)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Read the labels from label.txt.</span>\n    label_path <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-c1\">FLAGS</span>.model_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/home/lg/projects/labels.txt<span class=\"pl-pds\">'</span></span>)\n    label <span class=\"pl-k\">=</span> np.loadtxt(<span class=\"pl-v\">fname</span><span class=\"pl-k\">=</span>label_path,<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>)\n\n    top_k <span class=\"pl-k\">=</span> predictions.argsort()[<span class=\"pl-k\">-</span><span class=\"pl-c1\">FLAGS</span>.num_top_predictions:][::<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>]\n    <span class=\"pl-k\">for</span> node_id <span class=\"pl-k\">in</span> top_k:\n      label_string <span class=\"pl-k\">=</span> label[node_id]\n      score <span class=\"pl-k\">=</span> predictions[node_id]\n      <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">%s</span> (score = <span class=\"pl-c1\">%.5f</span>)<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (label_string, score))\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">_</span>):\n  image <span class=\"pl-k\">=</span> (<span class=\"pl-c1\">FLAGS</span>.image_file <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.image_file <span class=\"pl-k\">else</span> os.path.join(<span class=\"pl-c1\">FLAGS</span>.model_dir, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>cropped_panda.jpg<span class=\"pl-pds\">'</span></span>))\n  run_inference_on_image(image)\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n  parser <span class=\"pl-k\">=</span> argparse.ArgumentParser()\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> graph_def.pb: Binary representation of the GraphDef protocol buffer.</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> label.txt: the labels according to data tfrecord</span>\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--model_dir<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>/tmp/imagenet<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Path to graph_def.pb and label.txt<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--image_file<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-sr\"><span class=\"pl-k\">r</span><span class=\"pl-pds\">'</span>/home/lg/projects/data/flower_photos/daisy/5673728_71b8cb57eb<span class=\"pl-c1\">.</span>jpg<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Absolute path to image file.<span class=\"pl-pds\">'</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">'</span>--num_top_predictions<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Display this many predictions.<span class=\"pl-pds\">'</span></span>\n  )\n  <span class=\"pl-c1\">FLAGS</span>, unparsed <span class=\"pl-k\">=</span> parser.parse_known_args()\ntf.app.run(<span class=\"pl-v\">main</span><span class=\"pl-k\">=</span>main, <span class=\"pl-v\">argv</span><span class=\"pl-k\">=</span>[sys.argv[<span class=\"pl-c1\">0</span>]] <span class=\"pl-k\">+</span> unparsed)</pre></div>\n<p>The mobilenet v1 I used is in <a href=\"https://github.com/tensorflow/models/tree/master/research/slim/nets\">https://github.com/tensorflow/models/tree/master/research/slim/nets</a> .<br>\nI have tried inception v3, whether to eval or classify an image that can get right results. So I think  mobilenet_v1_eval.py must have a bug.</p>\n<p>Actually, I have tried two experiments, one is the custom codes(tf_train.py, tf_eval.py, tf_input.py, tf_inference.py, tf_classify_image.py referencing <a href=\"https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10\">https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10</a>) in <a href=\"https://github.com/GarryLau/draft_notes/tree/master/TF\">https://github.com/GarryLau/draft_notes/tree/master/TF</a>.<br>\nAnother one is referencing mobilenet_v1_train.py, mobilenet_v1_eval.py, mobilenet_v1.py, in <a href=\"https://github.com/tensorflow/models/tree/master/research/slim/nets\">https://github.com/tensorflow/models/tree/master/research/slim/nets</a> .<br>\nIn the begining, I think the custom codes have some problems, so I tried the second experiment that tensorflow official. But they are all wrong.</p>\n<h3>Source code / logs</h3>\n<p>All the codes I used are in:<br>\n<a href=\"https://github.com/GarryLau/draft_notes/tree/master/TF\">https://github.com/GarryLau/draft_notes/tree/master/TF</a><br>\n<a href=\"https://github.com/GarryLau/draft_notes/tree/master/create_tfrecord\">https://github.com/GarryLau/draft_notes/tree/master/create_tfrecord</a></p>", "body_text": "System information\n\nHave I written custom code:Yes\nOS Platform and Distribution:Linux Ubuntu 16.04\nTensorFlow installed from:binary(Anaconda)\nTensorFlow version:1.7\nPython version: Python 3.6.2\nBazel version:\nBuild label: 0.11.1\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Tue May 14 07:48:23 +50148 (1520362424903)\nBuild timestamp: 1520362424903\nBuild timestamp as int: 1520362424903\nCUDA/cuDNN version:CUDA 9.0, cuDNN v7.0\nGPU model and memory:GTX 1080Ti, 11GB\nExact command to reproduce:Just run mobilenet_v1_eval.py to evaluate the trained model, you will find the bug. If is_training=True you can get the right result.[The is_trainging are in mobilenet_v1.mobilenet_v1_arg_scope(is_training=True) and mobilenet_v1.mobilenet_v1(inputs, is_training=True) ]. Or remove \"slim.batch_norm\" in \"with slim.arg_scope([slim.batch_norm, slim.dropout],\" can also get the right result. \"with slim.arg_scope([slim.batch_norm, slim.dropout],\"  is in L362 of https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py\n\nDescribe the problem\nTotally, I have two problems.\nFirstly,\nIn the mobilenet_v1_eval.py, yeah, it's eval not train. When is_training=False, you will not get a right result. When is_training=True, you can get a right answer. Obviously, it's wrong! I guess it's a big bug associate with batch norm, but I cannot figure it out. Someone knows that?\nAttentation, the is_training is not the one in  flower_input(is_training=False), they are in mobilenet_v1.mobilenet_v1_arg_scope(is_training=True) and mobilenet_v1.mobilenet_v1(inputs, is_training=True). And flower_input() was a custom code referencing imagenet_input() in https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py\ndef build_model():\n  \"\"\"Build the mobilenet_v1 model for evaluation.\n\n  Returns:\n    g: graph with rewrites after insertion of quantization ops and batch norm\n    folding.\n    eval_ops: eval ops for inference.\n    variables_to_restore: List of variables to restore from checkpoint.\n  \"\"\"\n  g = tf.Graph()\n  with g.as_default():\n    inputs, labels = flower_input(is_training=False)\n    scope = mobilenet_v1.mobilenet_v1_arg_scope(\n        is_training=True, weight_decay=0.0)\n    with slim.arg_scope(scope):\n      logits, _ = mobilenet_v1.mobilenet_v1(\n          inputs,\n          is_training=True,\n          depth_multiplier=FLAGS.depth_multiplier,\n          num_classes=FLAGS.num_classes)\n\n    if FLAGS.quantize:\n      tf.contrib.quantize.create_eval_graph()\n\n    eval_ops = metrics(logits, labels)\n\n  return g, eval_ops\nSecondly,\nI use export_eval_pbtxt() in the following to get the \"mobilenet_v1_eval.pbtxt\".\ndef export_eval_pbtxt():\n  \"\"\"Export eval.pbtxt.\"\"\"\n  g = tf.Graph()\n  with g.as_default():\n    inputs = tf.placeholder(dtype=tf.float32,shape=[None,224,224,3])\n    scope = mobilenet_v1.mobilenet_v1_arg_scope(\n        is_training=False, weight_decay=0.0)\n    with slim.arg_scope(scope):\n      logits, _ = mobilenet_v1.mobilenet_v1(\n          inputs,\n          is_training=False,\n          depth_multiplier=FLAGS.depth_multiplier,\n          num_classes=FLAGS.num_classes)\n    eval_graph_file = '/home/lg/projects/mobilenet_v1_eval.pbtxt'\n    with tf.Session() as sess:\n          with open(eval_graph_file, 'w') as f:\n            f.write(str(g.as_graph_def()))\n\nThen, frozen the graph:\nbazel-bin/tensorflow/python/tools/freeze_graph  \\\n  --input_graph=/home/lg/projects/mobilenet_v1_eval.pbtxt \\\n  --input_checkpoint=/home/lg/projects/checkpoint/model.ckpt-20000 \\\n  --input_binary=false \\\n  --output_graph=/home/lg/projects/frozen_mobilenet_v1_224.pb  \\\n  --output_node_names=MobilenetV1/Predictions/Reshape_1  \\\n  --checkpoint_version=2\nThen I use the frozen .pb file to classify an image, it won't get a right result, no matter you use is_training is True or False above to get the \"mobilenet_v1_eval.pbtxt\".\nAnd the classify file is:\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport argparse\nimport os.path\nimport re\nimport sys\nimport tarfile\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow as tf\nFLAGS = None\n\n\ndef create_graph():\n  \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n  # Creates graph from saved graph_def.pb.\n  with tf.gfile.FastGFile(os.path.join(FLAGS.model_dir, r'/home/lg/projects/frozen_mobilenet_v1_224.pb'), 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    _ = tf.import_graph_def(graph_def,return_elements=['MobilenetV1/Predictions/Reshape_1:0'], name='lg')\n\ndef run_inference_on_image(image):\n  \"\"\"Runs inference on an image.\n  Args:\n    image: Image file name.\n  Returns:\n    Nothing\n  \"\"\"\n  if not tf.gfile.Exists(image):\n    tf.logging.fatal('File does not exist %s', image)\n\n  image_data = tf.gfile.FastGFile(image, 'rb').read()\n  img_data_jpg = tf.image.decode_jpeg(image_data) #\u56fe\u50cf\u89e3\u7801  \n  img_data_jpg = tf.image.convert_image_dtype(img_data_jpg, dtype=tf.float32) #\u6539\u53d8\u56fe\u50cf\u6570\u636e\u7684\u7c7b\u578b\n  img_data_jpg = tf.image.resize_image_with_crop_or_pad(img_data_jpg,224,224)\n\n  # Creates graph from saved GraphDef.\n  create_graph()\n\n  with tf.Session() as sess:\n    image_data = img_data_jpg.eval().reshape(-1,224,224,3)\n    softmax_tensor = sess.graph.get_tensor_by_name('lg/MobilenetV1/Predictions/Reshape_1:0')\n    predictions = sess.run(softmax_tensor, {'lg/Placeholder:0': image_data})\n    predictions = np.squeeze(predictions)\n    print('predictions: ',predictions)\n    # Read the labels from label.txt.\n    label_path = os.path.join(FLAGS.model_dir, '/home/lg/projects/labels.txt')\n    label = np.loadtxt(fname=label_path,dtype=str)\n\n    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n    for node_id in top_k:\n      label_string = label[node_id]\n      score = predictions[node_id]\n      print('%s (score = %.5f)' % (label_string, score))\n\ndef main(_):\n  image = (FLAGS.image_file if FLAGS.image_file else os.path.join(FLAGS.model_dir, 'cropped_panda.jpg'))\n  run_inference_on_image(image)\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  # graph_def.pb: Binary representation of the GraphDef protocol buffer.\n  # label.txt: the labels according to data tfrecord\n  parser.add_argument(\n      '--model_dir',\n      type=str,\n      default='/tmp/imagenet',\n      help='Path to graph_def.pb and label.txt'\n  )\n  parser.add_argument(\n      '--image_file',\n      type=str,\n      default=r'/home/lg/projects/data/flower_photos/daisy/5673728_71b8cb57eb.jpg',\n      help='Absolute path to image file.'\n  )\n  parser.add_argument(\n      '--num_top_predictions',\n      type=int,\n      default=2,\n      help='Display this many predictions.'\n  )\n  FLAGS, unparsed = parser.parse_known_args()\ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\nThe mobilenet v1 I used is in https://github.com/tensorflow/models/tree/master/research/slim/nets .\nI have tried inception v3, whether to eval or classify an image that can get right results. So I think  mobilenet_v1_eval.py must have a bug.\nActually, I have tried two experiments, one is the custom codes(tf_train.py, tf_eval.py, tf_input.py, tf_inference.py, tf_classify_image.py referencing https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10) in https://github.com/GarryLau/draft_notes/tree/master/TF.\nAnother one is referencing mobilenet_v1_train.py, mobilenet_v1_eval.py, mobilenet_v1.py, in https://github.com/tensorflow/models/tree/master/research/slim/nets .\nIn the begining, I think the custom codes have some problems, so I tried the second experiment that tensorflow official. But they are all wrong.\nSource code / logs\nAll the codes I used are in:\nhttps://github.com/GarryLau/draft_notes/tree/master/TF\nhttps://github.com/GarryLau/draft_notes/tree/master/create_tfrecord", "body": "### System information\r\n- **Have I written custom code**:Yes\r\n- **OS Platform and Distribution**:Linux Ubuntu 16.04\r\n- **TensorFlow installed from**:binary(Anaconda)\r\n- **TensorFlow version**:1.7\r\n- **Python version**: Python 3.6.2\r\n- **Bazel version**:\r\nBuild label: 0.11.1\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue May 14 07:48:23 +50148 (1520362424903)\r\nBuild timestamp: 1520362424903\r\nBuild timestamp as int: 1520362424903\r\n- **CUDA/cuDNN version**:CUDA 9.0, cuDNN v7.0\r\n- **GPU model and memory**:GTX 1080Ti, 11GB\r\n- **Exact command to reproduce**:Just run mobilenet_v1_eval.py to evaluate the trained model, you will find the bug. If **is_training=True you can get the right result**.[The is_trainging are in mobilenet_v1.mobilenet_v1_arg_scope(is_training=True) and mobilenet_v1.mobilenet_v1(inputs, is_training=True) ]. **Or remove \"slim.batch_norm\" in \"with slim.arg_scope([slim.batch_norm, slim.dropout],\" can also get the right result.** \"with slim.arg_scope([slim.batch_norm, slim.dropout],\"  is in L362 of https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py\r\n\r\n### Describe the problem\r\nTotally, I have two problems.\r\n**Firstly**,\r\nIn the mobilenet_v1_eval.py, yeah, it's eval not train. When is_training=False, you will not get a right result. When is_training=True, you can get a right answer. Obviously, it's wrong! I guess it's a big bug associate with batch norm, but I cannot figure it out. Someone knows that? \r\nAttentation, the is_training is not the one in  flower_input(is_training=False), they are in mobilenet_v1.mobilenet_v1_arg_scope(is_training=True) and mobilenet_v1.mobilenet_v1(inputs, is_training=True). And **flower_input() was a custom code referencing imagenet_input()** in https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py\r\n```python\r\ndef build_model():\r\n  \"\"\"Build the mobilenet_v1 model for evaluation.\r\n\r\n  Returns:\r\n    g: graph with rewrites after insertion of quantization ops and batch norm\r\n    folding.\r\n    eval_ops: eval ops for inference.\r\n    variables_to_restore: List of variables to restore from checkpoint.\r\n  \"\"\"\r\n  g = tf.Graph()\r\n  with g.as_default():\r\n    inputs, labels = flower_input(is_training=False)\r\n    scope = mobilenet_v1.mobilenet_v1_arg_scope(\r\n        is_training=True, weight_decay=0.0)\r\n    with slim.arg_scope(scope):\r\n      logits, _ = mobilenet_v1.mobilenet_v1(\r\n          inputs,\r\n          is_training=True,\r\n          depth_multiplier=FLAGS.depth_multiplier,\r\n          num_classes=FLAGS.num_classes)\r\n\r\n    if FLAGS.quantize:\r\n      tf.contrib.quantize.create_eval_graph()\r\n\r\n    eval_ops = metrics(logits, labels)\r\n\r\n  return g, eval_ops\r\n``` \r\n**Secondly**,\r\nI use export_eval_pbtxt() in the following to get the \"mobilenet_v1_eval.pbtxt\".\r\n```python\r\ndef export_eval_pbtxt():\r\n  \"\"\"Export eval.pbtxt.\"\"\"\r\n  g = tf.Graph()\r\n  with g.as_default():\r\n    inputs = tf.placeholder(dtype=tf.float32,shape=[None,224,224,3])\r\n    scope = mobilenet_v1.mobilenet_v1_arg_scope(\r\n        is_training=False, weight_decay=0.0)\r\n    with slim.arg_scope(scope):\r\n      logits, _ = mobilenet_v1.mobilenet_v1(\r\n          inputs,\r\n          is_training=False,\r\n          depth_multiplier=FLAGS.depth_multiplier,\r\n          num_classes=FLAGS.num_classes)\r\n    eval_graph_file = '/home/lg/projects/mobilenet_v1_eval.pbtxt'\r\n    with tf.Session() as sess:\r\n          with open(eval_graph_file, 'w') as f:\r\n            f.write(str(g.as_graph_def()))\r\n\r\n```\r\nThen, frozen the graph:\r\n\r\n```python\r\nbazel-bin/tensorflow/python/tools/freeze_graph  \\\r\n  --input_graph=/home/lg/projects/mobilenet_v1_eval.pbtxt \\\r\n  --input_checkpoint=/home/lg/projects/checkpoint/model.ckpt-20000 \\\r\n  --input_binary=false \\\r\n  --output_graph=/home/lg/projects/frozen_mobilenet_v1_224.pb  \\\r\n  --output_node_names=MobilenetV1/Predictions/Reshape_1  \\\r\n  --checkpoint_version=2\r\n```\r\n\r\nThen I use the frozen .pb file to classify an image, it won't get a right result, no matter you use is_training is True or False above to get the \"mobilenet_v1_eval.pbtxt\".\r\nAnd the classify file is:\r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport os.path\r\nimport re\r\nimport sys\r\nimport tarfile\r\n\r\nimport numpy as np\r\nfrom six.moves import urllib\r\nimport tensorflow as tf\r\nFLAGS = None\r\n\r\n\r\ndef create_graph():\r\n  \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\r\n  # Creates graph from saved graph_def.pb.\r\n  with tf.gfile.FastGFile(os.path.join(FLAGS.model_dir, r'/home/lg/projects/frozen_mobilenet_v1_224.pb'), 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    _ = tf.import_graph_def(graph_def,return_elements=['MobilenetV1/Predictions/Reshape_1:0'], name='lg')\r\n\r\ndef run_inference_on_image(image):\r\n  \"\"\"Runs inference on an image.\r\n  Args:\r\n    image: Image file name.\r\n  Returns:\r\n    Nothing\r\n  \"\"\"\r\n  if not tf.gfile.Exists(image):\r\n    tf.logging.fatal('File does not exist %s', image)\r\n\r\n  image_data = tf.gfile.FastGFile(image, 'rb').read()\r\n  img_data_jpg = tf.image.decode_jpeg(image_data) #\u56fe\u50cf\u89e3\u7801  \r\n  img_data_jpg = tf.image.convert_image_dtype(img_data_jpg, dtype=tf.float32) #\u6539\u53d8\u56fe\u50cf\u6570\u636e\u7684\u7c7b\u578b\r\n  img_data_jpg = tf.image.resize_image_with_crop_or_pad(img_data_jpg,224,224)\r\n\r\n  # Creates graph from saved GraphDef.\r\n  create_graph()\r\n\r\n  with tf.Session() as sess:\r\n    image_data = img_data_jpg.eval().reshape(-1,224,224,3)\r\n    softmax_tensor = sess.graph.get_tensor_by_name('lg/MobilenetV1/Predictions/Reshape_1:0')\r\n    predictions = sess.run(softmax_tensor, {'lg/Placeholder:0': image_data})\r\n    predictions = np.squeeze(predictions)\r\n    print('predictions: ',predictions)\r\n    # Read the labels from label.txt.\r\n    label_path = os.path.join(FLAGS.model_dir, '/home/lg/projects/labels.txt')\r\n    label = np.loadtxt(fname=label_path,dtype=str)\r\n\r\n    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\r\n    for node_id in top_k:\r\n      label_string = label[node_id]\r\n      score = predictions[node_id]\r\n      print('%s (score = %.5f)' % (label_string, score))\r\n\r\ndef main(_):\r\n  image = (FLAGS.image_file if FLAGS.image_file else os.path.join(FLAGS.model_dir, 'cropped_panda.jpg'))\r\n  run_inference_on_image(image)\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  # graph_def.pb: Binary representation of the GraphDef protocol buffer.\r\n  # label.txt: the labels according to data tfrecord\r\n  parser.add_argument(\r\n      '--model_dir',\r\n      type=str,\r\n      default='/tmp/imagenet',\r\n      help='Path to graph_def.pb and label.txt'\r\n  )\r\n  parser.add_argument(\r\n      '--image_file',\r\n      type=str,\r\n      default=r'/home/lg/projects/data/flower_photos/daisy/5673728_71b8cb57eb.jpg',\r\n      help='Absolute path to image file.'\r\n  )\r\n  parser.add_argument(\r\n      '--num_top_predictions',\r\n      type=int,\r\n      default=2,\r\n      help='Display this many predictions.'\r\n  )\r\n  FLAGS, unparsed = parser.parse_known_args()\r\ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n```\r\n\r\nThe mobilenet v1 I used is in https://github.com/tensorflow/models/tree/master/research/slim/nets .\r\nI have tried inception v3, whether to eval or classify an image that can get right results. So I think  mobilenet_v1_eval.py must have a bug. \r\n\r\nActually, I have tried two experiments, one is the custom codes(tf_train.py, tf_eval.py, tf_input.py, tf_inference.py, tf_classify_image.py referencing https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10) in https://github.com/GarryLau/draft_notes/tree/master/TF.\r\nAnother one is referencing mobilenet_v1_train.py, mobilenet_v1_eval.py, mobilenet_v1.py, in https://github.com/tensorflow/models/tree/master/research/slim/nets .\r\nIn the begining, I think the custom codes have some problems, so I tried the second experiment that tensorflow official. But they are all wrong.\r\n\r\n### Source code / logs\r\nAll the codes I used are in:\r\nhttps://github.com/GarryLau/draft_notes/tree/master/TF\r\nhttps://github.com/GarryLau/draft_notes/tree/master/create_tfrecord\r\n"}