{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/241498789", "html_url": "https://github.com/tensorflow/tensorflow/issues/3886#issuecomment-241498789", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3886", "id": 241498789, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MTQ5ODc4OQ==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-22T18:07:03Z", "updated_at": "2016-08-22T18:07:03Z", "author_association": "MEMBER", "body_html": "<p>I believe this code is actually non-deterministic.  (at least I see <strong>both</strong> values if I run repeatedly)</p>\n<p>If you look at the GraphDef using this code:</p>\n<pre><code>tf.train.write_graph(sess.graph.as_graph_def(),  '.',  'issue3886.pbtxt')\n</code></pre>\n<p>The Variable read of x is cached using an Identity op called <code>Variable/read</code>.  There is no control dependency between the cached read and the assign.  There <strong>is</strong> a control dependency on the Const input to the Add op. (<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2342391\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yuanbyu\">@yuanbyu</a> is the expert on why this is the case)</p>\n<p>Here is the full GraphDef for reference:</p>\n<pre><code>node {\n  name: \"Variable/initial_value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Variable\"\n  op: \"Variable\"\n  attr {\n    key: \"container\"\n    value {\n      s: \"\"\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"shape\"\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: \"shared_name\"\n    value {\n      s: \"\"\n    }\n  }\n}\nnode {\n  name: \"Variable/Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Variable/initial_value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: \"Variable/read\"\n  op: \"Identity\"\n  input: \"Variable\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign/value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Assign/value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: \"add/y\"\n  op: \"Const\"\n  input: \"^Assign\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: \"add\"\n  op: \"Add\"\n  input: \"Variable/read\"\n  input: \"add/y\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nversions {\n  producer: 9\n}\n</code></pre>", "body_text": "I believe this code is actually non-deterministic.  (at least I see both values if I run repeatedly)\nIf you look at the GraphDef using this code:\ntf.train.write_graph(sess.graph.as_graph_def(),  '.',  'issue3886.pbtxt')\n\nThe Variable read of x is cached using an Identity op called Variable/read.  There is no control dependency between the cached read and the assign.  There is a control dependency on the Const input to the Add op. (@yuanbyu is the expert on why this is the case)\nHere is the full GraphDef for reference:\nnode {\n  name: \"Variable/initial_value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Variable\"\n  op: \"Variable\"\n  attr {\n    key: \"container\"\n    value {\n      s: \"\"\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"shape\"\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: \"shared_name\"\n    value {\n      s: \"\"\n    }\n  }\n}\nnode {\n  name: \"Variable/Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Variable/initial_value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: \"Variable/read\"\n  op: \"Identity\"\n  input: \"Variable\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign/value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Assign/value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: \"add/y\"\n  op: \"Const\"\n  input: \"^Assign\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: \"add\"\n  op: \"Add\"\n  input: \"Variable/read\"\n  input: \"add/y\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nversions {\n  producer: 9\n}", "body": "I believe this code is actually non-deterministic.  (at least I see **both** values if I run repeatedly)\n\nIf you look at the GraphDef using this code:\n\n```\ntf.train.write_graph(sess.graph.as_graph_def(),  '.',  'issue3886.pbtxt')\n```\n\nThe Variable read of x is cached using an Identity op called `Variable/read`.  There is no control dependency between the cached read and the assign.  There **is** a control dependency on the Const input to the Add op. (@yuanbyu is the expert on why this is the case)\n\nHere is the full GraphDef for reference:\n\n```\nnode {\n  name: \"Variable/initial_value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Variable\"\n  op: \"Variable\"\n  attr {\n    key: \"container\"\n    value {\n      s: \"\"\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"shape\"\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: \"shared_name\"\n    value {\n      s: \"\"\n    }\n  }\n}\nnode {\n  name: \"Variable/Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Variable/initial_value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: \"Variable/read\"\n  op: \"Identity\"\n  input: \"Variable\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign/value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Assign/value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: \"add/y\"\n  op: \"Const\"\n  input: \"^Assign\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: \"add\"\n  op: \"Add\"\n  input: \"Variable/read\"\n  input: \"add/y\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nversions {\n  producer: 9\n}\n```\n"}