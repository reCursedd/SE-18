{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21303", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21303/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21303/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21303/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21303", "id": 346544011, "node_id": "MDU6SXNzdWUzNDY1NDQwMTE=", "number": 21303, "title": "Memory Issue with my Tensorflow Code", "user": {"login": "sunjeet95", "id": 27850143, "node_id": "MDQ6VXNlcjI3ODUwMTQz", "avatar_url": "https://avatars1.githubusercontent.com/u/27850143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sunjeet95", "html_url": "https://github.com/sunjeet95", "followers_url": "https://api.github.com/users/sunjeet95/followers", "following_url": "https://api.github.com/users/sunjeet95/following{/other_user}", "gists_url": "https://api.github.com/users/sunjeet95/gists{/gist_id}", "starred_url": "https://api.github.com/users/sunjeet95/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sunjeet95/subscriptions", "organizations_url": "https://api.github.com/users/sunjeet95/orgs", "repos_url": "https://api.github.com/users/sunjeet95/repos", "events_url": "https://api.github.com/users/sunjeet95/events{/privacy}", "received_events_url": "https://api.github.com/users/sunjeet95/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, {"login": "cy89", "id": 29663194, "node_id": "MDQ6VXNlcjI5NjYzMTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/29663194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cy89", "html_url": "https://github.com/cy89", "followers_url": "https://api.github.com/users/cy89/followers", "following_url": "https://api.github.com/users/cy89/following{/other_user}", "gists_url": "https://api.github.com/users/cy89/gists{/gist_id}", "starred_url": "https://api.github.com/users/cy89/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cy89/subscriptions", "organizations_url": "https://api.github.com/users/cy89/orgs", "repos_url": "https://api.github.com/users/cy89/repos", "events_url": "https://api.github.com/users/cy89/events{/privacy}", "received_events_url": "https://api.github.com/users/cy89/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-08-01T10:37:05Z", "updated_at": "2018-09-10T08:17:18Z", "closed_at": "2018-09-10T08:17:18Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<p><strong>Have I written custom code: Yes<br>\nOS Platform and Distribution: Linux Ubuntu 16.04<br>\nTensorFlow installed from binary<br>\nBazel version: N/A<br>\nPython version 2.7<br>\nTensorFlow version 1.9.0<br>\nCUDA/cuDNN version CUDA 9.0<br>\nGPU model and memory:  Nvidia 860M and memory 4 GB<br>\nExact command to reproduce: N/A<br>\nMobile device:N/A</strong></p>\n<p><strong>The problem:</strong><br>\nI wrote a tensorflow code DDQN network to run with gpu and I am getting an Odd Memory problem. My processes list from system monitor shows that my memory utilized by the python code remains almost constant and increases very slowly as there is a increase in replay buffer size(Its list which stores samples). But in resources it shows that my memory is increasing steeply and is not analogous with the python program. For example when I start the code the memory utilized by the system is around 3.8 GB with python code taking around 1.5 GB of memory but after sometime like an hour or so the memory utilized by the system increases to 9-10 GB with the python code utilizing around 1.8GB.</p>\n<h3>Source code</h3>\n<pre><code>import tensorflow as tf\nimport numpy as np \t\nfrom PIL import Image\nimport time\nimport os, os.path\nimport cPickle as pickle\nfrom colorama import Fore, Back, Style\nfrom collections import deque,OrderedDict\nfrom blist import *\nimport gc\n#import pylab as pl\nimport sys\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance\n\n\nTraining_Dataset_1=\"Imagenet_Sequencing_filtered.pickle\"\n#Training_Dataset_2=\"OTB_Dataset.pickle\"\nTraining_Dataset_2=\"Dataset_VOT.pickle\"\n\nTest_Dataset=\"OTB_Dataset.pickle\"\nResults_file=\"Test_Results.pickle\"\n#Replay_Memory_file=\"Replay_Memory.pickle\"\n\nimport Layers\nimport RNN_State_update\nimport One_Shot_Representation\nimport Image_Cropping_Resizing\nimport Getting_Pretrained_caffenet_Parameters\nimport Grid_Generation\nimport Others_Func\n\n\nweights=Getting_Pretrained_caffenet_Parameters.param()\n\nNumber_RNN_Cell_Units=512\nNumber_of_Actions=11\n\nMini_batch=32\t\t\t\t\t\t\t\t\t#Batch Size over which gradient would be evaluated\nMax_episodes=200\t\t\t\t\t\t\t\t\t\t\t\nK_iterations=20 \t\t\t\t\t\t\t\t#Number of Times to Sample and Perform gradient update before collecting new dataset\nDiscount_Factor=0.99\nNumber_of_Epochs=1\nNumber_of_Training_Videos_1=1000\nNumber_of_Training_Videos_2=70\nNumber_of_Testing_videos=94\nBatch_Size=1\nReplayMemory=200000\nWeight_Update_Step_Size=10000\t\t\t\t\t\t#Updatation of weights from Evaluation Network to target network\n\nsess=tf.Session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True))\n\nclass CNN_RNN_Layers():\n\n# This class combines all the CNNs\n\n\tdef __init__(self, input,Batch_Size):\n\n\t\tself.input=input \t\t\t\t#T-1 and T Images with cropped using he Groundtruth Function\n\n\t\tself.input_1=input[0:Batch_Size]\n\t\tself.input_2=input[Batch_Size: 2*Batch_Size]\n\n\t\tself.Batch_Size=Batch_Size\n\n\n\t\twith tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_1=weights[0]\n\t\t\tself.bias_1=weights[1]\n\n\t\t\tself.conv1_input_1= Layers.Convolayer(self.input_1, self.weights_1, self.bias_1, group=1, stride=(4,4) , pad_type='VALID' , name='Convolution_Layer_1_input_1')\n\t\t\tself.conv1_max_pooled_input_1=tf.nn.max_pool(value=self.conv1_input_1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Conv_1_Maxpool_input_1')\n\t\t\tself.conv1_normalized_input_1=tf.nn.local_response_normalization(self.conv1_max_pooled_input_1,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_1_Normalization_input_1')\n\n\t\twith tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.conv1_input_2= Layers.Convolayer(self.input_2, self.weights_1, self.bias_1, group=1, stride=(4,4) , pad_type='VALID' , name='Convolution_Layer_1_input_2')\n\t\t\tself.conv1_max_pooled_input_2=tf.nn.max_pool(value=self.conv1_input_2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Conv_1_Maxpool_input_2')\n\t\t\tself.conv1_normalized_input_2=tf.nn.local_response_normalization(self.conv1_max_pooled_input_2,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_1_Normalization_input_2')\n\t\t\t\n\t\twith tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_2=weights[2]\n\t\t\tself.bias_2=weights[3]\n\n\t\t\tself.conv2_input_1= Layers.Convolayer(self.conv1_normalized_input_1, self.weights_2, self.bias_2, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_2_input_1')\n\t\t\tself.conv2_max_pooled_input_1=tf.nn.max_pool(self.conv2_input_1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_2_Maxpool_input_1')\n\t\t\tself.conv2_normalized_input_1=tf.nn.local_response_normalization(self.conv2_max_pooled_input_1,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_2_Normalization_input_1')\n\n\t\twith tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.conv2_input_2= Layers.Convolayer(self.conv1_normalized_input_2, self.weights_2, self.bias_2, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_2_input_2')\n\t\t\tself.conv2_max_pooled_input_2=tf.nn.max_pool(self.conv2_input_2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_2_Maxpool_input_2')\n\t\t\tself.conv2_normalized_input_2=tf.nn.local_response_normalization(self.conv2_max_pooled_input_2,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_2_Normalization_input_2')\n\n\t\t\t\n\t\twith tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_3=weights[4]\n\t\t\tself.bias_3=weights[5]\n\n\t\t\tself.conv3_input_1= Layers.Convolayer(self.conv2_normalized_input_1, self.weights_3, self.bias_3, group=1, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_3_input_1')\n\n\t\twith tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):\t\n\t\t\t\n\t\t\tself.conv3_input_2= Layers.Convolayer(self.conv2_normalized_input_2, self.weights_3, self.bias_3, group=1, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_3_input_2')\n\t\t\n\t\twith tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_4=weights[6]\n\t\t\tself.bias_4=weights[7]\n\n\t\t\tself.conv4_input_1= Layers.Convolayer(self.conv3_input_1, self.weights_4, self.bias_4, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_4_input_1')\n\t\twith tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE):\n\t\t\t\n\t\t\tself.conv4_input_2= Layers.Convolayer(self.conv3_input_2, self.weights_4, self.bias_4, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_4_input_1')\n\t\t\t\n\t\twith tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_5=weights[8]\n\t\t\tself.bias_5=weights[9]\n\n\t\t\tself.conv5_input_1= Layers.Convolayer(self.conv4_input_1, self.weights_5, self.bias_5, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_5_input_1')\n\t\t\tself.conv5_max_pooled_input_1=tf.nn.max_pool(self.conv5_input_1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_5_Maxpool_input_1')\n\n\t\twith tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE):\t\n\n\t\t\tself.conv5_input_2= Layers.Convolayer(self.conv4_input_2, self.weights_5, self.bias_5, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_5_input_2')\n\t\t\tself.conv5_max_pooled_input_2=tf.nn.max_pool(self.conv5_input_2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_5_Maxpool_input_2')\t\t\n\t\t\t\n\t\t#Starting the Fully Connected Layers After the CNN. Here We use the inbuilt densely connected layer.\n\t\tself.input_fully_connected_input_1=tf.layers.flatten(self.conv5_max_pooled_input_1, name='Flatten_input_1')\n\t\tself.input_fully_connected_input_2=tf.layers.flatten(self.conv5_max_pooled_input_2, name='Flatten_input_2')\n\n\t\tself.concatenated_output=tf.concat([tf.reshape(self.input_fully_connected_input_1, shape=[Batch_Size, -1]), \n\t\t\t\t\t\t\t\t\t\t\ttf.reshape(self.input_fully_connected_input_2, shape=[Batch_Size, -1])], axis=-1)\n\nclass fully_connected():\n\n\t\tdef __init__(self, input, scope_name,Batch_Size):\n\n\t\t\tself.input=input \n\n\t\t\twith tf.variable_scope(scope_name) as scope:\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\twith tf.variable_scope('First_Fully_Connected', reuse=tf.AUTO_REUSE):\n\n\t\t\t\t\tself.fully_connected_1_output=tf.layers.dense(inputs = self.input, units=4096, activation=tf.nn.relu, name=\"Dense_Layer_2\")\n\n\t\t\t\twith tf.variable_scope('Second_Fully_Connected', reuse=tf.AUTO_REUSE):\n\n\t\t\t\t\tself.fully_connected_2_output=tf.layers.dense(inputs = self.fully_connected_1_output, units=2048, activation=tf.nn.relu, name=\"Dense_Layer_3\")\n\n\t\t\t\twith tf.variable_scope('Output_Layer', reuse=tf.AUTO_REUSE):\n\t\t\t\n\t\t\t\t\tself.dense_output= Layers.Dense_Layer(self.fully_connected_2_output, Number_of_Actions, name='Action_Output_Layer')\n\t\t\t\t\tself.Action_Output=tf.argmax(self.dense_output, axis=-1, name='Output_Action_as_Given_by_Deep_Networks')\n\n\t\t\t\t\tself.max_Q_Values=tf.reduce_max(self.dense_output, axis=-1)\n\n\t\t\t\t\tself.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=scope.name)\n\t\t\t\t\tself.trainable_vars_by_name = {var.name[len(scope.name):]: var for var in self.trainable_vars}\n\n\n\t\tdef Q_Values_of_Given_State_Action(self, actions_, y_targets):\n\n\t\t\tself.dense_output=self.dense_output\n\n\t\t\tactions_=tf.reshape(tf.cast(actions_, tf.int32), shape=(Mini_batch,1))\n\t\t\tz=tf.reshape(tf.range(tf.shape(self.dense_output)[0]), shape=(Mini_batch,1) )\n\n\t\t\tindex_=tf.concat((z,actions_), axis=-1)\n\n\t\t\tself.Q_Values_Select_Actions=tf.gather_nd(self.dense_output, index_)\n\n\t\t\t#loss_=tf.divide((tf.reduce_sum (tf.square(Q_Values_Select_Actions-y_targets))), 2)\n\t\t\t#loss_= y_targets-Q_Values_Select_Actions\t\t#Getting the difference between the target network and evaluation network\n\t\t\tloss_=tf.reduce_mean(tf.square(self.Q_Values_Select_Actions-y_targets))\n\n\t\t\treturn loss_\n\n\n\n\ndef Target_Values(r_t,s_t_plus_1,termination_criteria):\n\n\t#For DDQN\n\n\ts_t_plus_1=np.reshape(s_t_plus_1, newshape=(32,18432))\n\n\tOutput_Q_Values_Eval=sess.run((Eval_Network_Q_Values), feed_dict={x_Eval_Net:s_t_plus_1})\t#Getting the Q-Values from evaluation network\n\taction_=np.argmax(Output_Q_Values_Eval,axis=1)\t#Getting the actions array\n\tOutput_Q_Values_target=sess.run((Q_Values_Target), feed_dict={x_Target_Values:s_t_plus_1})\t#Getting the Q-Values from target network\n\n\tQ_values_selected=[]\n\tfor temp ,a in zip(range(32), action_):\n\n\t\tQ_values_selected.append(Output_Q_Values_target[temp][a])\n\ty_target_values=Others_Func.Y_Target(Q_values_selected, r_t,Discount_Factor)\n\n\tfor i in range(32):\n\t\tif(termination_criteria[i]==True):\n\t\t\ty_target_values[i]=r_t[i]\n\n\treturn y_target_values\n\n\ndef Evaluation_Network(s_t, a_t, y_Targets ):\n\n\twith tf.variable_scope('Eval_Network') as scope:\n\n\t\ts_t=np.reshape(s_t, newshape=(32, 18432))\n\n\t\ttotal_loss,_=sess.run((loss,train), feed_dict={x_Eval_Net:s_t, a_t_eval:a_t,y_Targets_eval:y_Targets})\t#Train the network and get the loss\n\n\t\treturn total_loss #Return the loss\n\n\ndef DQN(samples_):\n\t\n\ts_t,a_t,r_t,s_t_plus_1, termination_criteria=Others_Func.samples_seperation_generation(samples_)\n\n\tTargets=Target_Values(r_t,s_t_plus_1,termination_criteria)\n\tEval=Evaluation_Network(s_t,a_t, Targets)\t\t# Train the evaluation network and get the loss\n\n\tdel(s_t, a_t,r_t,s_t_plus_1)\n\tgc.collect()\t\n\treturn Eval \t#Return the loss\n\nwith tf.device('/device:GPU:0'):\n\n\tx_sampling=tf.placeholder(dtype=tf.float32,shape=(Batch_Size*2,227,227,3), name=\"x_sampling\") \t#Images resized to 224x224x3\n\n\tCNN_RNN_Layer_Sampling=CNN_RNN_Layers(x_sampling,Batch_Size)\t\t#Creating the Object for CNN-RNN Layers\n\tstate_eval_sampling=CNN_RNN_Layer_Sampling.concatenated_output\n\t\n\t##########################################\n\tx_Target_Values=tf.placeholder(dtype=tf.float32,shape=(None, 18432), name=\"x_Target_Values\") \t#Images resized to 224x224x3\n\tfully_connected_Target=fully_connected(x_Target_Values,'Target_Network',Mini_batch)\t#Creating the Object for CNN-RNN Layers\n\tQ_Values_Target=fully_connected_Target.dense_output\n\ttarget_max_Q_Value=fully_connected_Target.max_Q_Values\n\ttarget_vars = fully_connected_Target.trainable_vars_by_name\n\n\t################################################################\n\tx_Eval_Net=tf.placeholder(dtype=tf.float32,shape=(None,18432), name=\"x_Eval_Net\") \t#Images resized to 224x224x3\n\ta_t_eval=tf.placeholder(dtype=tf.int32,shape=(Mini_batch), name=\"a_t_eval\")\n\ty_Targets_eval=tf.placeholder(dtype=tf.float32,shape=(Mini_batch), name=\"y_Targets_eval\")\n\t\n\tfully_connected_Eval=fully_connected(x_Eval_Net,  'Eval_Network',Mini_batch)\t\t#Creating the Object for CNN-RNN Layers\n\tEval_Network_Q_Values=fully_connected_Eval.dense_output \t\t\t\t\t\t\t\t\t#Getting the Q-Values os the current state using the evaluation network\n\tEval_Network_max_Q_Value=fully_connected_Eval.max_Q_Values\n\teval_vars = fully_connected_Eval.trainable_vars_by_name\n\t\n\tloss=fully_connected_Eval.Q_Values_of_Given_State_Action(a_t_eval,y_Targets_eval)\n\toptimizer = tf.train.AdamOptimizer(learning_rate=0.0001,beta1=0.9)\n\ttrain = optimizer.minimize(loss, var_list=tf.trainable_variables(scope='Eval_Network'))\n\n\t#######################\n\n\tcopy_ops =[target_var.assign(eval_vars[var_name]) for var_name, target_var in target_vars.items()]\n\tcopy_online_to_target = tf.group(*copy_ops)\n\n\t######################\n\tinit_op = tf.global_variables_initializer()\n\tsess.run(init_op)\n</code></pre>", "body_text": "System information\nHave I written custom code: Yes\nOS Platform and Distribution: Linux Ubuntu 16.04\nTensorFlow installed from binary\nBazel version: N/A\nPython version 2.7\nTensorFlow version 1.9.0\nCUDA/cuDNN version CUDA 9.0\nGPU model and memory:  Nvidia 860M and memory 4 GB\nExact command to reproduce: N/A\nMobile device:N/A\nThe problem:\nI wrote a tensorflow code DDQN network to run with gpu and I am getting an Odd Memory problem. My processes list from system monitor shows that my memory utilized by the python code remains almost constant and increases very slowly as there is a increase in replay buffer size(Its list which stores samples). But in resources it shows that my memory is increasing steeply and is not analogous with the python program. For example when I start the code the memory utilized by the system is around 3.8 GB with python code taking around 1.5 GB of memory but after sometime like an hour or so the memory utilized by the system increases to 9-10 GB with the python code utilizing around 1.8GB.\nSource code\nimport tensorflow as tf\nimport numpy as np \t\nfrom PIL import Image\nimport time\nimport os, os.path\nimport cPickle as pickle\nfrom colorama import Fore, Back, Style\nfrom collections import deque,OrderedDict\nfrom blist import *\nimport gc\n#import pylab as pl\nimport sys\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance\n\n\nTraining_Dataset_1=\"Imagenet_Sequencing_filtered.pickle\"\n#Training_Dataset_2=\"OTB_Dataset.pickle\"\nTraining_Dataset_2=\"Dataset_VOT.pickle\"\n\nTest_Dataset=\"OTB_Dataset.pickle\"\nResults_file=\"Test_Results.pickle\"\n#Replay_Memory_file=\"Replay_Memory.pickle\"\n\nimport Layers\nimport RNN_State_update\nimport One_Shot_Representation\nimport Image_Cropping_Resizing\nimport Getting_Pretrained_caffenet_Parameters\nimport Grid_Generation\nimport Others_Func\n\n\nweights=Getting_Pretrained_caffenet_Parameters.param()\n\nNumber_RNN_Cell_Units=512\nNumber_of_Actions=11\n\nMini_batch=32\t\t\t\t\t\t\t\t\t#Batch Size over which gradient would be evaluated\nMax_episodes=200\t\t\t\t\t\t\t\t\t\t\t\nK_iterations=20 \t\t\t\t\t\t\t\t#Number of Times to Sample and Perform gradient update before collecting new dataset\nDiscount_Factor=0.99\nNumber_of_Epochs=1\nNumber_of_Training_Videos_1=1000\nNumber_of_Training_Videos_2=70\nNumber_of_Testing_videos=94\nBatch_Size=1\nReplayMemory=200000\nWeight_Update_Step_Size=10000\t\t\t\t\t\t#Updatation of weights from Evaluation Network to target network\n\nsess=tf.Session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True))\n\nclass CNN_RNN_Layers():\n\n# This class combines all the CNNs\n\n\tdef __init__(self, input,Batch_Size):\n\n\t\tself.input=input \t\t\t\t#T-1 and T Images with cropped using he Groundtruth Function\n\n\t\tself.input_1=input[0:Batch_Size]\n\t\tself.input_2=input[Batch_Size: 2*Batch_Size]\n\n\t\tself.Batch_Size=Batch_Size\n\n\n\t\twith tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_1=weights[0]\n\t\t\tself.bias_1=weights[1]\n\n\t\t\tself.conv1_input_1= Layers.Convolayer(self.input_1, self.weights_1, self.bias_1, group=1, stride=(4,4) , pad_type='VALID' , name='Convolution_Layer_1_input_1')\n\t\t\tself.conv1_max_pooled_input_1=tf.nn.max_pool(value=self.conv1_input_1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Conv_1_Maxpool_input_1')\n\t\t\tself.conv1_normalized_input_1=tf.nn.local_response_normalization(self.conv1_max_pooled_input_1,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_1_Normalization_input_1')\n\n\t\twith tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.conv1_input_2= Layers.Convolayer(self.input_2, self.weights_1, self.bias_1, group=1, stride=(4,4) , pad_type='VALID' , name='Convolution_Layer_1_input_2')\n\t\t\tself.conv1_max_pooled_input_2=tf.nn.max_pool(value=self.conv1_input_2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Conv_1_Maxpool_input_2')\n\t\t\tself.conv1_normalized_input_2=tf.nn.local_response_normalization(self.conv1_max_pooled_input_2,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_1_Normalization_input_2')\n\t\t\t\n\t\twith tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_2=weights[2]\n\t\t\tself.bias_2=weights[3]\n\n\t\t\tself.conv2_input_1= Layers.Convolayer(self.conv1_normalized_input_1, self.weights_2, self.bias_2, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_2_input_1')\n\t\t\tself.conv2_max_pooled_input_1=tf.nn.max_pool(self.conv2_input_1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_2_Maxpool_input_1')\n\t\t\tself.conv2_normalized_input_1=tf.nn.local_response_normalization(self.conv2_max_pooled_input_1,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_2_Normalization_input_1')\n\n\t\twith tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.conv2_input_2= Layers.Convolayer(self.conv1_normalized_input_2, self.weights_2, self.bias_2, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_2_input_2')\n\t\t\tself.conv2_max_pooled_input_2=tf.nn.max_pool(self.conv2_input_2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_2_Maxpool_input_2')\n\t\t\tself.conv2_normalized_input_2=tf.nn.local_response_normalization(self.conv2_max_pooled_input_2,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_2_Normalization_input_2')\n\n\t\t\t\n\t\twith tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_3=weights[4]\n\t\t\tself.bias_3=weights[5]\n\n\t\t\tself.conv3_input_1= Layers.Convolayer(self.conv2_normalized_input_1, self.weights_3, self.bias_3, group=1, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_3_input_1')\n\n\t\twith tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):\t\n\t\t\t\n\t\t\tself.conv3_input_2= Layers.Convolayer(self.conv2_normalized_input_2, self.weights_3, self.bias_3, group=1, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_3_input_2')\n\t\t\n\t\twith tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_4=weights[6]\n\t\t\tself.bias_4=weights[7]\n\n\t\t\tself.conv4_input_1= Layers.Convolayer(self.conv3_input_1, self.weights_4, self.bias_4, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_4_input_1')\n\t\twith tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE):\n\t\t\t\n\t\t\tself.conv4_input_2= Layers.Convolayer(self.conv3_input_2, self.weights_4, self.bias_4, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_4_input_1')\n\t\t\t\n\t\twith tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE):\n\n\t\t\tself.weights_5=weights[8]\n\t\t\tself.bias_5=weights[9]\n\n\t\t\tself.conv5_input_1= Layers.Convolayer(self.conv4_input_1, self.weights_5, self.bias_5, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_5_input_1')\n\t\t\tself.conv5_max_pooled_input_1=tf.nn.max_pool(self.conv5_input_1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_5_Maxpool_input_1')\n\n\t\twith tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE):\t\n\n\t\t\tself.conv5_input_2= Layers.Convolayer(self.conv4_input_2, self.weights_5, self.bias_5, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_5_input_2')\n\t\t\tself.conv5_max_pooled_input_2=tf.nn.max_pool(self.conv5_input_2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_5_Maxpool_input_2')\t\t\n\t\t\t\n\t\t#Starting the Fully Connected Layers After the CNN. Here We use the inbuilt densely connected layer.\n\t\tself.input_fully_connected_input_1=tf.layers.flatten(self.conv5_max_pooled_input_1, name='Flatten_input_1')\n\t\tself.input_fully_connected_input_2=tf.layers.flatten(self.conv5_max_pooled_input_2, name='Flatten_input_2')\n\n\t\tself.concatenated_output=tf.concat([tf.reshape(self.input_fully_connected_input_1, shape=[Batch_Size, -1]), \n\t\t\t\t\t\t\t\t\t\t\ttf.reshape(self.input_fully_connected_input_2, shape=[Batch_Size, -1])], axis=-1)\n\nclass fully_connected():\n\n\t\tdef __init__(self, input, scope_name,Batch_Size):\n\n\t\t\tself.input=input \n\n\t\t\twith tf.variable_scope(scope_name) as scope:\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\twith tf.variable_scope('First_Fully_Connected', reuse=tf.AUTO_REUSE):\n\n\t\t\t\t\tself.fully_connected_1_output=tf.layers.dense(inputs = self.input, units=4096, activation=tf.nn.relu, name=\"Dense_Layer_2\")\n\n\t\t\t\twith tf.variable_scope('Second_Fully_Connected', reuse=tf.AUTO_REUSE):\n\n\t\t\t\t\tself.fully_connected_2_output=tf.layers.dense(inputs = self.fully_connected_1_output, units=2048, activation=tf.nn.relu, name=\"Dense_Layer_3\")\n\n\t\t\t\twith tf.variable_scope('Output_Layer', reuse=tf.AUTO_REUSE):\n\t\t\t\n\t\t\t\t\tself.dense_output= Layers.Dense_Layer(self.fully_connected_2_output, Number_of_Actions, name='Action_Output_Layer')\n\t\t\t\t\tself.Action_Output=tf.argmax(self.dense_output, axis=-1, name='Output_Action_as_Given_by_Deep_Networks')\n\n\t\t\t\t\tself.max_Q_Values=tf.reduce_max(self.dense_output, axis=-1)\n\n\t\t\t\t\tself.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=scope.name)\n\t\t\t\t\tself.trainable_vars_by_name = {var.name[len(scope.name):]: var for var in self.trainable_vars}\n\n\n\t\tdef Q_Values_of_Given_State_Action(self, actions_, y_targets):\n\n\t\t\tself.dense_output=self.dense_output\n\n\t\t\tactions_=tf.reshape(tf.cast(actions_, tf.int32), shape=(Mini_batch,1))\n\t\t\tz=tf.reshape(tf.range(tf.shape(self.dense_output)[0]), shape=(Mini_batch,1) )\n\n\t\t\tindex_=tf.concat((z,actions_), axis=-1)\n\n\t\t\tself.Q_Values_Select_Actions=tf.gather_nd(self.dense_output, index_)\n\n\t\t\t#loss_=tf.divide((tf.reduce_sum (tf.square(Q_Values_Select_Actions-y_targets))), 2)\n\t\t\t#loss_= y_targets-Q_Values_Select_Actions\t\t#Getting the difference between the target network and evaluation network\n\t\t\tloss_=tf.reduce_mean(tf.square(self.Q_Values_Select_Actions-y_targets))\n\n\t\t\treturn loss_\n\n\n\n\ndef Target_Values(r_t,s_t_plus_1,termination_criteria):\n\n\t#For DDQN\n\n\ts_t_plus_1=np.reshape(s_t_plus_1, newshape=(32,18432))\n\n\tOutput_Q_Values_Eval=sess.run((Eval_Network_Q_Values), feed_dict={x_Eval_Net:s_t_plus_1})\t#Getting the Q-Values from evaluation network\n\taction_=np.argmax(Output_Q_Values_Eval,axis=1)\t#Getting the actions array\n\tOutput_Q_Values_target=sess.run((Q_Values_Target), feed_dict={x_Target_Values:s_t_plus_1})\t#Getting the Q-Values from target network\n\n\tQ_values_selected=[]\n\tfor temp ,a in zip(range(32), action_):\n\n\t\tQ_values_selected.append(Output_Q_Values_target[temp][a])\n\ty_target_values=Others_Func.Y_Target(Q_values_selected, r_t,Discount_Factor)\n\n\tfor i in range(32):\n\t\tif(termination_criteria[i]==True):\n\t\t\ty_target_values[i]=r_t[i]\n\n\treturn y_target_values\n\n\ndef Evaluation_Network(s_t, a_t, y_Targets ):\n\n\twith tf.variable_scope('Eval_Network') as scope:\n\n\t\ts_t=np.reshape(s_t, newshape=(32, 18432))\n\n\t\ttotal_loss,_=sess.run((loss,train), feed_dict={x_Eval_Net:s_t, a_t_eval:a_t,y_Targets_eval:y_Targets})\t#Train the network and get the loss\n\n\t\treturn total_loss #Return the loss\n\n\ndef DQN(samples_):\n\t\n\ts_t,a_t,r_t,s_t_plus_1, termination_criteria=Others_Func.samples_seperation_generation(samples_)\n\n\tTargets=Target_Values(r_t,s_t_plus_1,termination_criteria)\n\tEval=Evaluation_Network(s_t,a_t, Targets)\t\t# Train the evaluation network and get the loss\n\n\tdel(s_t, a_t,r_t,s_t_plus_1)\n\tgc.collect()\t\n\treturn Eval \t#Return the loss\n\nwith tf.device('/device:GPU:0'):\n\n\tx_sampling=tf.placeholder(dtype=tf.float32,shape=(Batch_Size*2,227,227,3), name=\"x_sampling\") \t#Images resized to 224x224x3\n\n\tCNN_RNN_Layer_Sampling=CNN_RNN_Layers(x_sampling,Batch_Size)\t\t#Creating the Object for CNN-RNN Layers\n\tstate_eval_sampling=CNN_RNN_Layer_Sampling.concatenated_output\n\t\n\t##########################################\n\tx_Target_Values=tf.placeholder(dtype=tf.float32,shape=(None, 18432), name=\"x_Target_Values\") \t#Images resized to 224x224x3\n\tfully_connected_Target=fully_connected(x_Target_Values,'Target_Network',Mini_batch)\t#Creating the Object for CNN-RNN Layers\n\tQ_Values_Target=fully_connected_Target.dense_output\n\ttarget_max_Q_Value=fully_connected_Target.max_Q_Values\n\ttarget_vars = fully_connected_Target.trainable_vars_by_name\n\n\t################################################################\n\tx_Eval_Net=tf.placeholder(dtype=tf.float32,shape=(None,18432), name=\"x_Eval_Net\") \t#Images resized to 224x224x3\n\ta_t_eval=tf.placeholder(dtype=tf.int32,shape=(Mini_batch), name=\"a_t_eval\")\n\ty_Targets_eval=tf.placeholder(dtype=tf.float32,shape=(Mini_batch), name=\"y_Targets_eval\")\n\t\n\tfully_connected_Eval=fully_connected(x_Eval_Net,  'Eval_Network',Mini_batch)\t\t#Creating the Object for CNN-RNN Layers\n\tEval_Network_Q_Values=fully_connected_Eval.dense_output \t\t\t\t\t\t\t\t\t#Getting the Q-Values os the current state using the evaluation network\n\tEval_Network_max_Q_Value=fully_connected_Eval.max_Q_Values\n\teval_vars = fully_connected_Eval.trainable_vars_by_name\n\t\n\tloss=fully_connected_Eval.Q_Values_of_Given_State_Action(a_t_eval,y_Targets_eval)\n\toptimizer = tf.train.AdamOptimizer(learning_rate=0.0001,beta1=0.9)\n\ttrain = optimizer.minimize(loss, var_list=tf.trainable_variables(scope='Eval_Network'))\n\n\t#######################\n\n\tcopy_ops =[target_var.assign(eval_vars[var_name]) for var_name, target_var in target_vars.items()]\n\tcopy_online_to_target = tf.group(*copy_ops)\n\n\t######################\n\tinit_op = tf.global_variables_initializer()\n\tsess.run(init_op)", "body": "------------------------\r\n\r\n### System information\r\n\r\n**Have I written custom code: Yes\r\nOS Platform and Distribution: Linux Ubuntu 16.04\r\n TensorFlow installed from binary\r\nBazel version: N/A\r\nPython version 2.7\r\nTensorFlow version 1.9.0\r\nCUDA/cuDNN version CUDA 9.0\r\nGPU model and memory:  Nvidia 860M and memory 4 GB\r\nExact command to reproduce: N/A\r\nMobile device:N/A**\r\n\r\n**The problem:**\r\nI wrote a tensorflow code DDQN network to run with gpu and I am getting an Odd Memory problem. My processes list from system monitor shows that my memory utilized by the python code remains almost constant and increases very slowly as there is a increase in replay buffer size(Its list which stores samples). But in resources it shows that my memory is increasing steeply and is not analogous with the python program. For example when I start the code the memory utilized by the system is around 3.8 GB with python code taking around 1.5 GB of memory but after sometime like an hour or so the memory utilized by the system increases to 9-10 GB with the python code utilizing around 1.8GB. \r\n\r\n### Source code \r\n```\r\nimport tensorflow as tf\r\nimport numpy as np \t\r\nfrom PIL import Image\r\nimport time\r\nimport os, os.path\r\nimport cPickle as pickle\r\nfrom colorama import Fore, Back, Style\r\nfrom collections import deque,OrderedDict\r\nfrom blist import *\r\nimport gc\r\n#import pylab as pl\r\nimport sys\r\nimport matplotlib.pyplot as plt\r\nfrom PIL import Image, ImageDraw, ImageEnhance\r\n\r\n\r\nTraining_Dataset_1=\"Imagenet_Sequencing_filtered.pickle\"\r\n#Training_Dataset_2=\"OTB_Dataset.pickle\"\r\nTraining_Dataset_2=\"Dataset_VOT.pickle\"\r\n\r\nTest_Dataset=\"OTB_Dataset.pickle\"\r\nResults_file=\"Test_Results.pickle\"\r\n#Replay_Memory_file=\"Replay_Memory.pickle\"\r\n\r\nimport Layers\r\nimport RNN_State_update\r\nimport One_Shot_Representation\r\nimport Image_Cropping_Resizing\r\nimport Getting_Pretrained_caffenet_Parameters\r\nimport Grid_Generation\r\nimport Others_Func\r\n\r\n\r\nweights=Getting_Pretrained_caffenet_Parameters.param()\r\n\r\nNumber_RNN_Cell_Units=512\r\nNumber_of_Actions=11\r\n\r\nMini_batch=32\t\t\t\t\t\t\t\t\t#Batch Size over which gradient would be evaluated\r\nMax_episodes=200\t\t\t\t\t\t\t\t\t\t\t\r\nK_iterations=20 \t\t\t\t\t\t\t\t#Number of Times to Sample and Perform gradient update before collecting new dataset\r\nDiscount_Factor=0.99\r\nNumber_of_Epochs=1\r\nNumber_of_Training_Videos_1=1000\r\nNumber_of_Training_Videos_2=70\r\nNumber_of_Testing_videos=94\r\nBatch_Size=1\r\nReplayMemory=200000\r\nWeight_Update_Step_Size=10000\t\t\t\t\t\t#Updatation of weights from Evaluation Network to target network\r\n\r\nsess=tf.Session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True))\r\n\r\nclass CNN_RNN_Layers():\r\n\r\n# This class combines all the CNNs\r\n\r\n\tdef __init__(self, input,Batch_Size):\r\n\r\n\t\tself.input=input \t\t\t\t#T-1 and T Images with cropped using he Groundtruth Function\r\n\r\n\t\tself.input_1=input[0:Batch_Size]\r\n\t\tself.input_2=input[Batch_Size: 2*Batch_Size]\r\n\r\n\t\tself.Batch_Size=Batch_Size\r\n\r\n\r\n\t\twith tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.weights_1=weights[0]\r\n\t\t\tself.bias_1=weights[1]\r\n\r\n\t\t\tself.conv1_input_1= Layers.Convolayer(self.input_1, self.weights_1, self.bias_1, group=1, stride=(4,4) , pad_type='VALID' , name='Convolution_Layer_1_input_1')\r\n\t\t\tself.conv1_max_pooled_input_1=tf.nn.max_pool(value=self.conv1_input_1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Conv_1_Maxpool_input_1')\r\n\t\t\tself.conv1_normalized_input_1=tf.nn.local_response_normalization(self.conv1_max_pooled_input_1,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_1_Normalization_input_1')\r\n\r\n\t\twith tf.variable_scope(\"conv1\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.conv1_input_2= Layers.Convolayer(self.input_2, self.weights_1, self.bias_1, group=1, stride=(4,4) , pad_type='VALID' , name='Convolution_Layer_1_input_2')\r\n\t\t\tself.conv1_max_pooled_input_2=tf.nn.max_pool(value=self.conv1_input_2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Conv_1_Maxpool_input_2')\r\n\t\t\tself.conv1_normalized_input_2=tf.nn.local_response_normalization(self.conv1_max_pooled_input_2,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_1_Normalization_input_2')\r\n\t\t\t\r\n\t\twith tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.weights_2=weights[2]\r\n\t\t\tself.bias_2=weights[3]\r\n\r\n\t\t\tself.conv2_input_1= Layers.Convolayer(self.conv1_normalized_input_1, self.weights_2, self.bias_2, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_2_input_1')\r\n\t\t\tself.conv2_max_pooled_input_1=tf.nn.max_pool(self.conv2_input_1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_2_Maxpool_input_1')\r\n\t\t\tself.conv2_normalized_input_1=tf.nn.local_response_normalization(self.conv2_max_pooled_input_1,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_2_Normalization_input_1')\r\n\r\n\t\twith tf.variable_scope(\"conv2\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.conv2_input_2= Layers.Convolayer(self.conv1_normalized_input_2, self.weights_2, self.bias_2, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_2_input_2')\r\n\t\t\tself.conv2_max_pooled_input_2=tf.nn.max_pool(self.conv2_input_2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_2_Maxpool_input_2')\r\n\t\t\tself.conv2_normalized_input_2=tf.nn.local_response_normalization(self.conv2_max_pooled_input_2,depth_radius=1,bias=1,alpha=0.0001,beta=0.75,name='Conv_2_Normalization_input_2')\r\n\r\n\t\t\t\r\n\t\twith tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.weights_3=weights[4]\r\n\t\t\tself.bias_3=weights[5]\r\n\r\n\t\t\tself.conv3_input_1= Layers.Convolayer(self.conv2_normalized_input_1, self.weights_3, self.bias_3, group=1, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_3_input_1')\r\n\r\n\t\twith tf.variable_scope(\"conv3\", reuse=tf.AUTO_REUSE):\t\r\n\t\t\t\r\n\t\t\tself.conv3_input_2= Layers.Convolayer(self.conv2_normalized_input_2, self.weights_3, self.bias_3, group=1, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_3_input_2')\r\n\t\t\r\n\t\twith tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.weights_4=weights[6]\r\n\t\t\tself.bias_4=weights[7]\r\n\r\n\t\t\tself.conv4_input_1= Layers.Convolayer(self.conv3_input_1, self.weights_4, self.bias_4, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_4_input_1')\r\n\t\twith tf.variable_scope(\"conv4\", reuse=tf.AUTO_REUSE):\r\n\t\t\t\r\n\t\t\tself.conv4_input_2= Layers.Convolayer(self.conv3_input_2, self.weights_4, self.bias_4, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_4_input_1')\r\n\t\t\t\r\n\t\twith tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\tself.weights_5=weights[8]\r\n\t\t\tself.bias_5=weights[9]\r\n\r\n\t\t\tself.conv5_input_1= Layers.Convolayer(self.conv4_input_1, self.weights_5, self.bias_5, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_5_input_1')\r\n\t\t\tself.conv5_max_pooled_input_1=tf.nn.max_pool(self.conv5_input_1, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_5_Maxpool_input_1')\r\n\r\n\t\twith tf.variable_scope(\"conv5\", reuse=tf.AUTO_REUSE):\t\r\n\r\n\t\t\tself.conv5_input_2= Layers.Convolayer(self.conv4_input_2, self.weights_5, self.bias_5, group=2, stride=(1,1) , pad_type='SAME' , name='Convolution_Layer_5_input_2')\r\n\t\t\tself.conv5_max_pooled_input_2=tf.nn.max_pool(self.conv5_input_2, ksize=[1,3,3,1], strides=[1,2,2,1],padding='VALID', name='Conv_5_Maxpool_input_2')\t\t\r\n\t\t\t\r\n\t\t#Starting the Fully Connected Layers After the CNN. Here We use the inbuilt densely connected layer.\r\n\t\tself.input_fully_connected_input_1=tf.layers.flatten(self.conv5_max_pooled_input_1, name='Flatten_input_1')\r\n\t\tself.input_fully_connected_input_2=tf.layers.flatten(self.conv5_max_pooled_input_2, name='Flatten_input_2')\r\n\r\n\t\tself.concatenated_output=tf.concat([tf.reshape(self.input_fully_connected_input_1, shape=[Batch_Size, -1]), \r\n\t\t\t\t\t\t\t\t\t\t\ttf.reshape(self.input_fully_connected_input_2, shape=[Batch_Size, -1])], axis=-1)\r\n\r\nclass fully_connected():\r\n\r\n\t\tdef __init__(self, input, scope_name,Batch_Size):\r\n\r\n\t\t\tself.input=input \r\n\r\n\t\t\twith tf.variable_scope(scope_name) as scope:\r\n\t\t\t\t\t\t\t\t\t\t\t\r\n\t\t\t\twith tf.variable_scope('First_Fully_Connected', reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\t\t\tself.fully_connected_1_output=tf.layers.dense(inputs = self.input, units=4096, activation=tf.nn.relu, name=\"Dense_Layer_2\")\r\n\r\n\t\t\t\twith tf.variable_scope('Second_Fully_Connected', reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\t\t\tself.fully_connected_2_output=tf.layers.dense(inputs = self.fully_connected_1_output, units=2048, activation=tf.nn.relu, name=\"Dense_Layer_3\")\r\n\r\n\t\t\t\twith tf.variable_scope('Output_Layer', reuse=tf.AUTO_REUSE):\r\n\t\t\t\r\n\t\t\t\t\tself.dense_output= Layers.Dense_Layer(self.fully_connected_2_output, Number_of_Actions, name='Action_Output_Layer')\r\n\t\t\t\t\tself.Action_Output=tf.argmax(self.dense_output, axis=-1, name='Output_Action_as_Given_by_Deep_Networks')\r\n\r\n\t\t\t\t\tself.max_Q_Values=tf.reduce_max(self.dense_output, axis=-1)\r\n\r\n\t\t\t\t\tself.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=scope.name)\r\n\t\t\t\t\tself.trainable_vars_by_name = {var.name[len(scope.name):]: var for var in self.trainable_vars}\r\n\r\n\r\n\t\tdef Q_Values_of_Given_State_Action(self, actions_, y_targets):\r\n\r\n\t\t\tself.dense_output=self.dense_output\r\n\r\n\t\t\tactions_=tf.reshape(tf.cast(actions_, tf.int32), shape=(Mini_batch,1))\r\n\t\t\tz=tf.reshape(tf.range(tf.shape(self.dense_output)[0]), shape=(Mini_batch,1) )\r\n\r\n\t\t\tindex_=tf.concat((z,actions_), axis=-1)\r\n\r\n\t\t\tself.Q_Values_Select_Actions=tf.gather_nd(self.dense_output, index_)\r\n\r\n\t\t\t#loss_=tf.divide((tf.reduce_sum (tf.square(Q_Values_Select_Actions-y_targets))), 2)\r\n\t\t\t#loss_= y_targets-Q_Values_Select_Actions\t\t#Getting the difference between the target network and evaluation network\r\n\t\t\tloss_=tf.reduce_mean(tf.square(self.Q_Values_Select_Actions-y_targets))\r\n\r\n\t\t\treturn loss_\r\n\r\n\r\n\r\n\r\ndef Target_Values(r_t,s_t_plus_1,termination_criteria):\r\n\r\n\t#For DDQN\r\n\r\n\ts_t_plus_1=np.reshape(s_t_plus_1, newshape=(32,18432))\r\n\r\n\tOutput_Q_Values_Eval=sess.run((Eval_Network_Q_Values), feed_dict={x_Eval_Net:s_t_plus_1})\t#Getting the Q-Values from evaluation network\r\n\taction_=np.argmax(Output_Q_Values_Eval,axis=1)\t#Getting the actions array\r\n\tOutput_Q_Values_target=sess.run((Q_Values_Target), feed_dict={x_Target_Values:s_t_plus_1})\t#Getting the Q-Values from target network\r\n\r\n\tQ_values_selected=[]\r\n\tfor temp ,a in zip(range(32), action_):\r\n\r\n\t\tQ_values_selected.append(Output_Q_Values_target[temp][a])\r\n\ty_target_values=Others_Func.Y_Target(Q_values_selected, r_t,Discount_Factor)\r\n\r\n\tfor i in range(32):\r\n\t\tif(termination_criteria[i]==True):\r\n\t\t\ty_target_values[i]=r_t[i]\r\n\r\n\treturn y_target_values\r\n\r\n\r\ndef Evaluation_Network(s_t, a_t, y_Targets ):\r\n\r\n\twith tf.variable_scope('Eval_Network') as scope:\r\n\r\n\t\ts_t=np.reshape(s_t, newshape=(32, 18432))\r\n\r\n\t\ttotal_loss,_=sess.run((loss,train), feed_dict={x_Eval_Net:s_t, a_t_eval:a_t,y_Targets_eval:y_Targets})\t#Train the network and get the loss\r\n\r\n\t\treturn total_loss #Return the loss\r\n\r\n\r\ndef DQN(samples_):\r\n\t\r\n\ts_t,a_t,r_t,s_t_plus_1, termination_criteria=Others_Func.samples_seperation_generation(samples_)\r\n\r\n\tTargets=Target_Values(r_t,s_t_plus_1,termination_criteria)\r\n\tEval=Evaluation_Network(s_t,a_t, Targets)\t\t# Train the evaluation network and get the loss\r\n\r\n\tdel(s_t, a_t,r_t,s_t_plus_1)\r\n\tgc.collect()\t\r\n\treturn Eval \t#Return the loss\r\n\r\nwith tf.device('/device:GPU:0'):\r\n\r\n\tx_sampling=tf.placeholder(dtype=tf.float32,shape=(Batch_Size*2,227,227,3), name=\"x_sampling\") \t#Images resized to 224x224x3\r\n\r\n\tCNN_RNN_Layer_Sampling=CNN_RNN_Layers(x_sampling,Batch_Size)\t\t#Creating the Object for CNN-RNN Layers\r\n\tstate_eval_sampling=CNN_RNN_Layer_Sampling.concatenated_output\r\n\t\r\n\t##########################################\r\n\tx_Target_Values=tf.placeholder(dtype=tf.float32,shape=(None, 18432), name=\"x_Target_Values\") \t#Images resized to 224x224x3\r\n\tfully_connected_Target=fully_connected(x_Target_Values,'Target_Network',Mini_batch)\t#Creating the Object for CNN-RNN Layers\r\n\tQ_Values_Target=fully_connected_Target.dense_output\r\n\ttarget_max_Q_Value=fully_connected_Target.max_Q_Values\r\n\ttarget_vars = fully_connected_Target.trainable_vars_by_name\r\n\r\n\t################################################################\r\n\tx_Eval_Net=tf.placeholder(dtype=tf.float32,shape=(None,18432), name=\"x_Eval_Net\") \t#Images resized to 224x224x3\r\n\ta_t_eval=tf.placeholder(dtype=tf.int32,shape=(Mini_batch), name=\"a_t_eval\")\r\n\ty_Targets_eval=tf.placeholder(dtype=tf.float32,shape=(Mini_batch), name=\"y_Targets_eval\")\r\n\t\r\n\tfully_connected_Eval=fully_connected(x_Eval_Net,  'Eval_Network',Mini_batch)\t\t#Creating the Object for CNN-RNN Layers\r\n\tEval_Network_Q_Values=fully_connected_Eval.dense_output \t\t\t\t\t\t\t\t\t#Getting the Q-Values os the current state using the evaluation network\r\n\tEval_Network_max_Q_Value=fully_connected_Eval.max_Q_Values\r\n\teval_vars = fully_connected_Eval.trainable_vars_by_name\r\n\t\r\n\tloss=fully_connected_Eval.Q_Values_of_Given_State_Action(a_t_eval,y_Targets_eval)\r\n\toptimizer = tf.train.AdamOptimizer(learning_rate=0.0001,beta1=0.9)\r\n\ttrain = optimizer.minimize(loss, var_list=tf.trainable_variables(scope='Eval_Network'))\r\n\r\n\t#######################\r\n\r\n\tcopy_ops =[target_var.assign(eval_vars[var_name]) for var_name, target_var in target_vars.items()]\r\n\tcopy_online_to_target = tf.group(*copy_ops)\r\n\r\n\t######################\r\n\tinit_op = tf.global_variables_initializer()\r\n\tsess.run(init_op)\r\n```"}