{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21567", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21567/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21567/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21567/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21567", "id": 349930648, "node_id": "MDU6SXNzdWUzNDk5MzA2NDg=", "number": 21567, "title": "[question] [tflite] How to serialize Interpreter?", "user": {"login": "Buyduck", "id": 20967326, "node_id": "MDQ6VXNlcjIwOTY3MzI2", "avatar_url": "https://avatars0.githubusercontent.com/u/20967326?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Buyduck", "html_url": "https://github.com/Buyduck", "followers_url": "https://api.github.com/users/Buyduck/followers", "following_url": "https://api.github.com/users/Buyduck/following{/other_user}", "gists_url": "https://api.github.com/users/Buyduck/gists{/gist_id}", "starred_url": "https://api.github.com/users/Buyduck/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Buyduck/subscriptions", "organizations_url": "https://api.github.com/users/Buyduck/orgs", "repos_url": "https://api.github.com/users/Buyduck/repos", "events_url": "https://api.github.com/users/Buyduck/events{/privacy}", "received_events_url": "https://api.github.com/users/Buyduck/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-08-13T08:20:23Z", "updated_at": "2018-09-27T18:24:11Z", "closed_at": "2018-09-27T18:24:11Z", "author_association": "NONE", "body_html": "<p>Sorry for question, but could you, please, give me hint? I want to construct tflite model with C++ API (not with toco converter) and serialize it. If I use 'Interpreter' class for model creation, can I then convert it to FlatBufferModel somehow? Or the only opportunity is to create model via FlatBufferBuilder API?</p>", "body_text": "Sorry for question, but could you, please, give me hint? I want to construct tflite model with C++ API (not with toco converter) and serialize it. If I use 'Interpreter' class for model creation, can I then convert it to FlatBufferModel somehow? Or the only opportunity is to create model via FlatBufferBuilder API?", "body": "Sorry for question, but could you, please, give me hint? I want to construct tflite model with C++ API (not with toco converter) and serialize it. If I use 'Interpreter' class for model creation, can I then convert it to FlatBufferModel somehow? Or the only opportunity is to create model via FlatBufferBuilder API?"}