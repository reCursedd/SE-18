{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23198", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23198/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23198/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23198/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23198", "id": 373230074, "node_id": "MDU6SXNzdWUzNzMyMzAwNzQ=", "number": 23198, "title": "ResourceExhaustedError (see above for traceback): OOM when allocating tensor", "user": {"login": "nadianaji", "id": 18626373, "node_id": "MDQ6VXNlcjE4NjI2Mzcz", "avatar_url": "https://avatars1.githubusercontent.com/u/18626373?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nadianaji", "html_url": "https://github.com/nadianaji", "followers_url": "https://api.github.com/users/nadianaji/followers", "following_url": "https://api.github.com/users/nadianaji/following{/other_user}", "gists_url": "https://api.github.com/users/nadianaji/gists{/gist_id}", "starred_url": "https://api.github.com/users/nadianaji/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nadianaji/subscriptions", "organizations_url": "https://api.github.com/users/nadianaji/orgs", "repos_url": "https://api.github.com/users/nadianaji/repos", "events_url": "https://api.github.com/users/nadianaji/events{/privacy}", "received_events_url": "https://api.github.com/users/nadianaji/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097546578, "node_id": "MDU6TGFiZWwxMDk3NTQ2NTc4", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:keras", "name": "comp:keras", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-10-23T22:31:28Z", "updated_at": "2018-11-23T18:40:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Hi,<br>\nI want to feed CNN with my database. for this aim, I use ImageDataGenerator and I put my code here. but after implementing it produces this error:<br>\n\"ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,32,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc<br>\n[[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\"</p>\n<p>my database has 3 folders( train, test and validation). train and validation have 7 classes. train contains 564 images and validation contains 191 images. it is smal database but I do not know why it produces this error! could you please guide me about this problem? I do not know how can I solve this?</p>\n<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import shuffle\nfrom sklearn.cross_validation import train_test_split\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\n\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD,RMSprop,adam\n\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n#\nvalid_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n#\ntest_datagen = ImageDataGenerator(rescale=1./255)\n#\ntrain_generator = train_datagen.flow_from_directory(\n    directory=r\"E:\\databasetest\\train\",\n    target_size=(512, 512),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)\n#\nvalid_generator = valid_datagen.flow_from_directory(\n   directory=r\"E:\\databasetest\\validation\",\n    target_size=(512, 512),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)\n#\ntest_generator = test_datagen.flow_from_directory(\n    directory=r\"E:\\databasetest\\test\",\n    target_size=(512, 512),\n    color_mode=\"grayscale\",\n    batch_size=16,\n    class_mode=None,\n    shuffle=False,\n    seed=42\n)\n#\n## neural network model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3),border_mode='same', input_shape = (512, 512, 1), activation = 'relu'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64, 3, 3))\nmodel.add(Activation('relu'))\n#model.add(Convolution2D(64, 3, 3))\n#model.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = 'rmsprop',\n              metrics = ['accuracy'])\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)\n</code></pre>", "body_text": "Hi,\nI want to feed CNN with my database. for this aim, I use ImageDataGenerator and I put my code here. but after implementing it produces this error:\n\"ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,32,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n[[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\"\nmy database has 3 folders( train, test and validation). train and validation have 7 classes. train contains 564 images and validation contains 191 images. it is smal database but I do not know why it produces this error! could you please guide me about this problem? I do not know how can I solve this?\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import shuffle\nfrom sklearn.cross_validation import train_test_split\nfrom keras import backend as K\n#K.set_image_dim_ordering('th')\n\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD,RMSprop,adam\n\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n#\nvalid_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n#\ntest_datagen = ImageDataGenerator(rescale=1./255)\n#\ntrain_generator = train_datagen.flow_from_directory(\n    directory=r\"E:\\databasetest\\train\",\n    target_size=(512, 512),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)\n#\nvalid_generator = valid_datagen.flow_from_directory(\n   directory=r\"E:\\databasetest\\validation\",\n    target_size=(512, 512),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)\n#\ntest_generator = test_datagen.flow_from_directory(\n    directory=r\"E:\\databasetest\\test\",\n    target_size=(512, 512),\n    color_mode=\"grayscale\",\n    batch_size=16,\n    class_mode=None,\n    shuffle=False,\n    seed=42\n)\n#\n## neural network model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3),border_mode='same', input_shape = (512, 512, 1), activation = 'relu'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64, 3, 3))\nmodel.add(Activation('relu'))\n#model.add(Convolution2D(64, 3, 3))\n#model.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = 'rmsprop',\n              metrics = ['accuracy'])\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n)", "body": "Hi, \r\nI want to feed CNN with my database. for this aim, I use ImageDataGenerator and I put my code here. but after implementing it produces this error:  \r\n\"ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,32,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\"\r\n\r\nmy database has 3 folders( train, test and validation). train and validation have 7 classes. train contains 564 images and validation contains 191 images. it is smal database but I do not know why it produces this error! could you please guide me about this problem? I do not know how can I solve this?\r\n\r\n```\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom sklearn.utils import shuffle\r\nfrom sklearn.cross_validation import train_test_split\r\nfrom keras import backend as K\r\n#K.set_image_dim_ordering('th')\r\n\r\nfrom keras.utils import np_utils\r\nfrom keras.models import Sequential\r\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\r\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\r\nfrom keras.optimizers import SGD,RMSprop,adam\r\n\r\n\r\ntrain_datagen = ImageDataGenerator(\r\n        rescale=1./255,\r\n        shear_range=0.2,\r\n        zoom_range=0.2,\r\n        horizontal_flip=True)\r\n#\r\nvalid_datagen = ImageDataGenerator(\r\n        rescale=1./255,\r\n        shear_range=0.2,\r\n        zoom_range=0.2,\r\n        horizontal_flip=True)\r\n#\r\ntest_datagen = ImageDataGenerator(rescale=1./255)\r\n#\r\ntrain_generator = train_datagen.flow_from_directory(\r\n    directory=r\"E:\\databasetest\\train\",\r\n    target_size=(512, 512),\r\n    color_mode=\"grayscale\",\r\n    batch_size=32,\r\n    class_mode=\"categorical\",\r\n    shuffle=True,\r\n    seed=42\r\n)\r\n#\r\nvalid_generator = valid_datagen.flow_from_directory(\r\n   directory=r\"E:\\databasetest\\validation\",\r\n    target_size=(512, 512),\r\n    color_mode=\"grayscale\",\r\n    batch_size=32,\r\n    class_mode=\"categorical\",\r\n    shuffle=True,\r\n    seed=42\r\n)\r\n#\r\ntest_generator = test_datagen.flow_from_directory(\r\n    directory=r\"E:\\databasetest\\test\",\r\n    target_size=(512, 512),\r\n    color_mode=\"grayscale\",\r\n    batch_size=16,\r\n    class_mode=None,\r\n    shuffle=False,\r\n    seed=42\r\n)\r\n#\r\n## neural network model\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, (3,3),border_mode='same', input_shape = (512, 512, 1), activation = 'relu'))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Conv2D(32, 3, 3))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.5))\r\n\r\nmodel.add(Conv2D(64, 3, 3))\r\nmodel.add(Activation('relu'))\r\n#model.add(Convolution2D(64, 3, 3))\r\n#model.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.5))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(64))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(7))\r\nmodel.add(Activation('softmax'))\r\n\r\nmodel.summary()\r\n\r\nmodel.compile(loss = 'categorical_crossentropy',\r\n              optimizer = 'rmsprop',\r\n              metrics = ['accuracy'])\r\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\r\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\r\nmodel.fit_generator(generator=train_generator,\r\n                    steps_per_epoch=STEP_SIZE_TRAIN,\r\n                    validation_data=valid_generator,\r\n                    validation_steps=STEP_SIZE_VALID,\r\n                    epochs=10\r\n)\r\n```"}