{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23935", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23935/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23935/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23935/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23935", "id": 383728619, "node_id": "MDU6SXNzdWUzODM3Mjg2MTk=", "number": 23935, "title": "Can only utilize GPU after being run as root", "user": {"login": "KylePiira", "id": 17210104, "node_id": "MDQ6VXNlcjE3MjEwMTA0", "avatar_url": "https://avatars2.githubusercontent.com/u/17210104?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KylePiira", "html_url": "https://github.com/KylePiira", "followers_url": "https://api.github.com/users/KylePiira/followers", "following_url": "https://api.github.com/users/KylePiira/following{/other_user}", "gists_url": "https://api.github.com/users/KylePiira/gists{/gist_id}", "starred_url": "https://api.github.com/users/KylePiira/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KylePiira/subscriptions", "organizations_url": "https://api.github.com/users/KylePiira/orgs", "repos_url": "https://api.github.com/users/KylePiira/repos", "events_url": "https://api.github.com/users/KylePiira/events{/privacy}", "received_events_url": "https://api.github.com/users/KylePiira/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-11-23T07:53:35Z", "updated_at": "2018-11-24T00:09:26Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10 Buster Fresh Install (Testing)</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): 1.12.0</li>\n<li>Python version: 3.6/2.7</li>\n<li>Bazel version (if compiling from source):</li>\n<li>GCC/Compiler version (if compiling from source):</li>\n<li>CUDA/cuDNN version: CUDA 9.0.176 / cuDNN 9.0</li>\n<li>GPU model and memory: GeForce GTX 1060 6GB</li>\n</ul>\n<p><strong>What is happening</strong><br>\nWhen the system is first booted Tensorflow is not able to recognize the GPU instead returning <code>CUDA_ERROR_UNKNOWN: unknown error</code> but after running a version of Tensorflow as root all other instances start working.</p>\n<p><strong>Describe the expected behavior</strong><br>\nIn the example below the first instance of Tensorflow in the virtualenv should have been able to see the GPU.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nBelow is edited/commented version of an experiment I ran showcasing this bug. I have removed most of the verbose logging for brevity but the original can be found <a href=\"https://pastebin.com/B7vHcyjn\" rel=\"nofollow\">here</a>.</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Activate Virtualenv with Tensorflow 1.12.0</span>\nkyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ <span class=\"pl-c1\">source</span> env/bin/activate\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Export the paths to CUDA</span>\n(env) kyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64<span class=\"pl-pds\">\"</span></span>\n(env) kyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ <span class=\"pl-k\">export</span> CUDA_HOME=/usr/local/cuda\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Launch Python Interpreter</span>\n(env) kyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ python\nPython 3.6.7 (default, Oct 21 2018, 08:08:16) \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Import the TensorFlow installed in Virtualenv</span>\n&gt;&gt;&gt; import tensorflow as tf\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Test for GPUs</span>\n&gt;&gt;&gt; <span class=\"pl-en\">tf.test.is_gpu_available</span>()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> None are found</span>\nFalse\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Let's exit the Python interpreter</span>\n&gt;&gt;&gt; <span class=\"pl-en\">exit</span>()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> and deactivate the Virtualenv</span>\n(env) kyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ deactivate\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Login as superuser</span>\nkyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ sudo su\n[sudo] password <span class=\"pl-k\">for</span> kyle: \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Export paths to CUDA (again)</span>\nroot@Debian:/home/kyle/Code/ML# <span class=\"pl-k\">export</span> LD_LIBRARY_PATH=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-smi\">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64<span class=\"pl-pds\">\"</span></span>\nroot@Debian:/home/kyle/Code/ML# <span class=\"pl-k\">export</span> CUDA_HOME=/usr/local/cuda\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Launch Global Python Interpreter (as root)</span>\nroot@Debian:/home/kyle/Code/ML# python\nPython 2.7.15+ (default, Aug 31 2018, 11:56:52) \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Import a global install of TensorFlow 1.12.0</span>\n&gt;&gt;&gt; import tensorflow as tf\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Test for GPUs</span>\n&gt;&gt;&gt; <span class=\"pl-en\">tf.test.is_gpu_available</span>()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> It found one! :D</span>\nTrue\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Exit Python interpreter</span>\n&gt;&gt;&gt; <span class=\"pl-en\">exit</span>()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Exit root</span>\nroot@Debian:/home/kyle/Code/ML# <span class=\"pl-c1\">exit</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> We are now logged in as user 'kyle'</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Activate the same virtualenv as before</span>\nkyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ <span class=\"pl-c1\">source</span> env/bin/activate\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Enter the Virtualenv's Python interpreter</span>\n(env) kyle@Debian:<span class=\"pl-k\">~</span>/Code/ML$ python\nPython 3.6.7 (default, Oct 21 2018, 08:08:16) \n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Import Tensorflow from within Virtualenv</span>\n&gt;&gt;&gt; import tensorflow as tf\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Test for GPUs</span>\n&gt;&gt;&gt; <span class=\"pl-en\">tf.test.is_gpu_available</span>()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Now it found one? wtf.</span>\nTrue</pre></div>\n<p><strong>Other info / logs</strong><br>\nThe package <code>nvidia-modprobe</code> is already installed.<br>\nNvidia Driver: 390.87</p>\n<div class=\"highlight highlight-source-shell\"><pre>kyle@Debian:<span class=\"pl-k\">~</span>$ nvidia-smi\nFri Nov 23 02:46:11 2018       \n+-----------------------------------------------------------------------------+\n<span class=\"pl-k\">|</span> NVIDIA-SMI 390.87                 Driver Version: 390.87                    <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>-------------------------------+----------------------+----------------------+\n<span class=\"pl-k\">|</span> GPU  Name        Persistence-M<span class=\"pl-k\">|</span> Bus-Id        Disp.A <span class=\"pl-k\">|</span> Volatile Uncorr. ECC <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span> Fan  Temp  Perf  Pwr:Usage/Cap<span class=\"pl-k\">|</span>         Memory-Usage <span class=\"pl-k\">|</span> GPU-Util  Compute M. <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>===============================+======================+======================<span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>   0  GeForce GTX 106...  Off  <span class=\"pl-k\">|</span> 00000000:01:00.0  On <span class=\"pl-k\">|</span>                  N/A <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>  3%   49C    P8     9W / 120W <span class=\"pl-k\">|</span>    275MiB /  6070MiB <span class=\"pl-k\">|</span>      0%      Default <span class=\"pl-k\">|</span>\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n<span class=\"pl-k\">|</span> Processes:                                                       GPU Memory <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>  GPU       PID   Type   Process name                             Usage      <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>=============================================================================<span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>    0      1007      G   /usr/lib/xorg/Xorg                           152MiB <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>    0      1485      G   /usr/bin/kwin_x11                             36MiB <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>    0      1489      G   /usr/bin/krunner                               1MiB <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>    0      1491      G   /usr/bin/plasmashell                          30MiB <span class=\"pl-k\">|</span>\n<span class=\"pl-k\">|</span>    0      2729      G   ...quest-channel-token=5720462904883144478    51MiB <span class=\"pl-k\">|</span>\n+-----------------------------------------------------------------------------+</pre></div>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10 Buster Fresh Install (Testing)\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.12.0\nPython version: 3.6/2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: CUDA 9.0.176 / cuDNN 9.0\nGPU model and memory: GeForce GTX 1060 6GB\n\nWhat is happening\nWhen the system is first booted Tensorflow is not able to recognize the GPU instead returning CUDA_ERROR_UNKNOWN: unknown error but after running a version of Tensorflow as root all other instances start working.\nDescribe the expected behavior\nIn the example below the first instance of Tensorflow in the virtualenv should have been able to see the GPU.\nCode to reproduce the issue\nBelow is edited/commented version of an experiment I ran showcasing this bug. I have removed most of the verbose logging for brevity but the original can be found here.\n# Activate Virtualenv with Tensorflow 1.12.0\nkyle@Debian:~/Code/ML$ source env/bin/activate\n# Export the paths to CUDA\n(env) kyle@Debian:~/Code/ML$ export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\"\n(env) kyle@Debian:~/Code/ML$ export CUDA_HOME=/usr/local/cuda\n# Launch Python Interpreter\n(env) kyle@Debian:~/Code/ML$ python\nPython 3.6.7 (default, Oct 21 2018, 08:08:16) \n# Import the TensorFlow installed in Virtualenv\n>>> import tensorflow as tf\n# Test for GPUs\n>>> tf.test.is_gpu_available()\n# None are found\nFalse\n# Let's exit the Python interpreter\n>>> exit()\n# and deactivate the Virtualenv\n(env) kyle@Debian:~/Code/ML$ deactivate\n\n# Login as superuser\nkyle@Debian:~/Code/ML$ sudo su\n[sudo] password for kyle: \n# Export paths to CUDA (again)\nroot@Debian:/home/kyle/Code/ML# export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\"\nroot@Debian:/home/kyle/Code/ML# export CUDA_HOME=/usr/local/cuda\n# Launch Global Python Interpreter (as root)\nroot@Debian:/home/kyle/Code/ML# python\nPython 2.7.15+ (default, Aug 31 2018, 11:56:52) \n# Import a global install of TensorFlow 1.12.0\n>>> import tensorflow as tf\n# Test for GPUs\n>>> tf.test.is_gpu_available()\n# It found one! :D\nTrue\n# Exit Python interpreter\n>>> exit()\n# Exit root\nroot@Debian:/home/kyle/Code/ML# exit\n\n# We are now logged in as user 'kyle'\n# Activate the same virtualenv as before\nkyle@Debian:~/Code/ML$ source env/bin/activate\n# Enter the Virtualenv's Python interpreter\n(env) kyle@Debian:~/Code/ML$ python\nPython 3.6.7 (default, Oct 21 2018, 08:08:16) \n# Import Tensorflow from within Virtualenv\n>>> import tensorflow as tf\n# Test for GPUs\n>>> tf.test.is_gpu_available()\n# Now it found one? wtf.\nTrue\nOther info / logs\nThe package nvidia-modprobe is already installed.\nNvidia Driver: 390.87\nkyle@Debian:~$ nvidia-smi\nFri Nov 23 02:46:11 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\n|  3%   49C    P8     9W / 120W |    275MiB /  6070MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1007      G   /usr/lib/xorg/Xorg                           152MiB |\n|    0      1485      G   /usr/bin/kwin_x11                             36MiB |\n|    0      1489      G   /usr/bin/krunner                               1MiB |\n|    0      1491      G   /usr/bin/plasmashell                          30MiB |\n|    0      2729      G   ...quest-channel-token=5720462904883144478    51MiB |\n+-----------------------------------------------------------------------------+", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10 Buster Fresh Install (Testing)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6/2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 9.0.176 / cuDNN 9.0\r\n- GPU model and memory: GeForce GTX 1060 6GB\r\n\r\n**What is happening**\r\nWhen the system is first booted Tensorflow is not able to recognize the GPU instead returning `CUDA_ERROR_UNKNOWN: unknown error` but after running a version of Tensorflow as root all other instances start working.\r\n\r\n**Describe the expected behavior**\r\nIn the example below the first instance of Tensorflow in the virtualenv should have been able to see the GPU. \r\n\r\n**Code to reproduce the issue**\r\nBelow is edited/commented version of an experiment I ran showcasing this bug. I have removed most of the verbose logging for brevity but the original can be found [here](https://pastebin.com/B7vHcyjn).\r\n```bash\r\n# Activate Virtualenv with Tensorflow 1.12.0\r\nkyle@Debian:~/Code/ML$ source env/bin/activate\r\n# Export the paths to CUDA\r\n(env) kyle@Debian:~/Code/ML$ export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\"\r\n(env) kyle@Debian:~/Code/ML$ export CUDA_HOME=/usr/local/cuda\r\n# Launch Python Interpreter\r\n(env) kyle@Debian:~/Code/ML$ python\r\nPython 3.6.7 (default, Oct 21 2018, 08:08:16) \r\n# Import the TensorFlow installed in Virtualenv\r\n>>> import tensorflow as tf\r\n# Test for GPUs\r\n>>> tf.test.is_gpu_available()\r\n# None are found\r\nFalse\r\n# Let's exit the Python interpreter\r\n>>> exit()\r\n# and deactivate the Virtualenv\r\n(env) kyle@Debian:~/Code/ML$ deactivate\r\n\r\n# Login as superuser\r\nkyle@Debian:~/Code/ML$ sudo su\r\n[sudo] password for kyle: \r\n# Export paths to CUDA (again)\r\nroot@Debian:/home/kyle/Code/ML# export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\"\r\nroot@Debian:/home/kyle/Code/ML# export CUDA_HOME=/usr/local/cuda\r\n# Launch Global Python Interpreter (as root)\r\nroot@Debian:/home/kyle/Code/ML# python\r\nPython 2.7.15+ (default, Aug 31 2018, 11:56:52) \r\n# Import a global install of TensorFlow 1.12.0\r\n>>> import tensorflow as tf\r\n# Test for GPUs\r\n>>> tf.test.is_gpu_available()\r\n# It found one! :D\r\nTrue\r\n# Exit Python interpreter\r\n>>> exit()\r\n# Exit root\r\nroot@Debian:/home/kyle/Code/ML# exit\r\n\r\n# We are now logged in as user 'kyle'\r\n# Activate the same virtualenv as before\r\nkyle@Debian:~/Code/ML$ source env/bin/activate\r\n# Enter the Virtualenv's Python interpreter\r\n(env) kyle@Debian:~/Code/ML$ python\r\nPython 3.6.7 (default, Oct 21 2018, 08:08:16) \r\n# Import Tensorflow from within Virtualenv\r\n>>> import tensorflow as tf\r\n# Test for GPUs\r\n>>> tf.test.is_gpu_available()\r\n# Now it found one? wtf.\r\nTrue\r\n```\r\n\r\n**Other info / logs**\r\nThe package `nvidia-modprobe` is already installed. \r\nNvidia Driver: 390.87\r\n```bash\r\nkyle@Debian:~$ nvidia-smi\r\nFri Nov 23 02:46:11 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\r\n|  3%   49C    P8     9W / 120W |    275MiB /  6070MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1007      G   /usr/lib/xorg/Xorg                           152MiB |\r\n|    0      1485      G   /usr/bin/kwin_x11                             36MiB |\r\n|    0      1489      G   /usr/bin/krunner                               1MiB |\r\n|    0      1491      G   /usr/bin/plasmashell                          30MiB |\r\n|    0      2729      G   ...quest-channel-token=5720462904883144478    51MiB |\r\n+-----------------------------------------------------------------------------+\r\n```"}