{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/181058436", "html_url": "https://github.com/tensorflow/tensorflow/pull/882#issuecomment-181058436", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/882", "id": 181058436, "node_id": "MDEyOklzc3VlQ29tbWVudDE4MTA1ODQzNg==", "user": {"login": "manipopopo", "id": 14799222, "node_id": "MDQ6VXNlcjE0Nzk5MjIy", "avatar_url": "https://avatars2.githubusercontent.com/u/14799222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/manipopopo", "html_url": "https://github.com/manipopopo", "followers_url": "https://api.github.com/users/manipopopo/followers", "following_url": "https://api.github.com/users/manipopopo/following{/other_user}", "gists_url": "https://api.github.com/users/manipopopo/gists{/gist_id}", "starred_url": "https://api.github.com/users/manipopopo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/manipopopo/subscriptions", "organizations_url": "https://api.github.com/users/manipopopo/orgs", "repos_url": "https://api.github.com/users/manipopopo/repos", "events_url": "https://api.github.com/users/manipopopo/events{/privacy}", "received_events_url": "https://api.github.com/users/manipopopo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-02-07T17:37:51Z", "updated_at": "2016-02-08T11:33:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>When <code>feed_previous</code> is a boolean tensor, <code>embedding_rnn_seq2seq</code> will construct two <code>embedding_rnn_decoder</code> with <code>feed_previous=True</code> and <code>feed_previous=False</code>. During the course of training, gradients will propagate through the embeddings within the decoders when <code>feed_previous</code> is evaluated as false.</p>\n<p>However, when an user create <code>embedding_rnn_seq2seq</code> with <code>feed_previous=True</code>, there will be only one <code>embedding_rnn_decoder</code> with <code>feed_previous=True</code> in the model. It might be confusing that the embeddings within <code>embedding_rnn_decoder</code> learn nothing and remain as random initial values after training.</p>\n<p>To control whether embeddings for symbols generated by the decoder itself will be updated during the course of training, a new parameter <code>update_embedding_for_previous</code> is added to <code>embedding_rnn_decoder</code> and <code>embedding_attention_decoder</code>. For example, the following two cases have the same effect:</p>\n<ul>\n<li>Train <code>embedding_rnn_seq2seq</code> with <code>feed_previous=True</code>, which contains a <code>embedding_rnn_decoder</code> with <code>feed_previous=True</code> and <code>update_embedding_for_previous=True</code>. The decoder is fed with \"\" and outputs \"A, B, C\".</li>\n<li>Train <code>embedding_rnn_seq2seq</code> with <code>feed_previous=False</code>. The decoder is fed with \", A, B\".</li>\n</ul>\n<p>A test unit is added to check this.</p>", "body_text": "When feed_previous is a boolean tensor, embedding_rnn_seq2seq will construct two embedding_rnn_decoder with feed_previous=True and feed_previous=False. During the course of training, gradients will propagate through the embeddings within the decoders when feed_previous is evaluated as false.\nHowever, when an user create embedding_rnn_seq2seq with feed_previous=True, there will be only one embedding_rnn_decoder with feed_previous=True in the model. It might be confusing that the embeddings within embedding_rnn_decoder learn nothing and remain as random initial values after training.\nTo control whether embeddings for symbols generated by the decoder itself will be updated during the course of training, a new parameter update_embedding_for_previous is added to embedding_rnn_decoder and embedding_attention_decoder. For example, the following two cases have the same effect:\n\nTrain embedding_rnn_seq2seq with feed_previous=True, which contains a embedding_rnn_decoder with feed_previous=True and update_embedding_for_previous=True. The decoder is fed with \"\" and outputs \"A, B, C\".\nTrain embedding_rnn_seq2seq with feed_previous=False. The decoder is fed with \", A, B\".\n\nA test unit is added to check this.", "body": "When `feed_previous` is a boolean tensor, `embedding_rnn_seq2seq` will construct two `embedding_rnn_decoder` with `feed_previous=True` and `feed_previous=False`. During the course of training, gradients will propagate through the embeddings within the decoders when `feed_previous` is evaluated as false. \n\nHowever, when an user create `embedding_rnn_seq2seq` with `feed_previous=True`, there will be only one `embedding_rnn_decoder` with `feed_previous=True` in the model. It might be confusing that the embeddings within `embedding_rnn_decoder` learn nothing and remain as random initial values after training.\n\nTo control whether embeddings for symbols generated by the decoder itself will be updated during the course of training, a new parameter `update_embedding_for_previous` is added to `embedding_rnn_decoder` and `embedding_attention_decoder`. For example, the following two cases have the same effect:\n- Train `embedding_rnn_seq2seq` with `feed_previous=True`, which contains a `embedding_rnn_decoder` with `feed_previous=True` and `update_embedding_for_previous=True`. The decoder is fed with \"<Go>\" and outputs \"A, B, C\".\n- Train `embedding_rnn_seq2seq` with `feed_previous=False`. The decoder is fed with \"<Go>, A, B\".\n\nA test unit is added to check this.\n"}