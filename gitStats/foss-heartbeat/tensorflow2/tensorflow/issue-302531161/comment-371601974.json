{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/371601974", "html_url": "https://github.com/tensorflow/tensorflow/issues/17458#issuecomment-371601974", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17458", "id": 371601974, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTYwMTk3NA==", "user": {"login": "sfvaroglu", "id": 22965499, "node_id": "MDQ6VXNlcjIyOTY1NDk5", "avatar_url": "https://avatars0.githubusercontent.com/u/22965499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sfvaroglu", "html_url": "https://github.com/sfvaroglu", "followers_url": "https://api.github.com/users/sfvaroglu/followers", "following_url": "https://api.github.com/users/sfvaroglu/following{/other_user}", "gists_url": "https://api.github.com/users/sfvaroglu/gists{/gist_id}", "starred_url": "https://api.github.com/users/sfvaroglu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sfvaroglu/subscriptions", "organizations_url": "https://api.github.com/users/sfvaroglu/orgs", "repos_url": "https://api.github.com/users/sfvaroglu/repos", "events_url": "https://api.github.com/users/sfvaroglu/events{/privacy}", "received_events_url": "https://api.github.com/users/sfvaroglu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-08T19:46:16Z", "updated_at": "2018-03-08T19:46:16Z", "author_association": "NONE", "body_html": "<p>Could you elaborate on <em>`device:XLA_CPU:0\u2019 is used primarily for testing?</em> Using it in a non-distributed environment does not cause segmentation fault or non-convergence. Does it result in undefined behavior in distributed runtime?</p>\n<p>Setting config or scope to invoke XLA (as mentioned in <a href=\"https://www.tensorflow.org/performance/xla/jit\" rel=\"nofollow\">https://www.tensorflow.org/performance/xla/jit</a>) does not place ops on XLA_CPU device. The logs show all ops are either on <code>/job:worker/replica:0/task:0/device:CPU:0</code> or <code>/job:ps/replica:0/task:0/device:CPU:0</code>.</p>\n<p>Also, using <code>worker_device=device:XLA_CPU</code> in tf.train.replica_device_setter causes segmentation fault or NaN values.</p>\n<p>What is the recommended way of using XLA_CPU in a distributed environment?</p>", "body_text": "Could you elaborate on `device:XLA_CPU:0\u2019 is used primarily for testing? Using it in a non-distributed environment does not cause segmentation fault or non-convergence. Does it result in undefined behavior in distributed runtime?\nSetting config or scope to invoke XLA (as mentioned in https://www.tensorflow.org/performance/xla/jit) does not place ops on XLA_CPU device. The logs show all ops are either on /job:worker/replica:0/task:0/device:CPU:0 or /job:ps/replica:0/task:0/device:CPU:0.\nAlso, using worker_device=device:XLA_CPU in tf.train.replica_device_setter causes segmentation fault or NaN values.\nWhat is the recommended way of using XLA_CPU in a distributed environment?", "body": "Could you elaborate on _`device:XLA_CPU:0\u2019 is used primarily for testing?_ Using it in a non-distributed environment does not cause segmentation fault or non-convergence. Does it result in undefined behavior in distributed runtime? \r\n\r\nSetting config or scope to invoke XLA (as mentioned in https://www.tensorflow.org/performance/xla/jit) does not place ops on XLA_CPU device. The logs show all ops are either on `/job:worker/replica:0/task:0/device:CPU:0` or `/job:ps/replica:0/task:0/device:CPU:0`. \r\n\r\nAlso, using `worker_device=device:XLA_CPU` in tf.train.replica_device_setter causes segmentation fault or NaN values.\r\n\r\nWhat is the recommended way of using XLA_CPU in a distributed environment?"}