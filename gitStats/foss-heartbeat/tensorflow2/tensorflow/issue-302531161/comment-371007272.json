{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/371007272", "html_url": "https://github.com/tensorflow/tensorflow/issues/17458#issuecomment-371007272", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17458", "id": 371007272, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTAwNzI3Mg==", "user": {"login": "sfvaroglu", "id": 22965499, "node_id": "MDQ6VXNlcjIyOTY1NDk5", "avatar_url": "https://avatars0.githubusercontent.com/u/22965499?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sfvaroglu", "html_url": "https://github.com/sfvaroglu", "followers_url": "https://api.github.com/users/sfvaroglu/followers", "following_url": "https://api.github.com/users/sfvaroglu/following{/other_user}", "gists_url": "https://api.github.com/users/sfvaroglu/gists{/gist_id}", "starred_url": "https://api.github.com/users/sfvaroglu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sfvaroglu/subscriptions", "organizations_url": "https://api.github.com/users/sfvaroglu/orgs", "repos_url": "https://api.github.com/users/sfvaroglu/repos", "events_url": "https://api.github.com/users/sfvaroglu/events{/privacy}", "received_events_url": "https://api.github.com/users/sfvaroglu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-07T03:06:50Z", "updated_at": "2018-03-07T03:06:50Z", "author_association": "NONE", "body_html": "<p>The behavior is inconsistent. What I observed:</p>\n<ul>\n<li>segmentation fault on worker side (the number of steps where segmentation fault occurs is inconsistent), or</li>\n<li>no segmentation fault, but accuracy &lt; 0.1</li>\n</ul>\n<p>The same script runs fine (i.e. no segmentation fault or convergence problem) if <code>with tf.device('/device:CPU:0')</code> is used.</p>\n<pre><code>def main(_):\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\n\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n  server = tf.train.Server(cluster,\n                           job_name=FLAGS.job_name,\n                           task_index=FLAGS.task_index)\n\n\n  if FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n    global_step = tf.train.get_or_create_global_step()\n    \n    hooks=[tf.train.StopAtStepHook(num_steps=10)]\n\n    mnist = input_data.read_data_sets(FLAGS.data_dir)\n\n    with tf.device(tf.train.replica_device_setter(cluster=cluster)):\n      # Create the model\n      x = tf.placeholder(tf.float32, [None, 784])\n      w = tf.Variable(tf.zeros([784, 10]))\n      b = tf.Variable(tf.zeros([10]))\n      y = tf.matmul(x, w) + b\n\n      # Define loss and optimizer\n      y_ = tf.placeholder(tf.float32, [None, 10])\n\n      # The raw formulation of cross-entropy,\n      #\n      #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n      #                                 reduction_indices=[1]))\n      #\n      # can be numerically unstable.\n      #\n      # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n      # outputs of 'y', and then average across the batch.\n      cross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n      with tf.device('/device:XLA_CPU:0'):\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n    jit_level = 0\n    if FLAGS.xla:\n      # Turns on XLA JIT compilation.\n      jit_level = tf.OptimizerOptions.ON_1\n\n    config.graph_options.optimizer_options.global_jit_level = jit_level\n\n    with tf.train.MonitoredTrainingSession(master=server.target,\n                                           is_chief=(FLAGS.task_index==0),\n                                           hooks=hooks,\n                                           config=config) as sess:\n\n      train_loops = FLAGS.train_loop_count\n      start = time.time()\n      for i in range(train_loops):\n        batch_xs, batch_ys = mnist.train.next_batch(100)\n        (_, loss) = sess.run(\n          [train_step, cross_entropy], feed_dict={\n              x: batch_xs,\n              y_: batch_ys\n          })\n        print(\"step = %d, loss = %f\" % (i, loss))\n      end = time.time()\n      elapsed = (end - start)\n      print(\"Time elapsed: \", elapsed, \" seconds\" )\n\n      # Test trained model\n      if i == train_loops-1:\n        print(\"Accuracy: \", sess.run(\n          accuracy, feed_dict={\n            x: mnist.test.images,\n            y_: mnist.test.labels\n          }))\n</code></pre>", "body_text": "The behavior is inconsistent. What I observed:\n\nsegmentation fault on worker side (the number of steps where segmentation fault occurs is inconsistent), or\nno segmentation fault, but accuracy < 0.1\n\nThe same script runs fine (i.e. no segmentation fault or convergence problem) if with tf.device('/device:CPU:0') is used.\ndef main(_):\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\n\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n  server = tf.train.Server(cluster,\n                           job_name=FLAGS.job_name,\n                           task_index=FLAGS.task_index)\n\n\n  if FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n    global_step = tf.train.get_or_create_global_step()\n    \n    hooks=[tf.train.StopAtStepHook(num_steps=10)]\n\n    mnist = input_data.read_data_sets(FLAGS.data_dir)\n\n    with tf.device(tf.train.replica_device_setter(cluster=cluster)):\n      # Create the model\n      x = tf.placeholder(tf.float32, [None, 784])\n      w = tf.Variable(tf.zeros([784, 10]))\n      b = tf.Variable(tf.zeros([10]))\n      y = tf.matmul(x, w) + b\n\n      # Define loss and optimizer\n      y_ = tf.placeholder(tf.float32, [None, 10])\n\n      # The raw formulation of cross-entropy,\n      #\n      #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n      #                                 reduction_indices=[1]))\n      #\n      # can be numerically unstable.\n      #\n      # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n      # outputs of 'y', and then average across the batch.\n      cross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n      with tf.device('/device:XLA_CPU:0'):\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n    jit_level = 0\n    if FLAGS.xla:\n      # Turns on XLA JIT compilation.\n      jit_level = tf.OptimizerOptions.ON_1\n\n    config.graph_options.optimizer_options.global_jit_level = jit_level\n\n    with tf.train.MonitoredTrainingSession(master=server.target,\n                                           is_chief=(FLAGS.task_index==0),\n                                           hooks=hooks,\n                                           config=config) as sess:\n\n      train_loops = FLAGS.train_loop_count\n      start = time.time()\n      for i in range(train_loops):\n        batch_xs, batch_ys = mnist.train.next_batch(100)\n        (_, loss) = sess.run(\n          [train_step, cross_entropy], feed_dict={\n              x: batch_xs,\n              y_: batch_ys\n          })\n        print(\"step = %d, loss = %f\" % (i, loss))\n      end = time.time()\n      elapsed = (end - start)\n      print(\"Time elapsed: \", elapsed, \" seconds\" )\n\n      # Test trained model\n      if i == train_loops-1:\n        print(\"Accuracy: \", sess.run(\n          accuracy, feed_dict={\n            x: mnist.test.images,\n            y_: mnist.test.labels\n          }))", "body": "The behavior is inconsistent. What I observed:\r\n- segmentation fault on worker side (the number of steps where segmentation fault occurs is inconsistent), or\r\n- no segmentation fault, but accuracy < 0.1\r\n\r\nThe same script runs fine (i.e. no segmentation fault or convergence problem) if `with tf.device('/device:CPU:0')` is used. \r\n\r\n```\r\ndef main(_):\r\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\r\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\r\n\r\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\r\n\r\n  server = tf.train.Server(cluster,\r\n                           job_name=FLAGS.job_name,\r\n                           task_index=FLAGS.task_index)\r\n\r\n\r\n  if FLAGS.job_name == \"ps\":\r\n    server.join()\r\n  elif FLAGS.job_name == \"worker\":\r\n    global_step = tf.train.get_or_create_global_step()\r\n    \r\n    hooks=[tf.train.StopAtStepHook(num_steps=10)]\r\n\r\n    mnist = input_data.read_data_sets(FLAGS.data_dir)\r\n\r\n    with tf.device(tf.train.replica_device_setter(cluster=cluster)):\r\n      # Create the model\r\n      x = tf.placeholder(tf.float32, [None, 784])\r\n      w = tf.Variable(tf.zeros([784, 10]))\r\n      b = tf.Variable(tf.zeros([10]))\r\n      y = tf.matmul(x, w) + b\r\n\r\n      # Define loss and optimizer\r\n      y_ = tf.placeholder(tf.float32, [None, 10])\r\n\r\n      # The raw formulation of cross-entropy,\r\n      #\r\n      #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\r\n      #                                 reduction_indices=[1]))\r\n      #\r\n      # can be numerically unstable.\r\n      #\r\n      # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\r\n      # outputs of 'y', and then average across the batch.\r\n      cross_entropy = tf.reduce_mean(\r\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\r\n\r\n      with tf.device('/device:XLA_CPU:0'):\r\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\r\n\r\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\r\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\r\n    jit_level = 0\r\n    if FLAGS.xla:\r\n      # Turns on XLA JIT compilation.\r\n      jit_level = tf.OptimizerOptions.ON_1\r\n\r\n    config.graph_options.optimizer_options.global_jit_level = jit_level\r\n\r\n    with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                           is_chief=(FLAGS.task_index==0),\r\n                                           hooks=hooks,\r\n                                           config=config) as sess:\r\n\r\n      train_loops = FLAGS.train_loop_count\r\n      start = time.time()\r\n      for i in range(train_loops):\r\n        batch_xs, batch_ys = mnist.train.next_batch(100)\r\n        (_, loss) = sess.run(\r\n          [train_step, cross_entropy], feed_dict={\r\n              x: batch_xs,\r\n              y_: batch_ys\r\n          })\r\n        print(\"step = %d, loss = %f\" % (i, loss))\r\n      end = time.time()\r\n      elapsed = (end - start)\r\n      print(\"Time elapsed: \", elapsed, \" seconds\" )\r\n\r\n      # Test trained model\r\n      if i == train_loops-1:\r\n        print(\"Accuracy: \", sess.run(\r\n          accuracy, feed_dict={\r\n            x: mnist.test.images,\r\n            y_: mnist.test.labels\r\n          }))\r\n```"}