{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396385448", "html_url": "https://github.com/tensorflow/tensorflow/issues/19657#issuecomment-396385448", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19657", "id": 396385448, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjM4NTQ0OA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-11T20:59:48Z", "updated_at": "2018-06-11T20:59:48Z", "author_association": "MEMBER", "body_html": "<p>Apologies for the delayed response. Yup, <code>tf.data.Dataset.from_tensor_slices(x)</code> will embed <code>x</code> as a constant tensor inside the graph. With the dataset size you're describing, using an initializable iterator (as you suggested) with a placeholder would be more appropriate. Something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\ndata <span class=\"pl-k\">=</span> tf.placeholder(tf.float32)\nds <span class=\"pl-k\">=</span> tf.data.Dataset.from_tensor_slices(data)\nitr <span class=\"pl-k\">=</span> ds.make_initializable_iterator()\n<span class=\"pl-c1\">next</span> <span class=\"pl-k\">=</span> itr.get_next()\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Feed the data when initializing the iterator</span>\n  sess.run(itr.initializer, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{data: np.random.rand(<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">100</span>)})\n  <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n    <span class=\"pl-c1\">print</span>(sess.run(<span class=\"pl-c1\">next</span>))</pre></div>\n<p>Without the placeholder, the tensor content ends up in the graph def. With <code>one_shot_iterator</code>, it ends up in the graph def twice.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1072079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jsimsa\">@jsimsa</a> : Perhaps the documentation could be enhanced to make this more obvious?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=30874603\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/samsamoa\">@samsamoa</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1250236\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fogelton\">@fogelton</a> : Does this sound reasonable?</p>", "body_text": "Apologies for the delayed response. Yup, tf.data.Dataset.from_tensor_slices(x) will embed x as a constant tensor inside the graph. With the dataset size you're describing, using an initializable iterator (as you suggested) with a placeholder would be more appropriate. Something like this:\nimport tensorflow as tf\nimport numpy as np\n\ndata = tf.placeholder(tf.float32)\nds = tf.data.Dataset.from_tensor_slices(data)\nitr = ds.make_initializable_iterator()\nnext = itr.get_next()\n\nwith tf.Session() as sess:\n  # Feed the data when initializing the iterator\n  sess.run(itr.initializer, feed_dict={data: np.random.rand(100, 100)})\n  for _ in range(10):\n    print(sess.run(next))\nWithout the placeholder, the tensor content ends up in the graph def. With one_shot_iterator, it ends up in the graph def twice.\n@mrry @jsimsa : Perhaps the documentation could be enhanced to make this more obvious?\n@samsamoa @fogelton : Does this sound reasonable?", "body": "Apologies for the delayed response. Yup, `tf.data.Dataset.from_tensor_slices(x)` will embed `x` as a constant tensor inside the graph. With the dataset size you're describing, using an initializable iterator (as you suggested) with a placeholder would be more appropriate. Something like this:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndata = tf.placeholder(tf.float32)\r\nds = tf.data.Dataset.from_tensor_slices(data)\r\nitr = ds.make_initializable_iterator()\r\nnext = itr.get_next()\r\n\r\nwith tf.Session() as sess:\r\n  # Feed the data when initializing the iterator\r\n  sess.run(itr.initializer, feed_dict={data: np.random.rand(100, 100)})\r\n  for _ in range(10):\r\n    print(sess.run(next))\r\n```\r\n\r\nWithout the placeholder, the tensor content ends up in the graph def. With `one_shot_iterator`, it ends up in the graph def twice.\r\n\r\n@mrry @jsimsa : Perhaps the documentation could be enhanced to make this more obvious?\r\n\r\n@samsamoa @fogelton : Does this sound reasonable?"}