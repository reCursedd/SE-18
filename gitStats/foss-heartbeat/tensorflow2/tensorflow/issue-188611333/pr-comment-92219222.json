{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/92219222", "pull_request_review_id": 12729234, "id": 92219222, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDkyMjE5MjIy", "diff_hunk": "@@ -1481,6 +1483,57 @@ def max_pool2d(inputs,\n \n \n @add_arg_scope\n+def maxout(inputs,\n+           num_units,\n+           axis=None,\n+           outputs_collections=None,\n+           scope=None):\n+  \"\"\"Adds a maxout op from https://arxiv.org/abs/1302.4389\n+\n+    \"Maxout Networks\"\n+\n+    Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, Yoshua\n+    Bengio\n+\n+\n+  Max pooling is performed in given filter/channel dimension. This can also be\n+  used after fully-connected layers to reduce number of features.\n+\n+\n+  Args:\n+    inputs: A Tensor on which maxout will be performed\n+    num_units: Specifies how many features will remain after max pooling at the\n+      channel dimension. This must be multiple of number of channels.\n+    axis: The dimension where max pooling will be performed. Default is the\n+      last dimension.\n+    outputs_collections: The collections to which the outputs are added.\n+    scope: Optional scope for name_scope.\n+\n+  Returns:\n+    A `Tensor` representing the results of the pooling operation.\n+\n+  Raises:\n+    ValueError: if num_units is not multiple of number of features.\n+    \"\"\"\n+  with ops.name_scope(scope, 'MaxOut', [inputs]) as sc:\n+    inputs = ops.convert_to_tensor(inputs)\n+    shape = inputs.get_shape().as_list()\n+    if axis is None:\n+      # Assume that channel is the last dimension\n+      axis = -1\n+    num_channels = shape[axis]\n+    if num_channels % num_units:\n+      raise ValueError('number of features({}) is not '\n+                       'a multiple of num_units({})'\n+              .format(num_channels, num_units))\n+    shape[axis] = -1", "path": "tensorflow/contrib/layers/python/layers/layers.py", "position": 63, "original_position": 63, "commit_id": "0d2d8bd00eb4b70c301ee3e479ef7ed51041f864", "original_commit_id": "0d2d8bd00eb4b70c301ee3e479ef7ed51041f864", "user": {"login": "ilblackdragon", "id": 175486, "node_id": "MDQ6VXNlcjE3NTQ4Ng==", "avatar_url": "https://avatars2.githubusercontent.com/u/175486?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ilblackdragon", "html_url": "https://github.com/ilblackdragon", "followers_url": "https://api.github.com/users/ilblackdragon/followers", "following_url": "https://api.github.com/users/ilblackdragon/following{/other_user}", "gists_url": "https://api.github.com/users/ilblackdragon/gists{/gist_id}", "starred_url": "https://api.github.com/users/ilblackdragon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ilblackdragon/subscriptions", "organizations_url": "https://api.github.com/users/ilblackdragon/orgs", "repos_url": "https://api.github.com/users/ilblackdragon/repos", "events_url": "https://api.github.com/users/ilblackdragon/events{/privacy}", "received_events_url": "https://api.github.com/users/ilblackdragon/received_events", "type": "User", "site_admin": false}, "body": "should it be `= num_units`?\r\n[it's better not to have -1 in reshape, as it's easy to wrongly reshape and not know about it]", "created_at": "2016-12-13T17:18:41Z", "updated_at": "2016-12-13T17:20:13Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/5528#discussion_r92219222", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/5528", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/92219222"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/5528#discussion_r92219222"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/5528"}}, "body_html": "<p>should it be <code>= num_units</code>?<br>\n[it's better not to have -1 in reshape, as it's easy to wrongly reshape and not know about it]</p>", "body_text": "should it be = num_units?\n[it's better not to have -1 in reshape, as it's easy to wrongly reshape and not know about it]"}