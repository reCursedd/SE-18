{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422098405", "html_url": "https://github.com/tensorflow/tensorflow/issues/21358#issuecomment-422098405", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21358", "id": 422098405, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjA5ODQwNQ==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-17T17:18:35Z", "updated_at": "2018-09-17T17:18:35Z", "author_association": "MEMBER", "body_html": "<p>The <code>CUDA_VISIBILE_DEVICES</code> environment variable controls the GPUs that are visible to TensorFlow (or really any CUDA library).</p>\n<p>The names of devices in TensorFlow (<code>\"/gpu:0\") are assigned in serial order based on what is visible. Thus, when you set </code>CUDA_VISIBLE_DEVICES=1<code>, then the TensorFlow device name \"/gpu:0\" corresponds to it (since it is referring to the one and only device visible to TensorFlow). As mentioned above, you should be able to see the physical device where things are happening via </code>nvidia-smi`.</p>\n<p>I'm tempted to close this out (since when <code>CUDA_VISIBLE_DEVICES</code> is set, then no CUDA library client  can know of the existence of non-visible devices anyway, or so I think).</p>\n<p>Feel free to reopen if I'm misunderstood.<br>\nThanks.</p>", "body_text": "The CUDA_VISIBILE_DEVICES environment variable controls the GPUs that are visible to TensorFlow (or really any CUDA library).\nThe names of devices in TensorFlow (\"/gpu:0\") are assigned in serial order based on what is visible. Thus, when you set CUDA_VISIBLE_DEVICES=1, then the TensorFlow device name \"/gpu:0\" corresponds to it (since it is referring to the one and only device visible to TensorFlow). As mentioned above, you should be able to see the physical device where things are happening via nvidia-smi`.\nI'm tempted to close this out (since when CUDA_VISIBLE_DEVICES is set, then no CUDA library client  can know of the existence of non-visible devices anyway, or so I think).\nFeel free to reopen if I'm misunderstood.\nThanks.", "body": "The `CUDA_VISIBILE_DEVICES` environment variable controls the GPUs that are visible to TensorFlow (or really any CUDA library).\r\n\r\nThe names of devices in TensorFlow (`\"/gpu:0\") are assigned in serial order based on what is visible. Thus, when you set `CUDA_VISIBLE_DEVICES=1`, then the TensorFlow device name \"/gpu:0\" corresponds to it (since it is referring to the one and only device visible to TensorFlow). As mentioned above, you should be able to see the physical device where things are happening via `nvidia-smi`.\r\n\r\nI'm tempted to close this out (since when `CUDA_VISIBLE_DEVICES` is set, then no CUDA library client  can know of the existence of non-visible devices anyway, or so I think).\r\n\r\nFeel free to reopen if I'm misunderstood.\r\nThanks."}