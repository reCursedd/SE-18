{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/234758443", "pull_request_review_id": 176468916, "id": 234758443, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNDc1ODQ0Mw==", "diff_hunk": "@@ -0,0 +1,400 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// ROCM userspace driver library wrapper functionality.\n+\n+#ifndef TENSORFLOW_STREAM_EXECUTOR_ROCM_ROCM_DRIVER_H_\n+#define TENSORFLOW_STREAM_EXECUTOR_ROCM_ROCM_DRIVER_H_\n+\n+#include <stddef.h>\n+#include \"tensorflow/stream_executor/platform/port.h\"\n+\n+#include \"rocm/include/hip/hip_runtime.h\"\n+#include \"tensorflow/stream_executor/device_options.h\"\n+#include \"tensorflow/stream_executor/lib/status.h\"\n+#include \"tensorflow/stream_executor/lib/statusor.h\"\n+#include \"tensorflow/stream_executor/platform/port.h\"\n+\n+namespace stream_executor {\n+namespace rocm {\n+\n+// Identifies the memory space where an allocation resides. See\n+// ROCMDriver::GetPointerMemorySpace().\n+enum class MemorySpace { kHost, kDevice };\n+\n+// Returns a casual string, such as \"host\" for the provided memory space.\n+string MemorySpaceString(MemorySpace memory_space);\n+\n+// ROCMDriver contains wrappers for calls to the userspace library driver. It's\n+// useful to isolate these calls and put basic wrappers around them to separate\n+// userspace library driver behaviors from the rest of the program.\n+//\n+// At the moment it's simply used as a namespace.\n+//\n+// The calls log any specific errors internally and return whether the operation\n+// was successful to the caller.\n+//\n+// Thread safety: these functions should not be used from signal handlers.\n+class ROCMDriver {", "path": "tensorflow/stream_executor/rocm/rocm_driver.h", "position": 50, "original_position": 50, "commit_id": "9226372134ab2e6b58c8f933391fb693a0f11f1f", "original_commit_id": "9226372134ab2e6b58c8f933391fb693a0f11f1f", "user": {"login": "deven-amd", "id": 36858332, "node_id": "MDQ6VXNlcjM2ODU4MzMy", "avatar_url": "https://avatars2.githubusercontent.com/u/36858332?v=4", "gravatar_id": "", "url": "https://api.github.com/users/deven-amd", "html_url": "https://github.com/deven-amd", "followers_url": "https://api.github.com/users/deven-amd/followers", "following_url": "https://api.github.com/users/deven-amd/following{/other_user}", "gists_url": "https://api.github.com/users/deven-amd/gists{/gist_id}", "starred_url": "https://api.github.com/users/deven-amd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/deven-amd/subscriptions", "organizations_url": "https://api.github.com/users/deven-amd/orgs", "repos_url": "https://api.github.com/users/deven-amd/repos", "events_url": "https://api.github.com/users/deven-amd/events{/privacy}", "received_events_url": "https://api.github.com/users/deven-amd/received_events", "type": "User", "site_admin": false}, "body": "interesting idea about having \r\n- a common `gpu/gpu_driver.h`, \r\n- but implementation specific  `rocm/gpu_driver.cc` and `cuda/gpu_driver.cc` files. \r\n\r\nI had not considered that route...implementation wise it will be cleaner than the `ifdef` route, but I won't be sure it will work, until I code up a working  prototype. Let me do that and get back to you.\r\n\r\n\r\nAssuming we can merge gpu_driver.[h,cpp] as you have suggested above, we will probably need to do down the same route for other classes like CUDAEvent/ROCMEvent.  \r\n\r\nI did prototype a gpu/gpu_event.[h,cc] implementation and currently both the .h and .cc files need `ifdefs` in them. This is because \r\n- the type of the class member `parent_` , and \r\n- the return type of the `cuda_event() / rocm_event()` method \r\n\r\nare both  CUDA/ROCM implementation specific.\r\n\r\n\r\nWe can probably get away with a common `gpu/gpu_event.h` file, but will need separate `rocm/gpu_event.cc` and `cuda/gpu_event.cc` files. \r\n\r\nSo the best case scenario we are looking at is having a bunch of `gpu/*.h` files with their equivalent `.cc` files in the `cuda` / `rocm` dirs.  I am not convinced that this is better that what we have currently.", "created_at": "2018-11-19T19:50:01Z", "updated_at": "2018-11-19T19:50:02Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/22669#discussion_r234758443", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22669", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/234758443"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/22669#discussion_r234758443"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/22669"}}, "body_html": "<p>interesting idea about having</p>\n<ul>\n<li>a common <code>gpu/gpu_driver.h</code>,</li>\n<li>but implementation specific  <code>rocm/gpu_driver.cc</code> and <code>cuda/gpu_driver.cc</code> files.</li>\n</ul>\n<p>I had not considered that route...implementation wise it will be cleaner than the <code>ifdef</code> route, but I won't be sure it will work, until I code up a working  prototype. Let me do that and get back to you.</p>\n<p>Assuming we can merge gpu_driver.[h,cpp] as you have suggested above, we will probably need to do down the same route for other classes like CUDAEvent/ROCMEvent.</p>\n<p>I did prototype a gpu/gpu_event.[h,cc] implementation and currently both the .h and .cc files need <code>ifdefs</code> in them. This is because</p>\n<ul>\n<li>the type of the class member <code>parent_</code> , and</li>\n<li>the return type of the <code>cuda_event() / rocm_event()</code> method</li>\n</ul>\n<p>are both  CUDA/ROCM implementation specific.</p>\n<p>We can probably get away with a common <code>gpu/gpu_event.h</code> file, but will need separate <code>rocm/gpu_event.cc</code> and <code>cuda/gpu_event.cc</code> files.</p>\n<p>So the best case scenario we are looking at is having a bunch of <code>gpu/*.h</code> files with their equivalent <code>.cc</code> files in the <code>cuda</code> / <code>rocm</code> dirs.  I am not convinced that this is better that what we have currently.</p>", "body_text": "interesting idea about having\n\na common gpu/gpu_driver.h,\nbut implementation specific  rocm/gpu_driver.cc and cuda/gpu_driver.cc files.\n\nI had not considered that route...implementation wise it will be cleaner than the ifdef route, but I won't be sure it will work, until I code up a working  prototype. Let me do that and get back to you.\nAssuming we can merge gpu_driver.[h,cpp] as you have suggested above, we will probably need to do down the same route for other classes like CUDAEvent/ROCMEvent.\nI did prototype a gpu/gpu_event.[h,cc] implementation and currently both the .h and .cc files need ifdefs in them. This is because\n\nthe type of the class member parent_ , and\nthe return type of the cuda_event() / rocm_event() method\n\nare both  CUDA/ROCM implementation specific.\nWe can probably get away with a common gpu/gpu_event.h file, but will need separate rocm/gpu_event.cc and cuda/gpu_event.cc files.\nSo the best case scenario we are looking at is having a bunch of gpu/*.h files with their equivalent .cc files in the cuda / rocm dirs.  I am not convinced that this is better that what we have currently.", "in_reply_to_id": 230946354}