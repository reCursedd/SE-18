{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/190424509", "html_url": "https://github.com/tensorflow/tensorflow/issues/1317#issuecomment-190424509", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1317", "id": 190424509, "node_id": "MDEyOklzc3VlQ29tbWVudDE5MDQyNDUwOQ==", "user": {"login": "lukaszkaiser", "id": 684901, "node_id": "MDQ6VXNlcjY4NDkwMQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/684901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lukaszkaiser", "html_url": "https://github.com/lukaszkaiser", "followers_url": "https://api.github.com/users/lukaszkaiser/followers", "following_url": "https://api.github.com/users/lukaszkaiser/following{/other_user}", "gists_url": "https://api.github.com/users/lukaszkaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/lukaszkaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lukaszkaiser/subscriptions", "organizations_url": "https://api.github.com/users/lukaszkaiser/orgs", "repos_url": "https://api.github.com/users/lukaszkaiser/repos", "events_url": "https://api.github.com/users/lukaszkaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/lukaszkaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2016-02-29T22:21:21Z", "updated_at": "2016-02-29T22:21:21Z", "author_association": "MEMBER", "body_html": "<p>In some sense the reuse checks in tf.get_variable are indeed superfluous -- one could, as you say, just always create non-existent variables regardless of the reuse-check setting (and get rid of reuse).</p>\n<p>When designing variable_scope we discussed this issue at length. The decision to enforce reuse-checks was motivated by a history of research model development. It happened a few times that people trained models that had more variables than they thought, exactly because these parameters were silently created in the way you suggest. The models still gave reasonable results, so the problem was hard to debug -- but the results with proper reuse were much better. Taking this into account we decided to enforce reuse checks quite strictly. But it's python -- it's easy to disable the checks if you want to, e.g., like this.</p>\n<pre><code>def unsafe_get_variable(name, ...):\n  try tf.get_variable(name, ...)\n  except _:\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n      tf.get_variable(name, ...)\n</code></pre>\n<p>But it's a dangerous road, the checks can save you some debugging later, so consider not disabling them.</p>", "body_text": "In some sense the reuse checks in tf.get_variable are indeed superfluous -- one could, as you say, just always create non-existent variables regardless of the reuse-check setting (and get rid of reuse).\nWhen designing variable_scope we discussed this issue at length. The decision to enforce reuse-checks was motivated by a history of research model development. It happened a few times that people trained models that had more variables than they thought, exactly because these parameters were silently created in the way you suggest. The models still gave reasonable results, so the problem was hard to debug -- but the results with proper reuse were much better. Taking this into account we decided to enforce reuse checks quite strictly. But it's python -- it's easy to disable the checks if you want to, e.g., like this.\ndef unsafe_get_variable(name, ...):\n  try tf.get_variable(name, ...)\n  except _:\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n      tf.get_variable(name, ...)\n\nBut it's a dangerous road, the checks can save you some debugging later, so consider not disabling them.", "body": "In some sense the reuse checks in tf.get_variable are indeed superfluous -- one could, as you say, just always create non-existent variables regardless of the reuse-check setting (and get rid of reuse).\n\nWhen designing variable_scope we discussed this issue at length. The decision to enforce reuse-checks was motivated by a history of research model development. It happened a few times that people trained models that had more variables than they thought, exactly because these parameters were silently created in the way you suggest. The models still gave reasonable results, so the problem was hard to debug -- but the results with proper reuse were much better. Taking this into account we decided to enforce reuse checks quite strictly. But it's python -- it's easy to disable the checks if you want to, e.g., like this.\n\n```\ndef unsafe_get_variable(name, ...):\n  try tf.get_variable(name, ...)\n  except _:\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n      tf.get_variable(name, ...)\n```\n\nBut it's a dangerous road, the checks can save you some debugging later, so consider not disabling them.\n"}