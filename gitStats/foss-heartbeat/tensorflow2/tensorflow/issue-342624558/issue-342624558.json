{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20960", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20960/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20960/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20960/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20960", "id": 342624558, "node_id": "MDU6SXNzdWUzNDI2MjQ1NTg=", "number": 20960, "title": "Placeholder will cause incompelet shape bug in tf.profiler.profile", "user": {"login": "caffett", "id": 11462215, "node_id": "MDQ6VXNlcjExNDYyMjE1", "avatar_url": "https://avatars2.githubusercontent.com/u/11462215?v=4", "gravatar_id": "", "url": "https://api.github.com/users/caffett", "html_url": "https://github.com/caffett", "followers_url": "https://api.github.com/users/caffett/followers", "following_url": "https://api.github.com/users/caffett/following{/other_user}", "gists_url": "https://api.github.com/users/caffett/gists{/gist_id}", "starred_url": "https://api.github.com/users/caffett/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/caffett/subscriptions", "organizations_url": "https://api.github.com/users/caffett/orgs", "repos_url": "https://api.github.com/users/caffett/repos", "events_url": "https://api.github.com/users/caffett/events{/privacy}", "received_events_url": "https://api.github.com/users/caffett/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-07-19T08:15:33Z", "updated_at": "2018-08-20T22:25:17Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 18.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.8.0-0-g93bc2e2072 1.8.0</li>\n<li><strong>Python version</strong>: Python 3.6.5 (default, Apr  1 2018, 05:46:30)</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>: Please run the code in Source code / logs section.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/profile_model_architecture.md#profile-model-float-operations\">documentation</a> tells us that</p>\n<blockquote>\n<p>It is suggested to pass in -run_meta_path if shape is only known during runtime. tfprof can fill in the missing shape with the runtime shape information from RunMetadata.</p>\n</blockquote>\n<p>It cannot work when the graphs contain <code>placeholder</code>.<br>\nThe reason is that the node name of placeholder in RunMetadata is different from its name in graph_def.<br>\nThe bug will be reproduced in the next section.</p>\n<h3>Source code / logs</h3>\n<p>The code reproduce the bug</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> The code reproduce the bug</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\nX <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">3</span>), <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>X<span class=\"pl-pds\">'</span></span>)\ny <span class=\"pl-k\">=</span> tf.constant([[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>],\n                 [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>],\n                 [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>]], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nmul_op <span class=\"pl-k\">=</span> tf.matmul(X, y)\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    x <span class=\"pl-k\">=</span> np.random.random([<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>])\n\n    tf.profiler.profile(\n        tf.get_default_graph(),\n        <span class=\"pl-v\">cmd</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>op<span class=\"pl-pds\">'</span></span>,\n        <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>tf.profiler.ProfileOptionBuilder.float_operation())\n\n    run_metadata <span class=\"pl-k\">=</span> tf.RunMetadata()\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-c1\">print</span>(sess.run(mul_op, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{X: x},\n                       <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>tf.RunOptions(\n                           <span class=\"pl-v\">trace_level</span><span class=\"pl-k\">=</span>tf.RunOptions.<span class=\"pl-c1\">FULL_TRACE</span>),\n                       <span class=\"pl-v\">run_metadata</span><span class=\"pl-k\">=</span>run_metadata))\n\n    tf.profiler.profile(\n        tf.get_default_graph(),\n        <span class=\"pl-v\">cmd</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>op<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">run_meta</span><span class=\"pl-k\">=</span>run_metadata,\n        <span class=\"pl-v\">options</span><span class=\"pl-k\">=</span>tf.profiler.ProfileOptionBuilder.float_operation())\n</pre></div>\n<p>The output is</p>\n<pre><code>1 ops no flops stats due to incomplete shapes.\nParsing Inputs...\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\n\n======================End of Report==========================\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n2018-07-19 03:34:30.726274: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n[[1.4957699 2.9915397 4.48731   5.9830794]\n [2.083395  4.16679   6.2501845 8.33358  ]]\nParsing Inputs...\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\n\n======================End of Report==========================\n</code></pre>\n<p>When I first call the tf.profiler.profile, I do not pass run_metadata to it. Therefore, here should be the <code>incomplete shape</code>. However, it does not make sense that it still reports the <code>Incomplete shape</code> even if I pass the run_matadata to call the tf.profiler.profile again.</p>\n<p>I think the problem is that the node name of placeholder in RunMetadata is different with its name in graph_def.  I traced the code until <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/tfprof_logger.py#L46\">here</a>, and printed the 'run_meta' and 'graph_def'.<br>\nThe output is</p>\n<pre lang=\"pdb\"><code>(Pdb) p run_meta\nstep_stats {\n  dev_stats {\n    device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n    node_stats {\n      node_name: \"_SOURCE\"\n      all_start_micros: 1531987298848369\n      op_start_rel_micros: 2\n      op_end_rel_micros: 3\n      all_end_rel_micros: 9\n      memory {\n        allocator_name: \"cpu\"\n      }\n      timeline_label: \"_SOURCE = NoOp()\"\n      scheduled_micros: 1531987298848358\n      memory_stats {\n      }\n    }\n    node_stats {\n      node_name: \"_arg_X_0_0\"\n      all_start_micros: 1531987298848383\n      op_end_rel_micros: 2\n      all_end_rel_micros: 7\n      memory {\n        allocator_name: \"cpu\"\n      }\n      output {\n        tensor_description {\n          dtype: DT_FLOAT\n          shape {\n            dim {\n              size: 2\n            }\n            dim {\n              size: 3\n            }\n          }\n          allocation_description {\n            requested_bytes: 24\n            allocator_name: \"cpu\"\n          }\n        }\n      }\n      timeline_label: \"_arg_X_0_0 = _Arg()\"\n      scheduled_micros: 1531987298848378\n      memory_stats {\n      }\n    }\n    node_stats {\n      node_name: \"Const\"\n      all_start_micros: 1531987298848391\n      op_end_rel_micros: 3\n      all_end_rel_micros: 4\n      memory {\n        allocator_name: \"cpu\"\n      }\n      output {\n        tensor_description {\n          dtype: DT_FLOAT\n          shape {\n            dim {\n              size: 3\n            }\n            dim {\n              size: 4\n            }\n          }\n          allocation_description {\n            requested_bytes: 48\n            allocator_name: \"cpu\"\n            ptr: 140275567738880\n          }\n        }\n      }\n      timeline_label: \"Const = Const()\"\n      scheduled_micros: 1531987298848390\n      memory_stats {\n        persistent_memory_size: 48\n      }\n    }\n    node_stats {\n      node_name: \"MatMul\"\n      all_start_micros: 1531987298848396\n      op_end_rel_micros: 69\n      all_end_rel_micros: 72\n      memory {\n        allocator_name: \"cpu\"\n        total_bytes: 32\n        peak_bytes: 32\n        live_bytes: 32\n        allocation_records {\n          alloc_micros: 1531987298848437\n          alloc_bytes: 32\n        }\n      }\n      output {\n        tensor_description {\n          dtype: DT_FLOAT\n          shape {\n            dim {\n              size: 2\n            }\n            dim {\n              size: 4\n            }\n          }\n          allocation_description {\n            requested_bytes: 32\n            allocated_bytes: 32\n            allocator_name: \"cpu\"\n            allocation_id: 1\n            has_single_reference: true\n            ptr: 140275513085952\n          }\n        }\n      }\n      timeline_label: \"MatMul = MatMul(_arg_X_0_0, Const)\"\n      scheduled_micros: 1531987298848395\n      memory_stats {\n      }\n    }\n    node_stats {\n      node_name: \"_retval_MatMul_0_0\"\n      all_start_micros: 1531987298848470\n      op_start_rel_micros: 1\n      op_end_rel_micros: 1\n      all_end_rel_micros: 3\n      memory {\n        allocator_name: \"cpu\"\n      }\n      timeline_label: \"_retval_MatMul_0_0 = _Retval(MatMul)\"\n      scheduled_micros: 1531987298848468\n      memory_stats {\n      }\n    }\n  }\n}\n</code></pre>\n<pre lang=\"pdb\"><code>(Pdb) p graph.as_graph_def()\nnode {\n  name: \"X\"\n  op: \"Placeholder\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"shape\"\n    value {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 3\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"Const\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 3\n          }\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\"\n      }\n    }\n  }\n}\nnode {\n  name: \"MatMul\"\n  op: \"MatMul\"\n  input: \"X\"\n  input: \"Const\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"transpose_a\"\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: \"transpose_b\"\n    value {\n      b: false\n    }\n  }\n}\nversions {\n  producer: 26\n}\n\n</code></pre>\n<p>We can find the node name of placeholder is different in the two output, in the run_meatdata, the node name is <code>_arg_X_0_0</code>, however, it is <code>X</code> in the graph_def.<br>\nAs a result, code <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/tfprof_logger.py#L46\">here</a> will not work properly.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): pip\nTensorFlow version (use command below): v1.8.0-0-g93bc2e2072 1.8.0\nPython version: Python 3.6.5 (default, Apr  1 2018, 05:46:30)\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce: Please run the code in Source code / logs section.\n\nDescribe the problem\nThe documentation tells us that\n\nIt is suggested to pass in -run_meta_path if shape is only known during runtime. tfprof can fill in the missing shape with the runtime shape information from RunMetadata.\n\nIt cannot work when the graphs contain placeholder.\nThe reason is that the node name of placeholder in RunMetadata is different from its name in graph_def.\nThe bug will be reproduced in the next section.\nSource code / logs\nThe code reproduce the bug\n# The code reproduce the bug\nimport tensorflow as tf\nimport numpy as np\n\nX = tf.placeholder(tf.float32, shape=(None, 3), name='X')\ny = tf.constant([[1, 2, 3, 4],\n                 [1, 2, 3, 4],\n                 [1, 2, 3, 4]], dtype=tf.float32)\nmul_op = tf.matmul(X, y)\n\nif __name__ == \"__main__\":\n    x = np.random.random([2, 3])\n\n    tf.profiler.profile(\n        tf.get_default_graph(),\n        cmd='op',\n        options=tf.profiler.ProfileOptionBuilder.float_operation())\n\n    run_metadata = tf.RunMetadata()\n    with tf.Session() as sess:\n        print(sess.run(mul_op, feed_dict={X: x},\n                       options=tf.RunOptions(\n                           trace_level=tf.RunOptions.FULL_TRACE),\n                       run_metadata=run_metadata))\n\n    tf.profiler.profile(\n        tf.get_default_graph(),\n        cmd='op', run_meta=run_metadata,\n        options=tf.profiler.ProfileOptionBuilder.float_operation())\n\nThe output is\n1 ops no flops stats due to incomplete shapes.\nParsing Inputs...\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\n\n======================End of Report==========================\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n2018-07-19 03:34:30.726274: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n[[1.4957699 2.9915397 4.48731   5.9830794]\n [2.083395  4.16679   6.2501845 8.33358  ]]\nParsing Inputs...\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\nIncomplete shape.\nIncomplete shape.\nIncomplete shape.\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\n\n======================End of Report==========================\n\nWhen I first call the tf.profiler.profile, I do not pass run_metadata to it. Therefore, here should be the incomplete shape. However, it does not make sense that it still reports the Incomplete shape even if I pass the run_matadata to call the tf.profiler.profile again.\nI think the problem is that the node name of placeholder in RunMetadata is different with its name in graph_def.  I traced the code until here, and printed the 'run_meta' and 'graph_def'.\nThe output is\n(Pdb) p run_meta\nstep_stats {\n  dev_stats {\n    device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n    node_stats {\n      node_name: \"_SOURCE\"\n      all_start_micros: 1531987298848369\n      op_start_rel_micros: 2\n      op_end_rel_micros: 3\n      all_end_rel_micros: 9\n      memory {\n        allocator_name: \"cpu\"\n      }\n      timeline_label: \"_SOURCE = NoOp()\"\n      scheduled_micros: 1531987298848358\n      memory_stats {\n      }\n    }\n    node_stats {\n      node_name: \"_arg_X_0_0\"\n      all_start_micros: 1531987298848383\n      op_end_rel_micros: 2\n      all_end_rel_micros: 7\n      memory {\n        allocator_name: \"cpu\"\n      }\n      output {\n        tensor_description {\n          dtype: DT_FLOAT\n          shape {\n            dim {\n              size: 2\n            }\n            dim {\n              size: 3\n            }\n          }\n          allocation_description {\n            requested_bytes: 24\n            allocator_name: \"cpu\"\n          }\n        }\n      }\n      timeline_label: \"_arg_X_0_0 = _Arg()\"\n      scheduled_micros: 1531987298848378\n      memory_stats {\n      }\n    }\n    node_stats {\n      node_name: \"Const\"\n      all_start_micros: 1531987298848391\n      op_end_rel_micros: 3\n      all_end_rel_micros: 4\n      memory {\n        allocator_name: \"cpu\"\n      }\n      output {\n        tensor_description {\n          dtype: DT_FLOAT\n          shape {\n            dim {\n              size: 3\n            }\n            dim {\n              size: 4\n            }\n          }\n          allocation_description {\n            requested_bytes: 48\n            allocator_name: \"cpu\"\n            ptr: 140275567738880\n          }\n        }\n      }\n      timeline_label: \"Const = Const()\"\n      scheduled_micros: 1531987298848390\n      memory_stats {\n        persistent_memory_size: 48\n      }\n    }\n    node_stats {\n      node_name: \"MatMul\"\n      all_start_micros: 1531987298848396\n      op_end_rel_micros: 69\n      all_end_rel_micros: 72\n      memory {\n        allocator_name: \"cpu\"\n        total_bytes: 32\n        peak_bytes: 32\n        live_bytes: 32\n        allocation_records {\n          alloc_micros: 1531987298848437\n          alloc_bytes: 32\n        }\n      }\n      output {\n        tensor_description {\n          dtype: DT_FLOAT\n          shape {\n            dim {\n              size: 2\n            }\n            dim {\n              size: 4\n            }\n          }\n          allocation_description {\n            requested_bytes: 32\n            allocated_bytes: 32\n            allocator_name: \"cpu\"\n            allocation_id: 1\n            has_single_reference: true\n            ptr: 140275513085952\n          }\n        }\n      }\n      timeline_label: \"MatMul = MatMul(_arg_X_0_0, Const)\"\n      scheduled_micros: 1531987298848395\n      memory_stats {\n      }\n    }\n    node_stats {\n      node_name: \"_retval_MatMul_0_0\"\n      all_start_micros: 1531987298848470\n      op_start_rel_micros: 1\n      op_end_rel_micros: 1\n      all_end_rel_micros: 3\n      memory {\n        allocator_name: \"cpu\"\n      }\n      timeline_label: \"_retval_MatMul_0_0 = _Retval(MatMul)\"\n      scheduled_micros: 1531987298848468\n      memory_stats {\n      }\n    }\n  }\n}\n\n(Pdb) p graph.as_graph_def()\nnode {\n  name: \"X\"\n  op: \"Placeholder\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"shape\"\n    value {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 3\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"Const\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 3\n          }\n          dim {\n            size: 4\n          }\n        }\n        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\"\n      }\n    }\n  }\n}\nnode {\n  name: \"MatMul\"\n  op: \"MatMul\"\n  input: \"X\"\n  input: \"Const\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"transpose_a\"\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: \"transpose_b\"\n    value {\n      b: false\n    }\n  }\n}\nversions {\n  producer: 26\n}\n\n\nWe can find the node name of placeholder is different in the two output, in the run_meatdata, the node name is _arg_X_0_0, however, it is X in the graph_def.\nAs a result, code here will not work properly.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0\r\n- **Python version**: Python 3.6.5 (default, Apr  1 2018, 05:46:30)\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Please run the code in Source code / logs section.\r\n\r\n\r\n### Describe the problem\r\nThe [documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/profile_model_architecture.md#profile-model-float-operations) tells us that\r\n> It is suggested to pass in -run_meta_path if shape is only known during runtime. tfprof can fill in the missing shape with the runtime shape information from RunMetadata. \r\n\r\nIt cannot work when the graphs contain `placeholder`.  \r\nThe reason is that the node name of placeholder in RunMetadata is different from its name in graph_def.  \r\nThe bug will be reproduced in the next section.\r\n\r\n### Source code / logs\r\nThe code reproduce the bug  \r\n```python   \r\n# The code reproduce the bug\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nX = tf.placeholder(tf.float32, shape=(None, 3), name='X')\r\ny = tf.constant([[1, 2, 3, 4],\r\n                 [1, 2, 3, 4],\r\n                 [1, 2, 3, 4]], dtype=tf.float32)\r\nmul_op = tf.matmul(X, y)\r\n\r\nif __name__ == \"__main__\":\r\n    x = np.random.random([2, 3])\r\n\r\n    tf.profiler.profile(\r\n        tf.get_default_graph(),\r\n        cmd='op',\r\n        options=tf.profiler.ProfileOptionBuilder.float_operation())\r\n\r\n    run_metadata = tf.RunMetadata()\r\n    with tf.Session() as sess:\r\n        print(sess.run(mul_op, feed_dict={X: x},\r\n                       options=tf.RunOptions(\r\n                           trace_level=tf.RunOptions.FULL_TRACE),\r\n                       run_metadata=run_metadata))\r\n\r\n    tf.profiler.profile(\r\n        tf.get_default_graph(),\r\n        cmd='op', run_meta=run_metadata,\r\n        options=tf.profiler.ProfileOptionBuilder.float_operation())\r\n\r\n```\r\nThe output is  \r\n```\r\n1 ops no flops stats due to incomplete shapes.\r\nParsing Inputs...\r\nIncomplete shape.\r\nIncomplete shape.\r\nIncomplete shape.\r\n\r\n=========================Options=============================\r\n-max_depth                  10000\r\n-min_bytes                  0\r\n-min_peak_bytes             0\r\n-min_residual_bytes         0\r\n-min_output_bytes           0\r\n-min_micros                 0\r\n-min_accelerator_micros     0\r\n-min_cpu_micros             0\r\n-min_params                 0\r\n-min_float_ops              1\r\n-min_occurrence             0\r\n-step                       -1\r\n-order_by                   float_ops\r\n-account_type_regexes       .*\r\n-start_name_regexes         .*\r\n-trim_name_regexes          \r\n-show_name_regexes          .*\r\n-hide_name_regexes          \r\n-account_displayed_op_only  true\r\n-select                     float_ops\r\n-output                     stdout:\r\n\r\n==================Model Analysis Report======================\r\n\r\nDoc:\r\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\r\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\r\n\r\nProfile:\r\nnode name | # float_ops\r\n\r\n======================End of Report==========================\r\nIncomplete shape.\r\nIncomplete shape.\r\nIncomplete shape.\r\n2018-07-19 03:34:30.726274: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n[[1.4957699 2.9915397 4.48731   5.9830794]\r\n [2.083395  4.16679   6.2501845 8.33358  ]]\r\nParsing Inputs...\r\nIncomplete shape.\r\nIncomplete shape.\r\nIncomplete shape.\r\n\r\n=========================Options=============================\r\n-max_depth                  10000\r\n-min_bytes                  0\r\n-min_peak_bytes             0\r\n-min_residual_bytes         0\r\n-min_output_bytes           0\r\n-min_micros                 0\r\n-min_accelerator_micros     0\r\n-min_cpu_micros             0\r\n-min_params                 0\r\n-min_float_ops              1\r\n-min_occurrence             0\r\n-step                       -1\r\n-order_by                   float_ops\r\n-account_type_regexes       .*\r\n-start_name_regexes         .*\r\n-trim_name_regexes          \r\n-show_name_regexes          .*\r\n-hide_name_regexes          \r\n-account_displayed_op_only  true\r\n-select                     float_ops\r\n-output                     stdout:\r\n\r\n==================Model Analysis Report======================\r\nIncomplete shape.\r\nIncomplete shape.\r\nIncomplete shape.\r\n\r\nDoc:\r\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\r\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\r\n\r\nProfile:\r\nnode name | # float_ops\r\n\r\n======================End of Report==========================\r\n```\r\nWhen I first call the tf.profiler.profile, I do not pass run_metadata to it. Therefore, here should be the `incomplete shape`. However, it does not make sense that it still reports the `Incomplete shape` even if I pass the run_matadata to call the tf.profiler.profile again. \r\n\r\nI think the problem is that the node name of placeholder in RunMetadata is different with its name in graph_def.  I traced the code until [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/tfprof_logger.py#L46), and printed the 'run_meta' and 'graph_def'.  \r\nThe output is  \r\n```pdb  \r\n(Pdb) p run_meta\r\nstep_stats {\r\n  dev_stats {\r\n    device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\r\n    node_stats {\r\n      node_name: \"_SOURCE\"\r\n      all_start_micros: 1531987298848369\r\n      op_start_rel_micros: 2\r\n      op_end_rel_micros: 3\r\n      all_end_rel_micros: 9\r\n      memory {\r\n        allocator_name: \"cpu\"\r\n      }\r\n      timeline_label: \"_SOURCE = NoOp()\"\r\n      scheduled_micros: 1531987298848358\r\n      memory_stats {\r\n      }\r\n    }\r\n    node_stats {\r\n      node_name: \"_arg_X_0_0\"\r\n      all_start_micros: 1531987298848383\r\n      op_end_rel_micros: 2\r\n      all_end_rel_micros: 7\r\n      memory {\r\n        allocator_name: \"cpu\"\r\n      }\r\n      output {\r\n        tensor_description {\r\n          dtype: DT_FLOAT\r\n          shape {\r\n            dim {\r\n              size: 2\r\n            }\r\n            dim {\r\n              size: 3\r\n            }\r\n          }\r\n          allocation_description {\r\n            requested_bytes: 24\r\n            allocator_name: \"cpu\"\r\n          }\r\n        }\r\n      }\r\n      timeline_label: \"_arg_X_0_0 = _Arg()\"\r\n      scheduled_micros: 1531987298848378\r\n      memory_stats {\r\n      }\r\n    }\r\n    node_stats {\r\n      node_name: \"Const\"\r\n      all_start_micros: 1531987298848391\r\n      op_end_rel_micros: 3\r\n      all_end_rel_micros: 4\r\n      memory {\r\n        allocator_name: \"cpu\"\r\n      }\r\n      output {\r\n        tensor_description {\r\n          dtype: DT_FLOAT\r\n          shape {\r\n            dim {\r\n              size: 3\r\n            }\r\n            dim {\r\n              size: 4\r\n            }\r\n          }\r\n          allocation_description {\r\n            requested_bytes: 48\r\n            allocator_name: \"cpu\"\r\n            ptr: 140275567738880\r\n          }\r\n        }\r\n      }\r\n      timeline_label: \"Const = Const()\"\r\n      scheduled_micros: 1531987298848390\r\n      memory_stats {\r\n        persistent_memory_size: 48\r\n      }\r\n    }\r\n    node_stats {\r\n      node_name: \"MatMul\"\r\n      all_start_micros: 1531987298848396\r\n      op_end_rel_micros: 69\r\n      all_end_rel_micros: 72\r\n      memory {\r\n        allocator_name: \"cpu\"\r\n        total_bytes: 32\r\n        peak_bytes: 32\r\n        live_bytes: 32\r\n        allocation_records {\r\n          alloc_micros: 1531987298848437\r\n          alloc_bytes: 32\r\n        }\r\n      }\r\n      output {\r\n        tensor_description {\r\n          dtype: DT_FLOAT\r\n          shape {\r\n            dim {\r\n              size: 2\r\n            }\r\n            dim {\r\n              size: 4\r\n            }\r\n          }\r\n          allocation_description {\r\n            requested_bytes: 32\r\n            allocated_bytes: 32\r\n            allocator_name: \"cpu\"\r\n            allocation_id: 1\r\n            has_single_reference: true\r\n            ptr: 140275513085952\r\n          }\r\n        }\r\n      }\r\n      timeline_label: \"MatMul = MatMul(_arg_X_0_0, Const)\"\r\n      scheduled_micros: 1531987298848395\r\n      memory_stats {\r\n      }\r\n    }\r\n    node_stats {\r\n      node_name: \"_retval_MatMul_0_0\"\r\n      all_start_micros: 1531987298848470\r\n      op_start_rel_micros: 1\r\n      op_end_rel_micros: 1\r\n      all_end_rel_micros: 3\r\n      memory {\r\n        allocator_name: \"cpu\"\r\n      }\r\n      timeline_label: \"_retval_MatMul_0_0 = _Retval(MatMul)\"\r\n      scheduled_micros: 1531987298848468\r\n      memory_stats {\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n```pdb    \r\n(Pdb) p graph.as_graph_def()\r\nnode {\r\n  name: \"X\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Const\"\r\n  op: \"Const\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"value\"\r\n    value {\r\n      tensor {\r\n        dtype: DT_FLOAT\r\n        tensor_shape {\r\n          dim {\r\n            size: 3\r\n          }\r\n          dim {\r\n            size: 4\r\n          }\r\n        }\r\n        tensor_content: \"\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\\000\\000\\200?\\000\\000\\000@\\000\\000@@\\000\\000\\200@\"\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"MatMul\"\r\n  op: \"MatMul\"\r\n  input: \"X\"\r\n  input: \"Const\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_a\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n  attr {\r\n    key: \"transpose_b\"\r\n    value {\r\n      b: false\r\n    }\r\n  }\r\n}\r\nversions {\r\n  producer: 26\r\n}\r\n\r\n```\r\n\r\nWe can find the node name of placeholder is different in the two output, in the run_meatdata, the node name is `_arg_X_0_0`, however, it is `X` in the graph_def. \r\nAs a result, code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/tfprof_logger.py#L46) will not work properly."}