{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/311155561", "html_url": "https://github.com/tensorflow/tensorflow/issues/6666#issuecomment-311155561", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6666", "id": 311155561, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMTE1NTU2MQ==", "user": {"login": "gabrielleyr", "id": 11844767, "node_id": "MDQ6VXNlcjExODQ0NzY3", "avatar_url": "https://avatars2.githubusercontent.com/u/11844767?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gabrielleyr", "html_url": "https://github.com/gabrielleyr", "followers_url": "https://api.github.com/users/gabrielleyr/followers", "following_url": "https://api.github.com/users/gabrielleyr/following{/other_user}", "gists_url": "https://api.github.com/users/gabrielleyr/gists{/gist_id}", "starred_url": "https://api.github.com/users/gabrielleyr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gabrielleyr/subscriptions", "organizations_url": "https://api.github.com/users/gabrielleyr/orgs", "repos_url": "https://api.github.com/users/gabrielleyr/repos", "events_url": "https://api.github.com/users/gabrielleyr/events{/privacy}", "received_events_url": "https://api.github.com/users/gabrielleyr/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-26T19:18:10Z", "updated_at": "2017-06-26T19:36:01Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> How would you suggest saving a Queue if the full dataset is not used at the point of saving? In that case, we need to keep the state of the Queue so it doesn't see the same old data again on restoring. If we save a .meta and restore the saver as in saver.restore(sess, tf.train.latest_checkpoint(\"./model/\")), will that save the Queue state?<br>\nAlternatively, if I use the method from <a href=\"http://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/\" rel=\"nofollow\">http://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/</a> of a slice_input_producer and tf.train.batch instead of a RandomShuffleQueue, do these have savable parameters that save the queue's place in the data so they can be safely reloaded with a Checkpoint?</p>", "body_text": "@yaroslavvb How would you suggest saving a Queue if the full dataset is not used at the point of saving? In that case, we need to keep the state of the Queue so it doesn't see the same old data again on restoring. If we save a .meta and restore the saver as in saver.restore(sess, tf.train.latest_checkpoint(\"./model/\")), will that save the Queue state?\nAlternatively, if I use the method from http://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/ of a slice_input_producer and tf.train.batch instead of a RandomShuffleQueue, do these have savable parameters that save the queue's place in the data so they can be safely reloaded with a Checkpoint?", "body": "@yaroslavvb How would you suggest saving a Queue if the full dataset is not used at the point of saving? In that case, we need to keep the state of the Queue so it doesn't see the same old data again on restoring. If we save a .meta and restore the saver as in saver.restore(sess, tf.train.latest_checkpoint(\"./model/\")), will that save the Queue state? \r\nAlternatively, if I use the method from http://ischlag.github.io/2016/06/19/tensorflow-input-pipeline-example/ of a slice_input_producer and tf.train.batch instead of a RandomShuffleQueue, do these have savable parameters that save the queue's place in the data so they can be safely reloaded with a Checkpoint? "}