{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318084041", "html_url": "https://github.com/tensorflow/tensorflow/issues/10669#issuecomment-318084041", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10669", "id": 318084041, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODA4NDA0MQ==", "user": {"login": "July-Morning", "id": 26812149, "node_id": "MDQ6VXNlcjI2ODEyMTQ5", "avatar_url": "https://avatars1.githubusercontent.com/u/26812149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/July-Morning", "html_url": "https://github.com/July-Morning", "followers_url": "https://api.github.com/users/July-Morning/followers", "following_url": "https://api.github.com/users/July-Morning/following{/other_user}", "gists_url": "https://api.github.com/users/July-Morning/gists{/gist_id}", "starred_url": "https://api.github.com/users/July-Morning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/July-Morning/subscriptions", "organizations_url": "https://api.github.com/users/July-Morning/orgs", "repos_url": "https://api.github.com/users/July-Morning/repos", "events_url": "https://api.github.com/users/July-Morning/events{/privacy}", "received_events_url": "https://api.github.com/users/July-Morning/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-26T15:11:26Z", "updated_at": "2017-07-26T15:11:26Z", "author_association": "NONE", "body_html": "<p>More questions than answers for now:</p>\n<ol>\n<li>\n<p>I tried memmapping of the frozen graph with convert_graphdef_memmapped_format, but when trying to load mapped frozen graph I get parse/reading errors both in C++ (ReadBinaryProto) and Python (import_graph_def). Should I do memmapping before or after freezing the graph? Haven't tried the second option cause I have initial graph.pb in text, not binary format.</p>\n</li>\n<li>\n<p>Is there a working example of saving model into SavedModel? I found <a href=\"https://github.com/tensorflow/serving/tree/master/tensorflow_serving/example\">these</a>, but it is not really clear what to do with FasterRCNN-like architecture (which is my case), when one has also bounding boxes as output and may have more that one input. Specifically I am confused with tf.saved_model.signature_constants.</p>\n</li>\n</ol>", "body_text": "More questions than answers for now:\n\n\nI tried memmapping of the frozen graph with convert_graphdef_memmapped_format, but when trying to load mapped frozen graph I get parse/reading errors both in C++ (ReadBinaryProto) and Python (import_graph_def). Should I do memmapping before or after freezing the graph? Haven't tried the second option cause I have initial graph.pb in text, not binary format.\n\n\nIs there a working example of saving model into SavedModel? I found these, but it is not really clear what to do with FasterRCNN-like architecture (which is my case), when one has also bounding boxes as output and may have more that one input. Specifically I am confused with tf.saved_model.signature_constants.", "body": "More questions than answers for now:\r\n\r\n1) I tried memmapping of the frozen graph with convert_graphdef_memmapped_format, but when trying to load mapped frozen graph I get parse/reading errors both in C++ (ReadBinaryProto) and Python (import_graph_def). Should I do memmapping before or after freezing the graph? Haven't tried the second option cause I have initial graph.pb in text, not binary format.\r\n\r\n2) Is there a working example of saving model into SavedModel? I found [these](https://github.com/tensorflow/serving/tree/master/tensorflow_serving/example), but it is not really clear what to do with FasterRCNN-like architecture (which is my case), when one has also bounding boxes as output and may have more that one input. Specifically I am confused with tf.saved_model.signature_constants."}