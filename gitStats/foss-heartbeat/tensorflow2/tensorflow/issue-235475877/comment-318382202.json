{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/318382202", "html_url": "https://github.com/tensorflow/tensorflow/issues/10669#issuecomment-318382202", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10669", "id": 318382202, "node_id": "MDEyOklzc3VlQ29tbWVudDMxODM4MjIwMg==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-27T14:39:24Z", "updated_at": "2017-07-27T14:39:24Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">In general the first run of a tensorflow session is slower as a lot of\nonce-only computation gets performed (graph pruning, GPU set up, etc)</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Thu, Jul 27, 2017 at 7:31 AM, July-Morning ***@***.***&gt; wrote:\n Well, I managed to save my model in SavedModel format and load it back in\n Python, but running time is as slow as while using a frozen graph.\n\n Here is how I save my model:\n ` export_path = './saved_model' + str(datetime.now()) + '/'\n builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n\n tensor_info_im = tf.saved_model.utils.build_tensor_info(model.image_input)\n tensor_info_pr = tf.saved_model.utils.build_tensor_info(model.keep_prob)\n tensor_info_bb = tf.saved_model.utils.build_tensor_info(model.det_boxes)\n tensor_info_sc = tf.saved_model.utils.build_tensor_info(model.det_probs)\n\n prediction_signature = (\n     tf.saved_model.signature_def_utils.build_signature_def(\n         inputs={'image_input:0': tensor_info_im, 'keep_prob:0':tensor_info_pr},\n         outputs={'bbox/trimming/bbox:0': tensor_info_bb, 'probability/score:0': tensor_info_sc},\n         method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n builder.add_meta_graph_and_variables(\n     sess, [tf.saved_model.tag_constants.SERVING],\n     signature_def_map={'predict': prediction_signature}, clear_devices = True)\n\n builder.save()\n\n `\n\n And this is how I load it:\n tf.saved_model.loader.load(sess, [\"serve\"], export_dir)\n\n Is something wrong here?\n\n Something else that I noticed: when I am running a restored tf session in\n a loop, first two runs are approximately as slow as with frozen graph or\n SavedModel. However after that it gets much (2x-3x) faster.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"235475877\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/10669\" href=\"https://github.com/tensorflow/tensorflow/issues/10669#issuecomment-318378089\">#10669 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAATxWmtdA8CkqkSFd3zC_I4AEbbCEnOks5sSJ8qgaJpZM4N4KAA\">https://github.com/notifications/unsubscribe-auth/AAATxWmtdA8CkqkSFd3zC_I4AEbbCEnOks5sSJ8qgaJpZM4N4KAA</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n<div class=\"email-signature-reply\">-- \n - Alex</div>\n</div>", "body_text": "In general the first run of a tensorflow session is slower as a lot of\nonce-only computation gets performed (graph pruning, GPU set up, etc)\n\u2026\nOn Thu, Jul 27, 2017 at 7:31 AM, July-Morning ***@***.***> wrote:\n Well, I managed to save my model in SavedModel format and load it back in\n Python, but running time is as slow as while using a frozen graph.\n\n Here is how I save my model:\n ` export_path = './saved_model' + str(datetime.now()) + '/'\n builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n\n tensor_info_im = tf.saved_model.utils.build_tensor_info(model.image_input)\n tensor_info_pr = tf.saved_model.utils.build_tensor_info(model.keep_prob)\n tensor_info_bb = tf.saved_model.utils.build_tensor_info(model.det_boxes)\n tensor_info_sc = tf.saved_model.utils.build_tensor_info(model.det_probs)\n\n prediction_signature = (\n     tf.saved_model.signature_def_utils.build_signature_def(\n         inputs={'image_input:0': tensor_info_im, 'keep_prob:0':tensor_info_pr},\n         outputs={'bbox/trimming/bbox:0': tensor_info_bb, 'probability/score:0': tensor_info_sc},\n         method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n builder.add_meta_graph_and_variables(\n     sess, [tf.saved_model.tag_constants.SERVING],\n     signature_def_map={'predict': prediction_signature}, clear_devices = True)\n\n builder.save()\n\n `\n\n And this is how I load it:\n tf.saved_model.loader.load(sess, [\"serve\"], export_dir)\n\n Is something wrong here?\n\n Something else that I noticed: when I am running a restored tf session in\n a loop, first two runs are approximately as slow as with frozen graph or\n SavedModel. However after that it gets much (2x-3x) faster.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#10669 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAATxWmtdA8CkqkSFd3zC_I4AEbbCEnOks5sSJ8qgaJpZM4N4KAA>\n .\n\n\n-- \n - Alex", "body": "In general the first run of a tensorflow session is slower as a lot of\nonce-only computation gets performed (graph pruning, GPU set up, etc)\n\nOn Thu, Jul 27, 2017 at 7:31 AM, July-Morning <notifications@github.com>\nwrote:\n\n> Well, I managed to save my model in SavedModel format and load it back in\n> Python, but running time is as slow as while using a frozen graph.\n>\n> Here is how I save my model:\n> ` export_path = './saved_model' + str(datetime.now()) + '/'\n> builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n>\n> tensor_info_im = tf.saved_model.utils.build_tensor_info(model.image_input)\n> tensor_info_pr = tf.saved_model.utils.build_tensor_info(model.keep_prob)\n> tensor_info_bb = tf.saved_model.utils.build_tensor_info(model.det_boxes)\n> tensor_info_sc = tf.saved_model.utils.build_tensor_info(model.det_probs)\n>\n> prediction_signature = (\n>     tf.saved_model.signature_def_utils.build_signature_def(\n>         inputs={'image_input:0': tensor_info_im, 'keep_prob:0':tensor_info_pr},\n>         outputs={'bbox/trimming/bbox:0': tensor_info_bb, 'probability/score:0': tensor_info_sc},\n>         method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n> builder.add_meta_graph_and_variables(\n>     sess, [tf.saved_model.tag_constants.SERVING],\n>     signature_def_map={'predict': prediction_signature}, clear_devices = True)\n>\n> builder.save()\n>\n> `\n>\n> And this is how I load it:\n> tf.saved_model.loader.load(sess, [\"serve\"], export_dir)\n>\n> Is something wrong here?\n>\n> Something else that I noticed: when I am running a restored tf session in\n> a loop, first two runs are approximately as slow as with frozen graph or\n> SavedModel. However after that it gets much (2x-3x) faster.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10669#issuecomment-318378089>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxWmtdA8CkqkSFd3zC_I4AEbbCEnOks5sSJ8qgaJpZM4N4KAA>\n> .\n>\n\n\n\n-- \n - Alex\n"}