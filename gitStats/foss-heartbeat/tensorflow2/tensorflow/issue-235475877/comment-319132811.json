{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/319132811", "html_url": "https://github.com/tensorflow/tensorflow/issues/10669#issuecomment-319132811", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10669", "id": 319132811, "node_id": "MDEyOklzc3VlQ29tbWVudDMxOTEzMjgxMQ==", "user": {"login": "July-Morning", "id": 26812149, "node_id": "MDQ6VXNlcjI2ODEyMTQ5", "avatar_url": "https://avatars1.githubusercontent.com/u/26812149?v=4", "gravatar_id": "", "url": "https://api.github.com/users/July-Morning", "html_url": "https://github.com/July-Morning", "followers_url": "https://api.github.com/users/July-Morning/followers", "following_url": "https://api.github.com/users/July-Morning/following{/other_user}", "gists_url": "https://api.github.com/users/July-Morning/gists{/gist_id}", "starred_url": "https://api.github.com/users/July-Morning/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/July-Morning/subscriptions", "organizations_url": "https://api.github.com/users/July-Morning/orgs", "repos_url": "https://api.github.com/users/July-Morning/repos", "events_url": "https://api.github.com/users/July-Morning/events{/privacy}", "received_events_url": "https://api.github.com/users/July-Morning/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-31T17:08:43Z", "updated_at": "2017-07-31T17:08:43Z", "author_association": "NONE", "body_html": "<p>Oh, I see. I will try to sum up shortly how it was and here we are now.</p>\n<ol>\n<li>I noticed that when I was loading frozen graph with C++ API tf session ran twice slower than in Python. I created a MNIST benchmark as an example, but <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alextp\">@alextp</a> showed that there was a stupid mistake in time measurement. So, for MNIST everything was fine (however, for my initial more complicated net it was not) and I closed the issue for a while.</li>\n</ol>\n<p><strong>From this moment on MNIST benchmark was not used, all experiments were done on another net.</strong></p>\n<ol start=\"2\">\n<li>When I came back to this problem, I noticed that I have that slowdown even if I load frozen graph with standard Python API. Thus, <strong>the issue seemed to be not in C++ API</strong>.</li>\n</ol>\n<p><strong>From this moment on I was using Python only!</strong></p>\n<ol start=\"3\">\n<li>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> advised me to try using SavedModel instead of freezing the graph, and I did (not sure if perfectly correct, but it worked) and got the same deceleration.</p>\n</li>\n<li>\n<p>I have run my scripts on another computer (with GPU) and got the same difference in time, so it does not seem to be an operation system or a specific build issue.</p>\n</li>\n</ol>\n<p><strong>So now the problem is as follows:<br>\nI have real-time performance when I am using restored model, but I get a 2-3x slowdown when I am trying to load either frozen graph or SavedModel. The question is: why (or what am I doing wrong) and how to get rid of this effect?</strong><br>\nModel files and python scripts can be found here:<br>\n<a href=\"https://github.com/July-Morning/Tensorflow_model_utils\">https://github.com/July-Morning/Tensorflow_model_utils</a></p>\n<p>Please let me know if it would be better to open another issue after all this mess.</p>", "body_text": "Oh, I see. I will try to sum up shortly how it was and here we are now.\n\nI noticed that when I was loading frozen graph with C++ API tf session ran twice slower than in Python. I created a MNIST benchmark as an example, but @alextp showed that there was a stupid mistake in time measurement. So, for MNIST everything was fine (however, for my initial more complicated net it was not) and I closed the issue for a while.\n\nFrom this moment on MNIST benchmark was not used, all experiments were done on another net.\n\nWhen I came back to this problem, I noticed that I have that slowdown even if I load frozen graph with standard Python API. Thus, the issue seemed to be not in C++ API.\n\nFrom this moment on I was using Python only!\n\n\n@yaroslavvb advised me to try using SavedModel instead of freezing the graph, and I did (not sure if perfectly correct, but it worked) and got the same deceleration.\n\n\nI have run my scripts on another computer (with GPU) and got the same difference in time, so it does not seem to be an operation system or a specific build issue.\n\n\nSo now the problem is as follows:\nI have real-time performance when I am using restored model, but I get a 2-3x slowdown when I am trying to load either frozen graph or SavedModel. The question is: why (or what am I doing wrong) and how to get rid of this effect?\nModel files and python scripts can be found here:\nhttps://github.com/July-Morning/Tensorflow_model_utils\nPlease let me know if it would be better to open another issue after all this mess.", "body": "Oh, I see. I will try to sum up shortly how it was and here we are now.\r\n\r\n1.  I noticed that when I was loading frozen graph with C++ API tf session ran twice slower than in Python. I created a MNIST benchmark as an example, but @alextp showed that there was a stupid mistake in time measurement. So, for MNIST everything was fine (however, for my initial more complicated net it was not) and I closed the issue for a while.\r\n\r\n**From this moment on MNIST benchmark was not used, all experiments were done on another net.**\r\n\r\n2. When I came back to this problem, I noticed that I have that slowdown even if I load frozen graph with standard Python API. Thus, **the issue seemed to be not in C++ API**.\r\n\r\n**From this moment on I was using Python only!**\r\n\r\n3. @yaroslavvb advised me to try using SavedModel instead of freezing the graph, and I did (not sure if perfectly correct, but it worked) and got the same deceleration.\r\n\r\n4. I have run my scripts on another computer (with GPU) and got the same difference in time, so it does not seem to be an operation system or a specific build issue. \r\n\r\n**So now the problem is as follows:\r\nI have real-time performance when I am using restored model, but I get a 2-3x slowdown when I am trying to load either frozen graph or SavedModel. The question is: why (or what am I doing wrong) and how to get rid of this effect?**\r\nModel files and python scripts can be found here:\r\nhttps://github.com/July-Morning/Tensorflow_model_utils\r\n\r\nPlease let me know if it would be better to open another issue after all this mess."}