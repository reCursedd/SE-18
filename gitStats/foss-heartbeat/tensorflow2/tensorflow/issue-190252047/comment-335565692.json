{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/335565692", "html_url": "https://github.com/tensorflow/tensorflow/issues/5688#issuecomment-335565692", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5688", "id": 335565692, "node_id": "MDEyOklzc3VlQ29tbWVudDMzNTU2NTY5Mg==", "user": {"login": "yzhwang", "id": 1002405, "node_id": "MDQ6VXNlcjEwMDI0MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1002405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yzhwang", "html_url": "https://github.com/yzhwang", "followers_url": "https://api.github.com/users/yzhwang/followers", "following_url": "https://api.github.com/users/yzhwang/following{/other_user}", "gists_url": "https://api.github.com/users/yzhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yzhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yzhwang/subscriptions", "organizations_url": "https://api.github.com/users/yzhwang/orgs", "repos_url": "https://api.github.com/users/yzhwang/repos", "events_url": "https://api.github.com/users/yzhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/yzhwang/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-10T18:29:37Z", "updated_at": "2017-10-10T18:29:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23520507\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/HggsHntr\">@HggsHntr</a> , thanks for the info! Since we do not have any Windows machine with Pascal/Maxwell card, I will provide some suggestions on how to further debugging the issue:</p>\n<ol>\n<li>os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'<br>\nor type:<br>\nset TF_CUDNN_USE_AUTOTUNE=0<br>\nThis will disable the autotune on convolutions, and force all cudnn convolution calls to use the default algorithm.<br>\nIf this doesn't solve the problem, that means it is not related to conv3d backprop op and must be other CUDA issues. I can tell you where to go from there. If this solves the problem, then it means that during the profiling of one of the internal cudnn kernels, there was some kernel launch error. I'm working on an extensive test suite for cudnn's convolution algorithms to help us spot which internal algorithm caused the problem. Before I release that tool, there is a hacky way to do it yourself though, you could try the following two things:</li>\n<li>Add cuda synchronization code and error checking code after each cudnnConvolutionBackwardFilter call:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L3398\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L3398</a><br>\nThe code can be something like this:</li>\n</ol>\n<pre><code>cudaThreadSynchronize();                                                                                                              \ncudaError_t err = cudaPeekAtLastError();\nif (err != cudaSuccess) {\n  LOG(FATAL) &lt;&lt; \"kernel launch error: \" &lt;&lt; err;\n}\n</code></pre>\n<ol start=\"2\">\n<li>Modify this function to get only one internal kernel for cudnnConvolutionBackwardFilter and test which one caused the failure:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L2540\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L2540</a><br>\nEither way, if you manage to reproduce the bug in TensorFlow, I will write a standalone cudnn C++ reproducer according to your shape and internal algorithm used and file it to NVIDIA. Let me know if that sounds OK to you. Another way is to wait for the extensive cudnn test tool I'm working on. I should be able to finish it before November.</li>\n</ol>", "body_text": "Hi @HggsHntr , thanks for the info! Since we do not have any Windows machine with Pascal/Maxwell card, I will provide some suggestions on how to further debugging the issue:\n\nos.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\nor type:\nset TF_CUDNN_USE_AUTOTUNE=0\nThis will disable the autotune on convolutions, and force all cudnn convolution calls to use the default algorithm.\nIf this doesn't solve the problem, that means it is not related to conv3d backprop op and must be other CUDA issues. I can tell you where to go from there. If this solves the problem, then it means that during the profiling of one of the internal cudnn kernels, there was some kernel launch error. I'm working on an extensive test suite for cudnn's convolution algorithms to help us spot which internal algorithm caused the problem. Before I release that tool, there is a hacky way to do it yourself though, you could try the following two things:\nAdd cuda synchronization code and error checking code after each cudnnConvolutionBackwardFilter call:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L3398\nThe code can be something like this:\n\ncudaThreadSynchronize();                                                                                                              \ncudaError_t err = cudaPeekAtLastError();\nif (err != cudaSuccess) {\n  LOG(FATAL) << \"kernel launch error: \" << err;\n}\n\n\nModify this function to get only one internal kernel for cudnnConvolutionBackwardFilter and test which one caused the failure:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L2540\nEither way, if you manage to reproduce the bug in TensorFlow, I will write a standalone cudnn C++ reproducer according to your shape and internal algorithm used and file it to NVIDIA. Let me know if that sounds OK to you. Another way is to wait for the extensive cudnn test tool I'm working on. I should be able to finish it before November.", "body": "Hi @HggsHntr , thanks for the info! Since we do not have any Windows machine with Pascal/Maxwell card, I will provide some suggestions on how to further debugging the issue:\r\n1) os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\r\nor type:\r\nset TF_CUDNN_USE_AUTOTUNE=0\r\nThis will disable the autotune on convolutions, and force all cudnn convolution calls to use the default algorithm.\r\nIf this doesn't solve the problem, that means it is not related to conv3d backprop op and must be other CUDA issues. I can tell you where to go from there. If this solves the problem, then it means that during the profiling of one of the internal cudnn kernels, there was some kernel launch error. I'm working on an extensive test suite for cudnn's convolution algorithms to help us spot which internal algorithm caused the problem. Before I release that tool, there is a hacky way to do it yourself though, you could try the following two things:\r\n1) Add cuda synchronization code and error checking code after each cudnnConvolutionBackwardFilter call:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L3398\r\nThe code can be something like this:\r\n```\r\ncudaThreadSynchronize();                                                                                                              \r\ncudaError_t err = cudaPeekAtLastError();\r\nif (err != cudaSuccess) {\r\n  LOG(FATAL) << \"kernel launch error: \" << err;\r\n}\r\n```\r\n\r\n2) Modify this function to get only one internal kernel for cudnnConvolutionBackwardFilter and test which one caused the failure:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L2540\r\nEither way, if you manage to reproduce the bug in TensorFlow, I will write a standalone cudnn C++ reproducer according to your shape and internal algorithm used and file it to NVIDIA. Let me know if that sounds OK to you. Another way is to wait for the extensive cudnn test tool I'm working on. I should be able to finish it before November."}