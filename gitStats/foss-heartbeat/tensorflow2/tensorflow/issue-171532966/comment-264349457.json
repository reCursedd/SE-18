{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/264349457", "html_url": "https://github.com/tensorflow/tensorflow/issues/3862#issuecomment-264349457", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3862", "id": 264349457, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDM0OTQ1Nw==", "user": {"login": "khaotik", "id": 6271084, "node_id": "MDQ6VXNlcjYyNzEwODQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/6271084?v=4", "gravatar_id": "", "url": "https://api.github.com/users/khaotik", "html_url": "https://github.com/khaotik", "followers_url": "https://api.github.com/users/khaotik/followers", "following_url": "https://api.github.com/users/khaotik/following{/other_user}", "gists_url": "https://api.github.com/users/khaotik/gists{/gist_id}", "starred_url": "https://api.github.com/users/khaotik/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/khaotik/subscriptions", "organizations_url": "https://api.github.com/users/khaotik/orgs", "repos_url": "https://api.github.com/users/khaotik/repos", "events_url": "https://api.github.com/users/khaotik/events{/privacy}", "received_events_url": "https://api.github.com/users/khaotik/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-02T01:37:14Z", "updated_at": "2016-12-02T01:51:33Z", "author_association": "NONE", "body_html": "<p>A fast O(n) solution.<br>\nAssume the input vector <code>x</code> and the upstream gradient <code>g</code> has the form:</p>\n<pre><code>x = [x1 x2 x3 ... xn, 0, -, -, ...]\ng = [g1 g2 g3 ... gn, gnp1, -, -, ...]\n</code></pre>\n<p><code>-</code> Elements are irrelevant in this computation because the leftmost 0 cause <code>cumprod</code> become 0 after that.</p>\n<p>The downstream gradient is:</p>\n<pre><code>[ dx1 ... dx &lt;use unsafe method&gt; ] + [ cumprod(x1,x2,x3...xn) * gnp1 ] + [0, 0, 0 ... 0]\n</code></pre>\n<p>To gain full speedup, the forward computation should record the index of first occurrence of <code>0</code>, and automatically <code>memset(0)</code> for the results after that. This optimization is unique to <code>cumprod</code> and can't be done to <code>cumsum</code>. The backward computation can just use that index to quickly do the job.</p>\n<p>Maybe it's a good idea to modify <code>cumprod</code> interface to <code>def cumprod(input, use_unsafe_grad=False)</code>, so that user can force unsafe method if it can ensure no zero elements in input.</p>\n<p>So far, this is useful in Deepmind's DNC model because it has a <code>cumprod</code> which often encounters zero.</p>\n<p>Sorry, not familiar with C++, so no PR yet.</p>", "body_text": "A fast O(n) solution.\nAssume the input vector x and the upstream gradient g has the form:\nx = [x1 x2 x3 ... xn, 0, -, -, ...]\ng = [g1 g2 g3 ... gn, gnp1, -, -, ...]\n\n- Elements are irrelevant in this computation because the leftmost 0 cause cumprod become 0 after that.\nThe downstream gradient is:\n[ dx1 ... dx <use unsafe method> ] + [ cumprod(x1,x2,x3...xn) * gnp1 ] + [0, 0, 0 ... 0]\n\nTo gain full speedup, the forward computation should record the index of first occurrence of 0, and automatically memset(0) for the results after that. This optimization is unique to cumprod and can't be done to cumsum. The backward computation can just use that index to quickly do the job.\nMaybe it's a good idea to modify cumprod interface to def cumprod(input, use_unsafe_grad=False), so that user can force unsafe method if it can ensure no zero elements in input.\nSo far, this is useful in Deepmind's DNC model because it has a cumprod which often encounters zero.\nSorry, not familiar with C++, so no PR yet.", "body": "A fast O(n) solution.\r\nAssume the input vector `x` and the upstream gradient `g` has the form:\r\n```\r\nx = [x1 x2 x3 ... xn, 0, -, -, ...]\r\ng = [g1 g2 g3 ... gn, gnp1, -, -, ...]\r\n```\r\n`-` Elements are irrelevant in this computation because the leftmost 0 cause `cumprod` become 0 after that.\r\n\r\nThe downstream gradient is:\r\n```\r\n[ dx1 ... dx <use unsafe method> ] + [ cumprod(x1,x2,x3...xn) * gnp1 ] + [0, 0, 0 ... 0]\r\n```\r\n\r\nTo gain full speedup, the forward computation should record the index of first occurrence of `0`, and automatically `memset(0)` for the results after that. This optimization is unique to `cumprod` and can't be done to `cumsum`. The backward computation can just use that index to quickly do the job.\r\n\r\nMaybe it's a good idea to modify `cumprod` interface to `def cumprod(input, use_unsafe_grad=False)`, so that user can force unsafe method if it can ensure no zero elements in input.\r\n\r\nSo far, this is useful in Deepmind's DNC model because it has a `cumprod` which often encounters zero.\r\n\r\nSorry, not familiar with C++, so no PR yet."}