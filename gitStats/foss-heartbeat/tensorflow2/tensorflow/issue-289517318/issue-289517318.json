{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16213", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16213/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16213/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16213/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16213", "id": 289517318, "node_id": "MDU6SXNzdWUyODk1MTczMTg=", "number": 16213, "title": "Non-chief replicas freeze after chief completes training", "user": {"login": "c8h10n4o2ed", "id": 7761076, "node_id": "MDQ6VXNlcjc3NjEwNzY=", "avatar_url": "https://avatars1.githubusercontent.com/u/7761076?v=4", "gravatar_id": "", "url": "https://api.github.com/users/c8h10n4o2ed", "html_url": "https://github.com/c8h10n4o2ed", "followers_url": "https://api.github.com/users/c8h10n4o2ed/followers", "following_url": "https://api.github.com/users/c8h10n4o2ed/following{/other_user}", "gists_url": "https://api.github.com/users/c8h10n4o2ed/gists{/gist_id}", "starred_url": "https://api.github.com/users/c8h10n4o2ed/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/c8h10n4o2ed/subscriptions", "organizations_url": "https://api.github.com/users/c8h10n4o2ed/orgs", "repos_url": "https://api.github.com/users/c8h10n4o2ed/repos", "events_url": "https://api.github.com/users/c8h10n4o2ed/events{/privacy}", "received_events_url": "https://api.github.com/users/c8h10n4o2ed/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-01-18T06:20:25Z", "updated_at": "2018-05-03T23:58:27Z", "closed_at": "2018-05-03T23:58:27Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.4.0-19-ga52c8d9, 1.4.1</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 6.0</li>\n<li><strong>GPU model and memory</strong>: Titan X (Pascal), 12 GiB</li>\n<li><strong>Exact command to reproduce</strong>: Custom Script</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Non-chief replicas freeze after chief completes training, when in synchronous mode.<br>\nThe problem appears to occur immediately after the chief shuts down.</p>\n<p>See attached source code for a complete example of multi-GPU demonstrating the problem on a toy dataset. Modify the cluster variable and start the PS first, followed by workers then the chief node last. This is somewhat broken out in run_distributed.sh.</p>\n<p><code>sv = tf.train.Supervisor( is_chief=(FLAGS.task_index == 0), global_step = global_step, init_op = init_op ) ... with sv.prepare_or_wait_for_session(server.target, config=config) as sess: # is chief if FLAGS.task_index == 0: sv.start_queue_runners(sess, [chief_queue_runner]) sess.run(init_token_op) ...</code></p>\n<h3>Source code / logs</h3>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/1641799/rnn-multi-gpu.zip\">rnn-multi-gpu.zip</a></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): v1.4.0-19-ga52c8d9, 1.4.1\nPython version: 2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 6.0\nGPU model and memory: Titan X (Pascal), 12 GiB\nExact command to reproduce: Custom Script\n\nDescribe the problem\nNon-chief replicas freeze after chief completes training, when in synchronous mode.\nThe problem appears to occur immediately after the chief shuts down.\nSee attached source code for a complete example of multi-GPU demonstrating the problem on a toy dataset. Modify the cluster variable and start the PS first, followed by workers then the chief node last. This is somewhat broken out in run_distributed.sh.\nsv = tf.train.Supervisor( is_chief=(FLAGS.task_index == 0), global_step = global_step, init_op = init_op ) ... with sv.prepare_or_wait_for_session(server.target, config=config) as sess: # is chief if FLAGS.task_index == 0: sv.start_queue_runners(sess, [chief_queue_runner]) sess.run(init_token_op) ...\nSource code / logs\nrnn-multi-gpu.zip", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9, 1.4.1\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 6.0\r\n- **GPU model and memory**: Titan X (Pascal), 12 GiB\r\n- **Exact command to reproduce**: Custom Script\r\n\r\n### Describe the problem\r\nNon-chief replicas freeze after chief completes training, when in synchronous mode.\r\nThe problem appears to occur immediately after the chief shuts down.\r\n\r\nSee attached source code for a complete example of multi-GPU demonstrating the problem on a toy dataset. Modify the cluster variable and start the PS first, followed by workers then the chief node last. This is somewhat broken out in run_distributed.sh.\r\n\r\n``\r\n        sv = tf.train.Supervisor(\r\n            is_chief=(FLAGS.task_index == 0),\r\n            global_step = global_step,\r\n            init_op = init_op\r\n        )\r\n        ...\r\n        with sv.prepare_or_wait_for_session(server.target, config=config) as sess:\r\n            # is chief\r\n            if FLAGS.task_index == 0:\r\n                sv.start_queue_runners(sess, [chief_queue_runner])\r\n                sess.run(init_token_op)\r\n        ...\r\n``\r\n\r\n### Source code / logs\r\n[rnn-multi-gpu.zip](https://github.com/tensorflow/tensorflow/files/1641799/rnn-multi-gpu.zip)\r\n\r\n"}