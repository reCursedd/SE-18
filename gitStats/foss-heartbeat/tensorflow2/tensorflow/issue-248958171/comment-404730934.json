{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404730934", "html_url": "https://github.com/tensorflow/tensorflow/issues/12132#issuecomment-404730934", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12132", "id": 404730934, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDczMDkzNA==", "user": {"login": "sharvil10", "id": 18349036, "node_id": "MDQ6VXNlcjE4MzQ5MDM2", "avatar_url": "https://avatars0.githubusercontent.com/u/18349036?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sharvil10", "html_url": "https://github.com/sharvil10", "followers_url": "https://api.github.com/users/sharvil10/followers", "following_url": "https://api.github.com/users/sharvil10/following{/other_user}", "gists_url": "https://api.github.com/users/sharvil10/gists{/gist_id}", "starred_url": "https://api.github.com/users/sharvil10/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sharvil10/subscriptions", "organizations_url": "https://api.github.com/users/sharvil10/orgs", "repos_url": "https://api.github.com/users/sharvil10/repos", "events_url": "https://api.github.com/users/sharvil10/events{/privacy}", "received_events_url": "https://api.github.com/users/sharvil10/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-13T05:37:57Z", "updated_at": "2018-07-13T05:37:57Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17768094\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/stengoes\">@stengoes</a> In your code you've used convolution's associative property by combining the filters of separable convolution and 1x1 convolution assuming that both operation does not use non linearity. After that, you have used this effective filter to convolve with the original input image. This entire operation is taking less time as the first combining operation is applied on much smaller tensors(filters) compared to the other approach(depth separable conv using native functions.). However, this assumption  of linearity does not hold as we do use relu after separable convolution and also the 1x1 convolution in the original MobileNetv1. So, you cannot use the <strong>normal</strong> method. I have edited your code and added the relu after each operation. It should give you an assertion error at line <strong>np.testing.assert_almost_equal(norm, sep, decimal=3)</strong> when you try to run it.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> time\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Define a scenario</span>\nbatch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\nchannels <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\nimage_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">32</span>\nfeature_maps <span class=\"pl-k\">=</span> <span class=\"pl-c1\">64</span>\nfilter_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">15</span>\ndepthwise_filters <span class=\"pl-k\">=</span> <span class=\"pl-c1\">8</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Dummy images</span>\nimages <span class=\"pl-k\">=</span> tf.random_normal(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[batch_size, channels, image_size, image_size], \n                          <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Filter definitions</span>\nbasis_filters <span class=\"pl-k\">=</span> tf.random_normal(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[filter_size, filter_size, channels, depthwise_filters], \n                                 <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\ncoeffs <span class=\"pl-k\">=</span> tf.random_normal(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[channels, depthwise_filters, feature_maps], \n                          <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Normal method</span>\neffective_filters <span class=\"pl-k\">=</span> tf.einsum(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>hwcm,cmn-&gt;hwcn<span class=\"pl-pds\">'</span></span>, basis_filters, coeffs)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>nm = tf.Print(effective_filters, [effective_filters], message=\"This is a: \")</span>\nnormal <span class=\"pl-k\">=</span> tf.nn.conv2d(images, \n                      effective_filters, \n                      <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>], \n                      <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SAME<span class=\"pl-pds\">\"</span></span>, \n                      <span class=\"pl-v\">use_cudnn_on_gpu</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, \n                      <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>NCHW<span class=\"pl-pds\">\"</span></span>\n                      )\nnormal <span class=\"pl-k\">=</span> tf.nn.relu(normal)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Separable method</span>\ndepthwise <span class=\"pl-k\">=</span> tf.nn.depthwise_conv2d_native(images, \n                                          basis_filters, \n                                          <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>], \n                                          <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>SAME<span class=\"pl-pds\">\"</span></span>, \n                                          <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>NCHW<span class=\"pl-pds\">\"</span></span>,\n                                          )\ndepthwise <span class=\"pl-k\">=</span> tf.nn.relu(depthwise)\ncoeffs <span class=\"pl-k\">=</span> tf.reshape(coeffs, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, channels<span class=\"pl-k\">*</span>depthwise_filters, feature_maps])\n\nseparable <span class=\"pl-k\">=</span> tf.nn.conv2d(depthwise, \n                         coeffs, \n                         <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">1</span>], \n                         <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>VALID<span class=\"pl-pds\">\"</span></span>, \n                         <span class=\"pl-v\">use_cudnn_on_gpu</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, \n                         <span class=\"pl-v\">data_format</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>NCHW<span class=\"pl-pds\">\"</span></span>,\n                         )\nseparable <span class=\"pl-k\">=</span> tf.nn.relu(separable)\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Assert equality of the different methods</span>\n    norm, sep <span class=\"pl-k\">=</span> sess.run([normal, separable])\n    np.testing.assert_almost_equal(norm, sep, <span class=\"pl-v\">decimal</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">3</span>)\n\n    repeats <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Benchmark normal method</span>\n    start <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(repeats):\n        _ <span class=\"pl-k\">=</span> sess.run(normal)\n    end <span class=\"pl-k\">=</span> time.time()\n    d1 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>((end <span class=\"pl-k\">-</span> start) <span class=\"pl-k\">/</span> repeats <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1000</span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Benchmark seperable method</span>\n    start <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> _ <span class=\"pl-k\">in</span> <span class=\"pl-v\">xrange</span>(repeats):\n        _ <span class=\"pl-k\">=</span> sess.run(separable)\n    end <span class=\"pl-k\">=</span> time.time()\n    d2 <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>((end <span class=\"pl-k\">-</span> start) <span class=\"pl-k\">/</span> repeats <span class=\"pl-k\">*</span> <span class=\"pl-c1\">1000</span>)\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Print results</span>\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Normal method: <span class=\"pl-c1\">{}</span>ms <span class=\"pl-cce\">\\t</span> Separable method: <span class=\"pl-c1\">{}</span>ms<span class=\"pl-pds\">\"</span></span>.format(d1, d2))\n    writer.close()</pre></div>", "body_text": "@stengoes In your code you've used convolution's associative property by combining the filters of separable convolution and 1x1 convolution assuming that both operation does not use non linearity. After that, you have used this effective filter to convolve with the original input image. This entire operation is taking less time as the first combining operation is applied on much smaller tensors(filters) compared to the other approach(depth separable conv using native functions.). However, this assumption  of linearity does not hold as we do use relu after separable convolution and also the 1x1 convolution in the original MobileNetv1. So, you cannot use the normal method. I have edited your code and added the relu after each operation. It should give you an assertion error at line np.testing.assert_almost_equal(norm, sep, decimal=3) when you try to run it.\nimport tensorflow as tf\nimport numpy as np\nimport time\n\n# Define a scenario\nbatch_size = 64\nchannels = 32\nimage_size = 32\nfeature_maps = 64\nfilter_size = 15\ndepthwise_filters = 8\n\n# Dummy images\nimages = tf.random_normal(shape=[batch_size, channels, image_size, image_size], \n                          dtype=tf.float32)\n\n# Filter definitions\nbasis_filters = tf.random_normal(shape=[filter_size, filter_size, channels, depthwise_filters], \n                                 dtype=tf.float32)\ncoeffs = tf.random_normal(shape=[channels, depthwise_filters, feature_maps], \n                          dtype=tf.float32)\n\n# Normal method\neffective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\n#nm = tf.Print(effective_filters, [effective_filters], message=\"This is a: \")\nnormal = tf.nn.conv2d(images, \n                      effective_filters, \n                      strides=[1, 1, 1, 1], \n                      padding=\"SAME\", \n                      use_cudnn_on_gpu=True, \n                      data_format=\"NCHW\"\n                      )\nnormal = tf.nn.relu(normal)\n# Separable method\ndepthwise = tf.nn.depthwise_conv2d_native(images, \n                                          basis_filters, \n                                          strides=[1, 1, 1, 1], \n                                          padding=\"SAME\", \n                                          data_format=\"NCHW\",\n                                          )\ndepthwise = tf.nn.relu(depthwise)\ncoeffs = tf.reshape(coeffs, [1, 1, channels*depthwise_filters, feature_maps])\n\nseparable = tf.nn.conv2d(depthwise, \n                         coeffs, \n                         strides=[1, 1, 1, 1], \n                         padding=\"VALID\", \n                         use_cudnn_on_gpu=True, \n                         data_format=\"NCHW\",\n                         )\nseparable = tf.nn.relu(separable)\nwith tf.Session() as sess:\n    # Assert equality of the different methods\n    norm, sep = sess.run([normal, separable])\n    np.testing.assert_almost_equal(norm, sep, decimal=3)\n\n    repeats = 100\n\n    # Benchmark normal method\n    start = time.time()\n    for _ in xrange(repeats):\n        _ = sess.run(normal)\n    end = time.time()\n    d1 = int((end - start) / repeats * 1000)\n\n    # Benchmark seperable method\n    start = time.time()\n    for _ in xrange(repeats):\n        _ = sess.run(separable)\n    end = time.time()\n    d2 = int((end - start) / repeats * 1000)\n\n    # Print results\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\n    writer.close()", "body": "@stengoes In your code you've used convolution's associative property by combining the filters of separable convolution and 1x1 convolution assuming that both operation does not use non linearity. After that, you have used this effective filter to convolve with the original input image. This entire operation is taking less time as the first combining operation is applied on much smaller tensors(filters) compared to the other approach(depth separable conv using native functions.). However, this assumption  of linearity does not hold as we do use relu after separable convolution and also the 1x1 convolution in the original MobileNetv1. So, you cannot use the **normal** method. I have edited your code and added the relu after each operation. It should give you an assertion error at line **np.testing.assert_almost_equal(norm, sep, decimal=3)** when you try to run it.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n# Define a scenario\r\nbatch_size = 64\r\nchannels = 32\r\nimage_size = 32\r\nfeature_maps = 64\r\nfilter_size = 15\r\ndepthwise_filters = 8\r\n\r\n# Dummy images\r\nimages = tf.random_normal(shape=[batch_size, channels, image_size, image_size], \r\n                          dtype=tf.float32)\r\n\r\n# Filter definitions\r\nbasis_filters = tf.random_normal(shape=[filter_size, filter_size, channels, depthwise_filters], \r\n                                 dtype=tf.float32)\r\ncoeffs = tf.random_normal(shape=[channels, depthwise_filters, feature_maps], \r\n                          dtype=tf.float32)\r\n\r\n# Normal method\r\neffective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\n#nm = tf.Print(effective_filters, [effective_filters], message=\"This is a: \")\r\nnormal = tf.nn.conv2d(images, \r\n                      effective_filters, \r\n                      strides=[1, 1, 1, 1], \r\n                      padding=\"SAME\", \r\n                      use_cudnn_on_gpu=True, \r\n                      data_format=\"NCHW\"\r\n                      )\r\nnormal = tf.nn.relu(normal)\r\n# Separable method\r\ndepthwise = tf.nn.depthwise_conv2d_native(images, \r\n                                          basis_filters, \r\n                                          strides=[1, 1, 1, 1], \r\n                                          padding=\"SAME\", \r\n                                          data_format=\"NCHW\",\r\n                                          )\r\ndepthwise = tf.nn.relu(depthwise)\r\ncoeffs = tf.reshape(coeffs, [1, 1, channels*depthwise_filters, feature_maps])\r\n\r\nseparable = tf.nn.conv2d(depthwise, \r\n                         coeffs, \r\n                         strides=[1, 1, 1, 1], \r\n                         padding=\"VALID\", \r\n                         use_cudnn_on_gpu=True, \r\n                         data_format=\"NCHW\",\r\n                         )\r\nseparable = tf.nn.relu(separable)\r\nwith tf.Session() as sess:\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=3)\r\n\r\n    repeats = 100\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in xrange(repeats):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d2 = int((end - start) / repeats * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\r\n    writer.close()\r\n``` "}