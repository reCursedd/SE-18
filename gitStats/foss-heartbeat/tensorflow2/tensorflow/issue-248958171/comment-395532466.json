{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/395532466", "html_url": "https://github.com/tensorflow/tensorflow/issues/12132#issuecomment-395532466", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12132", "id": 395532466, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTUzMjQ2Ng==", "user": {"login": "kyle-dorman", "id": 2000807, "node_id": "MDQ6VXNlcjIwMDA4MDc=", "avatar_url": "https://avatars1.githubusercontent.com/u/2000807?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kyle-dorman", "html_url": "https://github.com/kyle-dorman", "followers_url": "https://api.github.com/users/kyle-dorman/followers", "following_url": "https://api.github.com/users/kyle-dorman/following{/other_user}", "gists_url": "https://api.github.com/users/kyle-dorman/gists{/gist_id}", "starred_url": "https://api.github.com/users/kyle-dorman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kyle-dorman/subscriptions", "organizations_url": "https://api.github.com/users/kyle-dorman/orgs", "repos_url": "https://api.github.com/users/kyle-dorman/repos", "events_url": "https://api.github.com/users/kyle-dorman/events{/privacy}", "received_events_url": "https://api.github.com/users/kyle-dorman/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-07T19:11:04Z", "updated_at": "2018-06-07T19:13:29Z", "author_association": "NONE", "body_html": "<p>I was also previously having issues with the speed of separable convolutions but it was because of how I was using them. The effectiveness of separable convolutions compared to normal convolutions depends on two variables, the number of channels and the depth multiplier. This script demonstrates where separable convolutions are faster than normal convolutions and where they are slower.</p>\n<pre><code>import time\nfrom typing import Tuple\n\nimport numpy as np\nimport tensorflow as tf\n\n\n# Define a scenario\nIMAGE_SIZE = 320\nCHANNELS_BATCH_SIZE = 2048  # channels * batch_size\nKERNEL_SIZE = 3\nREPEATS = 100\n\n\ndef build_ops(image: tf.Tensor, channels: int, depth_multiplier: int) -&gt; Tuple[tf.Operation, tf.Operation]:\n    with tf.variable_scope(\"{}_{}\".format(channels, depth_multiplier)):\n        in_channels = out_channels = channels\n        data_format = \"NCHW\"\n\n        # Filter definitions\n        basis_filters = tf.random_normal(\n            shape=[KERNEL_SIZE, KERNEL_SIZE, in_channels, depth_multiplier], dtype=tf.float32)\n        coeffs = tf.random_normal(\n            shape=[in_channels, depth_multiplier, out_channels], dtype=tf.float32)\n\n        sep_coffs = tf.reshape(coeffs, [1, 1, channels * depth_multiplier, out_channels])\n\n        # Normal method\n        effective_filters = tf.einsum('hwcm,cmn-&gt;hwcn', basis_filters, coeffs)\n\n        # Separable method\n        depthwise = tf.nn.depthwise_conv2d_native(\n            image,\n            basis_filters,\n            strides=[1, 1, 1, 1],\n            padding=\"SAME\",\n            data_format=data_format)\n\n        separable = tf.nn.conv2d(\n            depthwise,\n            sep_coffs,\n            strides=[1, 1, 1, 1],\n            padding=\"VALID\",\n            use_cudnn_on_gpu=True,\n            data_format=data_format)\n\n        # Normal method\n        normal = tf.nn.conv2d(\n            image,\n            effective_filters,\n            strides=[1, 1, 1, 1],\n            padding=\"SAME\",\n            use_cudnn_on_gpu=True,\n            data_format=data_format)\n\n        return normal, separable\n\n\ndef run(sess: tf.Session, normal: tf.Operation, separable: tf.Operation):\n    # Assert equality of the different methods\n    norm, sep = sess.run([normal, separable])\n    np.testing.assert_almost_equal(norm, sep, decimal=2)\n\n    # Benchmark normal method\n    start = time.time()\n    for _ in range(REPEATS):\n        _ = sess.run(normal)\n    end = time.time()\n    d1 = int((end - start) / REPEATS * 1000)\n\n    # Benchmark seperable method\n    start = time.time()\n    for _ in range(REPEATS):\n        _ = sess.run(separable)\n    end = time.time()\n    d2 = int((end - start) / REPEATS * 1000)\n\n    # Print results\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\n\n\nif __name__ == '__main__':\n    with tf.Session() as sess:\n        for channels in [32, 128, 1024]:\n            # adjust batch_size so gpu doesn't run out of memory\n            batch_size = CHANNELS_BATCH_SIZE // channels\n            image = tf.random_normal(shape=[batch_size, channels, IMAGE_SIZE, IMAGE_SIZE], dtype=tf.float32)\n\n            for depth_multiplier in [1, 4, 8]:\n                normal, separable = build_ops(image, channels, depth_multiplier)\n\n                print('Channels:', channels, 'depth_multiplier:', depth_multiplier)\n                run(sess, normal, separable)\n</code></pre>\n<p>Results:</p>\n<pre><code>Channels: 32 depth_multiplier: 1\nNormal method: 145ms \t Separable method: 139ms\n\nChannels: 32 depth_multiplier: 4\nNormal method: 139ms \t Separable method: 173ms\n\nChannels: 32 depth_multiplier: 8\nNormal method: 139ms \t Separable method: 219ms\n\nChannels: 128 depth_multiplier: 1\nNormal method: 149ms \t Separable method: 141ms\n\nChannels: 128 depth_multiplier: 4\nNormal method: 149ms \t Separable method: 181ms\n\nChannels: 128 depth_multiplier: 8\nNormal method: 149ms \t Separable method: 237ms\n\nChannels: 1024 depth_multiplier: 1\nNormal method: 414ms \t Separable method: 168ms\n\nChannels: 1024 depth_multiplier: 4\nNormal method: 414ms \t Separable method: 296ms\n\nChannels: 1024 depth_multiplier: 8\nNormal method: 414ms \t Separable method: 473ms\n</code></pre>\n<p>When channels is small (32) separable convs are actually slower than normal convs. The value of separable convs is apparent as the number of channels increases. The inflection point is ~64 channels.</p>\n<p>The depth multiplier does not effect the runtime performance of normal convolutions. Which makes sense, the matrix multiplication of the <code>basis_filters</code> and the <code>coeffs</code> above drops the depth multiplier value from the <code>effective_filters</code> shape. So the depth multiplier will only effect the runtime of the separable conv. The public architectures using separable convolutions that I am familiar with all use depth multipliers of 1 (e.g. MobileNet and Xception).</p>\n<p>For my own projects, I have been using normal convolutions for the first 2-3 layers and switch to separable convs when the number of channels is at least 64. I also exclusively use a depth multiplier of 1. Using these two ideas I have personally seen models using separable convs perform 50-100% faster than models using only normal convs.</p>", "body_text": "I was also previously having issues with the speed of separable convolutions but it was because of how I was using them. The effectiveness of separable convolutions compared to normal convolutions depends on two variables, the number of channels and the depth multiplier. This script demonstrates where separable convolutions are faster than normal convolutions and where they are slower.\nimport time\nfrom typing import Tuple\n\nimport numpy as np\nimport tensorflow as tf\n\n\n# Define a scenario\nIMAGE_SIZE = 320\nCHANNELS_BATCH_SIZE = 2048  # channels * batch_size\nKERNEL_SIZE = 3\nREPEATS = 100\n\n\ndef build_ops(image: tf.Tensor, channels: int, depth_multiplier: int) -> Tuple[tf.Operation, tf.Operation]:\n    with tf.variable_scope(\"{}_{}\".format(channels, depth_multiplier)):\n        in_channels = out_channels = channels\n        data_format = \"NCHW\"\n\n        # Filter definitions\n        basis_filters = tf.random_normal(\n            shape=[KERNEL_SIZE, KERNEL_SIZE, in_channels, depth_multiplier], dtype=tf.float32)\n        coeffs = tf.random_normal(\n            shape=[in_channels, depth_multiplier, out_channels], dtype=tf.float32)\n\n        sep_coffs = tf.reshape(coeffs, [1, 1, channels * depth_multiplier, out_channels])\n\n        # Normal method\n        effective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\n\n        # Separable method\n        depthwise = tf.nn.depthwise_conv2d_native(\n            image,\n            basis_filters,\n            strides=[1, 1, 1, 1],\n            padding=\"SAME\",\n            data_format=data_format)\n\n        separable = tf.nn.conv2d(\n            depthwise,\n            sep_coffs,\n            strides=[1, 1, 1, 1],\n            padding=\"VALID\",\n            use_cudnn_on_gpu=True,\n            data_format=data_format)\n\n        # Normal method\n        normal = tf.nn.conv2d(\n            image,\n            effective_filters,\n            strides=[1, 1, 1, 1],\n            padding=\"SAME\",\n            use_cudnn_on_gpu=True,\n            data_format=data_format)\n\n        return normal, separable\n\n\ndef run(sess: tf.Session, normal: tf.Operation, separable: tf.Operation):\n    # Assert equality of the different methods\n    norm, sep = sess.run([normal, separable])\n    np.testing.assert_almost_equal(norm, sep, decimal=2)\n\n    # Benchmark normal method\n    start = time.time()\n    for _ in range(REPEATS):\n        _ = sess.run(normal)\n    end = time.time()\n    d1 = int((end - start) / REPEATS * 1000)\n\n    # Benchmark seperable method\n    start = time.time()\n    for _ in range(REPEATS):\n        _ = sess.run(separable)\n    end = time.time()\n    d2 = int((end - start) / REPEATS * 1000)\n\n    # Print results\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\n\n\nif __name__ == '__main__':\n    with tf.Session() as sess:\n        for channels in [32, 128, 1024]:\n            # adjust batch_size so gpu doesn't run out of memory\n            batch_size = CHANNELS_BATCH_SIZE // channels\n            image = tf.random_normal(shape=[batch_size, channels, IMAGE_SIZE, IMAGE_SIZE], dtype=tf.float32)\n\n            for depth_multiplier in [1, 4, 8]:\n                normal, separable = build_ops(image, channels, depth_multiplier)\n\n                print('Channels:', channels, 'depth_multiplier:', depth_multiplier)\n                run(sess, normal, separable)\n\nResults:\nChannels: 32 depth_multiplier: 1\nNormal method: 145ms \t Separable method: 139ms\n\nChannels: 32 depth_multiplier: 4\nNormal method: 139ms \t Separable method: 173ms\n\nChannels: 32 depth_multiplier: 8\nNormal method: 139ms \t Separable method: 219ms\n\nChannels: 128 depth_multiplier: 1\nNormal method: 149ms \t Separable method: 141ms\n\nChannels: 128 depth_multiplier: 4\nNormal method: 149ms \t Separable method: 181ms\n\nChannels: 128 depth_multiplier: 8\nNormal method: 149ms \t Separable method: 237ms\n\nChannels: 1024 depth_multiplier: 1\nNormal method: 414ms \t Separable method: 168ms\n\nChannels: 1024 depth_multiplier: 4\nNormal method: 414ms \t Separable method: 296ms\n\nChannels: 1024 depth_multiplier: 8\nNormal method: 414ms \t Separable method: 473ms\n\nWhen channels is small (32) separable convs are actually slower than normal convs. The value of separable convs is apparent as the number of channels increases. The inflection point is ~64 channels.\nThe depth multiplier does not effect the runtime performance of normal convolutions. Which makes sense, the matrix multiplication of the basis_filters and the coeffs above drops the depth multiplier value from the effective_filters shape. So the depth multiplier will only effect the runtime of the separable conv. The public architectures using separable convolutions that I am familiar with all use depth multipliers of 1 (e.g. MobileNet and Xception).\nFor my own projects, I have been using normal convolutions for the first 2-3 layers and switch to separable convs when the number of channels is at least 64. I also exclusively use a depth multiplier of 1. Using these two ideas I have personally seen models using separable convs perform 50-100% faster than models using only normal convs.", "body": "I was also previously having issues with the speed of separable convolutions but it was because of how I was using them. The effectiveness of separable convolutions compared to normal convolutions depends on two variables, the number of channels and the depth multiplier. This script demonstrates where separable convolutions are faster than normal convolutions and where they are slower.\r\n```\r\nimport time\r\nfrom typing import Tuple\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\n# Define a scenario\r\nIMAGE_SIZE = 320\r\nCHANNELS_BATCH_SIZE = 2048  # channels * batch_size\r\nKERNEL_SIZE = 3\r\nREPEATS = 100\r\n\r\n\r\ndef build_ops(image: tf.Tensor, channels: int, depth_multiplier: int) -> Tuple[tf.Operation, tf.Operation]:\r\n    with tf.variable_scope(\"{}_{}\".format(channels, depth_multiplier)):\r\n        in_channels = out_channels = channels\r\n        data_format = \"NCHW\"\r\n\r\n        # Filter definitions\r\n        basis_filters = tf.random_normal(\r\n            shape=[KERNEL_SIZE, KERNEL_SIZE, in_channels, depth_multiplier], dtype=tf.float32)\r\n        coeffs = tf.random_normal(\r\n            shape=[in_channels, depth_multiplier, out_channels], dtype=tf.float32)\r\n\r\n        sep_coffs = tf.reshape(coeffs, [1, 1, channels * depth_multiplier, out_channels])\r\n\r\n        # Normal method\r\n        effective_filters = tf.einsum('hwcm,cmn->hwcn', basis_filters, coeffs)\r\n\r\n        # Separable method\r\n        depthwise = tf.nn.depthwise_conv2d_native(\r\n            image,\r\n            basis_filters,\r\n            strides=[1, 1, 1, 1],\r\n            padding=\"SAME\",\r\n            data_format=data_format)\r\n\r\n        separable = tf.nn.conv2d(\r\n            depthwise,\r\n            sep_coffs,\r\n            strides=[1, 1, 1, 1],\r\n            padding=\"VALID\",\r\n            use_cudnn_on_gpu=True,\r\n            data_format=data_format)\r\n\r\n        # Normal method\r\n        normal = tf.nn.conv2d(\r\n            image,\r\n            effective_filters,\r\n            strides=[1, 1, 1, 1],\r\n            padding=\"SAME\",\r\n            use_cudnn_on_gpu=True,\r\n            data_format=data_format)\r\n\r\n        return normal, separable\r\n\r\n\r\ndef run(sess: tf.Session, normal: tf.Operation, separable: tf.Operation):\r\n    # Assert equality of the different methods\r\n    norm, sep = sess.run([normal, separable])\r\n    np.testing.assert_almost_equal(norm, sep, decimal=2)\r\n\r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in range(REPEATS):\r\n        _ = sess.run(normal)\r\n    end = time.time()\r\n    d1 = int((end - start) / REPEATS * 1000)\r\n\r\n    # Benchmark seperable method\r\n    start = time.time()\r\n    for _ in range(REPEATS):\r\n        _ = sess.run(separable)\r\n    end = time.time()\r\n    d2 = int((end - start) / REPEATS * 1000)\r\n\r\n    # Print results\r\n    print(\"Normal method: {}ms \\t Separable method: {}ms\".format(d1, d2))\r\n\r\n\r\nif __name__ == '__main__':\r\n    with tf.Session() as sess:\r\n        for channels in [32, 128, 1024]:\r\n            # adjust batch_size so gpu doesn't run out of memory\r\n            batch_size = CHANNELS_BATCH_SIZE // channels\r\n            image = tf.random_normal(shape=[batch_size, channels, IMAGE_SIZE, IMAGE_SIZE], dtype=tf.float32)\r\n\r\n            for depth_multiplier in [1, 4, 8]:\r\n                normal, separable = build_ops(image, channels, depth_multiplier)\r\n\r\n                print('Channels:', channels, 'depth_multiplier:', depth_multiplier)\r\n                run(sess, normal, separable)\r\n```\r\nResults:\r\n```\r\nChannels: 32 depth_multiplier: 1\r\nNormal method: 145ms \t Separable method: 139ms\r\n\r\nChannels: 32 depth_multiplier: 4\r\nNormal method: 139ms \t Separable method: 173ms\r\n\r\nChannels: 32 depth_multiplier: 8\r\nNormal method: 139ms \t Separable method: 219ms\r\n\r\nChannels: 128 depth_multiplier: 1\r\nNormal method: 149ms \t Separable method: 141ms\r\n\r\nChannels: 128 depth_multiplier: 4\r\nNormal method: 149ms \t Separable method: 181ms\r\n\r\nChannels: 128 depth_multiplier: 8\r\nNormal method: 149ms \t Separable method: 237ms\r\n\r\nChannels: 1024 depth_multiplier: 1\r\nNormal method: 414ms \t Separable method: 168ms\r\n\r\nChannels: 1024 depth_multiplier: 4\r\nNormal method: 414ms \t Separable method: 296ms\r\n\r\nChannels: 1024 depth_multiplier: 8\r\nNormal method: 414ms \t Separable method: 473ms\r\n```\r\nWhen channels is small (32) separable convs are actually slower than normal convs. The value of separable convs is apparent as the number of channels increases. The inflection point is ~64 channels.\r\n\r\nThe depth multiplier does not effect the runtime performance of normal convolutions. Which makes sense, the matrix multiplication of the `basis_filters` and the `coeffs` above drops the depth multiplier value from the `effective_filters` shape. So the depth multiplier will only effect the runtime of the separable conv. The public architectures using separable convolutions that I am familiar with all use depth multipliers of 1 (e.g. MobileNet and Xception).\r\n\r\nFor my own projects, I have been using normal convolutions for the first 2-3 layers and switch to separable convs when the number of channels is at least 64. I also exclusively use a depth multiplier of 1. Using these two ideas I have personally seen models using separable convs perform 50-100% faster than models using only normal convs."}