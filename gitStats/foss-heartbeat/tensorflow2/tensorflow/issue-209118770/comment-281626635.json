{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/281626635", "html_url": "https://github.com/tensorflow/tensorflow/issues/7734#issuecomment-281626635", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7734", "id": 281626635, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTYyNjYzNQ==", "user": {"login": "Sean-Git", "id": 6144395, "node_id": "MDQ6VXNlcjYxNDQzOTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/6144395?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Sean-Git", "html_url": "https://github.com/Sean-Git", "followers_url": "https://api.github.com/users/Sean-Git/followers", "following_url": "https://api.github.com/users/Sean-Git/following{/other_user}", "gists_url": "https://api.github.com/users/Sean-Git/gists{/gist_id}", "starred_url": "https://api.github.com/users/Sean-Git/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Sean-Git/subscriptions", "organizations_url": "https://api.github.com/users/Sean-Git/orgs", "repos_url": "https://api.github.com/users/Sean-Git/repos", "events_url": "https://api.github.com/users/Sean-Git/events{/privacy}", "received_events_url": "https://api.github.com/users/Sean-Git/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-22T10:14:38Z", "updated_at": "2017-02-22T10:14:38Z", "author_association": "NONE", "body_html": "<p>I am just running the code in <em>wide_n_deep_tutorial.py</em> with some modification to read my own <strong>csv</strong> file. The modified code is as below:</p>\n<pre><code>def input_fn(file_names, batch_size):\n    # Read csv files and create examples dict\n    examples_dict = read_csv_examples(file_names, batch_size)\n\n    # Continuous features\n    feature_cols = {k: tf.string_to_number(examples_dict[k],\n                                           out_type=tf.float32) for k in CONTINUOUS_COLUMNS}\n\n    # Categorical features\n    feature_cols.update({\n                            k: tf.SparseTensor(\n                                indices=[[i, 0] for i in range(examples_dict[k].get_shape()[0])],\n                                values=examples_dict[k],\n                                shape=[int(examples_dict[k].get_shape()[0]), 1])\n                            for k in CATEGORICAL_COLUMNS})\n\n    label = tf.string_to_number(examples_dict[LABEL_COLUMN], out_type=tf.int32)\n\n    return feature_cols, label\n\n\ndef read_csv_examples(file_names, batch_size):\n    def parse_fn(record):\n        record_defaults = [tf.constant([''], dtype=tf.string)] * len(COLUMNS)\n\n        return tf.decode_csv(record, record_defaults)\n\n    examples_op = tf.contrib.learn.read_batch_examples(\n        file_names,\n        batch_size=batch_size,\n        queue_capacity=batch_size*2.5,\n        reader=tf.TextLineReader,\n        parse_fn=parse_fn,\n        #read_batch_size= batch_size,\n        #randomize_input=True,\n        num_threads=8\n    )\n\n    # Important: convert examples to dict for ease of use in `input_fn`\n    # Map each header to its respective column (COLUMNS order\n    # matters!\n    examples_dict_op = {}\n    for i, header in enumerate(COLUMNS):\n        examples_dict_op[header] = examples_op[:, i]\n\n    return examples_dict_op\n</code></pre>\n<p>If I set the param <em>read_batch_size</em>, error occurs.</p>", "body_text": "I am just running the code in wide_n_deep_tutorial.py with some modification to read my own csv file. The modified code is as below:\ndef input_fn(file_names, batch_size):\n    # Read csv files and create examples dict\n    examples_dict = read_csv_examples(file_names, batch_size)\n\n    # Continuous features\n    feature_cols = {k: tf.string_to_number(examples_dict[k],\n                                           out_type=tf.float32) for k in CONTINUOUS_COLUMNS}\n\n    # Categorical features\n    feature_cols.update({\n                            k: tf.SparseTensor(\n                                indices=[[i, 0] for i in range(examples_dict[k].get_shape()[0])],\n                                values=examples_dict[k],\n                                shape=[int(examples_dict[k].get_shape()[0]), 1])\n                            for k in CATEGORICAL_COLUMNS})\n\n    label = tf.string_to_number(examples_dict[LABEL_COLUMN], out_type=tf.int32)\n\n    return feature_cols, label\n\n\ndef read_csv_examples(file_names, batch_size):\n    def parse_fn(record):\n        record_defaults = [tf.constant([''], dtype=tf.string)] * len(COLUMNS)\n\n        return tf.decode_csv(record, record_defaults)\n\n    examples_op = tf.contrib.learn.read_batch_examples(\n        file_names,\n        batch_size=batch_size,\n        queue_capacity=batch_size*2.5,\n        reader=tf.TextLineReader,\n        parse_fn=parse_fn,\n        #read_batch_size= batch_size,\n        #randomize_input=True,\n        num_threads=8\n    )\n\n    # Important: convert examples to dict for ease of use in `input_fn`\n    # Map each header to its respective column (COLUMNS order\n    # matters!\n    examples_dict_op = {}\n    for i, header in enumerate(COLUMNS):\n        examples_dict_op[header] = examples_op[:, i]\n\n    return examples_dict_op\n\nIf I set the param read_batch_size, error occurs.", "body": "I am just running the code in _wide_n_deep_tutorial.py_ with some modification to read my own **csv** file. The modified code is as below:\r\n```\r\ndef input_fn(file_names, batch_size):\r\n    # Read csv files and create examples dict\r\n    examples_dict = read_csv_examples(file_names, batch_size)\r\n\r\n    # Continuous features\r\n    feature_cols = {k: tf.string_to_number(examples_dict[k],\r\n                                           out_type=tf.float32) for k in CONTINUOUS_COLUMNS}\r\n\r\n    # Categorical features\r\n    feature_cols.update({\r\n                            k: tf.SparseTensor(\r\n                                indices=[[i, 0] for i in range(examples_dict[k].get_shape()[0])],\r\n                                values=examples_dict[k],\r\n                                shape=[int(examples_dict[k].get_shape()[0]), 1])\r\n                            for k in CATEGORICAL_COLUMNS})\r\n\r\n    label = tf.string_to_number(examples_dict[LABEL_COLUMN], out_type=tf.int32)\r\n\r\n    return feature_cols, label\r\n\r\n\r\ndef read_csv_examples(file_names, batch_size):\r\n    def parse_fn(record):\r\n        record_defaults = [tf.constant([''], dtype=tf.string)] * len(COLUMNS)\r\n\r\n        return tf.decode_csv(record, record_defaults)\r\n\r\n    examples_op = tf.contrib.learn.read_batch_examples(\r\n        file_names,\r\n        batch_size=batch_size,\r\n        queue_capacity=batch_size*2.5,\r\n        reader=tf.TextLineReader,\r\n        parse_fn=parse_fn,\r\n        #read_batch_size= batch_size,\r\n        #randomize_input=True,\r\n        num_threads=8\r\n    )\r\n\r\n    # Important: convert examples to dict for ease of use in `input_fn`\r\n    # Map each header to its respective column (COLUMNS order\r\n    # matters!\r\n    examples_dict_op = {}\r\n    for i, header in enumerate(COLUMNS):\r\n        examples_dict_op[header] = examples_op[:, i]\r\n\r\n    return examples_dict_op\r\n```\r\nIf I set the param _read_batch_size_, error occurs."}