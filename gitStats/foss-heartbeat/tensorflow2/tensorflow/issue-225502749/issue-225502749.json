{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9576", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9576/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9576/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9576/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9576", "id": 225502749, "node_id": "MDU6SXNzdWUyMjU1MDI3NDk=", "number": 9576, "title": "dilated convolution in 3D, error:  No algorithm without scratch worked", "user": {"login": "weiliu620", "id": 6721243, "node_id": "MDQ6VXNlcjY3MjEyNDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6721243?v=4", "gravatar_id": "", "url": "https://api.github.com/users/weiliu620", "html_url": "https://github.com/weiliu620", "followers_url": "https://api.github.com/users/weiliu620/followers", "following_url": "https://api.github.com/users/weiliu620/following{/other_user}", "gists_url": "https://api.github.com/users/weiliu620/gists{/gist_id}", "starred_url": "https://api.github.com/users/weiliu620/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/weiliu620/subscriptions", "organizations_url": "https://api.github.com/users/weiliu620/orgs", "repos_url": "https://api.github.com/users/weiliu620/repos", "events_url": "https://api.github.com/users/weiliu620/events{/privacy}", "received_events_url": "https://api.github.com/users/weiliu620/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "mjanusz", "id": 328443, "node_id": "MDQ6VXNlcjMyODQ0Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/328443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjanusz", "html_url": "https://github.com/mjanusz", "followers_url": "https://api.github.com/users/mjanusz/followers", "following_url": "https://api.github.com/users/mjanusz/following{/other_user}", "gists_url": "https://api.github.com/users/mjanusz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjanusz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjanusz/subscriptions", "organizations_url": "https://api.github.com/users/mjanusz/orgs", "repos_url": "https://api.github.com/users/mjanusz/repos", "events_url": "https://api.github.com/users/mjanusz/events{/privacy}", "received_events_url": "https://api.github.com/users/mjanusz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "mjanusz", "id": 328443, "node_id": "MDQ6VXNlcjMyODQ0Mw==", "avatar_url": "https://avatars2.githubusercontent.com/u/328443?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjanusz", "html_url": "https://github.com/mjanusz", "followers_url": "https://api.github.com/users/mjanusz/followers", "following_url": "https://api.github.com/users/mjanusz/following{/other_user}", "gists_url": "https://api.github.com/users/mjanusz/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjanusz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjanusz/subscriptions", "organizations_url": "https://api.github.com/users/mjanusz/orgs", "repos_url": "https://api.github.com/users/mjanusz/repos", "events_url": "https://api.github.com/users/mjanusz/events{/privacy}", "received_events_url": "https://api.github.com/users/mjanusz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2017-05-01T19:17:10Z", "updated_at": "2018-02-08T01:07:13Z", "closed_at": "2018-02-08T01:07:05Z", "author_association": "NONE", "body_html": "<p>I'm using tf.nn.convolution to implement the dilated convolution in 3D. I got \"No algorithm without scratch worked\" error during training. Here is the related code</p>\n<p>To define the model,</p>\n<pre><code>def inference(self, images, is_training, keep_prob):\n        \"\"\" Forward inference\n        Return:\n\n        \"\"\"\n        c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))\n        score = self._conv(c1, scope = 'score', filters = 2,  filter_size = (1,1,1) )\n\n        pred = tf.nn.softmax(score)\n\n        # pdb.set_trace()\n        return score, pred\n\n    def _conv(self, in_tensor, filters, scope, filter_size = None):\n        \"\"\" \"\"\"\n\n        if self._wd is None:\n            myreg = None\n        else:\n            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))\n\n        if filter_size is None:\n            filter_size = self._filter_size\n\n        with tf.variable_scope(scope):\n            return tf.layers.conv3d(\n                in_tensor, filters = filters,\n                kernel_size = filter_size, padding = 'valid',\n                activation = None,\n                kernel_initializer  = tf.truncated_normal_initializer(stddev = self._stddev),\n                kernel_regularizer =myreg,\n                name = 'conv')        \n\n    def _dilation_conv(self, in_tensor, n_filters, scope, dilation_rate, filter_size = None):\n        \"\"\" dilated convolution filter with batch norm. \"\"\"\n        \n        if self._wd is None:\n            myreg = None\n        else:\n            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))\n\n        if filter_size is None:\n            filter_size = self._filter_size\n\n        batch_size, H, W, D, in_channel = in_tensor.get_shape().as_list()            \n\n        with tf.variable_scope(scope):\n            kernel = tf.get_variable('weights', shape = self._filter_size + (in_channel, n_filters),\n                                     dtype = tf.float32,\n                                     initializer = tf.truncated_normal_initializer(stddev=self._stddev))\n            output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')\n\n            # Somehow set training = True even for testing phase works\n            # better.\n            if self._bn:\n                output = tf.layers.batch_normalization(\n                    output, training = True, name = 'bn')\n\n            return tf.nn.relu(output, 'relu')\n            \n    def get_loss(self, labels, scores, beta = 0.9999):\n        \"\"\"\n        return total loss of the model, including data loss and\n        regularization loss.\n    \n        It looks that softmax_cross_entropy_with_logits does not need the\n        input logits 2 dimension. As long as the last dimension is for\n        classes, it should work. So, we do not need reshape the input tensor. \n\n        TF has a weighted_cross_entropy_with_logits, but this function is\n        for multi-class problem, i.e. a picture may have both a dog and a\n        truck.\n        \"\"\"\n\n        class_weight = tf.constant([beta, 1.0 - beta])\n        # TF suppot numpy's broadcasting. score array has dim BXY2,\n        # weights array has dim (2), which is broadcast to BXY2.\n        weighted_logits = tf.multiply(scores, class_weight)\n\n        # both logits and labels are BXY2 dimension. \n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = weighted_logits, labels = labels)\n        # fromm dim BXY to dim 0 (scalar)\n        cross_entropy_mean = tf.reduce_mean(cross_entropy, name = 'cross_entropy')\n\n        reg_loss_list = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n        if reg_loss_list:\n            return cross_entropy_mean + tf.add_n(reg_loss_list)\n        else:\n            return cross_entropy_mean\n</code></pre>\n<p>And to train the model, I used tf.train.AdamOptimizer. I didn't paste the training related code, since I don't think they are relevant, but I can add them later if that helps.</p>\n<p>Here is the error logs I saw:</p>\n<pre><code>In [40]: train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n2017-05-01 15:08:10.813716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Graphics Device, pci bus id: 0000:85:00.0)\n---------------------------------------------------------------------------\nNotFoundError                             Traceback (most recent call last)\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1038     try:\n-&gt; 1039       return fn(*args)\n   1040     except errors.OpError as e:\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n   1020                                  feed_dict, fetch_list, target_list,\n-&gt; 1021                                  status, run_metadata)\n   1022 \n\n/usr/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---&gt; 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--&gt; 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n\nNotFoundError: No algorithm without scratch worked!\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nNotFoundError                             Traceback (most recent call last)\n&lt;ipython-input-40-c48a6e49a4b4&gt; in &lt;module&gt;()\n----&gt; 1 train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n\n/home/weiliu/projects/seismic/code/weiliu/train.py in train(train_dataset, test_dataset, model, init_lr, summary_dir, in_ckpt, out_ckpt)\n    141                          keep_prob_pl: 0.5}\n    142 \n--&gt; 143             _, loss_value = sess.run([optimizer, loss], feed_dict = feed_dict)\n    144 \n    145             global_step_val = tf.train.global_step(sess, global_step)\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    776     try:\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 778                          run_metadata_ptr)\n    779       if run_metadata:\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    980     if final_fetches or final_targets:\n    981       results = self._do_run(handle, final_targets, final_fetches,\n--&gt; 982                              feed_dict_string, options, run_metadata)\n    983     else:\n    984       results = []\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1030     if handle is None:\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-&gt; 1032                            target_list, options, run_metadata)\n   1033     else:\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1050         except KeyError:\n   1051           pass\n-&gt; 1052       raise type(e)(node_def, op, message)\n   1053 \n   1054   def _extend_graph(self):\n\nNotFoundError: No algorithm without scratch worked!\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2', defined at:\n  File \"/usr/local/bin/ipython\", line 11, in &lt;module&gt;\n    sys.exit(start_ipython())\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/__init__.py\", line 119, in start_ipython\n    return launch_new_instance(argv=argv, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/ipapp.py\", line 348, in start\n    self.shell.mainloop()\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py\", line 440, in mainloop\n    self.interact()\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py\", line 431, in interact\n    self.run_cell(code, store_history=True)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-40-c48a6e49a4b4&gt;\", line 1, in &lt;module&gt;\n    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n  File \"/home/weiliu/projects/seismic/code/weiliu/train.py\", line 116, in train\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step = global_step)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in &lt;lambda&gt;\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py\", line 77, in _Conv3DGrad\n    padding=op.get_attr(\"padding\")),\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 663, in conv3d_backprop_input_v2\n    padding=padding, name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'c1/dilation_conv', defined at:\n  File \"/usr/local/bin/ipython\", line 11, in &lt;module&gt;\n    sys.exit(start_ipython())\n[elided 8 identical lines from previous traceback]\n  File \"&lt;ipython-input-40-c48a6e49a4b4&gt;\", line 1, in &lt;module&gt;\n    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n  File \"/home/weiliu/projects/seismic/code/weiliu/train.py\", line 67, in train\n    images_placeholder, is_training = istraining_pl, keep_prob = keep_prob_pl )\n  File \"/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py\", line 71, in inference\n    c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))\n  File \"/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py\", line 116, in _dilation_conv\n    output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 661, in convolution\n    op=op)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 331, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 653, in op\n    name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 140, in _non_atrous_convolution\n    name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 529, in conv3d\n    strides=strides, padding=padding, name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n\nNotFoundError (see above for traceback): No algorithm without scratch worked!\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\n</code></pre>\n<p>I also check the <code>atrous_convolution_test.py</code> and it seems I used it right.</p>\n<p>I'm on Ubuntu 14.04 64 bit, tensorflow version 1.1.0-rc2.</p>\n<p>If anyone can point me direction how to debug, that would be great.</p>", "body_text": "I'm using tf.nn.convolution to implement the dilated convolution in 3D. I got \"No algorithm without scratch worked\" error during training. Here is the related code\nTo define the model,\ndef inference(self, images, is_training, keep_prob):\n        \"\"\" Forward inference\n        Return:\n\n        \"\"\"\n        c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))\n        score = self._conv(c1, scope = 'score', filters = 2,  filter_size = (1,1,1) )\n\n        pred = tf.nn.softmax(score)\n\n        # pdb.set_trace()\n        return score, pred\n\n    def _conv(self, in_tensor, filters, scope, filter_size = None):\n        \"\"\" \"\"\"\n\n        if self._wd is None:\n            myreg = None\n        else:\n            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))\n\n        if filter_size is None:\n            filter_size = self._filter_size\n\n        with tf.variable_scope(scope):\n            return tf.layers.conv3d(\n                in_tensor, filters = filters,\n                kernel_size = filter_size, padding = 'valid',\n                activation = None,\n                kernel_initializer  = tf.truncated_normal_initializer(stddev = self._stddev),\n                kernel_regularizer =myreg,\n                name = 'conv')        \n\n    def _dilation_conv(self, in_tensor, n_filters, scope, dilation_rate, filter_size = None):\n        \"\"\" dilated convolution filter with batch norm. \"\"\"\n        \n        if self._wd is None:\n            myreg = None\n        else:\n            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))\n\n        if filter_size is None:\n            filter_size = self._filter_size\n\n        batch_size, H, W, D, in_channel = in_tensor.get_shape().as_list()            \n\n        with tf.variable_scope(scope):\n            kernel = tf.get_variable('weights', shape = self._filter_size + (in_channel, n_filters),\n                                     dtype = tf.float32,\n                                     initializer = tf.truncated_normal_initializer(stddev=self._stddev))\n            output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')\n\n            # Somehow set training = True even for testing phase works\n            # better.\n            if self._bn:\n                output = tf.layers.batch_normalization(\n                    output, training = True, name = 'bn')\n\n            return tf.nn.relu(output, 'relu')\n            \n    def get_loss(self, labels, scores, beta = 0.9999):\n        \"\"\"\n        return total loss of the model, including data loss and\n        regularization loss.\n    \n        It looks that softmax_cross_entropy_with_logits does not need the\n        input logits 2 dimension. As long as the last dimension is for\n        classes, it should work. So, we do not need reshape the input tensor. \n\n        TF has a weighted_cross_entropy_with_logits, but this function is\n        for multi-class problem, i.e. a picture may have both a dog and a\n        truck.\n        \"\"\"\n\n        class_weight = tf.constant([beta, 1.0 - beta])\n        # TF suppot numpy's broadcasting. score array has dim BXY2,\n        # weights array has dim (2), which is broadcast to BXY2.\n        weighted_logits = tf.multiply(scores, class_weight)\n\n        # both logits and labels are BXY2 dimension. \n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = weighted_logits, labels = labels)\n        # fromm dim BXY to dim 0 (scalar)\n        cross_entropy_mean = tf.reduce_mean(cross_entropy, name = 'cross_entropy')\n\n        reg_loss_list = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n        if reg_loss_list:\n            return cross_entropy_mean + tf.add_n(reg_loss_list)\n        else:\n            return cross_entropy_mean\n\nAnd to train the model, I used tf.train.AdamOptimizer. I didn't paste the training related code, since I don't think they are relevant, but I can add them later if that helps.\nHere is the error logs I saw:\nIn [40]: train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n2017-05-01 15:08:10.813716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:85:00.0)\n---------------------------------------------------------------------------\nNotFoundError                             Traceback (most recent call last)\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1038     try:\n-> 1039       return fn(*args)\n   1040     except errors.OpError as e:\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n   1020                                  feed_dict, fetch_list, target_list,\n-> 1021                                  status, run_metadata)\n   1022 \n\n/usr/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 466           pywrap_tensorflow.TF_GetCode(status))\n    467   finally:\n\nNotFoundError: No algorithm without scratch worked!\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nNotFoundError                             Traceback (most recent call last)\n<ipython-input-40-c48a6e49a4b4> in <module>()\n----> 1 train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n\n/home/weiliu/projects/seismic/code/weiliu/train.py in train(train_dataset, test_dataset, model, init_lr, summary_dir, in_ckpt, out_ckpt)\n    141                          keep_prob_pl: 0.5}\n    142 \n--> 143             _, loss_value = sess.run([optimizer, loss], feed_dict = feed_dict)\n    144 \n    145             global_step_val = tf.train.global_step(sess, global_step)\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    776     try:\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 778                          run_metadata_ptr)\n    779       if run_metadata:\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    980     if final_fetches or final_targets:\n    981       results = self._do_run(handle, final_targets, final_fetches,\n--> 982                              feed_dict_string, options, run_metadata)\n    983     else:\n    984       results = []\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1030     if handle is None:\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-> 1032                            target_list, options, run_metadata)\n   1033     else:\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1050         except KeyError:\n   1051           pass\n-> 1052       raise type(e)(node_def, op, message)\n   1053 \n   1054   def _extend_graph(self):\n\nNotFoundError: No algorithm without scratch worked!\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2', defined at:\n  File \"/usr/local/bin/ipython\", line 11, in <module>\n    sys.exit(start_ipython())\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/__init__.py\", line 119, in start_ipython\n    return launch_new_instance(argv=argv, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/ipapp.py\", line 348, in start\n    self.shell.mainloop()\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py\", line 440, in mainloop\n    self.interact()\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py\", line 431, in interact\n    self.run_cell(code, store_history=True)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-c48a6e49a4b4>\", line 1, in <module>\n    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n  File \"/home/weiliu/projects/seismic/code/weiliu/train.py\", line 116, in train\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step = global_step)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py\", line 77, in _Conv3DGrad\n    padding=op.get_attr(\"padding\")),\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 663, in conv3d_backprop_input_v2\n    padding=padding, name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'c1/dilation_conv', defined at:\n  File \"/usr/local/bin/ipython\", line 11, in <module>\n    sys.exit(start_ipython())\n[elided 8 identical lines from previous traceback]\n  File \"<ipython-input-40-c48a6e49a4b4>\", line 1, in <module>\n    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\n  File \"/home/weiliu/projects/seismic/code/weiliu/train.py\", line 67, in train\n    images_placeholder, is_training = istraining_pl, keep_prob = keep_prob_pl )\n  File \"/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py\", line 71, in inference\n    c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))\n  File \"/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py\", line 116, in _dilation_conv\n    output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 661, in convolution\n    op=op)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 331, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 653, in op\n    name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 140, in _non_atrous_convolution\n    name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 529, in conv3d\n    strides=strides, padding=padding, name=name)\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n\nNotFoundError (see above for traceback): No algorithm without scratch worked!\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\n\nI also check the atrous_convolution_test.py and it seems I used it right.\nI'm on Ubuntu 14.04 64 bit, tensorflow version 1.1.0-rc2.\nIf anyone can point me direction how to debug, that would be great.", "body": "I'm using tf.nn.convolution to implement the dilated convolution in 3D. I got \"No algorithm without scratch worked\" error during training. Here is the related code\r\n\r\nTo define the model,\r\n```\r\ndef inference(self, images, is_training, keep_prob):\r\n        \"\"\" Forward inference\r\n        Return:\r\n\r\n        \"\"\"\r\n        c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))\r\n        score = self._conv(c1, scope = 'score', filters = 2,  filter_size = (1,1,1) )\r\n\r\n        pred = tf.nn.softmax(score)\r\n\r\n        # pdb.set_trace()\r\n        return score, pred\r\n\r\n    def _conv(self, in_tensor, filters, scope, filter_size = None):\r\n        \"\"\" \"\"\"\r\n\r\n        if self._wd is None:\r\n            myreg = None\r\n        else:\r\n            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))\r\n\r\n        if filter_size is None:\r\n            filter_size = self._filter_size\r\n\r\n        with tf.variable_scope(scope):\r\n            return tf.layers.conv3d(\r\n                in_tensor, filters = filters,\r\n                kernel_size = filter_size, padding = 'valid',\r\n                activation = None,\r\n                kernel_initializer  = tf.truncated_normal_initializer(stddev = self._stddev),\r\n                kernel_regularizer =myreg,\r\n                name = 'conv')        \r\n\r\n    def _dilation_conv(self, in_tensor, n_filters, scope, dilation_rate, filter_size = None):\r\n        \"\"\" dilated convolution filter with batch norm. \"\"\"\r\n        \r\n        if self._wd is None:\r\n            myreg = None\r\n        else:\r\n            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))\r\n\r\n        if filter_size is None:\r\n            filter_size = self._filter_size\r\n\r\n        batch_size, H, W, D, in_channel = in_tensor.get_shape().as_list()            \r\n\r\n        with tf.variable_scope(scope):\r\n            kernel = tf.get_variable('weights', shape = self._filter_size + (in_channel, n_filters),\r\n                                     dtype = tf.float32,\r\n                                     initializer = tf.truncated_normal_initializer(stddev=self._stddev))\r\n            output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')\r\n\r\n            # Somehow set training = True even for testing phase works\r\n            # better.\r\n            if self._bn:\r\n                output = tf.layers.batch_normalization(\r\n                    output, training = True, name = 'bn')\r\n\r\n            return tf.nn.relu(output, 'relu')\r\n            \r\n    def get_loss(self, labels, scores, beta = 0.9999):\r\n        \"\"\"\r\n        return total loss of the model, including data loss and\r\n        regularization loss.\r\n    \r\n        It looks that softmax_cross_entropy_with_logits does not need the\r\n        input logits 2 dimension. As long as the last dimension is for\r\n        classes, it should work. So, we do not need reshape the input tensor. \r\n\r\n        TF has a weighted_cross_entropy_with_logits, but this function is\r\n        for multi-class problem, i.e. a picture may have both a dog and a\r\n        truck.\r\n        \"\"\"\r\n\r\n        class_weight = tf.constant([beta, 1.0 - beta])\r\n        # TF suppot numpy's broadcasting. score array has dim BXY2,\r\n        # weights array has dim (2), which is broadcast to BXY2.\r\n        weighted_logits = tf.multiply(scores, class_weight)\r\n\r\n        # both logits and labels are BXY2 dimension. \r\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = weighted_logits, labels = labels)\r\n        # fromm dim BXY to dim 0 (scalar)\r\n        cross_entropy_mean = tf.reduce_mean(cross_entropy, name = 'cross_entropy')\r\n\r\n        reg_loss_list = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\r\n        if reg_loss_list:\r\n            return cross_entropy_mean + tf.add_n(reg_loss_list)\r\n        else:\r\n            return cross_entropy_mean\r\n```\r\nAnd to train the model, I used tf.train.AdamOptimizer. I didn't paste the training related code, since I don't think they are relevant, but I can add them later if that helps. \r\n\r\nHere is the error logs I saw: \r\n``` \r\nIn [40]: train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\r\n2017-05-01 15:08:10.813716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:85:00.0)\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1038     try:\r\n-> 1039       return fn(*args)\r\n   1040     except errors.OpError as e:\r\n\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1020                                  feed_dict, fetch_list, target_list,\r\n-> 1021                                  status, run_metadata)\r\n   1022 \r\n\r\n/usr/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\r\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466           pywrap_tensorflow.TF_GetCode(status))\r\n    467   finally:\r\n\r\nNotFoundError: No algorithm without scratch worked!\r\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\r\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-40-c48a6e49a4b4> in <module>()\r\n----> 1 train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\r\n\r\n/home/weiliu/projects/seismic/code/weiliu/train.py in train(train_dataset, test_dataset, model, init_lr, summary_dir, in_ckpt, out_ckpt)\r\n    141                          keep_prob_pl: 0.5}\r\n    142 \r\n--> 143             _, loss_value = sess.run([optimizer, loss], feed_dict = feed_dict)\r\n    144 \r\n    145             global_step_val = tf.train.global_step(sess, global_step)\r\n\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    776     try:\r\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 778                          run_metadata_ptr)\r\n    779       if run_metadata:\r\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    980     if final_fetches or final_targets:\r\n    981       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 982                              feed_dict_string, options, run_metadata)\r\n    983     else:\r\n    984       results = []\r\n\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1030     if handle is None:\r\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1032                            target_list, options, run_metadata)\r\n   1033     else:\r\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1050         except KeyError:\r\n   1051           pass\r\n-> 1052       raise type(e)(node_def, op, message)\r\n   1053 \r\n   1054   def _extend_graph(self):\r\n\r\nNotFoundError: No algorithm without scratch worked!\r\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\r\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2', defined at:\r\n  File \"/usr/local/bin/ipython\", line 11, in <module>\r\n    sys.exit(start_ipython())\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/__init__.py\", line 119, in start_ipython\r\n    return launch_new_instance(argv=argv, **kwargs)\r\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/ipapp.py\", line 348, in start\r\n    self.shell.mainloop()\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py\", line 440, in mainloop\r\n    self.interact()\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py\", line 431, in interact\r\n    self.run_cell(code, store_history=True)\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-40-c48a6e49a4b4>\", line 1, in <module>\r\n    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\r\n  File \"/home/weiliu/projects/seismic/code/weiliu/train.py\", line 116, in train\r\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step = global_step)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py\", line 77, in _Conv3DGrad\r\n    padding=op.get_attr(\"padding\")),\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 663, in conv3d_backprop_input_v2\r\n    padding=padding, name=name)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\n...which was originally created as op 'c1/dilation_conv', defined at:\r\n  File \"/usr/local/bin/ipython\", line 11, in <module>\r\n    sys.exit(start_ipython())\r\n[elided 8 identical lines from previous traceback]\r\n  File \"<ipython-input-40-c48a6e49a4b4>\", line 1, in <module>\r\n    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')\r\n  File \"/home/weiliu/projects/seismic/code/weiliu/train.py\", line 67, in train\r\n    images_placeholder, is_training = istraining_pl, keep_prob = keep_prob_pl )\r\n  File \"/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py\", line 71, in inference\r\n    c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))\r\n  File \"/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py\", line 116, in _dilation_conv\r\n    output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 661, in convolution\r\n    op=op)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 331, in with_space_to_batch\r\n    return op(input, num_spatial_dims, padding)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 653, in op\r\n    name=name)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 140, in _non_atrous_convolution\r\n    name=name)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 529, in conv3d\r\n    strides=strides, padding=padding, name=name)\r\n  File \"/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n\r\nNotFoundError (see above for traceback): No algorithm without scratch worked!\r\n\t [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]\r\n\t [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_89_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n```\r\nI also check the `atrous_convolution_test.py` and it seems I used it right. \r\n\r\nI'm on Ubuntu 14.04 64 bit, tensorflow version 1.1.0-rc2. \r\n\r\nIf anyone can point me direction how to debug, that would be great. "}