{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9067", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9067/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9067/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9067/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9067", "id": 220390742, "node_id": "MDU6SXNzdWUyMjAzOTA3NDI=", "number": 9067, "title": "Tensorflow 1.1rc/1.01 too many epochs cause error?", "user": {"login": "Windaway", "id": 4530735, "node_id": "MDQ6VXNlcjQ1MzA3MzU=", "avatar_url": "https://avatars0.githubusercontent.com/u/4530735?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Windaway", "html_url": "https://github.com/Windaway", "followers_url": "https://api.github.com/users/Windaway/followers", "following_url": "https://api.github.com/users/Windaway/following{/other_user}", "gists_url": "https://api.github.com/users/Windaway/gists{/gist_id}", "starred_url": "https://api.github.com/users/Windaway/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Windaway/subscriptions", "organizations_url": "https://api.github.com/users/Windaway/orgs", "repos_url": "https://api.github.com/users/Windaway/repos", "events_url": "https://api.github.com/users/Windaway/events{/privacy}", "received_events_url": "https://api.github.com/users/Windaway/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-04-08T10:21:48Z", "updated_at": "2017-04-15T04:07:13Z", "closed_at": "2017-04-15T04:07:13Z", "author_association": "NONE", "body_html": "<p>Software:Tensorflow 1.1rc Python3.5.27&amp;Tensorflow 1.0.1 Python3.5.3 (Anaconda3) CUDA8.0+Cudnn5.1<br>\nOS:Windows 10 X64 1607<br>\nHW:i5 6400 Z170 16G 1070</p>\n<h3>Describe the problem clearly</h3>\n<p>When I train my mlp or lenet5, if I choose a large epoch number, then it will get a bad result?</p>\n<h3>Source Code / Logs</h3>\n<pre><code>from tensorflow.examples.tutorials.mnist import  input_data\nimport  tensorflow as tf\nmnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\nsess=tf.InteractiveSession()\nin_units=784\nh1_units=300\nW1=tf.Variable(tf.truncated_normal([in_units,h1_units],stddev=0.1))\nb1=tf.Variable(tf.zeros([h1_units]))\nW2=tf.Variable(tf.zeros([h1_units,10]))\nb2=tf.Variable(tf.zeros([10]))\nx=tf.placeholder(tf.float32,[None,in_units])\nkeep_prob=tf.placeholder(tf.float32)\nhidden1=tf.nn.relu(tf.matmul(x,W1)+b1)\nhidden1_drop=tf.nn.dropout(hidden1,keep_prob)\ny=tf.nn.softmax(tf.matmul(hidden1_drop,W2)+b2)\ny_=tf.placeholder(tf.float32,[None,10])\ncross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\ntrain_step=tf.train.AdagradOptimizer(0.03).minimize(cross_entropy)\ntf.global_variables_initializer().run()\ncorrect_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\nfor i in range(200000):\n    batch_xs,batch_ys=mnist.train.next_batch(500)\n    train_step.run({x:batch_xs,y_:batch_ys,keep_prob:0.8})\n    if i % 500==0:\n        print(i,\"--\",accuracy.eval({x:batch_xs,y_:batch_ys, keep_prob: 1.0}))\n\ncorrect_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\nprint(accuracy.eval({x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))\n</code></pre>\n<blockquote>\n<p>C:\\Anaconda3\\envs\\TensorflowRC\\python.exe D:/DL/3/mlp.py<br>\nExtracting MNIST_data/train-images-idx3-ubyte.gz<br>\nExtracting MNIST_data/train-labels-idx1-ubyte.gz<br>\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz<br>\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz<br>\n2017-04-08 18:07:28.117898: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.118165: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.118511: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.118745: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.120818: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.121070: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.121354: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.121578: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.<br>\n2017-04-08 18:07:28.511257: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:887] Found device 0 with properties:<br>\nname: GeForce GTX 1070<br>\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.645<br>\npciBusID 0000:01:00.0<br>\nTotal memory: 8.00GiB<br>\nFree memory: 6.65GiB<br>\n2017-04-08 18:07:28.511561: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:908] DMA: 0<br>\n2017-04-08 18:07:28.511694: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:918] 0:   Y<br>\n2017-04-08 18:07:28.511840: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)<br>\n0 -- 0.404<br>\n500 -- 0.914<br>\n1000 -- 0.932<br>\n1500 -- 0.95<br>\n2000 -- 0.966<br>\n2500 -- 0.944<br>\n3000 -- 0.952<br>\n3500 -- 0.966</p>\n</blockquote>\n<blockquote>\n<p>80500 -- 1.0<br>\n81000 -- 1.0<br>\n81500 -- 1.0<br>\n82000 -- 1.0<br>\n82500 -- 0.094<br>\n83000 -- 0.112<br>\n83500 -- 0.106<br>\n84000 -- 0.094<br>\n84500 -- 0.118<br>\n85000 -- 0.096<br>\n85500 -- 0.088<br>\n86000 -- 0.114<br>\n86500 -- 0.114<br>\n87000 -- 0.092<br>\n87500 -- 0.114<br>\n88000 -- 0.1<br>\n88500 -- 0.104</p>\n</blockquote>", "body_text": "Software:Tensorflow 1.1rc Python3.5.27&Tensorflow 1.0.1 Python3.5.3 (Anaconda3) CUDA8.0+Cudnn5.1\nOS:Windows 10 X64 1607\nHW:i5 6400 Z170 16G 1070\nDescribe the problem clearly\nWhen I train my mlp or lenet5, if I choose a large epoch number, then it will get a bad result?\nSource Code / Logs\nfrom tensorflow.examples.tutorials.mnist import  input_data\nimport  tensorflow as tf\nmnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\nsess=tf.InteractiveSession()\nin_units=784\nh1_units=300\nW1=tf.Variable(tf.truncated_normal([in_units,h1_units],stddev=0.1))\nb1=tf.Variable(tf.zeros([h1_units]))\nW2=tf.Variable(tf.zeros([h1_units,10]))\nb2=tf.Variable(tf.zeros([10]))\nx=tf.placeholder(tf.float32,[None,in_units])\nkeep_prob=tf.placeholder(tf.float32)\nhidden1=tf.nn.relu(tf.matmul(x,W1)+b1)\nhidden1_drop=tf.nn.dropout(hidden1,keep_prob)\ny=tf.nn.softmax(tf.matmul(hidden1_drop,W2)+b2)\ny_=tf.placeholder(tf.float32,[None,10])\ncross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\ntrain_step=tf.train.AdagradOptimizer(0.03).minimize(cross_entropy)\ntf.global_variables_initializer().run()\ncorrect_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\nfor i in range(200000):\n    batch_xs,batch_ys=mnist.train.next_batch(500)\n    train_step.run({x:batch_xs,y_:batch_ys,keep_prob:0.8})\n    if i % 500==0:\n        print(i,\"--\",accuracy.eval({x:batch_xs,y_:batch_ys, keep_prob: 1.0}))\n\ncorrect_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\nprint(accuracy.eval({x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))\n\n\nC:\\Anaconda3\\envs\\TensorflowRC\\python.exe D:/DL/3/mlp.py\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n2017-04-08 18:07:28.117898: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.118165: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.118511: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.118745: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.120818: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.121070: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.121354: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.121578: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-04-08 18:07:28.511257: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:887] Found device 0 with properties:\nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.645\npciBusID 0000:01:00.0\nTotal memory: 8.00GiB\nFree memory: 6.65GiB\n2017-04-08 18:07:28.511561: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:908] DMA: 0\n2017-04-08 18:07:28.511694: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:918] 0:   Y\n2017-04-08 18:07:28.511840: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\n0 -- 0.404\n500 -- 0.914\n1000 -- 0.932\n1500 -- 0.95\n2000 -- 0.966\n2500 -- 0.944\n3000 -- 0.952\n3500 -- 0.966\n\n\n80500 -- 1.0\n81000 -- 1.0\n81500 -- 1.0\n82000 -- 1.0\n82500 -- 0.094\n83000 -- 0.112\n83500 -- 0.106\n84000 -- 0.094\n84500 -- 0.118\n85000 -- 0.096\n85500 -- 0.088\n86000 -- 0.114\n86500 -- 0.114\n87000 -- 0.092\n87500 -- 0.114\n88000 -- 0.1\n88500 -- 0.104", "body": "Software:Tensorflow 1.1rc Python3.5.27&Tensorflow 1.0.1 Python3.5.3 (Anaconda3) CUDA8.0+Cudnn5.1\r\nOS:Windows 10 X64 1607\r\nHW:i5 6400 Z170 16G 1070\r\n\r\n### Describe the problem clearly\r\nWhen I train my mlp or lenet5, if I choose a large epoch number, then it will get a bad result?\r\n\r\n### Source Code / Logs\r\n```\r\nfrom tensorflow.examples.tutorials.mnist import  input_data\r\nimport  tensorflow as tf\r\nmnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\r\nsess=tf.InteractiveSession()\r\nin_units=784\r\nh1_units=300\r\nW1=tf.Variable(tf.truncated_normal([in_units,h1_units],stddev=0.1))\r\nb1=tf.Variable(tf.zeros([h1_units]))\r\nW2=tf.Variable(tf.zeros([h1_units,10]))\r\nb2=tf.Variable(tf.zeros([10]))\r\nx=tf.placeholder(tf.float32,[None,in_units])\r\nkeep_prob=tf.placeholder(tf.float32)\r\nhidden1=tf.nn.relu(tf.matmul(x,W1)+b1)\r\nhidden1_drop=tf.nn.dropout(hidden1,keep_prob)\r\ny=tf.nn.softmax(tf.matmul(hidden1_drop,W2)+b2)\r\ny_=tf.placeholder(tf.float32,[None,10])\r\ncross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\r\ntrain_step=tf.train.AdagradOptimizer(0.03).minimize(cross_entropy)\r\ntf.global_variables_initializer().run()\r\ncorrect_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\r\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\nfor i in range(200000):\r\n    batch_xs,batch_ys=mnist.train.next_batch(500)\r\n    train_step.run({x:batch_xs,y_:batch_ys,keep_prob:0.8})\r\n    if i % 500==0:\r\n        print(i,\"--\",accuracy.eval({x:batch_xs,y_:batch_ys, keep_prob: 1.0}))\r\n\r\ncorrect_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\r\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\nprint(accuracy.eval({x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))\r\n```\r\n\r\n\r\n\r\n\r\n> C:\\Anaconda3\\envs\\TensorflowRC\\python.exe D:/DL/3/mlp.py\r\n> Extracting MNIST_data/train-images-idx3-ubyte.gz\r\n> Extracting MNIST_data/train-labels-idx1-ubyte.gz\r\n> Extracting MNIST_data/t10k-images-idx3-ubyte.gz\r\n> Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\n> 2017-04-08 18:07:28.117898: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.118165: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.118511: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.118745: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.120818: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.121070: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.121354: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.121578: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n> 2017-04-08 18:07:28.511257: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:887] Found device 0 with properties: \r\n> name: GeForce GTX 1070\r\n> major: 6 minor: 1 memoryClockRate (GHz) 1.645\r\n> pciBusID 0000:01:00.0\r\n> Total memory: 8.00GiB\r\n> Free memory: 6.65GiB\r\n> 2017-04-08 18:07:28.511561: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:908] DMA: 0 \r\n> 2017-04-08 18:07:28.511694: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:918] 0:   Y \r\n> 2017-04-08 18:07:28.511840: I c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\r\n> 0 -- 0.404\r\n> 500 -- 0.914\r\n> 1000 -- 0.932\r\n> 1500 -- 0.95\r\n> 2000 -- 0.966\r\n> 2500 -- 0.944\r\n> 3000 -- 0.952\r\n> 3500 -- 0.966\r\n\r\n> \r\n> 80500 -- 1.0\r\n> 81000 -- 1.0\r\n> 81500 -- 1.0\r\n> 82000 -- 1.0\r\n> 82500 -- 0.094\r\n> 83000 -- 0.112\r\n> 83500 -- 0.106\r\n> 84000 -- 0.094\r\n> 84500 -- 0.118\r\n> 85000 -- 0.096\r\n> 85500 -- 0.088\r\n> 86000 -- 0.114\r\n> 86500 -- 0.114\r\n> 87000 -- 0.092\r\n> 87500 -- 0.114\r\n> 88000 -- 0.1\r\n> 88500 -- 0.104"}