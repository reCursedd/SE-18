{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288863402", "html_url": "https://github.com/tensorflow/tensorflow/issues/8602#issuecomment-288863402", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8602", "id": 288863402, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODg2MzQwMg==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-23T21:19:06Z", "updated_at": "2017-03-23T21:19:06Z", "author_association": "MEMBER", "body_html": "<p>I would not do this distributed. Unless I am missing something, I would run 4 different Tensorflow instances targeted at CPU:0, one for each model you are training.  If that performance looks poor you could go back and compare running multiple workers with a ps_server on a single server vs 1 instance not distributed.   If you think the performance is not expected, then you can compare (if you wanted) 1 instance vs. a distributed setup.  I would be interested in the results but I suspect for a normal 2 socket XEON it would not be better to run distributed on a single server.</p>", "body_text": "I would not do this distributed. Unless I am missing something, I would run 4 different Tensorflow instances targeted at CPU:0, one for each model you are training.  If that performance looks poor you could go back and compare running multiple workers with a ps_server on a single server vs 1 instance not distributed.   If you think the performance is not expected, then you can compare (if you wanted) 1 instance vs. a distributed setup.  I would be interested in the results but I suspect for a normal 2 socket XEON it would not be better to run distributed on a single server.", "body": "I would not do this distributed. Unless I am missing something, I would run 4 different Tensorflow instances targeted at CPU:0, one for each model you are training.  If that performance looks poor you could go back and compare running multiple workers with a ps_server on a single server vs 1 instance not distributed.   If you think the performance is not expected, then you can compare (if you wanted) 1 instance vs. a distributed setup.  I would be interested in the results but I suspect for a normal 2 socket XEON it would not be better to run distributed on a single server.  "}