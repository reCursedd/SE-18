{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3453", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3453/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3453/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3453/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3453", "id": 166912975, "node_id": "MDU6SXNzdWUxNjY5MTI5NzU=", "number": 3453, "title": "Saver (sharded) ignores number of checkpoints to keep", "user": {"login": "mmuneebs", "id": 16750872, "node_id": "MDQ6VXNlcjE2NzUwODcy", "avatar_url": "https://avatars1.githubusercontent.com/u/16750872?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mmuneebs", "html_url": "https://github.com/mmuneebs", "followers_url": "https://api.github.com/users/mmuneebs/followers", "following_url": "https://api.github.com/users/mmuneebs/following{/other_user}", "gists_url": "https://api.github.com/users/mmuneebs/gists{/gist_id}", "starred_url": "https://api.github.com/users/mmuneebs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mmuneebs/subscriptions", "organizations_url": "https://api.github.com/users/mmuneebs/orgs", "repos_url": "https://api.github.com/users/mmuneebs/repos", "events_url": "https://api.github.com/users/mmuneebs/events{/privacy}", "received_events_url": "https://api.github.com/users/mmuneebs/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-07-21T20:42:15Z", "updated_at": "2016-08-01T20:54:55Z", "closed_at": "2016-08-01T20:54:55Z", "author_association": "NONE", "body_html": "<p><code>tf.train.Saver()</code> has a default limit of 5 most recent checkpoints to keep (<code>max_to_keep=5</code>). When I use a Saver with <code>sharded=True</code> option, only one machine performs this check and keeps ALL the checkpoints without removing any of them.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 14.04 LTS<br>\nBuilt from source; commit hash: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/aa2cacd6627ffb296bedc910c957a0fd4a2f957f/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/aa2cacd6627ffb296bedc910c957a0fd4a2f957f\"><tt>aa2cacd</tt></a></p>\n<h3>Steps to reproduce</h3>\n<ul>\n<li>Init a sharded saver and pass it to the Supervisor for distributed training and auto-model saving after every <code>save_model_secs</code>.</li>\n</ul>\n<pre><code>saver = tf.train.Saver(sharded=True)\nsv = tf.train.Supervisor(is_chief=is_chief,\n                                 logdir=FLAGS.train_dir,\n                                 init_op=init_op,\n                                 summary_op=None,\n                                 global_step=global_step,\n                                 saver=saver,\n                                 save_model_secs=FLAGS.save_interval_secs)\n</code></pre>\n<ul>\n<li>Start two workers and one ps on machine 0. Start two more workers and one ps on machine 1.</li>\n<li>The saver keeps the 5 most recent sharded checkpoints on machine 0 (where the chief worker also runs). But machine 1 keeps all sharded checkpoints from beginning.</li>\n</ul>", "body_text": "tf.train.Saver() has a default limit of 5 most recent checkpoints to keep (max_to_keep=5). When I use a Saver with sharded=True option, only one machine performs this check and keeps ALL the checkpoints without removing any of them.\nEnvironment info\nOperating System: Ubuntu 14.04 LTS\nBuilt from source; commit hash: aa2cacd\nSteps to reproduce\n\nInit a sharded saver and pass it to the Supervisor for distributed training and auto-model saving after every save_model_secs.\n\nsaver = tf.train.Saver(sharded=True)\nsv = tf.train.Supervisor(is_chief=is_chief,\n                                 logdir=FLAGS.train_dir,\n                                 init_op=init_op,\n                                 summary_op=None,\n                                 global_step=global_step,\n                                 saver=saver,\n                                 save_model_secs=FLAGS.save_interval_secs)\n\n\nStart two workers and one ps on machine 0. Start two more workers and one ps on machine 1.\nThe saver keeps the 5 most recent sharded checkpoints on machine 0 (where the chief worker also runs). But machine 1 keeps all sharded checkpoints from beginning.", "body": "`tf.train.Saver()` has a default limit of 5 most recent checkpoints to keep (`max_to_keep=5`). When I use a Saver with `sharded=True` option, only one machine performs this check and keeps ALL the checkpoints without removing any of them.\n### Environment info\n\nOperating System: Ubuntu 14.04 LTS\nBuilt from source; commit hash: aa2cacd6627ffb296bedc910c957a0fd4a2f957f\n### Steps to reproduce\n- Init a sharded saver and pass it to the Supervisor for distributed training and auto-model saving after every `save_model_secs`.\n\n```\nsaver = tf.train.Saver(sharded=True)\nsv = tf.train.Supervisor(is_chief=is_chief,\n                                 logdir=FLAGS.train_dir,\n                                 init_op=init_op,\n                                 summary_op=None,\n                                 global_step=global_step,\n                                 saver=saver,\n                                 save_model_secs=FLAGS.save_interval_secs)\n```\n- Start two workers and one ps on machine 0. Start two more workers and one ps on machine 1.\n- The saver keeps the 5 most recent sharded checkpoints on machine 0 (where the chief worker also runs). But machine 1 keeps all sharded checkpoints from beginning.\n"}