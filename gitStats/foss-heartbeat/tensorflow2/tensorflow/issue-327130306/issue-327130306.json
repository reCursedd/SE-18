{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19603", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19603/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19603/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19603/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19603", "id": 327130306, "node_id": "MDU6SXNzdWUzMjcxMzAzMDY=", "number": 19603, "title": "terminate called after throwing an instance of 'std::bad_alloc', over 20Gb memory free", "user": {"login": "mullenba", "id": 8420667, "node_id": "MDQ6VXNlcjg0MjA2Njc=", "avatar_url": "https://avatars1.githubusercontent.com/u/8420667?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mullenba", "html_url": "https://github.com/mullenba", "followers_url": "https://api.github.com/users/mullenba/followers", "following_url": "https://api.github.com/users/mullenba/following{/other_user}", "gists_url": "https://api.github.com/users/mullenba/gists{/gist_id}", "starred_url": "https://api.github.com/users/mullenba/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mullenba/subscriptions", "organizations_url": "https://api.github.com/users/mullenba/orgs", "repos_url": "https://api.github.com/users/mullenba/repos", "events_url": "https://api.github.com/users/mullenba/events{/privacy}", "received_events_url": "https://api.github.com/users/mullenba/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-05-28T23:05:10Z", "updated_at": "2018-09-15T18:41:56Z", "closed_at": "2018-09-15T18:29:43Z", "author_association": "NONE", "body_html": "<p>Training a small model in Keras, getting this error after about 20 epochs (of 10000 samples).  While training is running, the system is chugging along happily with about 43Gb of memory free.  At about epoch 20, suddenly everything stops and free memory drops to about 20Gb before throwing the error.</p>\n<p>Seems to be the same issue as <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"224801656\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/9487\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/9487/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/9487\">#9487</a></p>\n<pre><code>terminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\n</code></pre>\n<p>tf_env data:</p>\n<blockquote>\n<p>== cat /etc/issue ===============================================<br>\nLinux 7ff559301433 4.10.0-37-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115969727\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/41\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/41/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/41\">#41</a>-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nYes</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux 7ff559301433 4.10.0-37-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115969727\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/41\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/41/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/41\">#41</a>-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy (1.14.3)<br>\nprotobuf (3.4.0)<br>\ntensorflow-gpu (1.3.0)<br>\ntensorflow-tensorboard (0.1.8)</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.3.0<br>\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee<br>\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nMon May 28 18:57:01 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 750 Ti  Off  | 00000000:0B:00.0 Off |                  N/A |<br>\n| 33%   30C    P0     1W /  38W |     11MiB /  2000MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  GeForce GTX 660     Off  | 00000000:14:00.0 N/A |                  N/A |<br>\n| 30%   34C    P0    N/A /  N/A |     11MiB /  1999MiB |     N/A      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    1                    Not Supported                                       |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61<br>\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a</p>\n</blockquote>\n<p>The data loading code isn't important, just opening files and getting 64x64 pixel chunks of each.  I'm attaching the actual NN code though.</p>\n<pre><code>import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.utils import multi_gpu_model\nfrom keras.layers import Convolution2D, MaxPooling2D, Conv2DTranspose\n\nfrom keras import backend as K\nK.clear_session()\n\nimport numpy as np\n\nimport dataPool2 as dp\n\ndef psnr(img1, img2):\n    #print(img1.shape, img2.shape)\n    #assert img1.shape == img2.shape\n\n    mse = tf.losses.mean_squared_error(img1, img2)\n\n    score = 3 * tf.log((255 ** 2) / mse)\n    \n    return 1 / score\n\ndef srcnnModel():\n\tmodel = Sequential()\n\tmodel.add(Convolution2D(64, (9, 9), activation='relu', padding='same', input_shape=(64,64,1)))\n\tmodel.add(Convolution2D(32, (1, 1), activation='relu', padding='same'))\n\tmodel.add(Convolution2D(1, (5, 5), padding='same'))\n\t\n\tmodel.compile(loss='mse',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n\treturn model\n\nwith tf.device('/cpu:0'):\n    model = srcnnModel()\n\nprint(model.summary())\n\t\nparallel_model = multi_gpu_model(model, gpus=2)\nparallel_model.compile(loss=psnr,\n                       optimizer='adam')\n\t\t\t\t   \n# Generate Data\nxYchan, xCrCb, yYchan, origY = dp.createDataset(\"test_images/\", 10000)\n\nparallel_model.fit(np.array(xYchan), np.array(yYchan), epochs=200, batch_size=128, callbacks=[\n                keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=3, verbose=0, mode='auto')],) \n</code></pre>", "body_text": "Training a small model in Keras, getting this error after about 20 epochs (of 10000 samples).  While training is running, the system is chugging along happily with about 43Gb of memory free.  At about epoch 20, suddenly everything stops and free memory drops to about 20Gb before throwing the error.\nSeems to be the same issue as #9487\nterminate called after throwing an instance of 'std::bad_alloc'\n  what():  std::bad_alloc\n\ntf_env data:\n\n== cat /etc/issue ===============================================\nLinux 7ff559301433 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nYes\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux 7ff559301433 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy (1.14.3)\nprotobuf (3.4.0)\ntensorflow-gpu (1.3.0)\ntensorflow-tensorboard (0.1.8)\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.3.0\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nMon May 28 18:57:01 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 750 Ti  Off  | 00000000:0B:00.0 Off |                  N/A |\n| 33%   30C    P0     1W /  38W |     11MiB /  2000MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 660     Off  | 00000000:14:00.0 N/A |                  N/A |\n| 30%   34C    P0    N/A /  N/A |     11MiB /  1999MiB |     N/A      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    1                    Not Supported                                       |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\n\nThe data loading code isn't important, just opening files and getting 64x64 pixel chunks of each.  I'm attaching the actual NN code though.\nimport tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.utils import multi_gpu_model\nfrom keras.layers import Convolution2D, MaxPooling2D, Conv2DTranspose\n\nfrom keras import backend as K\nK.clear_session()\n\nimport numpy as np\n\nimport dataPool2 as dp\n\ndef psnr(img1, img2):\n    #print(img1.shape, img2.shape)\n    #assert img1.shape == img2.shape\n\n    mse = tf.losses.mean_squared_error(img1, img2)\n\n    score = 3 * tf.log((255 ** 2) / mse)\n    \n    return 1 / score\n\ndef srcnnModel():\n\tmodel = Sequential()\n\tmodel.add(Convolution2D(64, (9, 9), activation='relu', padding='same', input_shape=(64,64,1)))\n\tmodel.add(Convolution2D(32, (1, 1), activation='relu', padding='same'))\n\tmodel.add(Convolution2D(1, (5, 5), padding='same'))\n\t\n\tmodel.compile(loss='mse',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n\treturn model\n\nwith tf.device('/cpu:0'):\n    model = srcnnModel()\n\nprint(model.summary())\n\t\nparallel_model = multi_gpu_model(model, gpus=2)\nparallel_model.compile(loss=psnr,\n                       optimizer='adam')\n\t\t\t\t   \n# Generate Data\nxYchan, xCrCb, yYchan, origY = dp.createDataset(\"test_images/\", 10000)\n\nparallel_model.fit(np.array(xYchan), np.array(yYchan), epochs=200, batch_size=128, callbacks=[\n                keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=3, verbose=0, mode='auto')],)", "body": "Training a small model in Keras, getting this error after about 20 epochs (of 10000 samples).  While training is running, the system is chugging along happily with about 43Gb of memory free.  At about epoch 20, suddenly everything stops and free memory drops to about 20Gb before throwing the error.\r\n\r\nSeems to be the same issue as #9487\r\n```\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\n```\r\n\r\n\r\ntf_env data:\r\n\r\n> == cat /etc/issue ===============================================\r\n> Linux 7ff559301433 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n> VERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\n> VERSION_ID=\"16.04\"\r\n> VERSION_CODENAME=xenial\r\n> \r\n> == are we in docker =============================================\r\n> Yes\r\n> \r\n> == compiler =====================================================\r\n> c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n> Copyright (C) 2015 Free Software Foundation, Inc.\r\n> This is free software; see the source for copying conditions.  There is NO\r\n> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n> \r\n> \r\n> == uname -a =====================================================\r\n> Linux 7ff559301433 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n> \r\n> == check pips ===================================================\r\n> numpy (1.14.3)\r\n> protobuf (3.4.0)\r\n> tensorflow-gpu (1.3.0)\r\n> tensorflow-tensorboard (0.1.8)\r\n> \r\n> == check for virtualenv =========================================\r\n> False\r\n> \r\n> == tensorflow import ============================================\r\n> tf.VERSION = 1.3.0\r\n> tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\n> tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\n> Sanity check: array([1], dtype=int32)\r\n> \r\n> == env ==========================================================\r\n> LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n> DYLD_LIBRARY_PATH is unset\r\n> \r\n> == nvidia-smi ===================================================\r\n> Mon May 28 18:57:01 2018       \r\n> +-----------------------------------------------------------------------------+\r\n> | NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\r\n> |-------------------------------+----------------------+----------------------+\r\n> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n> |===============================+======================+======================|\r\n> |   0  GeForce GTX 750 Ti  Off  | 00000000:0B:00.0 Off |                  N/A |\r\n> | 33%   30C    P0     1W /  38W |     11MiB /  2000MiB |      0%      Default |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   1  GeForce GTX 660     Off  | 00000000:14:00.0 N/A |                  N/A |\r\n> | 30%   34C    P0    N/A /  N/A |     11MiB /  1999MiB |     N/A      Default |\r\n> +-------------------------------+----------------------+----------------------+\r\n>                                                                                \r\n> +-----------------------------------------------------------------------------+\r\n> | Processes:                                                       GPU Memory |\r\n> |  GPU       PID   Type   Process name                             Usage      |\r\n> |=============================================================================|\r\n> |    1                    Not Supported                                       |\r\n> +-----------------------------------------------------------------------------+\r\n> \r\n> == cuda libs  ===================================================\r\n> /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n> /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n> \r\n\r\nThe data loading code isn't important, just opening files and getting 64x64 pixel chunks of each.  I'm attaching the actual NN code though.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.utils import multi_gpu_model\r\nfrom keras.layers import Convolution2D, MaxPooling2D, Conv2DTranspose\r\n\r\nfrom keras import backend as K\r\nK.clear_session()\r\n\r\nimport numpy as np\r\n\r\nimport dataPool2 as dp\r\n\r\ndef psnr(img1, img2):\r\n    #print(img1.shape, img2.shape)\r\n    #assert img1.shape == img2.shape\r\n\r\n    mse = tf.losses.mean_squared_error(img1, img2)\r\n\r\n    score = 3 * tf.log((255 ** 2) / mse)\r\n    \r\n    return 1 / score\r\n\r\ndef srcnnModel():\r\n\tmodel = Sequential()\r\n\tmodel.add(Convolution2D(64, (9, 9), activation='relu', padding='same', input_shape=(64,64,1)))\r\n\tmodel.add(Convolution2D(32, (1, 1), activation='relu', padding='same'))\r\n\tmodel.add(Convolution2D(1, (5, 5), padding='same'))\r\n\t\r\n\tmodel.compile(loss='mse',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n\r\n\treturn model\r\n\r\nwith tf.device('/cpu:0'):\r\n    model = srcnnModel()\r\n\r\nprint(model.summary())\r\n\t\r\nparallel_model = multi_gpu_model(model, gpus=2)\r\nparallel_model.compile(loss=psnr,\r\n                       optimizer='adam')\r\n\t\t\t\t   \r\n# Generate Data\r\nxYchan, xCrCb, yYchan, origY = dp.createDataset(\"test_images/\", 10000)\r\n\r\nparallel_model.fit(np.array(xYchan), np.array(yYchan), epochs=200, batch_size=128, callbacks=[\r\n                keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=3, verbose=0, mode='auto')],) \r\n```"}