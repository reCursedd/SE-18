{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/351884332", "html_url": "https://github.com/tensorflow/tensorflow/issues/12859#issuecomment-351884332", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12859", "id": 351884332, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTg4NDMzMg==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-15T01:11:49Z", "updated_at": "2017-12-15T01:11:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4192637\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/maxfiedler\">@maxfiedler</a> <code>Dataset.from_tensor_slices()</code> will always convert its arguments to tensors, so if you have a large input, it will always be encoded in the graph. The best way to work around this is to replace the list/array of inputs with a TensorFlow op that calculates the same list (e.g. <a href=\"https://www.tensorflow.org/api_docs/python/tf/matching_files\" rel=\"nofollow\"><code>tf.matching_files(pattern)</code></a>). If you need arbitrary Python logic to construct the list, you could instead use <code>Dataset.from_generator(lambda: list_of_file_path_strings)</code>, which will not encode the strings into the graph.</p>\n<p>(Note however that using <code>tf.matching_files()</code> is preferable to <code>Dataset.from_generator()</code> because the former allows you to save the graph and restore it. The Python functions used in <code>Dataset.from_generator()</code> will not be saved when you save the graph.)</p>", "body_text": "@maxfiedler Dataset.from_tensor_slices() will always convert its arguments to tensors, so if you have a large input, it will always be encoded in the graph. The best way to work around this is to replace the list/array of inputs with a TensorFlow op that calculates the same list (e.g. tf.matching_files(pattern)). If you need arbitrary Python logic to construct the list, you could instead use Dataset.from_generator(lambda: list_of_file_path_strings), which will not encode the strings into the graph.\n(Note however that using tf.matching_files() is preferable to Dataset.from_generator() because the former allows you to save the graph and restore it. The Python functions used in Dataset.from_generator() will not be saved when you save the graph.)", "body": "@maxfiedler `Dataset.from_tensor_slices()` will always convert its arguments to tensors, so if you have a large input, it will always be encoded in the graph. The best way to work around this is to replace the list/array of inputs with a TensorFlow op that calculates the same list (e.g. [`tf.matching_files(pattern)`](https://www.tensorflow.org/api_docs/python/tf/matching_files)). If you need arbitrary Python logic to construct the list, you could instead use `Dataset.from_generator(lambda: list_of_file_path_strings)`, which will not encode the strings into the graph.\r\n\r\n(Note however that using `tf.matching_files()` is preferable to `Dataset.from_generator()` because the former allows you to save the graph and restore it. The Python functions used in `Dataset.from_generator()` will not be saved when you save the graph.)"}