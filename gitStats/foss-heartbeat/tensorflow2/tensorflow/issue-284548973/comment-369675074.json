{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/369675074", "html_url": "https://github.com/tensorflow/tensorflow/pull/15640#issuecomment-369675074", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15640", "id": 369675074, "node_id": "MDEyOklzc3VlQ29tbWVudDM2OTY3NTA3NA==", "user": {"login": "xiejw", "id": 1184671, "node_id": "MDQ6VXNlcjExODQ2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1184671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiejw", "html_url": "https://github.com/xiejw", "followers_url": "https://api.github.com/users/xiejw/followers", "following_url": "https://api.github.com/users/xiejw/following{/other_user}", "gists_url": "https://api.github.com/users/xiejw/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiejw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiejw/subscriptions", "organizations_url": "https://api.github.com/users/xiejw/orgs", "repos_url": "https://api.github.com/users/xiejw/repos", "events_url": "https://api.github.com/users/xiejw/events{/privacy}", "received_events_url": "https://api.github.com/users/xiejw/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-01T17:55:01Z", "updated_at": "2018-03-01T17:56:15Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks. The code looks good to me. This is a tradeoff we need to decide. Currently, Estimator mostly works with ps in distributed model. But in future, this assumption might not hold anymore. Device_fn provides a better abstraction for that.</p>\n<p>Regarding the issue changing ps_strategy: The get_replica_device_setter can be much simplified as</p>\n<pre><code> def get_replica_device_setter(config, ps_strategy):\n  ps_ops = [\n      'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n      'MutableHashTableV2', 'MutableHashTableOfTensors',\n      'MutableHashTableOfTensorsV2', 'MutableDenseHashTable',\n      'MutableDenseHashTableV2', 'VarHandleOp'\n  ]\n\n worker_device = '/job:%s/task:%d' % (config.task_type, config.task_id) \n return training.replica_device_setter(\n        ps_tasks=config.num_ps_replicas,\n        worker_device=worker_device,\n        merge_devices=True,\n        ps_ops=ps_ops,\n        cluster=config.cluster_spec,\n        ps_strategy=ps_strategy)  # This is the only difference from the original code\n</code></pre>\n<p>As user is changing the ps_strategy, all the if-else branches are not necessary. The only remaining silly thing here is the ps_ops list. I think it should not be defined here and user needs to copy/paste. I will move it as a constant list to replica_device_setter. such that user can easily refer them. With that, user code could be significantly reduced. Does this sound reasonable?</p>", "body_text": "Thanks. The code looks good to me. This is a tradeoff we need to decide. Currently, Estimator mostly works with ps in distributed model. But in future, this assumption might not hold anymore. Device_fn provides a better abstraction for that.\nRegarding the issue changing ps_strategy: The get_replica_device_setter can be much simplified as\n def get_replica_device_setter(config, ps_strategy):\n  ps_ops = [\n      'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n      'MutableHashTableV2', 'MutableHashTableOfTensors',\n      'MutableHashTableOfTensorsV2', 'MutableDenseHashTable',\n      'MutableDenseHashTableV2', 'VarHandleOp'\n  ]\n\n worker_device = '/job:%s/task:%d' % (config.task_type, config.task_id) \n return training.replica_device_setter(\n        ps_tasks=config.num_ps_replicas,\n        worker_device=worker_device,\n        merge_devices=True,\n        ps_ops=ps_ops,\n        cluster=config.cluster_spec,\n        ps_strategy=ps_strategy)  # This is the only difference from the original code\n\nAs user is changing the ps_strategy, all the if-else branches are not necessary. The only remaining silly thing here is the ps_ops list. I think it should not be defined here and user needs to copy/paste. I will move it as a constant list to replica_device_setter. such that user can easily refer them. With that, user code could be significantly reduced. Does this sound reasonable?", "body": "Thanks. The code looks good to me. This is a tradeoff we need to decide. Currently, Estimator mostly works with ps in distributed model. But in future, this assumption might not hold anymore. Device_fn provides a better abstraction for that. \r\n\r\nRegarding the issue changing ps_strategy: The get_replica_device_setter can be much simplified as\r\n\r\n     def get_replica_device_setter(config, ps_strategy):\r\n      ps_ops = [\r\n          'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\r\n          'MutableHashTableV2', 'MutableHashTableOfTensors',\r\n          'MutableHashTableOfTensorsV2', 'MutableDenseHashTable',\r\n          'MutableDenseHashTableV2', 'VarHandleOp'\r\n      ]\r\n\r\n     worker_device = '/job:%s/task:%d' % (config.task_type, config.task_id) \r\n     return training.replica_device_setter(\r\n            ps_tasks=config.num_ps_replicas,\r\n            worker_device=worker_device,\r\n            merge_devices=True,\r\n            ps_ops=ps_ops,\r\n            cluster=config.cluster_spec,\r\n            ps_strategy=ps_strategy)  # This is the only difference from the original code\r\n \r\n\r\nAs user is changing the ps_strategy, all the if-else branches are not necessary. The only remaining silly thing here is the ps_ops list. I think it should not be defined here and user needs to copy/paste. I will move it as a constant list to replica_device_setter. such that user can easily refer them. With that, user code could be significantly reduced. Does this sound reasonable? "}