{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/366489336", "html_url": "https://github.com/tensorflow/tensorflow/pull/15640#issuecomment-366489336", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15640", "id": 366489336, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjQ4OTMzNg==", "user": {"login": "dave-msk", "id": 20377823, "node_id": "MDQ6VXNlcjIwMzc3ODIz", "avatar_url": "https://avatars0.githubusercontent.com/u/20377823?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dave-msk", "html_url": "https://github.com/dave-msk", "followers_url": "https://api.github.com/users/dave-msk/followers", "following_url": "https://api.github.com/users/dave-msk/following{/other_user}", "gists_url": "https://api.github.com/users/dave-msk/gists{/gist_id}", "starred_url": "https://api.github.com/users/dave-msk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dave-msk/subscriptions", "organizations_url": "https://api.github.com/users/dave-msk/orgs", "repos_url": "https://api.github.com/users/dave-msk/repos", "events_url": "https://api.github.com/users/dave-msk/events{/privacy}", "received_events_url": "https://api.github.com/users/dave-msk/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-18T03:14:54Z", "updated_at": "2018-02-18T03:14:54Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I see the current approach for distributed training is that the RunConfig first parses the <code>TF_CONFIG</code> environment variable to get details like <code>master</code>, <code>task_id</code>, <code>num_ps_replicas</code> etc. These are then used to create a replica device setter when Estimator is constructed through the <code>training.replica_device_setter</code> call. To allow a dynamic <code>device_fn</code> override while preserving the convenience of the current approach, I'd suggest we do it this way:</p>\n<ol>\n<li>We add a <a class=\"user-mention\" data-hovercard-type=\"organization\" data-hovercard-url=\"/orgs/Property/hovercard\" href=\"https://github.com/Property\">@Property</a> <code>device_fn</code> to RunConfig, set it <code>None</code> as default</li>\n<li>We call <code>self._config.device_fn</code> to get the most updated version of <code>device_fn</code> in <code>_train_model</code> in Estimator.</li>\n<li>If the <code>device_fn</code> is <code>None</code> (not overridden by user) in RunConfig, we use the current approach (via <code>training.replica_device_setter</code> call) to return a \"default\" device function, with the <code>ps_strategy</code> I added in my previous commit.</li>\n<li>If the <code>device_fn</code> is not <code>None</code> (overridden by user) in RunConfig, we return it directly.</li>\n</ol>\n<p>If one chooses to write his own device function, he would have to define the <code>device_fn</code> (<code>config.device = foo</code>) and take care of everything manually. If the user just wanted to specify a <code>ps_strategy</code> other than the default round-robin (e.g. the <code>tf.contrib.training.GreedyLoadBalancingStrategy</code>), he could just construct the RunConfig with <code>ps_strategy</code> or do a replace (<code>config = config.replace(ps_strategy=ps_strategy)</code>).</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1184671\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/xiejw\">@xiejw</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=577277\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martinwicke\">@martinwicke</a> what do you think?</p>", "body_text": "I see the current approach for distributed training is that the RunConfig first parses the TF_CONFIG environment variable to get details like master, task_id, num_ps_replicas etc. These are then used to create a replica device setter when Estimator is constructed through the training.replica_device_setter call. To allow a dynamic device_fn override while preserving the convenience of the current approach, I'd suggest we do it this way:\n\nWe add a @Property device_fn to RunConfig, set it None as default\nWe call self._config.device_fn to get the most updated version of device_fn in _train_model in Estimator.\nIf the device_fn is None (not overridden by user) in RunConfig, we use the current approach (via training.replica_device_setter call) to return a \"default\" device function, with the ps_strategy I added in my previous commit.\nIf the device_fn is not None (overridden by user) in RunConfig, we return it directly.\n\nIf one chooses to write his own device function, he would have to define the device_fn (config.device = foo) and take care of everything manually. If the user just wanted to specify a ps_strategy other than the default round-robin (e.g. the tf.contrib.training.GreedyLoadBalancingStrategy), he could just construct the RunConfig with ps_strategy or do a replace (config = config.replace(ps_strategy=ps_strategy)).\n@xiejw @martinwicke what do you think?", "body": "I see the current approach for distributed training is that the RunConfig first parses the `TF_CONFIG` environment variable to get details like `master`, `task_id`, `num_ps_replicas` etc. These are then used to create a replica device setter when Estimator is constructed through the `training.replica_device_setter` call. To allow a dynamic `device_fn` override while preserving the convenience of the current approach, I'd suggest we do it this way:\r\n\r\n1. We add a @property `device_fn` to RunConfig, set it `None` as default\r\n2. We call `self._config.device_fn` to get the most updated version of `device_fn` in `_train_model` in Estimator.\r\n3. If the `device_fn` is `None` (not overridden by user) in RunConfig, we use the current approach (via `training.replica_device_setter` call) to return a \"default\" device function, with the `ps_strategy` I added in my previous commit.\r\n4. If the `device_fn` is not `None` (overridden by user) in RunConfig, we return it directly.\r\n\r\nIf one chooses to write his own device function, he would have to define the `device_fn` (`config.device = foo`) and take care of everything manually. If the user just wanted to specify a `ps_strategy` other than the default round-robin (e.g. the `tf.contrib.training.GreedyLoadBalancingStrategy`), he could just construct the RunConfig with `ps_strategy` or do a replace (`config = config.replace(ps_strategy=ps_strategy)`).\r\n\r\n@xiejw @martinwicke what do you think?"}