{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/439255269", "html_url": "https://github.com/tensorflow/tensorflow/issues/23719#issuecomment-439255269", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23719", "id": 439255269, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTI1NTI2OQ==", "user": {"login": "byronyi", "id": 2613663, "node_id": "MDQ6VXNlcjI2MTM2NjM=", "avatar_url": "https://avatars2.githubusercontent.com/u/2613663?v=4", "gravatar_id": "", "url": "https://api.github.com/users/byronyi", "html_url": "https://github.com/byronyi", "followers_url": "https://api.github.com/users/byronyi/followers", "following_url": "https://api.github.com/users/byronyi/following{/other_user}", "gists_url": "https://api.github.com/users/byronyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/byronyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/byronyi/subscriptions", "organizations_url": "https://api.github.com/users/byronyi/orgs", "repos_url": "https://api.github.com/users/byronyi/repos", "events_url": "https://api.github.com/users/byronyi/events{/privacy}", "received_events_url": "https://api.github.com/users/byronyi/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-16T01:56:26Z", "updated_at": "2018-11-16T01:56:26Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=42785357\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ymodak\">@ymodak</a> Met the same problem on Ubuntu Linux 16.04. I do not think it is a duplicate of <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"379641101\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/23674\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/23674/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/23674\">#23674</a>.</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ ./configure\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the <span class=\"pl-c1\">command</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>bazel shutdown<span class=\"pl-pds\">\"</span></span>.\nYou have bazel 0.19.1 installed.\nPlease specify the location of python. [Default is /home/byronyi/tf/bin/python]:\n\n\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;string&gt;<span class=\"pl-pds\">\"</span></span>, line 1, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\nAttributeError: <span class=\"pl-s\"><span class=\"pl-pds\">'</span>module<span class=\"pl-pds\">'</span></span> object has no attribute <span class=\"pl-s\"><span class=\"pl-pds\">'</span>getsitepackages<span class=\"pl-pds\">'</span></span>\nFound possible Python library paths:\n  /home/byronyi/tf/lib/python2.7/site-packages\nPlease input the desired Python library path to use.  Default is [/home/byronyi/tf/lib/python2.7/site-packages]\n\nDo you wish to build TensorFlow with XLA JIT support<span class=\"pl-k\">?</span> [Y/n]:\nXLA JIT support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support<span class=\"pl-k\">?</span> [y/N]:\nNo OpenCL SYCL support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with ROCm support<span class=\"pl-k\">?</span> [y/N]:\nNo ROCm support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support<span class=\"pl-k\">?</span> [y/N]: y\nCUDA support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]:\n\n\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md <span class=\"pl-k\">for</span> more details. [Default is /usr/local/cuda]:\n\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]:\n\n\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md <span class=\"pl-k\">for</span> more details. [Default is /usr/local/cuda]:\n\n\nDo you wish to build TensorFlow with TensorRT support<span class=\"pl-k\">?</span> [y/N]:\nNo TensorRT support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nPlease specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]:\n\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build <span class=\"pl-k\">time</span> and binary size. [Default is: 3.5,7.0]: 7.0\n\n\nDo you want to use clang as CUDA compiler<span class=\"pl-k\">?</span> [y/N]:\nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\n\n\nDo you wish to build TensorFlow with MPI support<span class=\"pl-k\">?</span> [y/N]:\nNo MPI support will be enabled <span class=\"pl-k\">for</span> TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--config=opt<span class=\"pl-pds\">\"</span></span> is specified [Default is -march<span class=\"pl-k\">=</span>native -Wno-sign-compare]:\n\n\nWould you like to interactively configure ./WORKSPACE <span class=\"pl-k\">for</span> Android builds<span class=\"pl-k\">?</span> [y/N]:\nNot configuring the WORKSPACE <span class=\"pl-k\">for</span> Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--config=&lt;&gt;<span class=\"pl-pds\">\"</span></span> to your build command. See .bazelrc <span class=\"pl-k\">for</span> more details.\n\t--config=mkl         \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build with MKL support.</span>\n\t--config=monolithic  \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Config for mostly static monolithic build.</span>\n\t--config=gdr         \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build with GDR support.</span>\n\t--config=verbs       \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build with libverbs support.</span>\n\t--config=ngraph      \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Build with Intel nGraph support.</span>\n\t--config=dynamic_kernels\t<span class=\"pl-c\"><span class=\"pl-c\">#</span> (Experimental) Build kernels into separate shared objects.</span>\nPreconfigured Bazel build configs to DISABLE default on features:\n\t--config=noaws       \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Disable AWS S3 filesystem support.</span>\n\t--config=nogcp       \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Disable GCP support.</span>\n\t--config=nohdfs      \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Disable HDFS support.</span>\n\t--config=noignite    \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Disable Apacha Ignite support.</span>\n\t--config=nokafka     \t<span class=\"pl-c\"><span class=\"pl-c\">#</span> Disable Apache Kafka support.</span>\nConfiguration finished\n$ bazel build -c opt --config=opt //tensorflow/tools/pip_package:build_pip_package\nStarting <span class=\"pl-k\">local</span> Bazel server and connecting to it...\nERROR: /srv/nfs4/home/byronyi/.cache/bazel/_bazel_byronyi/fe336f47afec8b033fb4b29a6628548f/external/local_config_cc/BUILD:57:1: <span class=\"pl-k\">in</span> cc_toolchain rule @local_config_cc//:cc-compiler-k8: Error <span class=\"pl-k\">while</span> selecting cc_toolchain: Toolchain identifier <span class=\"pl-s\"><span class=\"pl-pds\">'</span>local<span class=\"pl-pds\">'</span></span> was not found, valid identifiers are [local_linux, local_darwin, local_windows]\nERROR: Analysis of target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>//tensorflow/tools/pip_package:build_pip_package<span class=\"pl-pds\">'</span></span> failed<span class=\"pl-k\">;</span> build aborted: Analysis of target <span class=\"pl-s\"><span class=\"pl-pds\">'</span>@local_config_cc//:cc-compiler-k8<span class=\"pl-pds\">'</span></span> failed<span class=\"pl-k\">;</span> build aborted\nINFO: Elapsed time: 2.701s\nINFO: 0 processes.\nFAILED: Build did NOT <span class=\"pl-c1\">complete</span> successfully (228 packages loaded, 1224 targets configured)\n    currently loading: tensorflow/core ... (6 packages)</pre></div>", "body_text": "@ymodak Met the same problem on Ubuntu Linux 16.04. I do not think it is a duplicate of #23674.\n$ ./configure\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\nYou have bazel 0.19.1 installed.\nPlease specify the location of python. [Default is /home/byronyi/tf/bin/python]:\n\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nAttributeError: 'module' object has no attribute 'getsitepackages'\nFound possible Python library paths:\n  /home/byronyi/tf/lib/python2.7/site-packages\nPlease input the desired Python library path to use.  Default is [/home/byronyi/tf/lib/python2.7/site-packages]\n\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]:\nXLA JIT support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\nNo OpenCL SYCL support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with ROCm support? [y/N]:\nNo ROCm support will be enabled for TensorFlow.\n\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\nCUDA support will be enabled for TensorFlow.\n\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]:\n\n\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n\n\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]:\n\n\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\n\n\nDo you wish to build TensorFlow with TensorRT support? [y/N]:\nNo TensorRT support will be enabled for TensorFlow.\n\nPlease specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]:\n\n\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,7.0]: 7.0\n\n\nDo you want to use clang as CUDA compiler? [y/N]:\nnvcc will be used as CUDA compiler.\n\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\n\n\nDo you wish to build TensorFlow with MPI support? [y/N]:\nNo MPI support will be enabled for TensorFlow.\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:\n\n\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\nNot configuring the WORKSPACE for Android builds.\n\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\n\t--config=mkl         \t# Build with MKL support.\n\t--config=monolithic  \t# Config for mostly static monolithic build.\n\t--config=gdr         \t# Build with GDR support.\n\t--config=verbs       \t# Build with libverbs support.\n\t--config=ngraph      \t# Build with Intel nGraph support.\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\nPreconfigured Bazel build configs to DISABLE default on features:\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\n\t--config=nogcp       \t# Disable GCP support.\n\t--config=nohdfs      \t# Disable HDFS support.\n\t--config=noignite    \t# Disable Apacha Ignite support.\n\t--config=nokafka     \t# Disable Apache Kafka support.\nConfiguration finished\n$ bazel build -c opt --config=opt //tensorflow/tools/pip_package:build_pip_package\nStarting local Bazel server and connecting to it...\nERROR: /srv/nfs4/home/byronyi/.cache/bazel/_bazel_byronyi/fe336f47afec8b033fb4b29a6628548f/external/local_config_cc/BUILD:57:1: in cc_toolchain rule @local_config_cc//:cc-compiler-k8: Error while selecting cc_toolchain: Toolchain identifier 'local' was not found, valid identifiers are [local_linux, local_darwin, local_windows]\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis of target '@local_config_cc//:cc-compiler-k8' failed; build aborted\nINFO: Elapsed time: 2.701s\nINFO: 0 processes.\nFAILED: Build did NOT complete successfully (228 packages loaded, 1224 targets configured)\n    currently loading: tensorflow/core ... (6 packages)", "body": "@ymodak Met the same problem on Ubuntu Linux 16.04. I do not think it is a duplicate of #23674.\r\n\r\n```bash\r\n$ ./configure\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.19.1 installed.\r\nPlease specify the location of python. [Default is /home/byronyi/tf/bin/python]:\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'getsitepackages'\r\nFound possible Python library paths:\r\n  /home/byronyi/tf/lib/python2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/byronyi/tf/lib/python2.7/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]:\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]:\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]:\r\n\r\n\r\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]:\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]:\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]:\r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,7.0]: 7.0\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]:\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]:\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apacha Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\nConfiguration finished\r\n$ bazel build -c opt --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nERROR: /srv/nfs4/home/byronyi/.cache/bazel/_bazel_byronyi/fe336f47afec8b033fb4b29a6628548f/external/local_config_cc/BUILD:57:1: in cc_toolchain rule @local_config_cc//:cc-compiler-k8: Error while selecting cc_toolchain: Toolchain identifier 'local' was not found, valid identifiers are [local_linux, local_darwin, local_windows]\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis of target '@local_config_cc//:cc-compiler-k8' failed; build aborted\r\nINFO: Elapsed time: 2.701s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (228 packages loaded, 1224 targets configured)\r\n    currently loading: tensorflow/core ... (6 packages)\r\n```"}