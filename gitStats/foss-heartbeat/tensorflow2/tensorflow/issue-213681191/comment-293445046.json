{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/293445046", "html_url": "https://github.com/tensorflow/tensorflow/issues/8340#issuecomment-293445046", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8340", "id": 293445046, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MzQ0NTA0Ng==", "user": {"login": "ClimbsRocks", "id": 7017045, "node_id": "MDQ6VXNlcjcwMTcwNDU=", "avatar_url": "https://avatars0.githubusercontent.com/u/7017045?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ClimbsRocks", "html_url": "https://github.com/ClimbsRocks", "followers_url": "https://api.github.com/users/ClimbsRocks/followers", "following_url": "https://api.github.com/users/ClimbsRocks/following{/other_user}", "gists_url": "https://api.github.com/users/ClimbsRocks/gists{/gist_id}", "starred_url": "https://api.github.com/users/ClimbsRocks/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ClimbsRocks/subscriptions", "organizations_url": "https://api.github.com/users/ClimbsRocks/orgs", "repos_url": "https://api.github.com/users/ClimbsRocks/repos", "events_url": "https://api.github.com/users/ClimbsRocks/events{/privacy}", "received_events_url": "https://api.github.com/users/ClimbsRocks/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-12T01:19:08Z", "updated_at": "2017-04-12T01:19:08Z", "author_association": "NONE", "body_html": "<p>Thanks for the idea, but unfortunately that didn't help either.</p>\n<p>I was able to at least reduce the amount of logging during training time using the following code snippet</p>\n<pre><code># Suppress some level of logs\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom tensorflow import logging\nlogging.set_verbosity(logging.INFO)\nfrom keras.constraints import maxnorm\n# more imports and everything else follows below\n</code></pre>\n<p>The above reduces training logging, but I'm still facing several hundred lines of <code>tensorflow: Level 1: Registering</code> logging, which I assume comes when the package is first imported</p>\n<pre><code>tensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (&lt;function _FakeQuantWithMinMaxArgsGradient at 0x115e56320&gt;) in gradient.\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVars (&lt;function _FakeQuantWithMinMaxVarsGradient at 0x115ef9230&gt;) in gradient.\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (&lt;function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x115ef92a8&gt;) in gradient.\ntensorflow: Level 1: Registering MatMul,flops (&lt;function _calc_mat_mul_flops at 0x11611fcf8&gt;) in statistical functions.\ntensorflow: Level 1: Registering cond_context ((&lt;class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'&gt;, &lt;unbound method CondContext.to_proto&gt;, &lt;function from_proto at 0x1161c42a8&gt;)) in proto functions.\ntensorflow: Level 1: Registering while_context ((&lt;class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'&gt;, &lt;unbound method WhileContext.to_proto&gt;, &lt;function from_proto at 0x1161c4b18&gt;)) in proto functions.\ntensorflow: Level 1: Registering Pack (&lt;function _PackGrad at 0x11622bd70&gt;) in gradient.\ntensorflow: Level 1: Registering Unpack (&lt;function _UnpackGrad at 0x11622bde8&gt;) in gradient.\nten\n</code></pre>\n<p>The Registering logging is particularly annoying when running the test suite, because it puts several hundred lines of logs in between the info I'm scrolling between.</p>\n<p>Any thoughts? Can we get any signal from the fact that <code>logging.set_verbosity()</code> reduces logs for training, and use that to understanding how we might be able to suppress the Registering logging?</p>", "body_text": "Thanks for the idea, but unfortunately that didn't help either.\nI was able to at least reduce the amount of logging during training time using the following code snippet\n# Suppress some level of logs\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom tensorflow import logging\nlogging.set_verbosity(logging.INFO)\nfrom keras.constraints import maxnorm\n# more imports and everything else follows below\n\nThe above reduces training logging, but I'm still facing several hundred lines of tensorflow: Level 1: Registering logging, which I assume comes when the package is first imported\ntensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (<function _FakeQuantWithMinMaxArgsGradient at 0x115e56320>) in gradient.\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVars (<function _FakeQuantWithMinMaxVarsGradient at 0x115ef9230>) in gradient.\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (<function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x115ef92a8>) in gradient.\ntensorflow: Level 1: Registering MatMul,flops (<function _calc_mat_mul_flops at 0x11611fcf8>) in statistical functions.\ntensorflow: Level 1: Registering cond_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'>, <unbound method CondContext.to_proto>, <function from_proto at 0x1161c42a8>)) in proto functions.\ntensorflow: Level 1: Registering while_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'>, <unbound method WhileContext.to_proto>, <function from_proto at 0x1161c4b18>)) in proto functions.\ntensorflow: Level 1: Registering Pack (<function _PackGrad at 0x11622bd70>) in gradient.\ntensorflow: Level 1: Registering Unpack (<function _UnpackGrad at 0x11622bde8>) in gradient.\nten\n\nThe Registering logging is particularly annoying when running the test suite, because it puts several hundred lines of logs in between the info I'm scrolling between.\nAny thoughts? Can we get any signal from the fact that logging.set_verbosity() reduces logs for training, and use that to understanding how we might be able to suppress the Registering logging?", "body": "Thanks for the idea, but unfortunately that didn't help either. \r\n\r\nI was able to at least reduce the amount of logging during training time using the following code snippet \r\n\r\n```\r\n# Suppress some level of logs\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nfrom tensorflow import logging\r\nlogging.set_verbosity(logging.INFO)\r\nfrom keras.constraints import maxnorm\r\n# more imports and everything else follows below\r\n```\r\n\r\nThe above reduces training logging, but I'm still facing several hundred lines of `tensorflow: Level 1: Registering` logging, which I assume comes when the package is first imported\r\n\r\n```\r\ntensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (<function _FakeQuantWithMinMaxArgsGradient at 0x115e56320>) in gradient.\r\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVars (<function _FakeQuantWithMinMaxVarsGradient at 0x115ef9230>) in gradient.\r\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (<function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x115ef92a8>) in gradient.\r\ntensorflow: Level 1: Registering MatMul,flops (<function _calc_mat_mul_flops at 0x11611fcf8>) in statistical functions.\r\ntensorflow: Level 1: Registering cond_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'>, <unbound method CondContext.to_proto>, <function from_proto at 0x1161c42a8>)) in proto functions.\r\ntensorflow: Level 1: Registering while_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'>, <unbound method WhileContext.to_proto>, <function from_proto at 0x1161c4b18>)) in proto functions.\r\ntensorflow: Level 1: Registering Pack (<function _PackGrad at 0x11622bd70>) in gradient.\r\ntensorflow: Level 1: Registering Unpack (<function _UnpackGrad at 0x11622bde8>) in gradient.\r\nten\r\n``` \r\n\r\nThe Registering logging is particularly annoying when running the test suite, because it puts several hundred lines of logs in between the info I'm scrolling between. \r\n\r\nAny thoughts? Can we get any signal from the fact that `logging.set_verbosity()` reduces logs for training, and use that to understanding how we might be able to suppress the Registering logging? "}