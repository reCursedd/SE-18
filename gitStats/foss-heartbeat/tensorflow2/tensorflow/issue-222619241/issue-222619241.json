{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9301", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9301/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9301/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9301/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9301", "id": 222619241, "node_id": "MDU6SXNzdWUyMjI2MTkyNDE=", "number": 9301, "title": "Quantized graph fails to work on NVIDIA Jetson TX1 architecture although it worked on a normal PC?", "user": {"login": "kwotsin", "id": 11178344, "node_id": "MDQ6VXNlcjExMTc4MzQ0", "avatar_url": "https://avatars2.githubusercontent.com/u/11178344?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kwotsin", "html_url": "https://github.com/kwotsin", "followers_url": "https://api.github.com/users/kwotsin/followers", "following_url": "https://api.github.com/users/kwotsin/following{/other_user}", "gists_url": "https://api.github.com/users/kwotsin/gists{/gist_id}", "starred_url": "https://api.github.com/users/kwotsin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kwotsin/subscriptions", "organizations_url": "https://api.github.com/users/kwotsin/orgs", "repos_url": "https://api.github.com/users/kwotsin/repos", "events_url": "https://api.github.com/users/kwotsin/events{/privacy}", "received_events_url": "https://api.github.com/users/kwotsin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}, {"id": 473173351, "node_id": "MDU6TGFiZWw0NzMxNzMzNTE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:build/install", "name": "type:build/install", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 19, "created_at": "2017-04-19T05:00:25Z", "updated_at": "2018-10-24T21:16:15Z", "closed_at": "2018-10-24T21:16:15Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System Information</h3>\n<ul>\n<li><em>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?</em>:<br>\nNo</li>\n<li><em>OS Platform and Distribution (i.e. Linux Ubuntu 16.0)</em>:<br>\nUbuntu 16.04 LTS on NVIDIA Jetson TX1 (Linux for Tegra 24.1)</li>\n<li><em>TensorFlow installed from (source or binary)?</em>:<br>\nCompiled from source and installed via this wheel available here: <a href=\"https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hack\">https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hack</a></li>\n<li><em>TensorFlow version</em> (use command below):<br>\n1.0 Alpha</li>\n<li><em>CUDA/cuDNN version</em>:<br>\n8.0/5.1</li>\n<li><em>GPU Model and Memory</em>:<br>\nTegra X1, 4GB</li>\n</ul>\n<h3>Describe the problem clearly</h3>\n<p>When I ran a quantized graph on my laptop, it works quite as expected (just slightly lower accuracy compared to the frozen graph, while much lower size). However, when I transferred the exact same quantized graph to run on an Jetson TX1, the file gives me a highly inaccurate class prediction, at a 100% probability for the random class. On the other hand, when I tried to perform inference from the frozen graph (from which the quantized graph was derived) on both my laptop and the Jetson TX1, I got the exact same answers as expected.</p>\n<p>So I suspected it could have been an issue of data transfer causing the file to be slightly corrupted. I checked the files byte by byte at all points of transfer (from my laptop to memory stick, then memory stick to the Jetson), but I found the files are exactly the same. This is the command I used to check: <code>cmp $old_file $new_file || echo \"different files\"</code>.</p>\n<p>Thus, I am suspecting it could be an issue of how tensorflow performs on the Jetson TX1 ARM architecture (aarch64). Is there anyway to verify this, and if it is indeed a performance issue on an ARM architecture, is there a way to resolve this?</p>\n<p>Thank you for your help.</p>", "body_text": "System Information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:\nNo\nOS Platform and Distribution (i.e. Linux Ubuntu 16.0):\nUbuntu 16.04 LTS on NVIDIA Jetson TX1 (Linux for Tegra 24.1)\nTensorFlow installed from (source or binary)?:\nCompiled from source and installed via this wheel available here: https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hack\nTensorFlow version (use command below):\n1.0 Alpha\nCUDA/cuDNN version:\n8.0/5.1\nGPU Model and Memory:\nTegra X1, 4GB\n\nDescribe the problem clearly\nWhen I ran a quantized graph on my laptop, it works quite as expected (just slightly lower accuracy compared to the frozen graph, while much lower size). However, when I transferred the exact same quantized graph to run on an Jetson TX1, the file gives me a highly inaccurate class prediction, at a 100% probability for the random class. On the other hand, when I tried to perform inference from the frozen graph (from which the quantized graph was derived) on both my laptop and the Jetson TX1, I got the exact same answers as expected.\nSo I suspected it could have been an issue of data transfer causing the file to be slightly corrupted. I checked the files byte by byte at all points of transfer (from my laptop to memory stick, then memory stick to the Jetson), but I found the files are exactly the same. This is the command I used to check: cmp $old_file $new_file || echo \"different files\".\nThus, I am suspecting it could be an issue of how tensorflow performs on the Jetson TX1 ARM architecture (aarch64). Is there anyway to verify this, and if it is indeed a performance issue on an ARM architecture, is there a way to resolve this?\nThank you for your help.", "body": "### System Information\r\n- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:\r\nNo\r\n- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:\r\nUbuntu 16.04 LTS on NVIDIA Jetson TX1 (Linux for Tegra 24.1)\r\n- *TensorFlow installed from (source or binary)?*:\r\nCompiled from source and installed via this wheel available here: https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hack\r\n- *TensorFlow version* (use command below):\r\n1.0 Alpha\r\n- *CUDA/cuDNN version*:\r\n8.0/5.1\r\n- *GPU Model and Memory*:\r\nTegra X1, 4GB\r\n\r\n### Describe the problem clearly\r\nWhen I ran a quantized graph on my laptop, it works quite as expected (just slightly lower accuracy compared to the frozen graph, while much lower size). However, when I transferred the exact same quantized graph to run on an Jetson TX1, the file gives me a highly inaccurate class prediction, at a 100% probability for the random class. On the other hand, when I tried to perform inference from the frozen graph (from which the quantized graph was derived) on both my laptop and the Jetson TX1, I got the exact same answers as expected.\r\n\r\nSo I suspected it could have been an issue of data transfer causing the file to be slightly corrupted. I checked the files byte by byte at all points of transfer (from my laptop to memory stick, then memory stick to the Jetson), but I found the files are exactly the same. This is the command I used to check: `cmp $old_file $new_file || echo \"different files\"`.\r\n\r\nThus, I am suspecting it could be an issue of how tensorflow performs on the Jetson TX1 ARM architecture (aarch64). Is there anyway to verify this, and if it is indeed a performance issue on an ARM architecture, is there a way to resolve this?\r\n\r\nThank you for your help.\r\n"}