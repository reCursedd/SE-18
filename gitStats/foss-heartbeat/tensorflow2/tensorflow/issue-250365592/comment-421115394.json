{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421115394", "html_url": "https://github.com/tensorflow/tensorflow/pull/12299#issuecomment-421115394", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12299", "id": 421115394, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTExNTM5NA==", "user": {"login": "camaclean", "id": 8589292, "node_id": "MDQ6VXNlcjg1ODkyOTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8589292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/camaclean", "html_url": "https://github.com/camaclean", "followers_url": "https://api.github.com/users/camaclean/followers", "following_url": "https://api.github.com/users/camaclean/following{/other_user}", "gists_url": "https://api.github.com/users/camaclean/gists{/gist_id}", "starred_url": "https://api.github.com/users/camaclean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/camaclean/subscriptions", "organizations_url": "https://api.github.com/users/camaclean/orgs", "repos_url": "https://api.github.com/users/camaclean/repos", "events_url": "https://api.github.com/users/camaclean/events{/privacy}", "received_events_url": "https://api.github.com/users/camaclean/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-13T18:58:33Z", "updated_at": "2018-09-13T18:58:33Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1865411\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gibiansky\">@gibiansky</a></p>\n<p>For some reason, getting things to scale on Blue Waters has been harder than what I've seen from other centers. Last time we were benchmarking we were having trouble with crashes and such. Pytorch was much easier to get scaling well since it can use MPI's allreduce under the hood. Our network is a 3d torus with 2 nodes sharing an interconnect, which can do 2.9GB/s (effective) for each of the 6 directions and intelligently route packets along several links if there's bandwidth available. It also has hardware support for doing collective type operations to efficiently scatter data. Based on profiling counters on the interconnects, we haven't been able to come close to saturating our network bandwidth. Our biggest bottleneck seems to be more a matter of latency.</p>", "body_text": "@gibiansky\nFor some reason, getting things to scale on Blue Waters has been harder than what I've seen from other centers. Last time we were benchmarking we were having trouble with crashes and such. Pytorch was much easier to get scaling well since it can use MPI's allreduce under the hood. Our network is a 3d torus with 2 nodes sharing an interconnect, which can do 2.9GB/s (effective) for each of the 6 directions and intelligently route packets along several links if there's bandwidth available. It also has hardware support for doing collective type operations to efficiently scatter data. Based on profiling counters on the interconnects, we haven't been able to come close to saturating our network bandwidth. Our biggest bottleneck seems to be more a matter of latency.", "body": "@gibiansky \r\n\r\nFor some reason, getting things to scale on Blue Waters has been harder than what I've seen from other centers. Last time we were benchmarking we were having trouble with crashes and such. Pytorch was much easier to get scaling well since it can use MPI's allreduce under the hood. Our network is a 3d torus with 2 nodes sharing an interconnect, which can do 2.9GB/s (effective) for each of the 6 directions and intelligently route packets along several links if there's bandwidth available. It also has hardware support for doing collective type operations to efficiently scatter data. Based on profiling counters on the interconnects, we haven't been able to come close to saturating our network bandwidth. Our biggest bottleneck seems to be more a matter of latency."}