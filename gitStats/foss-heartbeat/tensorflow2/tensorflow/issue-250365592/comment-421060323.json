{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421060323", "html_url": "https://github.com/tensorflow/tensorflow/pull/12299#issuecomment-421060323", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12299", "id": 421060323, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTA2MDMyMw==", "user": {"login": "camaclean", "id": 8589292, "node_id": "MDQ6VXNlcjg1ODkyOTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8589292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/camaclean", "html_url": "https://github.com/camaclean", "followers_url": "https://api.github.com/users/camaclean/followers", "following_url": "https://api.github.com/users/camaclean/following{/other_user}", "gists_url": "https://api.github.com/users/camaclean/gists{/gist_id}", "starred_url": "https://api.github.com/users/camaclean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/camaclean/subscriptions", "organizations_url": "https://api.github.com/users/camaclean/orgs", "repos_url": "https://api.github.com/users/camaclean/repos", "events_url": "https://api.github.com/users/camaclean/events{/privacy}", "received_events_url": "https://api.github.com/users/camaclean/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-13T16:01:48Z", "updated_at": "2018-09-13T16:01:48Z", "author_association": "NONE", "body_html": "<p>Why is an allreduce manually implemented using point to point communications rather than using the likely much more optimized allreduce present in MPI? Do you have a specific reason for doing it yourself?</p>\n<p>Vendor MPI implementations like cray-mpich can use hardware support for collective communications and take advantage of tightly interconnected networks and don't load a single node with scheduling concerns. A ring allreduce has an abysmal performance in comparison on such networks, especially at scale (thousands of nodes).</p>\n<p>It would also take a lot less code to just <code>MPI_Iallreduce</code> when a rank has a tensor ready to reduce, then either periodically use <code>MPI_Testall</code> on waiting reduces or have a background thread use <code>MPI_Waitany</code> to progress the allreduce. Is there a reason why you can't just do this?</p>", "body_text": "Why is an allreduce manually implemented using point to point communications rather than using the likely much more optimized allreduce present in MPI? Do you have a specific reason for doing it yourself?\nVendor MPI implementations like cray-mpich can use hardware support for collective communications and take advantage of tightly interconnected networks and don't load a single node with scheduling concerns. A ring allreduce has an abysmal performance in comparison on such networks, especially at scale (thousands of nodes).\nIt would also take a lot less code to just MPI_Iallreduce when a rank has a tensor ready to reduce, then either periodically use MPI_Testall on waiting reduces or have a background thread use MPI_Waitany to progress the allreduce. Is there a reason why you can't just do this?", "body": "Why is an allreduce manually implemented using point to point communications rather than using the likely much more optimized allreduce present in MPI? Do you have a specific reason for doing it yourself?\r\n\r\nVendor MPI implementations like cray-mpich can use hardware support for collective communications and take advantage of tightly interconnected networks and don't load a single node with scheduling concerns. A ring allreduce has an abysmal performance in comparison on such networks, especially at scale (thousands of nodes).\r\n\r\nIt would also take a lot less code to just `MPI_Iallreduce` when a rank has a tensor ready to reduce, then either periodically use `MPI_Testall` on waiting reduces or have a background thread use `MPI_Waitany` to progress the allreduce. Is there a reason why you can't just do this?"}