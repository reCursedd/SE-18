{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421088399", "html_url": "https://github.com/tensorflow/tensorflow/pull/12299#issuecomment-421088399", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12299", "id": 421088399, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTA4ODM5OQ==", "user": {"login": "camaclean", "id": 8589292, "node_id": "MDQ6VXNlcjg1ODkyOTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/8589292?v=4", "gravatar_id": "", "url": "https://api.github.com/users/camaclean", "html_url": "https://github.com/camaclean", "followers_url": "https://api.github.com/users/camaclean/followers", "following_url": "https://api.github.com/users/camaclean/following{/other_user}", "gists_url": "https://api.github.com/users/camaclean/gists{/gist_id}", "starred_url": "https://api.github.com/users/camaclean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/camaclean/subscriptions", "organizations_url": "https://api.github.com/users/camaclean/orgs", "repos_url": "https://api.github.com/users/camaclean/repos", "events_url": "https://api.github.com/users/camaclean/events{/privacy}", "received_events_url": "https://api.github.com/users/camaclean/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-13T17:31:10Z", "updated_at": "2018-09-13T17:31:10Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1865411\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gibiansky\">@gibiansky</a></p>\n<p>Ah, I see. That makes sense. Unfortunately, our hardware is old and doesn't support true cuda aware MPI. We have 4,228 GPU nodes, each with a Tesla K20X, networked in a 3d torus. Each node isn't very fast, but we make up for it by having a lot of them (there's an additional 22,636 CPU nodes, but those aren't too useful for ML). It means having applications that can scale well, though, and getting Tensorflow to do so well has been painful. Cray has a Tensorflow ML plugin written specifically for their interconnects, but it's a bit finicky on our system and they don't really want to invest much effort in our older model system (It makes sense, but it's a struggle for me). So, I'm constantly on the look out for things to try and make Tensorflow scale better. We only recently upgraded from CUDA 7.5 to CUDA 9.1, so we were stuck on Tensorflow 1.4.1 for a long time, but now I'm back to investigating it.</p>\n<p>Have you tried doing a local intermediate reduction within the gpus on each node, then ireducing that? We only have one gpu per node, so it's not something I can test. Perhaps I'll have to write an HPC-orriented plugin of my own, since most are one gpu per node with larger node counts as opposed to high-gpu-count ML clusters like what you're targeting. Or perhaps there could be choices between allreduce methods to help support a broader range of hardware configurations.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a></p>\n<p>Good to know. I just hope the CUDA requirements don't evolve too fast to prevent us from upgrading when that feature is ready. As I mentioned above, we only just recently moved from CUDA 7.5 to CUDA 9.1, and CUDA 9.1 is all we will get until the end of the machine's life (probably the end of 2019). HPC system software tends to be updated more slowly than Tensorflow's dependencies since everything needs to be well tested, which I know has been an issue for other centers, as well. A lot of our users want the latest and greatest Tensorflow, but actually getting it running and performing well was the topic of a number of papers at this year's Cray User Group conference. I know HPC is only a small fraction of total users, but I'm glad you're adjusting the API to make it easier to run well on our big systems.</p>", "body_text": "@gibiansky\nAh, I see. That makes sense. Unfortunately, our hardware is old and doesn't support true cuda aware MPI. We have 4,228 GPU nodes, each with a Tesla K20X, networked in a 3d torus. Each node isn't very fast, but we make up for it by having a lot of them (there's an additional 22,636 CPU nodes, but those aren't too useful for ML). It means having applications that can scale well, though, and getting Tensorflow to do so well has been painful. Cray has a Tensorflow ML plugin written specifically for their interconnects, but it's a bit finicky on our system and they don't really want to invest much effort in our older model system (It makes sense, but it's a struggle for me). So, I'm constantly on the look out for things to try and make Tensorflow scale better. We only recently upgraded from CUDA 7.5 to CUDA 9.1, so we were stuck on Tensorflow 1.4.1 for a long time, but now I'm back to investigating it.\nHave you tried doing a local intermediate reduction within the gpus on each node, then ireducing that? We only have one gpu per node, so it's not something I can test. Perhaps I'll have to write an HPC-orriented plugin of my own, since most are one gpu per node with larger node counts as opposed to high-gpu-count ML clusters like what you're targeting. Or perhaps there could be choices between allreduce methods to help support a broader range of hardware configurations.\n@poxvoculi\nGood to know. I just hope the CUDA requirements don't evolve too fast to prevent us from upgrading when that feature is ready. As I mentioned above, we only just recently moved from CUDA 7.5 to CUDA 9.1, and CUDA 9.1 is all we will get until the end of the machine's life (probably the end of 2019). HPC system software tends to be updated more slowly than Tensorflow's dependencies since everything needs to be well tested, which I know has been an issue for other centers, as well. A lot of our users want the latest and greatest Tensorflow, but actually getting it running and performing well was the topic of a number of papers at this year's Cray User Group conference. I know HPC is only a small fraction of total users, but I'm glad you're adjusting the API to make it easier to run well on our big systems.", "body": "@gibiansky \r\n\r\nAh, I see. That makes sense. Unfortunately, our hardware is old and doesn't support true cuda aware MPI. We have 4,228 GPU nodes, each with a Tesla K20X, networked in a 3d torus. Each node isn't very fast, but we make up for it by having a lot of them (there's an additional 22,636 CPU nodes, but those aren't too useful for ML). It means having applications that can scale well, though, and getting Tensorflow to do so well has been painful. Cray has a Tensorflow ML plugin written specifically for their interconnects, but it's a bit finicky on our system and they don't really want to invest much effort in our older model system (It makes sense, but it's a struggle for me). So, I'm constantly on the look out for things to try and make Tensorflow scale better. We only recently upgraded from CUDA 7.5 to CUDA 9.1, so we were stuck on Tensorflow 1.4.1 for a long time, but now I'm back to investigating it.\r\n\r\nHave you tried doing a local intermediate reduction within the gpus on each node, then ireducing that? We only have one gpu per node, so it's not something I can test. Perhaps I'll have to write an HPC-orriented plugin of my own, since most are one gpu per node with larger node counts as opposed to high-gpu-count ML clusters like what you're targeting. Or perhaps there could be choices between allreduce methods to help support a broader range of hardware configurations.\r\n\r\n@poxvoculi \r\n\r\nGood to know. I just hope the CUDA requirements don't evolve too fast to prevent us from upgrading when that feature is ready. As I mentioned above, we only just recently moved from CUDA 7.5 to CUDA 9.1, and CUDA 9.1 is all we will get until the end of the machine's life (probably the end of 2019). HPC system software tends to be updated more slowly than Tensorflow's dependencies since everything needs to be well tested, which I know has been an issue for other centers, as well. A lot of our users want the latest and greatest Tensorflow, but actually getting it running and performing well was the topic of a number of papers at this year's Cray User Group conference. I know HPC is only a small fraction of total users, but I'm glad you're adjusting the API to make it easier to run well on our big systems."}