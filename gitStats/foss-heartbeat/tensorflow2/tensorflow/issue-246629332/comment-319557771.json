{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/319557771", "html_url": "https://github.com/tensorflow/tensorflow/issues/11896#issuecomment-319557771", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11896", "id": 319557771, "node_id": "MDEyOklzc3VlQ29tbWVudDMxOTU1Nzc3MQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-02T03:30:17Z", "updated_at": "2017-08-02T03:30:17Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=14145160\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/qinglintian\">@qinglintian</a> if you keep your hyper-parameters (ie, learning rate) in shared variable, then you can adjust from any tensorflow client that's part of the cluster. Fault tolerance is achieved by checkpointing and restarting the training on failures. Permanent removal of workers can be handled with backup workers. Permanent removal of parameter servers is more tricky -- you have to repartition your parameter variables</p>", "body_text": "@qinglintian if you keep your hyper-parameters (ie, learning rate) in shared variable, then you can adjust from any tensorflow client that's part of the cluster. Fault tolerance is achieved by checkpointing and restarting the training on failures. Permanent removal of workers can be handled with backup workers. Permanent removal of parameter servers is more tricky -- you have to repartition your parameter variables", "body": "@qinglintian if you keep your hyper-parameters (ie, learning rate) in shared variable, then you can adjust from any tensorflow client that's part of the cluster. Fault tolerance is achieved by checkpointing and restarting the training on failures. Permanent removal of workers can be handled with backup workers. Permanent removal of parameter servers is more tricky -- you have to repartition your parameter variables"}