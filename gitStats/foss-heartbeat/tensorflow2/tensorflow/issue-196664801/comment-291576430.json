{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/291576430", "html_url": "https://github.com/tensorflow/tensorflow/pull/6421#issuecomment-291576430", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6421", "id": 291576430, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MTU3NjQzMA==", "user": {"login": "mhnatiuk", "id": 2299492, "node_id": "MDQ6VXNlcjIyOTk0OTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2299492?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mhnatiuk", "html_url": "https://github.com/mhnatiuk", "followers_url": "https://api.github.com/users/mhnatiuk/followers", "following_url": "https://api.github.com/users/mhnatiuk/following{/other_user}", "gists_url": "https://api.github.com/users/mhnatiuk/gists{/gist_id}", "starred_url": "https://api.github.com/users/mhnatiuk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mhnatiuk/subscriptions", "organizations_url": "https://api.github.com/users/mhnatiuk/orgs", "repos_url": "https://api.github.com/users/mhnatiuk/repos", "events_url": "https://api.github.com/users/mhnatiuk/events{/privacy}", "received_events_url": "https://api.github.com/users/mhnatiuk/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-04T17:40:22Z", "updated_at": "2017-04-04T17:43:12Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nI'm trying to use tf.contrib.seq2seq.sequence_loss with dynamic_decode output, but I always get tensor incompatibility error, because, the output of dynamic_decoder is variable, and input to sequence_loss is not. Basically, example code that raises this problem is.:<br>\nThe code seems fine when I feed sequence length placeholders with fixed-sized length.</p>\n<pre><code>`with tf.device(\"/cpu:0\"), tf.name_scope(\"embeddings\"):\n        W_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\n        target_embedded_chars = tf.nn.embedding_lookup(W_target_emb, tf.stack(self.decoder_inputs))\n    with tf.name_scope(\"decoder\"):\n        half = tf.constant(0.5)\n        dec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\n        if not forward_only:\n            helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\n           \n\n        else:\n            helper = seq2seq.GreedyEmbeddingHelper(target_embedded_chars, \n                                                   start_tokens=self.decoder_inputs[0],\n                                                   end_token=data_utils.EOS_ID)\n\n    \n       \n        my_decoder = seq2seq.BasicDecoder(cell=MultiRNNCell([DeviceWrapper(ResidualWrapper(LSTMBlockCell(num_units=size)),\n                                                                           device='/gpu:%d' % i) for i in range(self.num_gpus) ]),\n                                          helper=helper,\n                                          initial_state=encoder_final_state)\n    \n        decoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\n                   swap_memory = True)\n\nwith tf.name_scope(\"loss\"):\n    self.logits = tf.reshape(decoder_outputs.rnn_output, [self.batch_size, self.decoder_max_size, -1], name=\"logits_\")\n    self.sample_ids = decoder_outputs.sample_id\n    self.loss = loss.sequence_loss(self.logits, tf.transpose(tf.stack(targets), [1,0], name=\"targets_\"),\n                                                 tf.transpose(tf.stack(self.target_weights), [1,0], name=\"weights_\"),\n                                                 softmax_loss_function = softmax_loss_function)\n</code></pre>\n<p>`</p>", "body_text": "Hi,\nI'm trying to use tf.contrib.seq2seq.sequence_loss with dynamic_decode output, but I always get tensor incompatibility error, because, the output of dynamic_decoder is variable, and input to sequence_loss is not. Basically, example code that raises this problem is.:\nThe code seems fine when I feed sequence length placeholders with fixed-sized length.\n`with tf.device(\"/cpu:0\"), tf.name_scope(\"embeddings\"):\n        W_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\n        target_embedded_chars = tf.nn.embedding_lookup(W_target_emb, tf.stack(self.decoder_inputs))\n    with tf.name_scope(\"decoder\"):\n        half = tf.constant(0.5)\n        dec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\n        if not forward_only:\n            helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\n           \n\n        else:\n            helper = seq2seq.GreedyEmbeddingHelper(target_embedded_chars, \n                                                   start_tokens=self.decoder_inputs[0],\n                                                   end_token=data_utils.EOS_ID)\n\n    \n       \n        my_decoder = seq2seq.BasicDecoder(cell=MultiRNNCell([DeviceWrapper(ResidualWrapper(LSTMBlockCell(num_units=size)),\n                                                                           device='/gpu:%d' % i) for i in range(self.num_gpus) ]),\n                                          helper=helper,\n                                          initial_state=encoder_final_state)\n    \n        decoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\n                   swap_memory = True)\n\nwith tf.name_scope(\"loss\"):\n    self.logits = tf.reshape(decoder_outputs.rnn_output, [self.batch_size, self.decoder_max_size, -1], name=\"logits_\")\n    self.sample_ids = decoder_outputs.sample_id\n    self.loss = loss.sequence_loss(self.logits, tf.transpose(tf.stack(targets), [1,0], name=\"targets_\"),\n                                                 tf.transpose(tf.stack(self.target_weights), [1,0], name=\"weights_\"),\n                                                 softmax_loss_function = softmax_loss_function)\n\n`", "body": "Hi,\r\nI'm trying to use tf.contrib.seq2seq.sequence_loss with dynamic_decode output, but I always get tensor incompatibility error, because, the output of dynamic_decoder is variable, and input to sequence_loss is not. Basically, example code that raises this problem is.:\r\nThe code seems fine when I feed sequence length placeholders with fixed-sized length.\r\n\r\n    `with tf.device(\"/cpu:0\"), tf.name_scope(\"embeddings\"):\r\n            W_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name=\"W_target_emb\")\r\n            target_embedded_chars = tf.nn.embedding_lookup(W_target_emb, tf.stack(self.decoder_inputs))\r\n        with tf.name_scope(\"decoder\"):\r\n            half = tf.constant(0.5)\r\n            dec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)\r\n            if not forward_only:\r\n                helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)\r\n               \r\n\r\n            else:\r\n                helper = seq2seq.GreedyEmbeddingHelper(target_embedded_chars, \r\n                                                       start_tokens=self.decoder_inputs[0],\r\n                                                       end_token=data_utils.EOS_ID)\r\n\r\n        \r\n           \r\n            my_decoder = seq2seq.BasicDecoder(cell=MultiRNNCell([DeviceWrapper(ResidualWrapper(LSTMBlockCell(num_units=size)),\r\n                                                                               device='/gpu:%d' % i) for i in range(self.num_gpus) ]),\r\n                                              helper=helper,\r\n                                              initial_state=encoder_final_state)\r\n        \r\n            decoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,\r\n                       swap_memory = True)\r\n\r\n    with tf.name_scope(\"loss\"):\r\n        self.logits = tf.reshape(decoder_outputs.rnn_output, [self.batch_size, self.decoder_max_size, -1], name=\"logits_\")\r\n        self.sample_ids = decoder_outputs.sample_id\r\n        self.loss = loss.sequence_loss(self.logits, tf.transpose(tf.stack(targets), [1,0], name=\"targets_\"),\r\n                                                     tf.transpose(tf.stack(self.target_weights), [1,0], name=\"weights_\"),\r\n                                                     softmax_loss_function = softmax_loss_function)\r\n`\r\n"}