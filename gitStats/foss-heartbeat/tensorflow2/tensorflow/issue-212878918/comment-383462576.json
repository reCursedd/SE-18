{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/383462576", "html_url": "https://github.com/tensorflow/tensorflow/issues/8220#issuecomment-383462576", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8220", "id": 383462576, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MzQ2MjU3Ng==", "user": {"login": "Lancerchiang", "id": 35952525, "node_id": "MDQ6VXNlcjM1OTUyNTI1", "avatar_url": "https://avatars2.githubusercontent.com/u/35952525?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lancerchiang", "html_url": "https://github.com/Lancerchiang", "followers_url": "https://api.github.com/users/Lancerchiang/followers", "following_url": "https://api.github.com/users/Lancerchiang/following{/other_user}", "gists_url": "https://api.github.com/users/Lancerchiang/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lancerchiang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lancerchiang/subscriptions", "organizations_url": "https://api.github.com/users/Lancerchiang/orgs", "repos_url": "https://api.github.com/users/Lancerchiang/repos", "events_url": "https://api.github.com/users/Lancerchiang/events{/privacy}", "received_events_url": "https://api.github.com/users/Lancerchiang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-23T05:55:01Z", "updated_at": "2018-04-23T10:34:20Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1450614\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/suharshs\">@suharshs</a> Python multiprocessing works fine with tensorflow. The only thing should be noticed is that tensorflow must be imported independently inside each process (must use multiprocessing instead of multithreading since tensorflow will take over the entire process). Below is how I achieved multi-GPU and multiprocessing inferencing and I hope it helps:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> multiprocessing\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">Predictor</span>(<span class=\"pl-e\">multiprocessing</span>.<span class=\"pl-e\">Process</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">input_queue</span>, <span class=\"pl-smi\">gpu_id</span>):\n        multiprocessing.Process.<span class=\"pl-c1\">__init__</span>(<span class=\"pl-c1\">self</span>)\n        <span class=\"pl-c1\">self</span>.input_queue <span class=\"pl-k\">=</span> input_queue\n        <span class=\"pl-c1\">self</span>.gpu_id <span class=\"pl-k\">=</span> gpu_id\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>set GPU id before importing tensorflow!!!!!!!!!!!!!</span>\n        os.environ[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>CUDA_VISIBLE_DEVICES<span class=\"pl-pds\">\"</span></span>] <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-c1\">{}</span><span class=\"pl-pds\">\"</span></span>.format(<span class=\"pl-c1\">self</span>.gpu_id)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>import tensorflow here</span>\n        <span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n        sess <span class=\"pl-k\">=</span> tf.Session()\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Using device #<span class=\"pl-c1\">%s</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-c1\">self</span>.gpu_id)\n        a <span class=\"pl-k\">=</span> tf.placeholder(tf.int16, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>)\n        y <span class=\"pl-k\">=</span> tf.identity(a, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>y<span class=\"pl-pds\">'</span></span>)\n        <span class=\"pl-k\">while</span> <span class=\"pl-c1\">True</span>:\n            <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.input_queue.get()\n            <span class=\"pl-k\">if</span> <span class=\"pl-c1\">input</span> <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n                <span class=\"pl-c1\">self</span>.input_queue.task_done()\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Exiting Process <span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-c1\">self</span>.gpu_id)\n                <span class=\"pl-k\">break</span>\n            <span class=\"pl-k\">else</span>:\n                <span class=\"pl-c1\">print</span> sess.run(y, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{a: <span class=\"pl-c1\">input</span>})\n                <span class=\"pl-c1\">self</span>.input_queue.task_done()\n        sess.close()\n        <span class=\"pl-k\">return</span>\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n    jobs <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">4</span>, <span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">6</span>, <span class=\"pl-c1\">7</span>, <span class=\"pl-c1\">8</span>, <span class=\"pl-c1\">9</span>, <span class=\"pl-c1\">10</span>]\n    num_gpus <span class=\"pl-k\">=</span> <span class=\"pl-c1\">2</span>\n    p_list <span class=\"pl-k\">=</span> []\n    input_queue <span class=\"pl-k\">=</span> multiprocessing.JoinableQueue()\n\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_gpus):\n        p <span class=\"pl-k\">=</span> Predictor(input_queue, i)\n        p_list.append(p)\n    <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> p_list:\n        p.start()\n    <span class=\"pl-k\">for</span> job <span class=\"pl-k\">in</span> jobs:\n        input_queue.put(job)\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_gpus):\n        input_queue.put(<span class=\"pl-c1\">None</span>)\n\n    input_queue.join()\n    <span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> p_list:\n        p.join()</pre></div>", "body_text": "@suharshs Python multiprocessing works fine with tensorflow. The only thing should be noticed is that tensorflow must be imported independently inside each process (must use multiprocessing instead of multithreading since tensorflow will take over the entire process). Below is how I achieved multi-GPU and multiprocessing inferencing and I hope it helps:\nimport os\nimport multiprocessing\n\n\nclass Predictor(multiprocessing.Process):\n    def __init__(self, input_queue, gpu_id):\n        multiprocessing.Process.__init__(self)\n        self.input_queue = input_queue\n        self.gpu_id = gpu_id\n    def run(self):\n        #set GPU id before importing tensorflow!!!!!!!!!!!!!\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(self.gpu_id)\n        #import tensorflow here\n        import tensorflow as tf\n        sess = tf.Session()\n        print('Using device #%s' % self.gpu_id)\n        a = tf.placeholder(tf.int16, name='a')\n        y = tf.identity(a, name='y')\n        while True:\n            input = self.input_queue.get()\n            if input is None:\n                self.input_queue.task_done()\n                print(\"Exiting Process %d\" % self.gpu_id)\n                break\n            else:\n                print sess.run(y, feed_dict={a: input})\n                self.input_queue.task_done()\n        sess.close()\n        return\n\nif __name__ == \"__main__\":\n    jobs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    num_gpus = 2\n    p_list = []\n    input_queue = multiprocessing.JoinableQueue()\n\n    for i in range(num_gpus):\n        p = Predictor(input_queue, i)\n        p_list.append(p)\n    for p in p_list:\n        p.start()\n    for job in jobs:\n        input_queue.put(job)\n    for i in range(num_gpus):\n        input_queue.put(None)\n\n    input_queue.join()\n    for p in p_list:\n        p.join()", "body": "@suharshs Python multiprocessing works fine with tensorflow. The only thing should be noticed is that tensorflow must be imported independently inside each process (must use multiprocessing instead of multithreading since tensorflow will take over the entire process). Below is how I achieved multi-GPU and multiprocessing inferencing and I hope it helps:\r\n\r\n\r\n```python\r\nimport os\r\nimport multiprocessing\r\n\r\n\r\nclass Predictor(multiprocessing.Process):\r\n    def __init__(self, input_queue, gpu_id):\r\n        multiprocessing.Process.__init__(self)\r\n        self.input_queue = input_queue\r\n        self.gpu_id = gpu_id\r\n    def run(self):\r\n        #set GPU id before importing tensorflow!!!!!!!!!!!!!\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(self.gpu_id)\r\n        #import tensorflow here\r\n        import tensorflow as tf\r\n        sess = tf.Session()\r\n        print('Using device #%s' % self.gpu_id)\r\n        a = tf.placeholder(tf.int16, name='a')\r\n        y = tf.identity(a, name='y')\r\n        while True:\r\n            input = self.input_queue.get()\r\n            if input is None:\r\n                self.input_queue.task_done()\r\n                print(\"Exiting Process %d\" % self.gpu_id)\r\n                break\r\n            else:\r\n                print sess.run(y, feed_dict={a: input})\r\n                self.input_queue.task_done()\r\n        sess.close()\r\n        return\r\n\r\nif __name__ == \"__main__\":\r\n    jobs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\r\n    num_gpus = 2\r\n    p_list = []\r\n    input_queue = multiprocessing.JoinableQueue()\r\n\r\n    for i in range(num_gpus):\r\n        p = Predictor(input_queue, i)\r\n        p_list.append(p)\r\n    for p in p_list:\r\n        p.start()\r\n    for job in jobs:\r\n        input_queue.put(job)\r\n    for i in range(num_gpus):\r\n        input_queue.put(None)\r\n\r\n    input_queue.join()\r\n    for p in p_list:\r\n        p.join()\r\n```"}