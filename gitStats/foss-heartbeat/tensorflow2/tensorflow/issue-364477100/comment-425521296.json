{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425521296", "html_url": "https://github.com/tensorflow/tensorflow/issues/22564#issuecomment-425521296", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22564", "id": 425521296, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTUyMTI5Ng==", "user": {"login": "Elites2017", "id": 35799396, "node_id": "MDQ6VXNlcjM1Nzk5Mzk2", "avatar_url": "https://avatars2.githubusercontent.com/u/35799396?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Elites2017", "html_url": "https://github.com/Elites2017", "followers_url": "https://api.github.com/users/Elites2017/followers", "following_url": "https://api.github.com/users/Elites2017/following{/other_user}", "gists_url": "https://api.github.com/users/Elites2017/gists{/gist_id}", "starred_url": "https://api.github.com/users/Elites2017/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Elites2017/subscriptions", "organizations_url": "https://api.github.com/users/Elites2017/orgs", "repos_url": "https://api.github.com/users/Elites2017/repos", "events_url": "https://api.github.com/users/Elites2017/events{/privacy}", "received_events_url": "https://api.github.com/users/Elites2017/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-28T18:11:00Z", "updated_at": "2018-09-28T18:21:06Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>For SSD models trained with detection API, you should use this <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py\">binary</a> to convert the graph.</p>\n</blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=35853368\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pkulzc\">@pkulzc</a> I've used images of size 256 x 256. in the binary file you mentioned, they say:<br>\n<strong>Inputs:<br>\n'normalized_input_image_tensor': a float32 tensor of shape<br>\n[1, height, width, 3] containing the normalized input image. Note that the<br>\nheight and width must be compatible with the height and width configured in<br>\nthe fixed_shape_image resizer options in the pipeline config proto.</strong></p>\n<p>I haven't done anything in that pipeline config proto, where is that file? Do I need to pass the dimension of the pictures used to trained my model in that file?</p>\n<p>With the binary mentioned, will I have to convert the frozen graph I will have after exportation to tflite format in order to use it for mobile devices or that frozen graph can be directly used on mobile devices without conversion?</p>", "body_text": "For SSD models trained with detection API, you should use this binary to convert the graph.\n\n@pkulzc I've used images of size 256 x 256. in the binary file you mentioned, they say:\nInputs:\n'normalized_input_image_tensor': a float32 tensor of shape\n[1, height, width, 3] containing the normalized input image. Note that the\nheight and width must be compatible with the height and width configured in\nthe fixed_shape_image resizer options in the pipeline config proto.\nI haven't done anything in that pipeline config proto, where is that file? Do I need to pass the dimension of the pictures used to trained my model in that file?\nWith the binary mentioned, will I have to convert the frozen graph I will have after exportation to tflite format in order to use it for mobile devices or that frozen graph can be directly used on mobile devices without conversion?", "body": "> \r\n> \r\n> For SSD models trained with detection API, you should use this [binary](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py) to convert the graph.\r\n\r\n@pkulzc I've used images of size 256 x 256. in the binary file you mentioned, they say:\r\n**Inputs:\r\n'normalized_input_image_tensor': a float32 tensor of shape\r\n[1, height, width, 3] containing the normalized input image. Note that the\r\nheight and width must be compatible with the height and width configured in\r\nthe fixed_shape_image resizer options in the pipeline config proto.**\r\n\r\nI haven't done anything in that pipeline config proto, where is that file? Do I need to pass the dimension of the pictures used to trained my model in that file? \r\n\r\nWith the binary mentioned, will I have to convert the frozen graph I will have after exportation to tflite format in order to use it for mobile devices or that frozen graph can be directly used on mobile devices without conversion? "}