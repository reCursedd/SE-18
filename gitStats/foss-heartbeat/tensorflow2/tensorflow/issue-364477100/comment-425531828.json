{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425531828", "html_url": "https://github.com/tensorflow/tensorflow/issues/22564#issuecomment-425531828", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22564", "id": 425531828, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTUzMTgyOA==", "user": {"login": "Elites2017", "id": 35799396, "node_id": "MDQ6VXNlcjM1Nzk5Mzk2", "avatar_url": "https://avatars2.githubusercontent.com/u/35799396?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Elites2017", "html_url": "https://github.com/Elites2017", "followers_url": "https://api.github.com/users/Elites2017/followers", "following_url": "https://api.github.com/users/Elites2017/following{/other_user}", "gists_url": "https://api.github.com/users/Elites2017/gists{/gist_id}", "starred_url": "https://api.github.com/users/Elites2017/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Elites2017/subscriptions", "organizations_url": "https://api.github.com/users/Elites2017/orgs", "repos_url": "https://api.github.com/users/Elites2017/repos", "events_url": "https://api.github.com/users/Elites2017/events{/privacy}", "received_events_url": "https://api.github.com/users/Elites2017/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-28T18:50:27Z", "updated_at": "2018-09-28T18:51:14Z", "author_association": "NONE", "body_html": "<blockquote>\n<p>Please read the comments carefully. It says</p>\n<blockquote>\n<p>The exported graph has the following input and output nodes.<br>\nInputs:<br>\n'normalized_input_image_tensor': ...</p>\n</blockquote>\n<p>So when you export the graph, you don't need to provide this.</p>\n<p>After this exporting you don't need to convert again. See this <a href=\"https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\" rel=\"nofollow\">post</a> for some more details.</p>\n</blockquote>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=35853368\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/pkulzc\">@pkulzc</a>  Maybe I misunderstood whe you said that I don't need to convert the frozen graph obtained to tflite after exportation. I thouth I could use that graph directly into an android app.</p>\n<p>About the link you mentionned, where do I get those parameters <strong>(input_shapes=1,300,300,3)</strong> or <strong>should I replace the 300 x 300 by 256 x 256 which are the width and height of the images that I've used to trained the model or those are deflautf parameters</strong>? What about the std_value, mean_value?</p>\n<p>bazel run -c opt tensorflow/contrib/lite/toco:toco -- <br>\n--input_file=$OUTPUT_DIR/tflite_graph.pb <br>\n--output_file=$OUTPUT_DIR/detect.tflite <br>\n--input_shapes=1,300,300,3 <br>\n--input_arrays=normalized_input_image_tensor <br>\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  <br>\n--inference_type=QUANTIZED_UINT8 <br>\n--mean_values=128 <br>\n--std_values=128 <br>\n--change_concat_input_ranges=false <br>\n--allow_custom_ops</p>", "body_text": "Please read the comments carefully. It says\n\nThe exported graph has the following input and output nodes.\nInputs:\n'normalized_input_image_tensor': ...\n\nSo when you export the graph, you don't need to provide this.\nAfter this exporting you don't need to convert again. See this post for some more details.\n\n@pkulzc  Maybe I misunderstood whe you said that I don't need to convert the frozen graph obtained to tflite after exportation. I thouth I could use that graph directly into an android app.\nAbout the link you mentionned, where do I get those parameters (input_shapes=1,300,300,3) or should I replace the 300 x 300 by 256 x 256 which are the width and height of the images that I've used to trained the model or those are deflautf parameters? What about the std_value, mean_value?\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \n--input_file=$OUTPUT_DIR/tflite_graph.pb \n--output_file=$OUTPUT_DIR/detect.tflite \n--input_shapes=1,300,300,3 \n--input_arrays=normalized_input_image_tensor \n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \n--inference_type=QUANTIZED_UINT8 \n--mean_values=128 \n--std_values=128 \n--change_concat_input_ranges=false \n--allow_custom_ops", "body": "> \r\n> \r\n> Please read the comments carefully. It says\r\n> \r\n> > The exported graph has the following input and output nodes.\r\n> > Inputs:\r\n> > 'normalized_input_image_tensor': ...\r\n> \r\n> So when you export the graph, you don't need to provide this.\r\n> \r\n> After this exporting you don't need to convert again. See this [post](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193) for some more details.\r\n\r\n@pkulzc  Maybe I misunderstood whe you said that I don't need to convert the frozen graph obtained to tflite after exportation. I thouth I could use that graph directly into an android app.\r\n\r\nAbout the link you mentionned, where do I get those parameters **(input_shapes=1,300,300,3)** or **should I replace the 300 x 300 by 256 x 256 which are the width and height of the images that I've used to trained the model or those are deflautf parameters**? What about the std_value, mean_value?\r\n\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \\\r\n--input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n--output_file=$OUTPUT_DIR/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--mean_values=128 \\\r\n--std_values=128 \\\r\n--change_concat_input_ranges=false \\\r\n--allow_custom_ops"}