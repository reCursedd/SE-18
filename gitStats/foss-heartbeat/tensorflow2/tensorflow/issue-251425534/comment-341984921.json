{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/341984921", "html_url": "https://github.com/tensorflow/tensorflow/issues/12414#issuecomment-341984921", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12414", "id": 341984921, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MTk4NDkyMQ==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-05T16:18:09Z", "updated_at": "2017-11-05T16:18:09Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"email-fragment\">Yes, you can wrap the dataset with a repeat () call and use an outer for\nloop for reach epoch if you know the number of elements per epoch.</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sat, Nov 4, 2017, 10:23 PM Jeremy Hsu ***@***.***&gt; wrote:\n Maybe there are some other causes because by setting the\n num_parallel_calls argument to 1 in tf.data.Dataset.map doesn't prevent\n the warning from flooding.\n\n BTW, a very useless tip to avoid the warning is by using for-loops\n instead of try-except (and remember to run the initializer every time\n before the loop). However, this only works when the dataset is simple\n enough that you know the exact number of iterations per epoch...\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"251425534\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/12414\" href=\"https://github.com/tensorflow/tensorflow/issues/12414#issuecomment-341950080\">#12414 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/ABtim9Lr0GYVCOSb0RWqKvRMSsbLtaB5ks5szUZtgaJpZM4O8Vau\">https://github.com/notifications/unsubscribe-auth/ABtim9Lr0GYVCOSb0RWqKvRMSsbLtaB5ks5szUZtgaJpZM4O8Vau</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Yes, you can wrap the dataset with a repeat () call and use an outer for\nloop for reach epoch if you know the number of elements per epoch.\n\u2026\nOn Sat, Nov 4, 2017, 10:23 PM Jeremy Hsu ***@***.***> wrote:\n Maybe there are some other causes because by setting the\n num_parallel_calls argument to 1 in tf.data.Dataset.map doesn't prevent\n the warning from flooding.\n\n BTW, a very useless tip to avoid the warning is by using for-loops\n instead of try-except (and remember to run the initializer every time\n before the loop). However, this only works when the dataset is simple\n enough that you know the exact number of iterations per epoch...\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#12414 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/ABtim9Lr0GYVCOSb0RWqKvRMSsbLtaB5ks5szUZtgaJpZM4O8Vau>\n .", "body": "Yes, you can wrap the dataset with a repeat () call and use an outer for\nloop for reach epoch if you know the number of elements per epoch.\n\nOn Sat, Nov 4, 2017, 10:23 PM Jeremy Hsu <notifications@github.com> wrote:\n\n> Maybe there are some other causes because by setting the\n> num_parallel_calls argument to 1 in tf.data.Dataset.map doesn't prevent\n> the warning from flooding.\n>\n> BTW, a very useless tip to avoid the warning is by using for-loops\n> instead of try-except (and remember to run the initializer every time\n> before the loop). However, this only works when the dataset is simple\n> enough that you know the exact number of iterations per epoch...\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12414#issuecomment-341950080>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim9Lr0GYVCOSb0RWqKvRMSsbLtaB5ks5szUZtgaJpZM4O8Vau>\n> .\n>\n"}