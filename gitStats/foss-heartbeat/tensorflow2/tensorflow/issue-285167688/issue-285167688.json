{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15722", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15722/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15722/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15722/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15722", "id": 285167688, "node_id": "MDU6SXNzdWUyODUxNjc2ODg=", "number": 15722, "title": "Image Adjustments API doesn't clearly specify input range", "user": {"login": "ahundt", "id": 55744, "node_id": "MDQ6VXNlcjU1NzQ0", "avatar_url": "https://avatars1.githubusercontent.com/u/55744?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ahundt", "html_url": "https://github.com/ahundt", "followers_url": "https://api.github.com/users/ahundt/followers", "following_url": "https://api.github.com/users/ahundt/following{/other_user}", "gists_url": "https://api.github.com/users/ahundt/gists{/gist_id}", "starred_url": "https://api.github.com/users/ahundt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ahundt/subscriptions", "organizations_url": "https://api.github.com/users/ahundt/orgs", "repos_url": "https://api.github.com/users/ahundt/repos", "events_url": "https://api.github.com/users/ahundt/events{/privacy}", "received_events_url": "https://api.github.com/users/ahundt/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 10, "created_at": "2017-12-29T23:10:37Z", "updated_at": "2018-02-08T23:42:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>Describe the problem</h3>\n<p>There is a documentation issue with a possible corresponding tf.keras bug.<br>\nThe <a href=\"https://www.tensorflow.org/api_guides/python/image#Image_Adjustments\" rel=\"nofollow\">tf image adjustments guide</a> doesn't document the inputs. It appears they can be in a <code>[0, 1]</code> range or <code>[0, MAX]</code> based on comments in tf.slim where the relevant APIs are used.</p>\n<p>This may have led to preprocessing bugs in other utilities such as keras and tf.keras, which believe tf expects the range <code>[-1, 1]</code> see <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"285166223\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/8916\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/8916/hovercard\" href=\"https://github.com/keras-team/keras/issues/8916\">keras-team/keras#8916</a>, the following includes additional details from that issue:</p>\n<p>It appears Keras' imagenet image preprocessing may be inconsistent with how it is done in tf, in particular keras sets values to <code>[-1, 1]</code> while in tf the expected range is <code>[0, 1]</code>.</p>\n<ul>\n<li><a href=\"https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing.py#L284\">slim/preprocessing/inception_preprocessing.py</a>\n<ul>\n<li>notes <code>If dtype is tf.float32 then the range should be [0, 1]</code></li>\n</ul>\n</li>\n<li><a href=\"https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py#L72\">keras preprocess_input()</a>\n<ul>\n<li>notes <code>tf: will scale pixels between -1 and 1, sample-wise</code>.</li>\n</ul>\n</li>\n</ul>\n<p>Here is the key doc from Keras' <code>preprocess_input()</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">preprocess_input</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">data_format</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">mode</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>caffe<span class=\"pl-pds\">'</span></span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Preprocesses a tensor encoding a batch of images.</span>\n<span class=\"pl-s\">    # Arguments</span>\n<span class=\"pl-s\">        x: input Numpy or symoblic tensor, 3D or 4D.</span>\n<span class=\"pl-s\">        data_format: data format of the image tensor.</span>\n<span class=\"pl-s\">        mode: One of \"caffe\", \"tf\".</span>\n<span class=\"pl-s\">            - caffe: will convert the images from RGB to BGR,</span>\n<span class=\"pl-s\">                then will zero-center each color channel with</span>\n<span class=\"pl-s\">                respect to the ImageNet dataset,</span>\n<span class=\"pl-s\">                without scaling.</span>\n<span class=\"pl-s\">            - tf: will scale pixels between -1 and 1,</span>\n<span class=\"pl-s\">                sample-wise.</span>\n<span class=\"pl-s\">    # Returns</span>\n<span class=\"pl-s\">        Preprocessed tensor.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span></pre></div>\n<p>Here are the key docs from the tf slim function <code>preprocess_for_train()</code> which specify a [0, 1] range:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">preprocess_for_train</span>(<span class=\"pl-smi\">image</span>, <span class=\"pl-smi\">height</span>, <span class=\"pl-smi\">width</span>, <span class=\"pl-smi\">bbox</span>,\n                         <span class=\"pl-smi\">fast_mode</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                         <span class=\"pl-smi\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                         <span class=\"pl-smi\">add_image_summaries</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n  <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Distort one image for training a network.</span>\n<span class=\"pl-s\">  Distorting images provides a useful technique for augmenting the data</span>\n<span class=\"pl-s\">  set during training in order to make the network invariant to aspects</span>\n<span class=\"pl-s\">  of the image that do not effect the label.</span>\n<span class=\"pl-s\">  Additionally it would create image_summaries to display the different</span>\n<span class=\"pl-s\">  transformations applied to the image.</span>\n<span class=\"pl-s\">  Args:</span>\n<span class=\"pl-s\">    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be</span>\n<span class=\"pl-s\">      [0, 1], otherwise it would converted to tf.float32 assuming that the range</span>\n<span class=\"pl-s\">      is [0, MAX], where MAX is largest positive representable number for</span>\n<span class=\"pl-s\">      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).</span>\n<span class=\"pl-s\">    height: integer</span>\n<span class=\"pl-s\">    width: integer</span>\n<span class=\"pl-s\">    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]</span>\n<span class=\"pl-s\">      where each coordinate is [0, 1) and the coordinates are arranged</span>\n<span class=\"pl-s\">      as [ymin, xmin, ymax, xmax].</span>\n<span class=\"pl-s\">    fast_mode: Optional boolean, if True avoids slower transformations (i.e.</span>\n<span class=\"pl-s\">      bi-cubic resizing, random_hue or random_contrast).</span>\n<span class=\"pl-s\">    scope: Optional scope for name_scope.</span>\n<span class=\"pl-s\">    add_image_summaries: Enable image summaries.</span>\n<span class=\"pl-s\">  Returns:</span>\n<span class=\"pl-s\">    3-D float Tensor of distorted image used for training with range [-1, 1].</span>\n<span class=\"pl-s\">  <span class=\"pl-pds\">\"\"\"</span></span></pre></div>\n<p>side note:</p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"250318222\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/models/issues/2217\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/models/issues/2217/hovercard\" href=\"https://github.com/tensorflow/models/issues/2217\">tensorflow/models#2217</a> seems relevant</li>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"285166223\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/keras-team/keras/issues/8916\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/8916/hovercard\" href=\"https://github.com/keras-team/keras/issues/8916\">keras-team/keras#8916</a> is the corresponding keras issue</li>\n</ul>\n<h3>System information</h3>\n<p>Not relevant, this is a documentation + input value range issue.</p>\n<h3>Source code / logs</h3>\n<p>relevant links + code included above</p>", "body_text": "Describe the problem\nThere is a documentation issue with a possible corresponding tf.keras bug.\nThe tf image adjustments guide doesn't document the inputs. It appears they can be in a [0, 1] range or [0, MAX] based on comments in tf.slim where the relevant APIs are used.\nThis may have led to preprocessing bugs in other utilities such as keras and tf.keras, which believe tf expects the range [-1, 1] see keras-team/keras#8916, the following includes additional details from that issue:\nIt appears Keras' imagenet image preprocessing may be inconsistent with how it is done in tf, in particular keras sets values to [-1, 1] while in tf the expected range is [0, 1].\n\nslim/preprocessing/inception_preprocessing.py\n\nnotes If dtype is tf.float32 then the range should be [0, 1]\n\n\nkeras preprocess_input()\n\nnotes tf: will scale pixels between -1 and 1, sample-wise.\n\n\n\nHere is the key doc from Keras' preprocess_input():\ndef preprocess_input(x, data_format=None, mode='caffe'):\n    \"\"\"Preprocesses a tensor encoding a batch of images.\n    # Arguments\n        x: input Numpy or symoblic tensor, 3D or 4D.\n        data_format: data format of the image tensor.\n        mode: One of \"caffe\", \"tf\".\n            - caffe: will convert the images from RGB to BGR,\n                then will zero-center each color channel with\n                respect to the ImageNet dataset,\n                without scaling.\n            - tf: will scale pixels between -1 and 1,\n                sample-wise.\n    # Returns\n        Preprocessed tensor.\n    \"\"\"\nHere are the key docs from the tf slim function preprocess_for_train() which specify a [0, 1] range:\ndef preprocess_for_train(image, height, width, bbox,\n                         fast_mode=True,\n                         scope=None,\n                         add_image_summaries=True):\n  \"\"\"Distort one image for training a network.\n  Distorting images provides a useful technique for augmenting the data\n  set during training in order to make the network invariant to aspects\n  of the image that do not effect the label.\n  Additionally it would create image_summaries to display the different\n  transformations applied to the image.\n  Args:\n    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n      is [0, MAX], where MAX is largest positive representable number for\n      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).\n    height: integer\n    width: integer\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged\n      as [ymin, xmin, ymax, xmax].\n    fast_mode: Optional boolean, if True avoids slower transformations (i.e.\n      bi-cubic resizing, random_hue or random_contrast).\n    scope: Optional scope for name_scope.\n    add_image_summaries: Enable image summaries.\n  Returns:\n    3-D float Tensor of distorted image used for training with range [-1, 1].\n  \"\"\"\nside note:\n\ntensorflow/models#2217 seems relevant\nkeras-team/keras#8916 is the corresponding keras issue\n\nSystem information\nNot relevant, this is a documentation + input value range issue.\nSource code / logs\nrelevant links + code included above", "body": "### Describe the problem\r\n\r\nThere is a documentation issue with a possible corresponding tf.keras bug.\r\nThe [tf image adjustments guide](https://www.tensorflow.org/api_guides/python/image#Image_Adjustments) doesn't document the inputs. It appears they can be in a `[0, 1]` range or `[0, MAX]` based on comments in tf.slim where the relevant APIs are used. \r\n\r\nThis may have led to preprocessing bugs in other utilities such as keras and tf.keras, which believe tf expects the range `[-1, 1]` see https://github.com/keras-team/keras/issues/8916, the following includes additional details from that issue:\r\n\r\nIt appears Keras' imagenet image preprocessing may be inconsistent with how it is done in tf, in particular keras sets values to `[-1, 1]` while in tf the expected range is `[0, 1]`.\r\n\r\n- [slim/preprocessing/inception_preprocessing.py](https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing.py#L284) \r\n    - notes `If dtype is tf.float32 then the range should be [0, 1]`\r\n- [keras preprocess_input()](https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py#L72) \r\n    - notes `tf: will scale pixels between -1 and 1, sample-wise`.\r\n\r\nHere is the key doc from Keras' `preprocess_input()`:\r\n\r\n```python\r\n\r\ndef preprocess_input(x, data_format=None, mode='caffe'):\r\n    \"\"\"Preprocesses a tensor encoding a batch of images.\r\n    # Arguments\r\n        x: input Numpy or symoblic tensor, 3D or 4D.\r\n        data_format: data format of the image tensor.\r\n        mode: One of \"caffe\", \"tf\".\r\n            - caffe: will convert the images from RGB to BGR,\r\n                then will zero-center each color channel with\r\n                respect to the ImageNet dataset,\r\n                without scaling.\r\n            - tf: will scale pixels between -1 and 1,\r\n                sample-wise.\r\n    # Returns\r\n        Preprocessed tensor.\r\n    \"\"\"\r\n```\r\n\r\nHere are the key docs from the tf slim function `preprocess_for_train()` which specify a [0, 1] range:\r\n\r\n```python\r\ndef preprocess_for_train(image, height, width, bbox,\r\n                         fast_mode=True,\r\n                         scope=None,\r\n                         add_image_summaries=True):\r\n  \"\"\"Distort one image for training a network.\r\n  Distorting images provides a useful technique for augmenting the data\r\n  set during training in order to make the network invariant to aspects\r\n  of the image that do not effect the label.\r\n  Additionally it would create image_summaries to display the different\r\n  transformations applied to the image.\r\n  Args:\r\n    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\r\n      [0, 1], otherwise it would converted to tf.float32 assuming that the range\r\n      is [0, MAX], where MAX is largest positive representable number for\r\n      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).\r\n    height: integer\r\n    width: integer\r\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\r\n      where each coordinate is [0, 1) and the coordinates are arranged\r\n      as [ymin, xmin, ymax, xmax].\r\n    fast_mode: Optional boolean, if True avoids slower transformations (i.e.\r\n      bi-cubic resizing, random_hue or random_contrast).\r\n    scope: Optional scope for name_scope.\r\n    add_image_summaries: Enable image summaries.\r\n  Returns:\r\n    3-D float Tensor of distorted image used for training with range [-1, 1].\r\n  \"\"\"\r\n```\r\n\r\nside note: \r\n\r\n- https://github.com/tensorflow/models/issues/2217 seems relevant\r\n- https://github.com/keras-team/keras/issues/8916 is the corresponding keras issue\r\n\r\n### System information\r\n\r\nNot relevant, this is a documentation + input value range issue.\r\n\r\n### Source code / logs\r\n\r\nrelevant links + code included above"}