{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/362723293", "html_url": "https://github.com/tensorflow/tensorflow/issues/15722#issuecomment-362723293", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15722", "id": 362723293, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MjcyMzI5Mw==", "user": {"login": "parag2489", "id": 6313583, "node_id": "MDQ6VXNlcjYzMTM1ODM=", "avatar_url": "https://avatars1.githubusercontent.com/u/6313583?v=4", "gravatar_id": "", "url": "https://api.github.com/users/parag2489", "html_url": "https://github.com/parag2489", "followers_url": "https://api.github.com/users/parag2489/followers", "following_url": "https://api.github.com/users/parag2489/following{/other_user}", "gists_url": "https://api.github.com/users/parag2489/gists{/gist_id}", "starred_url": "https://api.github.com/users/parag2489/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/parag2489/subscriptions", "organizations_url": "https://api.github.com/users/parag2489/orgs", "repos_url": "https://api.github.com/users/parag2489/repos", "events_url": "https://api.github.com/users/parag2489/events{/privacy}", "received_events_url": "https://api.github.com/users/parag2489/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-02T22:13:42Z", "updated_at": "2018-02-02T22:40:36Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=55744\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ahundt\">@ahundt</a> Why will you call <a href=\"https://www.tensorflow.org/api_docs/python/tf/image/per_image_standardization\" rel=\"nofollow\">tf.image.per_image_standardization()</a> to bring the image from <code>[0, 255]</code> to <code>[0, 1]</code>? Why shouldn't we just cast the image as <code>float</code> first and then divide by <code>255</code>? Then subtract 0.5 and multiply by 2. You will get an image that has values lying in <code>[-1, 1]</code>. This is followed in Keras Inception preprocessing as seen <a href=\"https://stackoverflow.com/questions/44341258/preprocessing-function-of-inception-v3-in-keras\" rel=\"nofollow\">here</a>, <a href=\"https://github.com/keras-team/keras/issues/5416\" data-hovercard-type=\"issue\" data-hovercard-url=\"/keras-team/keras/issues/5416/hovercard\">here</a>, <a href=\"https://github.com/fchollet/deep-learning-models/blob/ccd0eb24996b4cbff4231b90cd44b057c0b20f14/inception_v3.py#L391\">here</a> and <a href=\"https://stackoverflow.com/a/42276427/1586200\" rel=\"nofollow\">here</a>.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=32556631\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/anj-s\">@anj-s</a>  Which version of preprocessing is correct? The one suggested by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=55744\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ahundt\">@ahundt</a> or the one mentioned in this comment?</p>\n<p>Also, <a href=\"https://github.com/tensorflow/models/blob/31adae5327c0258ce630f7b3e9f3cf0df78e3ba6/research/slim/preprocessing/inception_preprocessing.py#L279\">inception_preprocessing.py</a> does not do per image standardization, just subtracts 0.5 and multiplies by 2. I hope that is correct.</p>", "body_text": "@ahundt Why will you call tf.image.per_image_standardization() to bring the image from [0, 255] to [0, 1]? Why shouldn't we just cast the image as float first and then divide by 255? Then subtract 0.5 and multiply by 2. You will get an image that has values lying in [-1, 1]. This is followed in Keras Inception preprocessing as seen here, here, here and here.\n@anj-s  Which version of preprocessing is correct? The one suggested by @ahundt or the one mentioned in this comment?\nAlso, inception_preprocessing.py does not do per image standardization, just subtracts 0.5 and multiplies by 2. I hope that is correct.", "body": "@ahundt Why will you call [tf.image.per_image_standardization()](https://www.tensorflow.org/api_docs/python/tf/image/per_image_standardization) to bring the image from `[0, 255]` to `[0, 1]`? Why shouldn't we just cast the image as `float` first and then divide by `255`? Then subtract 0.5 and multiply by 2. You will get an image that has values lying in `[-1, 1]`. This is followed in Keras Inception preprocessing as seen [here](https://stackoverflow.com/questions/44341258/preprocessing-function-of-inception-v3-in-keras), [here](https://github.com/keras-team/keras/issues/5416), [here](https://github.com/fchollet/deep-learning-models/blob/ccd0eb24996b4cbff4231b90cd44b057c0b20f14/inception_v3.py#L391) and [here](https://stackoverflow.com/a/42276427/1586200).\r\n\r\n@anj-s  Which version of preprocessing is correct? The one suggested by @ahundt or the one mentioned in this comment?\r\n\r\nAlso, [inception_preprocessing.py](https://github.com/tensorflow/models/blob/31adae5327c0258ce630f7b3e9f3cf0df78e3ba6/research/slim/preprocessing/inception_preprocessing.py#L279) does not do per image standardization, just subtracts 0.5 and multiplies by 2. I hope that is correct."}