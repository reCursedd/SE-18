{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/414013755", "html_url": "https://github.com/tensorflow/tensorflow/issues/21401#issuecomment-414013755", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21401", "id": 414013755, "node_id": "MDEyOklzc3VlQ29tbWVudDQxNDAxMzc1NQ==", "user": {"login": "ChrisBellew", "id": 4590802, "node_id": "MDQ6VXNlcjQ1OTA4MDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/4590802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChrisBellew", "html_url": "https://github.com/ChrisBellew", "followers_url": "https://api.github.com/users/ChrisBellew/followers", "following_url": "https://api.github.com/users/ChrisBellew/following{/other_user}", "gists_url": "https://api.github.com/users/ChrisBellew/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChrisBellew/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChrisBellew/subscriptions", "organizations_url": "https://api.github.com/users/ChrisBellew/orgs", "repos_url": "https://api.github.com/users/ChrisBellew/repos", "events_url": "https://api.github.com/users/ChrisBellew/events{/privacy}", "received_events_url": "https://api.github.com/users/ChrisBellew/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-17T23:43:56Z", "updated_at": "2018-08-17T23:43:56Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Thanks Cliff.\n\nMy situation is that I am using V100 GPUs on AWS using keras/tensorflow.\nThere are some rules that you must use to ensure the calculations are half\nprecision floating point such as:\n\n* Setting float X to float 16\n* Ensuring input arrays are float 16\n\nIf you don't abide by these, the GPU will just use the standard single\nprecision cores and you won't get the significant speed up. My problem is\nthat I don't know if I have successfully moved some calculations onto the\ntensor cores or if I have made a mistake. I suppose I could ensure all my\ntypes are float 32 and then compare to the float 16 times, and they should\nbe very different, but i wanted to know if there was a way tensorflow could\ngive me some feedback.\n\nThanks</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sat., 18 Aug. 2018, 6:16 am Cliff Young, ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/ChrisBellew\">@ChrisBellew</a> &lt;<a href=\"https://github.com/ChrisBellew\">https://github.com/ChrisBellew</a>&gt; my understanding of V100\n architecture is that the TensorCores aren't separated out--they use the\n same registers and reuse the ALUs of the main SM. So it may not be\n meaningful to ask for the utilization of the TC versus the normal SIMD\n cores.\n\n I would think that what you actually want to know is the performance\n benefits from using the TensorCores. Is your problem that you don't have a\n V100 and want to know if your model is likely to benefit from running on\n it? If you have a V100 sample, can't you do end-to-end timing measurements\n on it versus the alternatives?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"347829128\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/21401\" href=\"https://github.com/tensorflow/tensorflow/issues/21401#issuecomment-414001164\">#21401 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AEYM0vRvCisXbpOP1ZAIk8sr_2P180mOks5uR0DXgaJpZM4Vv-Ty\">https://github.com/notifications/unsubscribe-auth/AEYM0vRvCisXbpOP1ZAIk8sr_2P180mOks5uR0DXgaJpZM4Vv-Ty</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Thanks Cliff.\n\nMy situation is that I am using V100 GPUs on AWS using keras/tensorflow.\nThere are some rules that you must use to ensure the calculations are half\nprecision floating point such as:\n\n* Setting float X to float 16\n* Ensuring input arrays are float 16\n\nIf you don't abide by these, the GPU will just use the standard single\nprecision cores and you won't get the significant speed up. My problem is\nthat I don't know if I have successfully moved some calculations onto the\ntensor cores or if I have made a mistake. I suppose I could ensure all my\ntypes are float 32 and then compare to the float 16 times, and they should\nbe very different, but i wanted to know if there was a way tensorflow could\ngive me some feedback.\n\nThanks\n\u2026\nOn Sat., 18 Aug. 2018, 6:16 am Cliff Young, ***@***.***> wrote:\n @ChrisBellew <https://github.com/ChrisBellew> my understanding of V100\n architecture is that the TensorCores aren't separated out--they use the\n same registers and reuse the ALUs of the main SM. So it may not be\n meaningful to ask for the utilization of the TC versus the normal SIMD\n cores.\n\n I would think that what you actually want to know is the performance\n benefits from using the TensorCores. Is your problem that you don't have a\n V100 and want to know if your model is likely to benefit from running on\n it? If you have a V100 sample, can't you do end-to-end timing measurements\n on it versus the alternatives?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#21401 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AEYM0vRvCisXbpOP1ZAIk8sr_2P180mOks5uR0DXgaJpZM4Vv-Ty>\n .", "body": "Thanks Cliff.\n\nMy situation is that I am using V100 GPUs on AWS using keras/tensorflow.\nThere are some rules that you must use to ensure the calculations are half\nprecision floating point such as:\n\n* Setting float X to float 16\n* Ensuring input arrays are float 16\n\nIf you don't abide by these, the GPU will just use the standard single\nprecision cores and you won't get the significant speed up. My problem is\nthat I don't know if I have successfully moved some calculations onto the\ntensor cores or if I have made a mistake. I suppose I could ensure all my\ntypes are float 32 and then compare to the float 16 times, and they should\nbe very different, but i wanted to know if there was a way tensorflow could\ngive me some feedback.\n\nThanks\n\nOn Sat., 18 Aug. 2018, 6:16 am Cliff Young, <notifications@github.com>\nwrote:\n\n> @ChrisBellew <https://github.com/ChrisBellew> my understanding of V100\n> architecture is that the TensorCores aren't separated out--they use the\n> same registers and reuse the ALUs of the main SM. So it may not be\n> meaningful to ask for the utilization of the TC versus the normal SIMD\n> cores.\n>\n> I would think that what you actually want to know is the performance\n> benefits from using the TensorCores. Is your problem that you don't have a\n> V100 and want to know if your model is likely to benefit from running on\n> it? If you have a V100 sample, can't you do end-to-end timing measurements\n> on it versus the alternatives?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21401#issuecomment-414001164>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEYM0vRvCisXbpOP1ZAIk8sr_2P180mOks5uR0DXgaJpZM4Vv-Ty>\n> .\n>\n"}