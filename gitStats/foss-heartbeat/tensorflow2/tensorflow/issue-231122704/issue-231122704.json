{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10167", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10167/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10167/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10167/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10167", "id": 231122704, "node_id": "MDU6SXNzdWUyMzExMjI3MDQ=", "number": 10167, "title": "Ability to completelly reset tensorflow state (Session.close() does not do that)", "user": {"login": "olegsinyavskiy", "id": 2086260, "node_id": "MDQ6VXNlcjIwODYyNjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/2086260?v=4", "gravatar_id": "", "url": "https://api.github.com/users/olegsinyavskiy", "html_url": "https://github.com/olegsinyavskiy", "followers_url": "https://api.github.com/users/olegsinyavskiy/followers", "following_url": "https://api.github.com/users/olegsinyavskiy/following{/other_user}", "gists_url": "https://api.github.com/users/olegsinyavskiy/gists{/gist_id}", "starred_url": "https://api.github.com/users/olegsinyavskiy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/olegsinyavskiy/subscriptions", "organizations_url": "https://api.github.com/users/olegsinyavskiy/orgs", "repos_url": "https://api.github.com/users/olegsinyavskiy/repos", "events_url": "https://api.github.com/users/olegsinyavskiy/events{/privacy}", "received_events_url": "https://api.github.com/users/olegsinyavskiy/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-24T17:57:47Z", "updated_at": "2017-05-26T05:06:58Z", "closed_at": "2017-05-26T04:10:23Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: parallels ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.4.5-jdk7</li>\n<li><strong>CUDA/cuDNN version</strong>: no cuda</li>\n<li><strong>GPU model and memory</strong>: no gpu</li>\n<li><strong>Exact command to reproduce</strong>: see the code below</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Bug:<br>\nsession.close() seems to imply that all resources would be freed and tensorflow state would be reset.<br>\nor Feature request:<br>\nIf I'm wrong about session.close(), then there should be a way to reset tensorflow state.</p>\n<p>When I first time create a session, tensorflow seem to initialize certain variables that I see as a printout like \"platform Host present with 8 visible devices\". However after I close the session I expect these resources to be freed. At least there would be nice to maybe have an additional command to close the device. After running this \"complete_device_close()\" command, I expect that a new session will initialize device again with the same printout.</p>\n<p>The lack of this behavior currently does not allow to run tensorflow sessions after a fork even in the case where I know that the parent process is never going to use tensorflow again. The following code hangs:</p>\n<div class=\"highlight highlight-source-python\"><pre>   <span class=\"pl-k\">import</span> multiprocessing\n   <span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_runner</span>():\n        sess <span class=\"pl-k\">=</span> tf.Session()\n        sess.run(tf.Variable(<span class=\"pl-c1\">0</span>.).initializer)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> this hangs after fork</span>\n        sess.close()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> here all resources should be cleared</span>\n\n    _runner()\n\n    p <span class=\"pl-k\">=</span> multiprocessing.Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>_runner)\n    p.start()\n    p.join()</pre></div>\n<p>There are multiple issues on \"hanging after fork\" topic:<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"187692328\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5448\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5448/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5448\">#5448</a><br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"156076935\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2448\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2448/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2448\">#2448</a><br>\nwith a solution to create a server or not to fork at all. However in my case parent process does not want to use tensorflow anymore so I expect to close it forever and the parent process and reopen it in a child. Suggested workarounds do not work for me because parent tensorflow use and a use in a child after fork happens in totally unrelated parts of the system and at different times and creating any coupling between them would be really ugly. We would better establish a practice to \"properly close tensorflow after you done\".</p>\n<p>Notice that initializing devices in multiple children after fork works fine if parent is not involved:</p>\n<div class=\"highlight highlight-source-python\"><pre>   <span class=\"pl-k\">import</span> multiprocessing\n   <span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_runner_2</span>(<span class=\"pl-smi\">index</span>):\n        sess <span class=\"pl-k\">=</span> tf.Session()\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n            <span class=\"pl-k\">import</span> time\n            time.sleep(<span class=\"pl-c1\">0.1</span>)\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>running <span class=\"pl-c1\">%d</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> index)\n            sess.run(tf.Variable(<span class=\"pl-c1\">0</span>.).initializer)\n        sess.close()\n\n    <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>):\n        p <span class=\"pl-k\">=</span> multiprocessing.Process(<span class=\"pl-v\">target</span><span class=\"pl-k\">=</span>_runner_2, <span class=\"pl-v\">args</span><span class=\"pl-k\">=</span>(j,))\n        p.start()</pre></div>\n<p>This code prints \"platform Host present with 8 visible devices\" 10 times.<br>\nThis suggests that there is no underlying reason to prevent sharing of CPU or any other resources in this case (I do not have GPU).</p>\n<p>Alternative phrasing of the feature request would be:<br>\n\"Make tensorflow fork-safe after certain full deinitialization command\"</p>\n<h3>Source code / logs</h3>\n<p>see above</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): parallels ubuntu 14.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.1.0\nBazel version (if compiling from source): 0.4.5-jdk7\nCUDA/cuDNN version: no cuda\nGPU model and memory: no gpu\nExact command to reproduce: see the code below\n\nDescribe the problem\nBug:\nsession.close() seems to imply that all resources would be freed and tensorflow state would be reset.\nor Feature request:\nIf I'm wrong about session.close(), then there should be a way to reset tensorflow state.\nWhen I first time create a session, tensorflow seem to initialize certain variables that I see as a printout like \"platform Host present with 8 visible devices\". However after I close the session I expect these resources to be freed. At least there would be nice to maybe have an additional command to close the device. After running this \"complete_device_close()\" command, I expect that a new session will initialize device again with the same printout.\nThe lack of this behavior currently does not allow to run tensorflow sessions after a fork even in the case where I know that the parent process is never going to use tensorflow again. The following code hangs:\n   import multiprocessing\n   import tensorflow as tf\n\n    def _runner():\n        sess = tf.Session()\n        sess.run(tf.Variable(0.).initializer)  # this hangs after fork\n        sess.close()  # here all resources should be cleared\n\n    _runner()\n\n    p = multiprocessing.Process(target=_runner)\n    p.start()\n    p.join()\nThere are multiple issues on \"hanging after fork\" topic:\n#5448\n#2448\nwith a solution to create a server or not to fork at all. However in my case parent process does not want to use tensorflow anymore so I expect to close it forever and the parent process and reopen it in a child. Suggested workarounds do not work for me because parent tensorflow use and a use in a child after fork happens in totally unrelated parts of the system and at different times and creating any coupling between them would be really ugly. We would better establish a practice to \"properly close tensorflow after you done\".\nNotice that initializing devices in multiple children after fork works fine if parent is not involved:\n   import multiprocessing\n   import tensorflow as tf\n\n    def _runner_2(index):\n        sess = tf.Session()\n        for i in range(10):\n            import time\n            time.sleep(0.1)\n            print('running %d' % index)\n            sess.run(tf.Variable(0.).initializer)\n        sess.close()\n\n    for j in range(10):\n        p = multiprocessing.Process(target=_runner_2, args=(j,))\n        p.start()\nThis code prints \"platform Host present with 8 visible devices\" 10 times.\nThis suggests that there is no underlying reason to prevent sharing of CPU or any other resources in this case (I do not have GPU).\nAlternative phrasing of the feature request would be:\n\"Make tensorflow fork-safe after certain full deinitialization command\"\nSource code / logs\nsee above", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: parallels ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Bazel version (if compiling from source)**: 0.4.5-jdk7\r\n- **CUDA/cuDNN version**: no cuda\r\n- **GPU model and memory**: no gpu\r\n- **Exact command to reproduce**: see the code below\r\n\r\n### Describe the problem\r\n\r\nBug:\r\nsession.close() seems to imply that all resources would be freed and tensorflow state would be reset.\r\nor Feature request:\r\nIf I'm wrong about session.close(), then there should be a way to reset tensorflow state. \r\n\r\nWhen I first time create a session, tensorflow seem to initialize certain variables that I see as a printout like \"platform Host present with 8 visible devices\". However after I close the session I expect these resources to be freed. At least there would be nice to maybe have an additional command to close the device. After running this \"complete_device_close()\" command, I expect that a new session will initialize device again with the same printout. \r\n\r\nThe lack of this behavior currently does not allow to run tensorflow sessions after a fork even in the case where I know that the parent process is never going to use tensorflow again. The following code hangs:\r\n```python\r\n   import multiprocessing\r\n   import tensorflow as tf\r\n\r\n    def _runner():\r\n        sess = tf.Session()\r\n        sess.run(tf.Variable(0.).initializer)  # this hangs after fork\r\n        sess.close()  # here all resources should be cleared\r\n\r\n    _runner()\r\n\r\n    p = multiprocessing.Process(target=_runner)\r\n    p.start()\r\n    p.join()\r\n```\r\nThere are multiple issues on \"hanging after fork\" topic:\r\nhttps://github.com/tensorflow/tensorflow/issues/5448\r\nhttps://github.com/tensorflow/tensorflow/issues/2448\r\nwith a solution to create a server or not to fork at all. However in my case parent process does not want to use tensorflow anymore so I expect to close it forever and the parent process and reopen it in a child. Suggested workarounds do not work for me because parent tensorflow use and a use in a child after fork happens in totally unrelated parts of the system and at different times and creating any coupling between them would be really ugly. We would better establish a practice to \"properly close tensorflow after you done\".\r\n\r\nNotice that initializing devices in multiple children after fork works fine if parent is not involved:\r\n```python\r\n   import multiprocessing\r\n   import tensorflow as tf\r\n\r\n    def _runner_2(index):\r\n        sess = tf.Session()\r\n        for i in range(10):\r\n            import time\r\n            time.sleep(0.1)\r\n            print('running %d' % index)\r\n            sess.run(tf.Variable(0.).initializer)\r\n        sess.close()\r\n\r\n    for j in range(10):\r\n        p = multiprocessing.Process(target=_runner_2, args=(j,))\r\n        p.start()\r\n```\r\nThis code prints \"platform Host present with 8 visible devices\" 10 times.\r\nThis suggests that there is no underlying reason to prevent sharing of CPU or any other resources in this case (I do not have GPU).\r\n\r\nAlternative phrasing of the feature request would be:\r\n\"Make tensorflow fork-safe after certain full deinitialization command\"\r\n\r\n### Source code / logs\r\nsee above\r\n"}