{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/380110126", "html_url": "https://github.com/tensorflow/tensorflow/issues/18380#issuecomment-380110126", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18380", "id": 380110126, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MDExMDEyNg==", "user": {"login": "Overdrivr", "id": 1294805, "node_id": "MDQ6VXNlcjEyOTQ4MDU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1294805?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Overdrivr", "html_url": "https://github.com/Overdrivr", "followers_url": "https://api.github.com/users/Overdrivr/followers", "following_url": "https://api.github.com/users/Overdrivr/following{/other_user}", "gists_url": "https://api.github.com/users/Overdrivr/gists{/gist_id}", "starred_url": "https://api.github.com/users/Overdrivr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Overdrivr/subscriptions", "organizations_url": "https://api.github.com/users/Overdrivr/orgs", "repos_url": "https://api.github.com/users/Overdrivr/repos", "events_url": "https://api.github.com/users/Overdrivr/events{/privacy}", "received_events_url": "https://api.github.com/users/Overdrivr/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-10T14:03:20Z", "updated_at": "2018-04-10T14:03:20Z", "author_association": "NONE", "body_html": "<p>Here a simple program that allocates a large tensor filled with zeros:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> sys\n\namount <span class=\"pl-k\">=</span> <span class=\"pl-c1\">int</span>(sys.argv[<span class=\"pl-c1\">1</span>])\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Generating tensor with <span class=\"pl-c1\">{}</span> zeros<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> amount)\n_data <span class=\"pl-k\">=</span> np.zeros(amount <span class=\"pl-k\">*</span> (<span class=\"pl-c1\">1</span> <span class=\"pl-k\">&lt;&lt;</span> <span class=\"pl-c1\">20</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32)\n\ndata_init <span class=\"pl-k\">=</span> tf.placeholder(tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>_data.shape)\ndata <span class=\"pl-k\">=</span> tf.Variable(data_init, <span class=\"pl-v\">trainable</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">collections</span><span class=\"pl-k\">=</span>[])\na <span class=\"pl-k\">=</span> tf.contrib.memory_stats.MaxBytesInUse()\nb <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Completed successfully<span class=\"pl-pds\">'</span></span>)\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    <span class=\"pl-c1\">print</span>(sess.run([data.initializer, a, b], <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{data_init: _data}))</pre></div>\n<p>Generating <code>1200</code> or <code>1300</code> zeros works ok</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ python alloc.py 1200\n/home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from <span class=\"pl-s\"><span class=\"pl-pds\">`</span>float<span class=\"pl-pds\">`</span></span> to <span class=\"pl-s\"><span class=\"pl-pds\">`</span>np.floating<span class=\"pl-pds\">`</span></span> is deprecated. In future, it will be treated as <span class=\"pl-s\"><span class=\"pl-pds\">`</span>np.float64 == np.dtype(float).type<span class=\"pl-pds\">`</span></span>.\n  from ._conv import register_converters as _register_converters\nGenerating amount  1200\nWARNING:tensorflow:From /home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed <span class=\"pl-k\">in</span> a future version.\nInstructions <span class=\"pl-k\">for</span> updating:\nUse the retry module or similar alternatives.\n2018-04-10 13:59:20.700598: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-04-10 13:59:20.816981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node <span class=\"pl-c1\">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-04-10 13:59:20.817404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:04.0\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\n2018-04-10 13:59:20.892493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node <span class=\"pl-c1\">read</span> from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-04-10 13:59:20.892925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:05.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-04-10 13:59:20.892991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1\n2018-04-10 13:59:21.439399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-04-10 13:59:21.439464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 \n2018-04-10 13:59:21.439474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N N \n2018-04-10 13:59:21.439479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   N N \n2018-04-10 13:59:21.439977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10750 MB memory) -<span class=\"pl-k\">&gt;</span> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n2018-04-10 13:59:21.627795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10765 MB memory) -<span class=\"pl-k\">&gt;</span> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n[None, 1280, b<span class=\"pl-s\"><span class=\"pl-pds\">'</span>I ran OK<span class=\"pl-pds\">'</span></span>]</pre></div>\n<p>But as soon as I go over 1300 the allocation fails:</p>\n<pre><code>2018-04-10 13:58:38.000952: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.27GiB.  Current allocation summary follows.\n2018-04-10 13:58:38.001045: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001086: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001098: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n2018-04-10 13:58:38.001111: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001117: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001125: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001135: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001145: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001151: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001158: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001179: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001191: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001201: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001209: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001219: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001226: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001232: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001239: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001246: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001254: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001265: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 10.50GiB allocated for chunks. 5.27GiB in use in bin. 5.27GiB client-requested in use in bin.\n2018-04-10 13:58:38.001278: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 5.27GiB was 256.00MiB, Chunk State: \n2018-04-10 13:58:38.001293: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 5.22GiB | Requested Size: 0B | in_use: 0, prev:   Size: 5.27GiB | Requested Size: 5.27GiB | in_use: 1\n2018-04-10 13:58:38.001307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280000 of size 1280\n2018-04-10 13:58:38.001318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280500 of size 5662310400\n2018-04-10 13:58:38.001326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x85ba80500 of size 5610339072\n2018-04-10 13:58:38.001336: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \n2018-04-10 13:58:38.001346: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\n2018-04-10 13:58:38.001354: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5662310400 totalling 5.27GiB\n2018-04-10 13:58:38.001364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 5.27GiB\n2018-04-10 13:58:38.001376: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \nLimit:                 11272650752\nInUse:                  5662311680\nMaxInUse:               5662311680\nNumAllocs:                       2\nMaxAllocSize:           5662310400\n</code></pre>\n<p>In fact, it seems that the allocator is not even able to allocate half of available memory for a single GPU. Is there a maximum limit for single memory allocations ?</p>", "body_text": "Here a simple program that allocates a large tensor filled with zeros:\nimport numpy as np\nimport tensorflow as tf\nimport sys\n\namount = int(sys.argv[1])\nprint('Generating tensor with {} zeros' % amount)\n_data = np.zeros(amount * (1 << 20), dtype=np.float32)\n\ndata_init = tf.placeholder(tf.float32, shape=_data.shape)\ndata = tf.Variable(data_init, trainable=False, collections=[])\na = tf.contrib.memory_stats.MaxBytesInUse()\nb = tf.constant('Completed successfully')\n\nwith tf.Session() as sess:\n    print(sess.run([data.initializer, a, b], feed_dict={data_init: _data}))\nGenerating 1200 or 1300 zeros works ok\n$ python alloc.py 1200\n/home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nGenerating amount  1200\nWARNING:tensorflow:From /home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse the retry module or similar alternatives.\n2018-04-10 13:59:20.700598: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-04-10 13:59:20.816981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-04-10 13:59:20.817404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:04.0\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\n2018-04-10 13:59:20.892493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-04-10 13:59:20.892925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 0000:00:05.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2018-04-10 13:59:20.892991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1\n2018-04-10 13:59:21.439399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-04-10 13:59:21.439464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 \n2018-04-10 13:59:21.439474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N N \n2018-04-10 13:59:21.439479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   N N \n2018-04-10 13:59:21.439977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10750 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n2018-04-10 13:59:21.627795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10765 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n[None, 1280, b'I ran OK']\nBut as soon as I go over 1300 the allocation fails:\n2018-04-10 13:58:38.000952: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.27GiB.  Current allocation summary follows.\n2018-04-10 13:58:38.001045: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001086: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001098: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n2018-04-10 13:58:38.001111: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001117: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001125: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001135: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001145: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001151: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001158: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001179: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001191: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001201: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001209: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001219: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001226: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001232: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001239: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001246: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001254: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n2018-04-10 13:58:38.001265: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 10.50GiB allocated for chunks. 5.27GiB in use in bin. 5.27GiB client-requested in use in bin.\n2018-04-10 13:58:38.001278: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 5.27GiB was 256.00MiB, Chunk State: \n2018-04-10 13:58:38.001293: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 5.22GiB | Requested Size: 0B | in_use: 0, prev:   Size: 5.27GiB | Requested Size: 5.27GiB | in_use: 1\n2018-04-10 13:58:38.001307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280000 of size 1280\n2018-04-10 13:58:38.001318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280500 of size 5662310400\n2018-04-10 13:58:38.001326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x85ba80500 of size 5610339072\n2018-04-10 13:58:38.001336: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \n2018-04-10 13:58:38.001346: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\n2018-04-10 13:58:38.001354: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5662310400 totalling 5.27GiB\n2018-04-10 13:58:38.001364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 5.27GiB\n2018-04-10 13:58:38.001376: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \nLimit:                 11272650752\nInUse:                  5662311680\nMaxInUse:               5662311680\nNumAllocs:                       2\nMaxAllocSize:           5662310400\n\nIn fact, it seems that the allocator is not even able to allocate half of available memory for a single GPU. Is there a maximum limit for single memory allocations ?", "body": "Here a simple program that allocates a large tensor filled with zeros:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport sys\r\n\r\namount = int(sys.argv[1])\r\nprint('Generating tensor with {} zeros' % amount)\r\n_data = np.zeros(amount * (1 << 20), dtype=np.float32)\r\n\r\ndata_init = tf.placeholder(tf.float32, shape=_data.shape)\r\ndata = tf.Variable(data_init, trainable=False, collections=[])\r\na = tf.contrib.memory_stats.MaxBytesInUse()\r\nb = tf.constant('Completed successfully')\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run([data.initializer, a, b], feed_dict={data_init: _data}))\r\n```\r\n\r\nGenerating `1200` or `1300` zeros works ok\r\n\r\n```bash\r\n$ python alloc.py 1200\r\n/home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nGenerating amount  1200\r\nWARNING:tensorflow:From /home/remi_beges/.local/share/virtualenvs/analog-OR2zGvr-/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse the retry module or similar alternatives.\r\n2018-04-10 13:59:20.700598: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-04-10 13:59:20.816981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-04-10 13:59:20.817404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:04.0\r\ntotalMemory: 11.17GiB freeMemory: 11.09GiB\r\n2018-04-10 13:59:20.892493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-04-10 13:59:20.892925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:05.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-04-10 13:59:20.892991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1\r\n2018-04-10 13:59:21.439399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-04-10 13:59:21.439464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 \r\n2018-04-10 13:59:21.439474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N N \r\n2018-04-10 13:59:21.439479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   N N \r\n2018-04-10 13:59:21.439977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10750 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\r\n2018-04-10 13:59:21.627795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10765 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\r\n[None, 1280, b'I ran OK']\r\n```\r\n\r\nBut as soon as I go over 1300 the allocation fails:\r\n\r\n```\r\n2018-04-10 13:58:38.000952: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.27GiB.  Current allocation summary follows.\r\n2018-04-10 13:58:38.001045: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001086: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001098: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\r\n2018-04-10 13:58:38.001111: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001117: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001125: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001135: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001145: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001151: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001158: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001179: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001191: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001201: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001209: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001219: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001226: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001232: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001239: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001246: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001254: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-04-10 13:58:38.001265: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks: 2, Chunks in use: 1. 10.50GiB allocated for chunks. 5.27GiB in use in bin. 5.27GiB client-requested in use in bin.\r\n2018-04-10 13:58:38.001278: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 5.27GiB was 256.00MiB, Chunk State: \r\n2018-04-10 13:58:38.001293: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 5.22GiB | Requested Size: 0B | in_use: 0, prev:   Size: 5.27GiB | Requested Size: 5.27GiB | in_use: 1\r\n2018-04-10 13:58:38.001307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280000 of size 1280\r\n2018-04-10 13:58:38.001318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0x70a280500 of size 5662310400\r\n2018-04-10 13:58:38.001326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0x85ba80500 of size 5610339072\r\n2018-04-10 13:58:38.001336: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by size: \r\n2018-04-10 13:58:38.001346: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.2KiB\r\n2018-04-10 13:58:38.001354: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5662310400 totalling 5.27GiB\r\n2018-04-10 13:58:38.001364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 5.27GiB\r\n2018-04-10 13:58:38.001376: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats: \r\nLimit:                 11272650752\r\nInUse:                  5662311680\r\nMaxInUse:               5662311680\r\nNumAllocs:                       2\r\nMaxAllocSize:           5662310400\r\n```\r\n\r\nIn fact, it seems that the allocator is not even able to allocate half of available memory for a single GPU. Is there a maximum limit for single memory allocations ?\r\n"}