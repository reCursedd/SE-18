{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/381215284", "html_url": "https://github.com/tensorflow/tensorflow/issues/18380#issuecomment-381215284", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18380", "id": 381215284, "node_id": "MDEyOklzc3VlQ29tbWVudDM4MTIxNTI4NA==", "user": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-13T17:59:18Z", "updated_at": "2018-04-13T17:59:18Z", "author_association": "MEMBER", "body_html": "<p>For the short example you posted, my guess is that when you initialize a Variable with a <code>tf.placeholder</code> fed with a feed dict, you need to allocate memory both for the Variable data and the <code>tf.placeholder</code>, requiring double the memory as what just the Variable requires. (<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> can you confirm this fact?)</p>\n<blockquote>\n<p>The memory Limit displayed by the error log accounts for the VRAM of a single GPU (12GB), while I was expecting to account both (24GB):</p>\n</blockquote>\n<p>Note that the limit is supposed to show only a single GPU. Each GPU has it's own memory, and ops assigned to that GPU will use that GPU's memory. If there is not enough memory on a GPU to run all the ops assigned to that GPU, you will get an OOM even if there is memory left on the other GPU.</p>\n<p>In your case, I would guess either you are running all/most your ops on GPU:0, or both GPUs would run out of memory and GPU:0 happens to run out of memory first.</p>", "body_text": "For the short example you posted, my guess is that when you initialize a Variable with a tf.placeholder fed with a feed dict, you need to allocate memory both for the Variable data and the tf.placeholder, requiring double the memory as what just the Variable requires. (@mrry can you confirm this fact?)\n\nThe memory Limit displayed by the error log accounts for the VRAM of a single GPU (12GB), while I was expecting to account both (24GB):\n\nNote that the limit is supposed to show only a single GPU. Each GPU has it's own memory, and ops assigned to that GPU will use that GPU's memory. If there is not enough memory on a GPU to run all the ops assigned to that GPU, you will get an OOM even if there is memory left on the other GPU.\nIn your case, I would guess either you are running all/most your ops on GPU:0, or both GPUs would run out of memory and GPU:0 happens to run out of memory first.", "body": "For the short example you posted, my guess is that when you initialize a Variable with a `tf.placeholder` fed with a feed dict, you need to allocate memory both for the Variable data and the `tf.placeholder`, requiring double the memory as what just the Variable requires. (@mrry can you confirm this fact?)\r\n\r\n>The memory Limit displayed by the error log accounts for the VRAM of a single GPU (12GB), while I was expecting to account both (24GB):\r\n\r\nNote that the limit is supposed to show only a single GPU. Each GPU has it's own memory, and ops assigned to that GPU will use that GPU's memory. If there is not enough memory on a GPU to run all the ops assigned to that GPU, you will get an OOM even if there is memory left on the other GPU.\r\n\r\nIn your case, I would guess either you are running all/most your ops on GPU:0, or both GPUs would run out of memory and GPU:0 happens to run out of memory first.\r\n"}