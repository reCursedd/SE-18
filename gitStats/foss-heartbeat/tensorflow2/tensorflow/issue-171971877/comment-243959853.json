{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/243959853", "html_url": "https://github.com/tensorflow/tensorflow/issues/3907#issuecomment-243959853", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3907", "id": 243959853, "node_id": "MDEyOklzc3VlQ29tbWVudDI0Mzk1OTg1Mw==", "user": {"login": "pfllo", "id": 5235521, "node_id": "MDQ6VXNlcjUyMzU1MjE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5235521?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pfllo", "html_url": "https://github.com/pfllo", "followers_url": "https://api.github.com/users/pfllo/followers", "following_url": "https://api.github.com/users/pfllo/following{/other_user}", "gists_url": "https://api.github.com/users/pfllo/gists{/gist_id}", "starred_url": "https://api.github.com/users/pfllo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pfllo/subscriptions", "organizations_url": "https://api.github.com/users/pfllo/orgs", "repos_url": "https://api.github.com/users/pfllo/repos", "events_url": "https://api.github.com/users/pfllo/events{/privacy}", "received_events_url": "https://api.github.com/users/pfllo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-01T02:37:04Z", "updated_at": "2016-09-01T02:39:21Z", "author_association": "NONE", "body_html": "<p>This feature is also needed when accumulating gradients.</p>\n<p>I want to accumulate the gradients of word embeddings over several iterations and update them together afterwards. Without sparse variable support, I can only initialize a huge zero tensor with the same size as the word embedding matrix first, accumulate the gradients with it and tf.assign_add this huge tensor to the word embedding matrix, which is very inefficient.</p>\n<p>Does anyone have some workarounds for this kind of things?</p>", "body_text": "This feature is also needed when accumulating gradients.\nI want to accumulate the gradients of word embeddings over several iterations and update them together afterwards. Without sparse variable support, I can only initialize a huge zero tensor with the same size as the word embedding matrix first, accumulate the gradients with it and tf.assign_add this huge tensor to the word embedding matrix, which is very inefficient.\nDoes anyone have some workarounds for this kind of things?", "body": "This feature is also needed when accumulating gradients. \n\nI want to accumulate the gradients of word embeddings over several iterations and update them together afterwards. Without sparse variable support, I can only initialize a huge zero tensor with the same size as the word embedding matrix first, accumulate the gradients with it and tf.assign_add this huge tensor to the word embedding matrix, which is very inefficient.\n\nDoes anyone have some workarounds for this kind of things?\n"}