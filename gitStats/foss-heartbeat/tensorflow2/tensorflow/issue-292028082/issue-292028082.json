{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16468", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16468/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16468/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16468/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16468", "id": 292028082, "node_id": "MDU6SXNzdWUyOTIwMjgwODI=", "number": 16468, "title": "Keras multi input and estimator", "user": {"login": "bhack", "id": 1710528, "node_id": "MDQ6VXNlcjE3MTA1Mjg=", "avatar_url": "https://avatars0.githubusercontent.com/u/1710528?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bhack", "html_url": "https://github.com/bhack", "followers_url": "https://api.github.com/users/bhack/followers", "following_url": "https://api.github.com/users/bhack/following{/other_user}", "gists_url": "https://api.github.com/users/bhack/gists{/gist_id}", "starred_url": "https://api.github.com/users/bhack/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bhack/subscriptions", "organizations_url": "https://api.github.com/users/bhack/orgs", "repos_url": "https://api.github.com/users/bhack/repos", "events_url": "https://api.github.com/users/bhack/events{/privacy}", "received_events_url": "https://api.github.com/users/bhack/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "open", "locked": false, "assignee": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 29, "created_at": "2018-01-26T20:52:39Z", "updated_at": "2018-11-19T23:24:43Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p>If I've interpreted it correctly seems that there is some strange behavior with Keras multi inputs and the estimator.</p>\n<ul>\n<li>Why input layers are renamed with <code>_1</code> suffix?</li>\n<li>Why TB display a <code>_2</code> suffixed parallel sub-graph?</li>\n</ul>\n<p>I've attached a snippet runnable on <a href=\"http://colab.research.google.com/\" rel=\"nofollow\">colab</a> and the TB rendered image.</p>\n<pre lang=\"import\" data-meta=\"tensorflow as tf\"><code>from tensorflow import keras as ks\nimport numpy as np\nfrom IPython.display import clear_output, Image, display, HTML\n\ndef strip_consts(graph_def, max_const_size=32):\n    \"\"\"Strip large constant values from graph_def.\"\"\"\n    strip_def = tf.GraphDef()\n    for n0 in graph_def.node:\n        n = strip_def.node.add() \n        n.MergeFrom(n0)\n        if n.op == 'Const':\n            tensor = n.attr['value'].tensor\n            size = len(tensor.tensor_content)\n            if size &gt; max_const_size:\n                tensor.tensor_content = \"&lt;stripped %d bytes&gt;\"%size\n    return strip_def\n\ndef show_graph(graph_def, max_const_size=32):\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    if hasattr(graph_def, 'as_graph_def'):\n        graph_def = graph_def.as_graph_def()\n    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n    code = \"\"\"\n        &lt;script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"&gt;&lt;/script&gt;\n        &lt;script&gt;\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        &lt;/script&gt;\n        &lt;link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()&gt;\n        &lt;div style=\"height:600px\"&gt;\n          &lt;tf-graph-basic id=\"{id}\"&gt;&lt;/tf-graph-basic&gt;\n        &lt;/div&gt;\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n\n    iframe = \"\"\"\n        &lt;iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"&gt;&lt;/iframe&gt;\n    \"\"\".format(code.replace('\"', '&amp;quot;'))\n    display(HTML(iframe))\n\nclass ExampleHook(tf.train.SessionRunHook):\n    def __init__(self):\n        print('Starting the session.')\n        return\n\n    def begin(self):\n        g = tf.get_default_graph()\n        show_graph(g)\n        print('Starting the session.')\n        \n        #for op in tf.get_default_graph().get_operations():\n          #print(str(op.name) )\n        \nmy_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"input_rgb\": np.array(np.random.rand(5,5,3).astype(np.float32)), \"input_gray\": np.array(np.random.rand(5,5,1).astype(np.float32)), \n       \"input_mix\": np.array(np.random.rand(5,5,1).astype(np.float32))},\n    y= np.array(np.random.rand(5,5,1)),\n      batch_size=1,\n      num_epochs=1,\n      shuffle=False)\n\ninput_rgb = ks.layers.Input(shape=(1,5, 5, 3), name=\"input_rgb\")\ninput_gray = ks.layers.Input(shape=(1,5, 5, 1), name=\"input_gray\")\ninput_mix = ks.layers.Input(shape=(1,5, 5, 1), name=\"input_mix\")\nrgb_gray = ks.layers.concatenate([input_rgb, input_gray, input_mix], name=\"rbg_gray\")\nx = ks.layers.Dense(1, activation='relu',name=\"Dense_1\")(rgb_gray)\nx = ks.layers.Dense(1, activation='softmax',name=\"softmax\")(x)\nmodel = ks.models.Model(\n        inputs=[input_rgb, input_gray, input_mix],\n        outputs=[x])\nmodel.compile(loss={ 'softmax': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())\n\n\nest = ks.estimator.model_to_estimator(\n            keras_model=model)\n\nmodel.summary()\nprint(model.input_names)\npred = list(est.predict(\n    input_fn=my_input_fn,\n    predict_keys=None,\n    hooks=[ExampleHook()],\n))\n</code></pre>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1710528/35459923-5eca90b8-02e2-11e8-8248-764671141850.png\"><img src=\"https://user-images.githubusercontent.com/1710528/35459923-5eca90b8-02e2-11e8-8248-764671141850.png\" alt=\"tb\" style=\"max-width:100%;\"></a></p>", "body_text": "If I've interpreted it correctly seems that there is some strange behavior with Keras multi inputs and the estimator.\n\nWhy input layers are renamed with _1 suffix?\nWhy TB display a _2 suffixed parallel sub-graph?\n\nI've attached a snippet runnable on colab and the TB rendered image.\nfrom tensorflow import keras as ks\nimport numpy as np\nfrom IPython.display import clear_output, Image, display, HTML\n\ndef strip_consts(graph_def, max_const_size=32):\n    \"\"\"Strip large constant values from graph_def.\"\"\"\n    strip_def = tf.GraphDef()\n    for n0 in graph_def.node:\n        n = strip_def.node.add() \n        n.MergeFrom(n0)\n        if n.op == 'Const':\n            tensor = n.attr['value'].tensor\n            size = len(tensor.tensor_content)\n            if size > max_const_size:\n                tensor.tensor_content = \"<stripped %d bytes>\"%size\n    return strip_def\n\ndef show_graph(graph_def, max_const_size=32):\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    if hasattr(graph_def, 'as_graph_def'):\n        graph_def = graph_def.as_graph_def()\n    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n    code = \"\"\"\n        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n        <script>\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        </script>\n        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n        <div style=\"height:600px\">\n          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n        </div>\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n\n    iframe = \"\"\"\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n    \"\"\".format(code.replace('\"', '&quot;'))\n    display(HTML(iframe))\n\nclass ExampleHook(tf.train.SessionRunHook):\n    def __init__(self):\n        print('Starting the session.')\n        return\n\n    def begin(self):\n        g = tf.get_default_graph()\n        show_graph(g)\n        print('Starting the session.')\n        \n        #for op in tf.get_default_graph().get_operations():\n          #print(str(op.name) )\n        \nmy_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"input_rgb\": np.array(np.random.rand(5,5,3).astype(np.float32)), \"input_gray\": np.array(np.random.rand(5,5,1).astype(np.float32)), \n       \"input_mix\": np.array(np.random.rand(5,5,1).astype(np.float32))},\n    y= np.array(np.random.rand(5,5,1)),\n      batch_size=1,\n      num_epochs=1,\n      shuffle=False)\n\ninput_rgb = ks.layers.Input(shape=(1,5, 5, 3), name=\"input_rgb\")\ninput_gray = ks.layers.Input(shape=(1,5, 5, 1), name=\"input_gray\")\ninput_mix = ks.layers.Input(shape=(1,5, 5, 1), name=\"input_mix\")\nrgb_gray = ks.layers.concatenate([input_rgb, input_gray, input_mix], name=\"rbg_gray\")\nx = ks.layers.Dense(1, activation='relu',name=\"Dense_1\")(rgb_gray)\nx = ks.layers.Dense(1, activation='softmax',name=\"softmax\")(x)\nmodel = ks.models.Model(\n        inputs=[input_rgb, input_gray, input_mix],\n        outputs=[x])\nmodel.compile(loss={ 'softmax': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())\n\n\nest = ks.estimator.model_to_estimator(\n            keras_model=model)\n\nmodel.summary()\nprint(model.input_names)\npred = list(est.predict(\n    input_fn=my_input_fn,\n    predict_keys=None,\n    hooks=[ExampleHook()],\n))", "body": "If I've interpreted it correctly seems that there is some strange behavior with Keras multi inputs and the estimator.\r\n\r\n- Why input layers are renamed with `_1` suffix?\r\n- Why TB display a `_2` suffixed parallel sub-graph?\r\n\r\nI've attached a snippet runnable on [colab](http://colab.research.google.com/) and the TB rendered image.\r\n\r\n \r\n```import tensorflow as tf\r\nfrom tensorflow import keras as ks\r\nimport numpy as np\r\nfrom IPython.display import clear_output, Image, display, HTML\r\n\r\ndef strip_consts(graph_def, max_const_size=32):\r\n    \"\"\"Strip large constant values from graph_def.\"\"\"\r\n    strip_def = tf.GraphDef()\r\n    for n0 in graph_def.node:\r\n        n = strip_def.node.add() \r\n        n.MergeFrom(n0)\r\n        if n.op == 'Const':\r\n            tensor = n.attr['value'].tensor\r\n            size = len(tensor.tensor_content)\r\n            if size > max_const_size:\r\n                tensor.tensor_content = \"<stripped %d bytes>\"%size\r\n    return strip_def\r\n\r\ndef show_graph(graph_def, max_const_size=32):\r\n    \"\"\"Visualize TensorFlow graph.\"\"\"\r\n    if hasattr(graph_def, 'as_graph_def'):\r\n        graph_def = graph_def.as_graph_def()\r\n    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\r\n    code = \"\"\"\r\n        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\r\n        <script>\r\n          function load() {{\r\n            document.getElementById(\"{id}\").pbtxt = {data};\r\n          }}\r\n        </script>\r\n        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\r\n        <div style=\"height:600px\">\r\n          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\r\n        </div>\r\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\r\n\r\n    iframe = \"\"\"\r\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\r\n    \"\"\".format(code.replace('\"', '&quot;'))\r\n    display(HTML(iframe))\r\n\r\nclass ExampleHook(tf.train.SessionRunHook):\r\n    def __init__(self):\r\n        print('Starting the session.')\r\n        return\r\n\r\n    def begin(self):\r\n        g = tf.get_default_graph()\r\n        show_graph(g)\r\n        print('Starting the session.')\r\n        \r\n        #for op in tf.get_default_graph().get_operations():\r\n          #print(str(op.name) )\r\n        \r\nmy_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"input_rgb\": np.array(np.random.rand(5,5,3).astype(np.float32)), \"input_gray\": np.array(np.random.rand(5,5,1).astype(np.float32)), \r\n       \"input_mix\": np.array(np.random.rand(5,5,1).astype(np.float32))},\r\n    y= np.array(np.random.rand(5,5,1)),\r\n      batch_size=1,\r\n      num_epochs=1,\r\n      shuffle=False)\r\n\r\ninput_rgb = ks.layers.Input(shape=(1,5, 5, 3), name=\"input_rgb\")\r\ninput_gray = ks.layers.Input(shape=(1,5, 5, 1), name=\"input_gray\")\r\ninput_mix = ks.layers.Input(shape=(1,5, 5, 1), name=\"input_mix\")\r\nrgb_gray = ks.layers.concatenate([input_rgb, input_gray, input_mix], name=\"rbg_gray\")\r\nx = ks.layers.Dense(1, activation='relu',name=\"Dense_1\")(rgb_gray)\r\nx = ks.layers.Dense(1, activation='softmax',name=\"softmax\")(x)\r\nmodel = ks.models.Model(\r\n        inputs=[input_rgb, input_gray, input_mix],\r\n        outputs=[x])\r\nmodel.compile(loss={ 'softmax': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())\r\n\r\n\r\nest = ks.estimator.model_to_estimator(\r\n            keras_model=model)\r\n\r\nmodel.summary()\r\nprint(model.input_names)\r\npred = list(est.predict(\r\n    input_fn=my_input_fn,\r\n    predict_keys=None,\r\n    hooks=[ExampleHook()],\r\n))\r\n```\r\n![tb](https://user-images.githubusercontent.com/1710528/35459923-5eca90b8-02e2-11e8-8248-764671141850.png)"}