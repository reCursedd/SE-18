{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20606", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20606/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20606/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20606/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20606", "id": 339106614, "node_id": "MDU6SXNzdWUzMzkxMDY2MTQ=", "number": 20606, "title": "[bug] events.out.tfevents files do not get closed.", "user": {"login": "renxida", "id": 10362952, "node_id": "MDQ6VXNlcjEwMzYyOTUy", "avatar_url": "https://avatars3.githubusercontent.com/u/10362952?v=4", "gravatar_id": "", "url": "https://api.github.com/users/renxida", "html_url": "https://github.com/renxida", "followers_url": "https://api.github.com/users/renxida/followers", "following_url": "https://api.github.com/users/renxida/following{/other_user}", "gists_url": "https://api.github.com/users/renxida/gists{/gist_id}", "starred_url": "https://api.github.com/users/renxida/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/renxida/subscriptions", "organizations_url": "https://api.github.com/users/renxida/orgs", "repos_url": "https://api.github.com/users/renxida/repos", "events_url": "https://api.github.com/users/renxida/events{/privacy}", "received_events_url": "https://api.github.com/users/renxida/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, {"login": "nfelt", "id": 710113, "node_id": "MDQ6VXNlcjcxMDExMw==", "avatar_url": "https://avatars0.githubusercontent.com/u/710113?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nfelt", "html_url": "https://github.com/nfelt", "followers_url": "https://api.github.com/users/nfelt/followers", "following_url": "https://api.github.com/users/nfelt/following{/other_user}", "gists_url": "https://api.github.com/users/nfelt/gists{/gist_id}", "starred_url": "https://api.github.com/users/nfelt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nfelt/subscriptions", "organizations_url": "https://api.github.com/users/nfelt/orgs", "repos_url": "https://api.github.com/users/nfelt/repos", "events_url": "https://api.github.com/users/nfelt/events{/privacy}", "received_events_url": "https://api.github.com/users/nfelt/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-07-07T01:25:31Z", "updated_at": "2018-11-14T19:22:16Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>Running a python script that trains and tests MANY models (tf.Estimator) failes with</p>\n<pre><code>tf.estimator Error: ResourceExhausted: too many open files (TF keeps events.out.tfevents files open)\n</code></pre>\n<p>Stackoverflow question &amp; proposed solution (by another person): <a href=\"https://stackoverflow.com/questions/50956551/tf-estimator-error-resourceexhausted-too-many-open-files-tf-keeps-events-out\" rel=\"nofollow\">https://stackoverflow.com/questions/50956551/tf-estimator-error-resourceexhausted-too-many-open-files-tf-keeps-events-out</a></p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 1604</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Source</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n== cat /etc/issue ===============================================<br>\nLinux gpubox1 4.4.0-128-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116433852\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/154\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/154/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/154\">#154</a>-Ubuntu SMP Fri May 25 14:15:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</li>\n</ul>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux gpubox1 4.4.0-128-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116433852\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/154\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/154/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/154\">#154</a>-Ubuntu SMP Fri May 25 14:15:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy                              1.14.3<br>\nnumpydoc                           0.8.0<br>\nprotobuf                           3.6.0<br>\ntensorflow                         1.9.0rc0</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.9.0-rc0<br>\ntf.GIT_VERSION = b'v1.8.0-3463-g39ea5a7'<br>\ntf.COMPILER_VERSION = b'v1.8.0-3463-g39ea5a7'<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH is unset<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nFri Jul  6 21:20:55 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |<br>\n| 42%   61C    P2    63W / 250W |  10664MiB / 11175MiB |     24%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |<br>\n| 29%   44C    P2    56W / 250W |  10631MiB / 11178MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0      1092      G   /usr/lib/xorg/Xorg                            89MiB |<br>\n|    0     19389      C   python                                     10563MiB |<br>\n|    1     19389      C   python                                     10619MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176<br>\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a</p>\n<ul>\n<li>\n<p><strong>Bazel ver:</strong> NA</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN</strong>: 9.0 / 7.1</p>\n</li>\n<li>\n<p><strong>GPU</strong>: NVIDIA 1080 Ti</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>: N/A; Running  <code>tf.Estimator.train </code> for some 1000 different estimators reproduces the problem.</p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Each tensorflow run does not close events.out.tfevent. Instead, they remain open, and eventually stops the process because there are too many open file handles.</p>\n<h3>Source code / logs</h3>\n<p>I'll do that on request</p>", "body_text": "Running a python script that trains and tests MANY models (tf.Estimator) failes with\ntf.estimator Error: ResourceExhausted: too many open files (TF keeps events.out.tfevents files open)\n\nStackoverflow question & proposed solution (by another person): https://stackoverflow.com/questions/50956551/tf-estimator-error-resourceexhausted-too-many-open-files-tf-keeps-events-out\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 1604\nTensorFlow installed from (source or binary): Source\nTensorFlow version (use command below):\n== cat /etc/issue ===============================================\nLinux gpubox1 4.4.0-128-generic #154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux gpubox1 4.4.0-128-generic #154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy                              1.14.3\nnumpydoc                           0.8.0\nprotobuf                           3.6.0\ntensorflow                         1.9.0rc0\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.9.0-rc0\ntf.GIT_VERSION = b'v1.8.0-3463-g39ea5a7'\ntf.COMPILER_VERSION = b'v1.8.0-3463-g39ea5a7'\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nFri Jul  6 21:20:55 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\n| 42%   61C    P2    63W / 250W |  10664MiB / 11175MiB |     24%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n| 29%   44C    P2    56W / 250W |  10631MiB / 11178MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      1092      G   /usr/lib/xorg/Xorg                            89MiB |\n|    0     19389      C   python                                     10563MiB |\n|    1     19389      C   python                                     10619MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\n\n\nBazel ver: NA\n\n\nCUDA/cuDNN: 9.0 / 7.1\n\n\nGPU: NVIDIA 1080 Ti\n\n\nExact command to reproduce: N/A; Running  tf.Estimator.train  for some 1000 different estimators reproduces the problem.\n\n\nDescribe the problem\nEach tensorflow run does not close events.out.tfevent. Instead, they remain open, and eventually stops the process because there are too many open file handles.\nSource code / logs\nI'll do that on request", "body": "Running a python script that trains and tests MANY models (tf.Estimator) failes with\r\n```\r\ntf.estimator Error: ResourceExhausted: too many open files (TF keeps events.out.tfevents files open)\r\n```\r\n\r\nStackoverflow question & proposed solution (by another person): https://stackoverflow.com/questions/50956551/tf-estimator-error-resourceexhausted-too-many-open-files-tf-keeps-events-out\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 1604\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: \r\n== cat /etc/issue ===============================================\r\nLinux gpubox1 4.4.0-128-generic #154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux gpubox1 4.4.0-128-generic #154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.3   \r\nnumpydoc                           0.8.0    \r\nprotobuf                           3.6.0    \r\ntensorflow                         1.9.0rc0 \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.9.0-rc0\r\ntf.GIT_VERSION = b'v1.8.0-3463-g39ea5a7'\r\ntf.COMPILER_VERSION = b'v1.8.0-3463-g39ea5a7'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri Jul  6 21:20:55 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n| 42%   61C    P2    63W / 250W |  10664MiB / 11175MiB |     24%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n| 29%   44C    P2    56W / 250W |  10631MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1092      G   /usr/lib/xorg/Xorg                            89MiB |\r\n|    0     19389      C   python                                     10563MiB |\r\n|    1     19389      C   python                                     10619MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\r\n- **Bazel ver:** NA\r\n- **CUDA/cuDNN**: 9.0 / 7.1\r\n- **GPU**: NVIDIA 1080 Ti\r\n\r\n- **Exact command to reproduce**: N/A; Running  `tf.Estimator.train ` for some 1000 different estimators reproduces the problem.\r\n\r\n### Describe the problem\r\nEach tensorflow run does not close events.out.tfevent. Instead, they remain open, and eventually stops the process because there are too many open file handles.\r\n\r\n### Source code / logs\r\nI'll do that on request\r\n\r\n"}