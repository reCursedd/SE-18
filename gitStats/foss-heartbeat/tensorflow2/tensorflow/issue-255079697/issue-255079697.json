{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12799", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12799/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12799/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12799/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12799", "id": 255079697, "node_id": "MDU6SXNzdWUyNTUwNzk2OTc=", "number": 12799, "title": "problem with optimize_for_inference", "user": {"login": "kollapsderwellenfunktion", "id": 11195352, "node_id": "MDQ6VXNlcjExMTk1MzUy", "avatar_url": "https://avatars0.githubusercontent.com/u/11195352?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kollapsderwellenfunktion", "html_url": "https://github.com/kollapsderwellenfunktion", "followers_url": "https://api.github.com/users/kollapsderwellenfunktion/followers", "following_url": "https://api.github.com/users/kollapsderwellenfunktion/following{/other_user}", "gists_url": "https://api.github.com/users/kollapsderwellenfunktion/gists{/gist_id}", "starred_url": "https://api.github.com/users/kollapsderwellenfunktion/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kollapsderwellenfunktion/subscriptions", "organizations_url": "https://api.github.com/users/kollapsderwellenfunktion/orgs", "repos_url": "https://api.github.com/users/kollapsderwellenfunktion/repos", "events_url": "https://api.github.com/users/kollapsderwellenfunktion/events{/privacy}", "received_events_url": "https://api.github.com/users/kollapsderwellenfunktion/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2017-09-04T16:02:39Z", "updated_at": "2018-09-15T18:39:10Z", "closed_at": "2017-09-06T11:48:17Z", "author_association": "NONE", "body_html": "<p>hi,<br>\nI'm using tensorflow 1.3.0 installed via pip with python 2.7.12 (Ubuntu 16.04, cuda 8, nvidia 1060)</p>\n<p>when i try to optimize a custom model trained with tensorflow 1.3.0 with</p>\n<p><code>python -m tensorflow.python.tools.optimize_for_inference --input saved_model.pb --output opt_model.pb --input_names=in --output_names=out</code></p>\n<p>i get the following error:</p>\n<pre><code>Traceback (most recent call last):\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in &lt;module&gt;\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/**********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\n    input_graph_def.ParseFromString(data)\n  File \"/home/***********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/message.py\", line 185, in ParseFromString\n    self.MergeFromString(serialized)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1069, in MergeFromString\n    if self._InternalParse(serialized, 0, length) != length:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 633, in DecodeField\n    if value._InternalParse(buffer, pos, new_pos) != new_pos:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 612, in DecodeRepeatedField\n    if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 743, in DecodeMap\n    if submsg._InternalParse(buffer, pos, new_pos) != new_pos:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1095, in InternalParse\n    new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 799, in _SkipGroup\n    new_pos = SkipField(buffer, pos, end, tag_bytes)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 814, in _SkipFixed32\n    raise _DecodeError('Truncated message.')\ngoogle.protobuf.message.DecodeError: Truncated message.\n</code></pre>\n<p>i already did a ' export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python'<br>\nwithout doing it i got</p>\n<pre><code>Traceback (most recent call last):\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in &lt;module&gt;\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\n    input_graph_def.ParseFromString(data)\ngoogle.protobuf.message.DecodeError: Error parsing message\n</code></pre>\n<p>I'm saving the model like:</p>\n<pre><code>builder = saved_model_builder.SavedModelBuilder(\"model\"))\nbuilder.add_meta_graph_and_variables(sess,['serve'],signature_def_map= {\"model\": tf.saved_model.signature_def_utils.predict_signature_def(inputs= {\"in\" : X }, outputs= {\"out\": pred_Y })})\nbuilder.save()\n</code></pre>\n<p>i had the same issue with 1.2.1, after this i did the upgrade to 1.3.0 via pip install --upgrade and a retrain.</p>\n<p>i have no issues loading and using the model with tensorflow-rust in my test application, but to add some context i got the error</p>\n<pre><code>Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef \nat  org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392) at org.tensorflow.contrib.android.TensorFlowInferenceInterface.&lt;init&gt;(TensorFlowInferenceInterface.java:96)\n</code></pre>\n<p>when trying to load the model with tensorflow on android. first i thought this would be because of some unsupported ops, so i went the optimize_for_inference way. but i guess it looks like a protobuf issue</p>\n<p>i would appreciate any hint to solve this issue.<br>\nwith best regards</p>", "body_text": "hi,\nI'm using tensorflow 1.3.0 installed via pip with python 2.7.12 (Ubuntu 16.04, cuda 8, nvidia 1060)\nwhen i try to optimize a custom model trained with tensorflow 1.3.0 with\npython -m tensorflow.python.tools.optimize_for_inference --input saved_model.pb --output opt_model.pb --input_names=in --output_names=out\ni get the following error:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in <module>\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/**********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\n    input_graph_def.ParseFromString(data)\n  File \"/home/***********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/message.py\", line 185, in ParseFromString\n    self.MergeFromString(serialized)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1069, in MergeFromString\n    if self._InternalParse(serialized, 0, length) != length:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 633, in DecodeField\n    if value._InternalParse(buffer, pos, new_pos) != new_pos:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 612, in DecodeRepeatedField\n    if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 743, in DecodeMap\n    if submsg._InternalParse(buffer, pos, new_pos) != new_pos:\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1095, in InternalParse\n    new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 799, in _SkipGroup\n    new_pos = SkipField(buffer, pos, end, tag_bytes)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 814, in _SkipFixed32\n    raise _DecodeError('Truncated message.')\ngoogle.protobuf.message.DecodeError: Truncated message.\n\ni already did a ' export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python'\nwithout doing it i got\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in <module>\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\n    input_graph_def.ParseFromString(data)\ngoogle.protobuf.message.DecodeError: Error parsing message\n\nI'm saving the model like:\nbuilder = saved_model_builder.SavedModelBuilder(\"model\"))\nbuilder.add_meta_graph_and_variables(sess,['serve'],signature_def_map= {\"model\": tf.saved_model.signature_def_utils.predict_signature_def(inputs= {\"in\" : X }, outputs= {\"out\": pred_Y })})\nbuilder.save()\n\ni had the same issue with 1.2.1, after this i did the upgrade to 1.3.0 via pip install --upgrade and a retrain.\ni have no issues loading and using the model with tensorflow-rust in my test application, but to add some context i got the error\nCaused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef \nat  org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392) at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)\n\nwhen trying to load the model with tensorflow on android. first i thought this would be because of some unsupported ops, so i went the optimize_for_inference way. but i guess it looks like a protobuf issue\ni would appreciate any hint to solve this issue.\nwith best regards", "body": "hi,\r\nI'm using tensorflow 1.3.0 installed via pip with python 2.7.12 (Ubuntu 16.04, cuda 8, nvidia 1060)\r\n\r\nwhen i try to optimize a custom model trained with tensorflow 1.3.0 with \r\n\r\n`python -m tensorflow.python.tools.optimize_for_inference --input saved_model.pb --output opt_model.pb --input_names=in --output_names=out`\r\n\r\ni get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/**********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\r\n    input_graph_def.ParseFromString(data)\r\n  File \"/home/***********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/message.py\", line 185, in ParseFromString\r\n    self.MergeFromString(serialized)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1069, in MergeFromString\r\n    if self._InternalParse(serialized, 0, length) != length:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 633, in DecodeField\r\n    if value._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 612, in DecodeRepeatedField\r\n    if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1105, in InternalParse\r\n    pos = field_decoder(buffer, new_pos, end, self, field_dict)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 743, in DecodeMap\r\n    if submsg._InternalParse(buffer, pos, new_pos) != new_pos:\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/python_message.py\", line 1095, in InternalParse\r\n    new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 799, in _SkipGroup\r\n    new_pos = SkipField(buffer, pos, end, tag_bytes)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/google/protobuf/internal/decoder.py\", line 814, in _SkipFixed32\r\n    raise _DecodeError('Truncated message.')\r\ngoogle.protobuf.message.DecodeError: Truncated message.\r\n```\r\n\r\n\r\ni already did a ' export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python'\r\nwithout doing it i got\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 146, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/*********/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/*********/tensorflow/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference.py\", line 83, in main\r\n    input_graph_def.ParseFromString(data)\r\ngoogle.protobuf.message.DecodeError: Error parsing message\r\n```\r\n\r\nI'm saving the model like:\r\n\r\n```\r\nbuilder = saved_model_builder.SavedModelBuilder(\"model\"))\r\nbuilder.add_meta_graph_and_variables(sess,['serve'],signature_def_map= {\"model\": tf.saved_model.signature_def_utils.predict_signature_def(inputs= {\"in\" : X }, outputs= {\"out\": pred_Y })})\r\nbuilder.save()\r\n```\r\n\r\ni had the same issue with 1.2.1, after this i did the upgrade to 1.3.0 via pip install --upgrade and a retrain.\r\n\r\ni have no issues loading and using the model with tensorflow-rust in my test application, but to add some context i got the error\r\n\r\n```\r\nCaused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef \r\nat  org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392) at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)\r\n```\r\n\r\nwhen trying to load the model with tensorflow on android. first i thought this would be because of some unsupported ops, so i went the optimize_for_inference way. but i guess it looks like a protobuf issue\r\n \r\ni would appreciate any hint to solve this issue.\r\nwith best regards\r\n\r\n"}