{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/342342748", "html_url": "https://github.com/tensorflow/tensorflow/issues/12937#issuecomment-342342748", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12937", "id": 342342748, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MjM0Mjc0OA==", "user": {"login": "kelvinxu", "id": 5659116, "node_id": "MDQ6VXNlcjU2NTkxMTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/5659116?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kelvinxu", "html_url": "https://github.com/kelvinxu", "followers_url": "https://api.github.com/users/kelvinxu/followers", "following_url": "https://api.github.com/users/kelvinxu/following{/other_user}", "gists_url": "https://api.github.com/users/kelvinxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/kelvinxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kelvinxu/subscriptions", "organizations_url": "https://api.github.com/users/kelvinxu/orgs", "repos_url": "https://api.github.com/users/kelvinxu/repos", "events_url": "https://api.github.com/users/kelvinxu/events{/privacy}", "received_events_url": "https://api.github.com/users/kelvinxu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-07T01:13:18Z", "updated_at": "2017-11-07T01:13:18Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=88808\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/skye\">@skye</a>  I encountered something similar when running tf.map_fn where the function was a neural network that did a bunch of gradient steps. The inputs were just slices of a minibatch.</p>\n<p>Basically this: <a href=\"https://github.com/cbfinn/maml/blob/master/maml.py#L78\">https://github.com/cbfinn/maml/blob/master/maml.py#L78</a></p>\n<p>I noticed that on CPU, there was parallelization, but on GPU no. Might there be a reason for this?</p>\n<p>It seems like the post here was not the same issue.</p>", "body_text": "Hi @skye  I encountered something similar when running tf.map_fn where the function was a neural network that did a bunch of gradient steps. The inputs were just slices of a minibatch.\nBasically this: https://github.com/cbfinn/maml/blob/master/maml.py#L78\nI noticed that on CPU, there was parallelization, but on GPU no. Might there be a reason for this?\nIt seems like the post here was not the same issue.", "body": "Hi @skye  I encountered something similar when running tf.map_fn where the function was a neural network that did a bunch of gradient steps. The inputs were just slices of a minibatch. \r\n\r\nBasically this: https://github.com/cbfinn/maml/blob/master/maml.py#L78\r\n\r\nI noticed that on CPU, there was parallelization, but on GPU no. Might there be a reason for this?\r\n\r\nIt seems like the post here was not the same issue. \r\n\r\n"}