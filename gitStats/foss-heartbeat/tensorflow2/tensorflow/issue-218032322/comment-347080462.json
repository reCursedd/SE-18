{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347080462", "html_url": "https://github.com/tensorflow/tensorflow/issues/8820#issuecomment-347080462", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8820", "id": 347080462, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzA4MDQ2Mg==", "user": {"login": "stevefox", "id": 5599297, "node_id": "MDQ6VXNlcjU1OTkyOTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/5599297?v=4", "gravatar_id": "", "url": "https://api.github.com/users/stevefox", "html_url": "https://github.com/stevefox", "followers_url": "https://api.github.com/users/stevefox/followers", "following_url": "https://api.github.com/users/stevefox/following{/other_user}", "gists_url": "https://api.github.com/users/stevefox/gists{/gist_id}", "starred_url": "https://api.github.com/users/stevefox/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/stevefox/subscriptions", "organizations_url": "https://api.github.com/users/stevefox/orgs", "repos_url": "https://api.github.com/users/stevefox/repos", "events_url": "https://api.github.com/users/stevefox/events{/privacy}", "received_events_url": "https://api.github.com/users/stevefox/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-27T05:11:48Z", "updated_at": "2017-11-27T05:11:48Z", "author_association": "NONE", "body_html": "<p>Google designed an ASIC with which they've done this called the Tensorflow Processing Unit (TPU). There's a fair amount of information on it that has been publicly released.</p>\n<ul>\n<li><a href=\"https://drive.google.com/file/d/0Bx4hafXDDq2EMzRNcy1vSUxtcEk/view\" rel=\"nofollow\">https://drive.google.com/file/d/0Bx4hafXDDq2EMzRNcy1vSUxtcEk/view</a></li>\n<li><a href=\"https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/\" rel=\"nofollow\">https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/</a></li>\n<li><a href=\"https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu\" rel=\"nofollow\">https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu</a></li>\n</ul>\n<p>You could use this as a starting point to design soft IP for an FPGA that could support a handful of tensorflow Ops you'd like to speed up, then write the TF device handlers and ops.</p>\n<p>You could potentially even design the software interface with Xilinx's OpenCL macros (and maybe even the IP) to make the tensorflow Ops simpler to implement so you don't need to write HDL manually. There's also reconfigure.io (program an FPGA with Go). It sounds like Hastlayer that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1976647\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Piedone\">@Piedone</a> mentiond does something similar as well.</p>", "body_text": "Google designed an ASIC with which they've done this called the Tensorflow Processing Unit (TPU). There's a fair amount of information on it that has been publicly released.\n\nhttps://drive.google.com/file/d/0Bx4hafXDDq2EMzRNcy1vSUxtcEk/view\nhttps://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/\nhttps://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu\n\nYou could use this as a starting point to design soft IP for an FPGA that could support a handful of tensorflow Ops you'd like to speed up, then write the TF device handlers and ops.\nYou could potentially even design the software interface with Xilinx's OpenCL macros (and maybe even the IP) to make the tensorflow Ops simpler to implement so you don't need to write HDL manually. There's also reconfigure.io (program an FPGA with Go). It sounds like Hastlayer that @Piedone mentiond does something similar as well.", "body": "Google designed an ASIC with which they've done this called the Tensorflow Processing Unit (TPU). There's a fair amount of information on it that has been publicly released.\r\n\r\n* https://drive.google.com/file/d/0Bx4hafXDDq2EMzRNcy1vSUxtcEk/view\r\n* https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/\r\n* https://cloud.google.com/blog/big-data/2017/05/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu\r\n\r\nYou could use this as a starting point to design soft IP for an FPGA that could support a handful of tensorflow Ops you'd like to speed up, then write the TF device handlers and ops.\r\n\r\nYou could potentially even design the software interface with Xilinx's OpenCL macros (and maybe even the IP) to make the tensorflow Ops simpler to implement so you don't need to write HDL manually. There's also reconfigure.io (program an FPGA with Go). It sounds like Hastlayer that @Piedone mentiond does something similar as well."}