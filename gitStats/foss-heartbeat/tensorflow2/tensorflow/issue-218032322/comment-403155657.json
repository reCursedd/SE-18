{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/403155657", "html_url": "https://github.com/tensorflow/tensorflow/issues/8820#issuecomment-403155657", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8820", "id": 403155657, "node_id": "MDEyOklzc3VlQ29tbWVudDQwMzE1NTY1Nw==", "user": {"login": "wilderfield", "id": 15713959, "node_id": "MDQ6VXNlcjE1NzEzOTU5", "avatar_url": "https://avatars1.githubusercontent.com/u/15713959?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wilderfield", "html_url": "https://github.com/wilderfield", "followers_url": "https://api.github.com/users/wilderfield/followers", "following_url": "https://api.github.com/users/wilderfield/following{/other_user}", "gists_url": "https://api.github.com/users/wilderfield/gists{/gist_id}", "starred_url": "https://api.github.com/users/wilderfield/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wilderfield/subscriptions", "organizations_url": "https://api.github.com/users/wilderfield/orgs", "repos_url": "https://api.github.com/users/wilderfield/repos", "events_url": "https://api.github.com/users/wilderfield/events{/privacy}", "received_events_url": "https://api.github.com/users/wilderfield/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-06T21:51:48Z", "updated_at": "2018-07-06T21:51:48Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">To those interested. I would like to share some thoughts, and some info.\n\nFull disclosure, I opened this feature request about 1.5 years ago, back\nwhen I was more clueless. Also, I have worked at Xilinx for the past 4\nyears. Just 3 months ago I started as a \"Machine Learning Engineer\", so now\nI am very aware of Xilinx's approach in this space.\n\nMachine Learning/Computer Vision is a very fast paced market. It seems like\nevery year there is a new state of the art network architecture. Given that\nan FPGA design cycle can take 6 months to a year, especially when a company\nis lacking FPGA know-how, Xilinx provisioned a hardware and software team\nto design a \"soft\" neural network accelerator core. The core is meant to be\ngeneral purpose, in that it can accelerate most network architectures. We\nare calling it \"XDNN\". The software is getting tagged as \"xfDNN\". Xilinx\nFast DNN. We are so great at coming up with names!\n\nThe core is designed specifically for accelerating inference, and it takes\nadvantage of fixed point arithmetic to squeeze more compute into the FPGA\nfabric/DSPs. This means trained networks must undergo an offline\nquantization process, to go from float32 to int8. There is various research\nshowing that this is an effective method to achieve faster inference with\nminimal loss in accuracy (1-2%).\n\nThe core accelerates convolutions, pooling (Max/Average), eltwise add, and\nReLU. We run the majority of the network on the FPGA, and leave the final\nfully connected, or region layers to the CPU. (There was no gain in adding\nhardware support for these final layers, since FC layers are being used\nless and less, and region layers can be quite custom).\n\nCurrently, we only support cloud: \"Amazon AWS EC2 F1\", and on-premise:\n\"VCU1525\". However we are working on bringing the core into Zynq\nUltraScale+ devices, as well as other cloud providers such as Nimbix.\n\nCheck out our repo if you are interested: <a href=\"https://github.com/Xilinx/ml-suite\">https://github.com/Xilinx/ml-suite</a>\n\nAlso, you can kick the tires directly at:\n<a href=\"https://aws.amazon.com/marketplace/pp/B077FM2JNS\">https://aws.amazon.com/marketplace/pp/B077FM2JNS</a>\n\nRight now, the documentation on github isn't great, but we are about to\npush a new release with much improved docs. There is an EA branch that\nshows a lot of our software. My job right now is to enhance our\ndocumentation, and also add usability features (Ease of use Python stuff).\nSo feel free to complain to me, it is my job. We have some really nice\njupyter notebook tutorials coming. I can be reached at\nb.lozano.havoc@gmail.com or bryan.lozano@xilinx.com.\n\nNow we come to framework support...\n\nInitially, we did some experiments, enabling caffe to directly call our\naccelerator. We got it working, but it was clear that there would be a lot\nof work to add support for various networks, and to support this across\nCaffe/Tensorflow/MXNET. Tensorflow was still evolving when we started. We\nsimply didn't have enough software people to support that.\n\nWhat we settled on is a compiler frontend that takes your network\ndefinition, and weights. The compiler does some optimization (layer\nmerging), then generates a schedule of commands to accelerate a given\nnetwork. This way, the majority of our software can be framework agnostic,\nbut the compiler will have to \"multi-lingual\". The compiler reads prototxt,\nor frozen tensorflow graphs for example.\n\nI would still love it, if tensorflow had hooks to directly run on the FPGA,\nbut I don't see it happening anytime soon. It probably wouldn't be that\nbad, especially if Tensorflow can make OpenCL calls.\n\nAnyways, if you want more info, don't hesitate to reach out.\n\nAgain, I can be reached at b.lozano.havoc@gmail.com or\nbryan.lozano@xilinx.com\n\nThanks,\nBryan</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Fri, Jul 6, 2018 at 1:11 PM, GDG ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/nlbutts\">@nlbutts</a> &lt;<a href=\"https://github.com/nlbutts\">https://github.com/nlbutts</a>&gt; did you make any progress? Is\n anyone aware of a solution that interfaces Tensorflow with FPGAs?\n\n There are some old attempts to add new devices to Tensorflow, but I did\n not see anything about FPGAs in particular.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"218032322\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8820\" href=\"https://github.com/tensorflow/tensorflow/issues/8820#issuecomment-403134168\">#8820 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AO_Gp91PZcBHOvm6xGlQuTOMPtmufXmdks5uD8SLgaJpZM4Mtp4A\">https://github.com/notifications/unsubscribe-auth/AO_Gp91PZcBHOvm6xGlQuTOMPtmufXmdks5uD8SLgaJpZM4Mtp4A</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "To those interested. I would like to share some thoughts, and some info.\n\nFull disclosure, I opened this feature request about 1.5 years ago, back\nwhen I was more clueless. Also, I have worked at Xilinx for the past 4\nyears. Just 3 months ago I started as a \"Machine Learning Engineer\", so now\nI am very aware of Xilinx's approach in this space.\n\nMachine Learning/Computer Vision is a very fast paced market. It seems like\nevery year there is a new state of the art network architecture. Given that\nan FPGA design cycle can take 6 months to a year, especially when a company\nis lacking FPGA know-how, Xilinx provisioned a hardware and software team\nto design a \"soft\" neural network accelerator core. The core is meant to be\ngeneral purpose, in that it can accelerate most network architectures. We\nare calling it \"XDNN\". The software is getting tagged as \"xfDNN\". Xilinx\nFast DNN. We are so great at coming up with names!\n\nThe core is designed specifically for accelerating inference, and it takes\nadvantage of fixed point arithmetic to squeeze more compute into the FPGA\nfabric/DSPs. This means trained networks must undergo an offline\nquantization process, to go from float32 to int8. There is various research\nshowing that this is an effective method to achieve faster inference with\nminimal loss in accuracy (1-2%).\n\nThe core accelerates convolutions, pooling (Max/Average), eltwise add, and\nReLU. We run the majority of the network on the FPGA, and leave the final\nfully connected, or region layers to the CPU. (There was no gain in adding\nhardware support for these final layers, since FC layers are being used\nless and less, and region layers can be quite custom).\n\nCurrently, we only support cloud: \"Amazon AWS EC2 F1\", and on-premise:\n\"VCU1525\". However we are working on bringing the core into Zynq\nUltraScale+ devices, as well as other cloud providers such as Nimbix.\n\nCheck out our repo if you are interested: https://github.com/Xilinx/ml-suite\n\nAlso, you can kick the tires directly at:\nhttps://aws.amazon.com/marketplace/pp/B077FM2JNS\n\nRight now, the documentation on github isn't great, but we are about to\npush a new release with much improved docs. There is an EA branch that\nshows a lot of our software. My job right now is to enhance our\ndocumentation, and also add usability features (Ease of use Python stuff).\nSo feel free to complain to me, it is my job. We have some really nice\njupyter notebook tutorials coming. I can be reached at\nb.lozano.havoc@gmail.com or bryan.lozano@xilinx.com.\n\nNow we come to framework support...\n\nInitially, we did some experiments, enabling caffe to directly call our\naccelerator. We got it working, but it was clear that there would be a lot\nof work to add support for various networks, and to support this across\nCaffe/Tensorflow/MXNET. Tensorflow was still evolving when we started. We\nsimply didn't have enough software people to support that.\n\nWhat we settled on is a compiler frontend that takes your network\ndefinition, and weights. The compiler does some optimization (layer\nmerging), then generates a schedule of commands to accelerate a given\nnetwork. This way, the majority of our software can be framework agnostic,\nbut the compiler will have to \"multi-lingual\". The compiler reads prototxt,\nor frozen tensorflow graphs for example.\n\nI would still love it, if tensorflow had hooks to directly run on the FPGA,\nbut I don't see it happening anytime soon. It probably wouldn't be that\nbad, especially if Tensorflow can make OpenCL calls.\n\nAnyways, if you want more info, don't hesitate to reach out.\n\nAgain, I can be reached at b.lozano.havoc@gmail.com or\nbryan.lozano@xilinx.com\n\nThanks,\nBryan\n\u2026\nOn Fri, Jul 6, 2018 at 1:11 PM, GDG ***@***.***> wrote:\n @nlbutts <https://github.com/nlbutts> did you make any progress? Is\n anyone aware of a solution that interfaces Tensorflow with FPGAs?\n\n There are some old attempts to add new devices to Tensorflow, but I did\n not see anything about FPGAs in particular.\n\n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <#8820 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AO_Gp91PZcBHOvm6xGlQuTOMPtmufXmdks5uD8SLgaJpZM4Mtp4A>\n .", "body": "To those interested. I would like to share some thoughts, and some info.\n\nFull disclosure, I opened this feature request about 1.5 years ago, back\nwhen I was more clueless. Also, I have worked at Xilinx for the past 4\nyears. Just 3 months ago I started as a \"Machine Learning Engineer\", so now\nI am very aware of Xilinx's approach in this space.\n\nMachine Learning/Computer Vision is a very fast paced market. It seems like\nevery year there is a new state of the art network architecture. Given that\nan FPGA design cycle can take 6 months to a year, especially when a company\nis lacking FPGA know-how, Xilinx provisioned a hardware and software team\nto design a \"soft\" neural network accelerator core. The core is meant to be\ngeneral purpose, in that it can accelerate most network architectures. We\nare calling it \"XDNN\". The software is getting tagged as \"xfDNN\". Xilinx\nFast DNN. We are so great at coming up with names!\n\nThe core is designed specifically for accelerating inference, and it takes\nadvantage of fixed point arithmetic to squeeze more compute into the FPGA\nfabric/DSPs. This means trained networks must undergo an offline\nquantization process, to go from float32 to int8. There is various research\nshowing that this is an effective method to achieve faster inference with\nminimal loss in accuracy (1-2%).\n\nThe core accelerates convolutions, pooling (Max/Average), eltwise add, and\nReLU. We run the majority of the network on the FPGA, and leave the final\nfully connected, or region layers to the CPU. (There was no gain in adding\nhardware support for these final layers, since FC layers are being used\nless and less, and region layers can be quite custom).\n\nCurrently, we only support cloud: \"Amazon AWS EC2 F1\", and on-premise:\n\"VCU1525\". However we are working on bringing the core into Zynq\nUltraScale+ devices, as well as other cloud providers such as Nimbix.\n\nCheck out our repo if you are interested: https://github.com/Xilinx/ml-suite\n\nAlso, you can kick the tires directly at:\nhttps://aws.amazon.com/marketplace/pp/B077FM2JNS\n\nRight now, the documentation on github isn't great, but we are about to\npush a new release with much improved docs. There is an EA branch that\nshows a lot of our software. My job right now is to enhance our\ndocumentation, and also add usability features (Ease of use Python stuff).\nSo feel free to complain to me, it is my job. We have some really nice\njupyter notebook tutorials coming. I can be reached at\nb.lozano.havoc@gmail.com or bryan.lozano@xilinx.com.\n\nNow we come to framework support...\n\nInitially, we did some experiments, enabling caffe to directly call our\naccelerator. We got it working, but it was clear that there would be a lot\nof work to add support for various networks, and to support this across\nCaffe/Tensorflow/MXNET. Tensorflow was still evolving when we started. We\nsimply didn't have enough software people to support that.\n\nWhat we settled on is a compiler frontend that takes your network\ndefinition, and weights. The compiler does some optimization (layer\nmerging), then generates a schedule of commands to accelerate a given\nnetwork. This way, the majority of our software can be framework agnostic,\nbut the compiler will have to \"multi-lingual\". The compiler reads prototxt,\nor frozen tensorflow graphs for example.\n\nI would still love it, if tensorflow had hooks to directly run on the FPGA,\nbut I don't see it happening anytime soon. It probably wouldn't be that\nbad, especially if Tensorflow can make OpenCL calls.\n\nAnyways, if you want more info, don't hesitate to reach out.\n\nAgain, I can be reached at b.lozano.havoc@gmail.com or\nbryan.lozano@xilinx.com\n\nThanks,\nBryan\n\nOn Fri, Jul 6, 2018 at 1:11 PM, GDG <notifications@github.com> wrote:\n\n> @nlbutts <https://github.com/nlbutts> did you make any progress? Is\n> anyone aware of a solution that interfaces Tensorflow with FPGAs?\n>\n> There are some old attempts to add new devices to Tensorflow, but I did\n> not see anything about FPGAs in particular.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/8820#issuecomment-403134168>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AO_Gp91PZcBHOvm6xGlQuTOMPtmufXmdks5uD8SLgaJpZM4Mtp4A>\n> .\n>\n"}