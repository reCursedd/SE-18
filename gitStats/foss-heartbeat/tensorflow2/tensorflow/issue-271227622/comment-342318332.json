{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/342318332", "html_url": "https://github.com/tensorflow/tensorflow/issues/14250#issuecomment-342318332", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14250", "id": 342318332, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MjMxODMzMg==", "user": {"login": "georgesterpu", "id": 6018251, "node_id": "MDQ6VXNlcjYwMTgyNTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/6018251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgesterpu", "html_url": "https://github.com/georgesterpu", "followers_url": "https://api.github.com/users/georgesterpu/followers", "following_url": "https://api.github.com/users/georgesterpu/following{/other_user}", "gists_url": "https://api.github.com/users/georgesterpu/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgesterpu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgesterpu/subscriptions", "organizations_url": "https://api.github.com/users/georgesterpu/orgs", "repos_url": "https://api.github.com/users/georgesterpu/repos", "events_url": "https://api.github.com/users/georgesterpu/events{/privacy}", "received_events_url": "https://api.github.com/users/georgesterpu/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-06T23:05:31Z", "updated_at": "2017-11-06T23:05:31Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You are completely right, <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=49262\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jart\">@jart</a>. It would be more appropriate if I rephrase the last sentence as : \"After going through the entire support thread in <a href=\"https://github.com/tensorflow/tensorflow/issues/7951\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/7951/hovercard\">[1]</a> and searching related content on StackOverflow too, to the best of my knowledge these functionalities have not been implemented yet.\"</p>\n<p>If you are unsure about the possibility of sorting a Dataset after applying the <code>group_by_window()</code> transformation, perhaps it would be fair to re-open the issue. Could you also help me find out what is the implicit order of the batches when this transformation is applied, please ?</p>\n<p>On batch skipping, could you please provide me an example of ignoring the batches grouped by a range of ids within <code>group_by_window</code> ? I am probably overthinking this, yet it seems that the id returned by <code>key_func</code> would not be available anymore at runtime. Maybe <code>reduce_func</code> could discard some batches instead ?</p>\n<p>Thank you</p>", "body_text": "You are completely right, @jart. It would be more appropriate if I rephrase the last sentence as : \"After going through the entire support thread in [1] and searching related content on StackOverflow too, to the best of my knowledge these functionalities have not been implemented yet.\"\nIf you are unsure about the possibility of sorting a Dataset after applying the group_by_window() transformation, perhaps it would be fair to re-open the issue. Could you also help me find out what is the implicit order of the batches when this transformation is applied, please ?\nOn batch skipping, could you please provide me an example of ignoring the batches grouped by a range of ids within group_by_window ? I am probably overthinking this, yet it seems that the id returned by key_func would not be available anymore at runtime. Maybe reduce_func could discard some batches instead ?\nThank you", "body": "You are completely right, @jart. It would be more appropriate if I rephrase the last sentence as : \"After going through the entire support thread in [[1]](https://github.com/tensorflow/tensorflow/issues/7951) and searching related content on StackOverflow too, to the best of my knowledge these functionalities have not been implemented yet.\" \r\n\r\nIf you are unsure about the possibility of sorting a Dataset after applying the `group_by_window()` transformation, perhaps it would be fair to re-open the issue. Could you also help me find out what is the implicit order of the batches when this transformation is applied, please ?\r\n\r\nOn batch skipping, could you please provide me an example of ignoring the batches grouped by a range of ids within `group_by_window` ? I am probably overthinking this, yet it seems that the id returned by `key_func` would not be available anymore at runtime. Maybe `reduce_func` could discard some batches instead ?\r\n\r\nThank you"}