{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/398875420", "html_url": "https://github.com/tensorflow/tensorflow/issues/20126#issuecomment-398875420", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20126", "id": 398875420, "node_id": "MDEyOklzc3VlQ29tbWVudDM5ODg3NTQyMA==", "user": {"login": "bpinette", "id": 3532734, "node_id": "MDQ6VXNlcjM1MzI3MzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/3532734?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bpinette", "html_url": "https://github.com/bpinette", "followers_url": "https://api.github.com/users/bpinette/followers", "following_url": "https://api.github.com/users/bpinette/following{/other_user}", "gists_url": "https://api.github.com/users/bpinette/gists{/gist_id}", "starred_url": "https://api.github.com/users/bpinette/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bpinette/subscriptions", "organizations_url": "https://api.github.com/users/bpinette/orgs", "repos_url": "https://api.github.com/users/bpinette/repos", "events_url": "https://api.github.com/users/bpinette/events{/privacy}", "received_events_url": "https://api.github.com/users/bpinette/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-20T19:52:58Z", "updated_at": "2018-06-20T19:52:58Z", "author_association": "NONE", "body_html": "<p>(I don't know if the following will help you track this down, but I'll leave this as a hint.)<br>\nI decided to spend the day looking at the code to see if I could somehow fix it locally.  I'm still looking, but here's what I found so far.  I put print statements at in the MirroredVariable constructor and also before the assert that gave rise to the error.  Here are the MirroredVariables that are being constructed:</p>\n<p>MirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': &lt;tf.Variable 'global_step:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:1': &lt;tf.Variable 'global_step/replica_1:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:2': &lt;tf.Variable 'global_step/replica_2:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:3': &lt;tf.Variable 'global_step/replica_3:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:4': &lt;tf.Variable 'global_step/replica_4:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:5': &lt;tf.Variable 'global_step/replica_5:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:6': &lt;tf.Variable 'global_step/replica_6:0' shape=() dtype=int64&gt;, '/job:localhost/replica:0/task:0/device:GPU:7': &lt;tf.Variable 'global_step/replica_7:0' shape=() dtype=int64&gt;}</p>\n<p>MirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': &lt;tf.Variable 'embeddings:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:1': &lt;tf.Variable 'embeddings/replica_1:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:2': &lt;tf.Variable 'embeddings/replica_2:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:3': &lt;tf.Variable 'embeddings/replica_3:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:4': &lt;tf.Variable 'embeddings/replica_4:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:5': &lt;tf.Variable 'embeddings/replica_5:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:6': &lt;tf.Variable 'embeddings/replica_6:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:7': &lt;tf.Variable 'embeddings/replica_7:0' shape=(20, 300) dtype=float32&gt;}</p>\n<p>OK, this makes sense to me.  The global_step variable is some TF variable that is maintained and updated by TF and the embeddings variable are the weights of my word2vec matrix, which I'm trying to learn.   Now let's take a look at the variables that the assertion is being applied to:</p>\n<p>MirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': &lt;tf.Variable 'embeddings:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:1': &lt;tf.Variable 'embeddings/replica_1:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:2': &lt;tf.Variable 'embeddings/replica_2:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:3': &lt;tf.Variable 'embeddings/replica_3:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:4': &lt;tf.Variable 'embeddings/replica_4:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:5': &lt;tf.Variable 'embeddings/replica_5:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:6': &lt;tf.Variable 'embeddings/replica_6:0' shape=(20, 300) dtype=float32&gt;, '/job:localhost/replica:0/task:0/device:GPU:7': &lt;tf.Variable 'embeddings/replica_7:0' shape=(20, 300) dtype=float32&gt;}</p>\n<p>PerDevice:{'/job:localhost/replica:0/task:0/device:GPU:0': &lt;tf.Variable 'Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:1': &lt;tf.Variable 'tower_1/Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:2': &lt;tf.Variable 'tower_2/Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:3': &lt;tf.Variable 'tower_3/Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:4': &lt;tf.Variable 'tower_4/Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:5': &lt;tf.Variable 'tower_5/Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:6': &lt;tf.Variable 'tower_6/Variable:0' shape=(20, 300) dtype=float32_ref&gt;, '/job:localhost/replica:0/task:0/device:GPU:7': &lt;tf.Variable 'tower_7/Variable:0' shape=(20, 300) dtype=float32_ref&gt;}</p>\n<p>The first thing we see is a MirroredVariable for the embeddings.  This makes sense, and it passes the assertion.  The next thing we see is a PerDevice variable that has the same shape as the embeddings variable, but is unnamed.  Hmmmmm....not one of my variables.  What might this be?  Is this possibly an internal tensor of gradients computed at a training step and being passed around?  If so, is the optimizer failing to create a MirroredVariable?  In any case, this is the variable that fails the assertion.</p>", "body_text": "(I don't know if the following will help you track this down, but I'll leave this as a hint.)\nI decided to spend the day looking at the code to see if I could somehow fix it locally.  I'm still looking, but here's what I found so far.  I put print statements at in the MirroredVariable constructor and also before the assert that gave rise to the error.  Here are the MirroredVariables that are being constructed:\nMirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'global_step:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'global_step/replica_1:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'global_step/replica_2:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'global_step/replica_3:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'global_step/replica_4:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'global_step/replica_5:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'global_step/replica_6:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'global_step/replica_7:0' shape=() dtype=int64>}\nMirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'embeddings:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'embeddings/replica_1:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'embeddings/replica_2:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'embeddings/replica_3:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'embeddings/replica_4:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'embeddings/replica_5:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'embeddings/replica_6:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'embeddings/replica_7:0' shape=(20, 300) dtype=float32>}\nOK, this makes sense to me.  The global_step variable is some TF variable that is maintained and updated by TF and the embeddings variable are the weights of my word2vec matrix, which I'm trying to learn.   Now let's take a look at the variables that the assertion is being applied to:\nMirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'embeddings:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'embeddings/replica_1:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'embeddings/replica_2:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'embeddings/replica_3:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'embeddings/replica_4:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'embeddings/replica_5:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'embeddings/replica_6:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'embeddings/replica_7:0' shape=(20, 300) dtype=float32>}\nPerDevice:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'tower_1/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'tower_2/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'tower_3/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'tower_4/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'tower_5/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'tower_6/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'tower_7/Variable:0' shape=(20, 300) dtype=float32_ref>}\nThe first thing we see is a MirroredVariable for the embeddings.  This makes sense, and it passes the assertion.  The next thing we see is a PerDevice variable that has the same shape as the embeddings variable, but is unnamed.  Hmmmmm....not one of my variables.  What might this be?  Is this possibly an internal tensor of gradients computed at a training step and being passed around?  If so, is the optimizer failing to create a MirroredVariable?  In any case, this is the variable that fails the assertion.", "body": "(I don't know if the following will help you track this down, but I'll leave this as a hint.)\r\nI decided to spend the day looking at the code to see if I could somehow fix it locally.  I'm still looking, but here's what I found so far.  I put print statements at in the MirroredVariable constructor and also before the assert that gave rise to the error.  Here are the MirroredVariables that are being constructed:\r\n\r\n MirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'global_step:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'global_step/replica_1:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'global_step/replica_2:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'global_step/replica_3:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'global_step/replica_4:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'global_step/replica_5:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'global_step/replica_6:0' shape=() dtype=int64>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'global_step/replica_7:0' shape=() dtype=int64>}\r\n\r\n MirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'embeddings:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'embeddings/replica_1:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'embeddings/replica_2:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'embeddings/replica_3:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'embeddings/replica_4:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'embeddings/replica_5:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'embeddings/replica_6:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'embeddings/replica_7:0' shape=(20, 300) dtype=float32>}\r\n\r\nOK, this makes sense to me.  The global_step variable is some TF variable that is maintained and updated by TF and the embeddings variable are the weights of my word2vec matrix, which I'm trying to learn.   Now let's take a look at the variables that the assertion is being applied to:\r\n\r\nMirroredVariable:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'embeddings:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'embeddings/replica_1:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'embeddings/replica_2:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'embeddings/replica_3:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'embeddings/replica_4:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'embeddings/replica_5:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'embeddings/replica_6:0' shape=(20, 300) dtype=float32>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'embeddings/replica_7:0' shape=(20, 300) dtype=float32>}\r\n\r\nPerDevice:{'/job:localhost/replica:0/task:0/device:GPU:0': <tf.Variable 'Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:1': <tf.Variable 'tower_1/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:2': <tf.Variable 'tower_2/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:3': <tf.Variable 'tower_3/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:4': <tf.Variable 'tower_4/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:5': <tf.Variable 'tower_5/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:6': <tf.Variable 'tower_6/Variable:0' shape=(20, 300) dtype=float32_ref>, '/job:localhost/replica:0/task:0/device:GPU:7': <tf.Variable 'tower_7/Variable:0' shape=(20, 300) dtype=float32_ref>}\r\n\r\nThe first thing we see is a MirroredVariable for the embeddings.  This makes sense, and it passes the assertion.  The next thing we see is a PerDevice variable that has the same shape as the embeddings variable, but is unnamed.  Hmmmmm....not one of my variables.  What might this be?  Is this possibly an internal tensor of gradients computed at a training step and being passed around?  If so, is the optimizer failing to create a MirroredVariable?  In any case, this is the variable that fails the assertion.\r\n\r\n\r\n\r\n\r\n\r\n"}