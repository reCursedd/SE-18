{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397485615", "html_url": "https://github.com/tensorflow/tensorflow/issues/19884#issuecomment-397485615", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19884", "id": 397485615, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzQ4NTYxNQ==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-15T01:22:23Z", "updated_at": "2018-06-15T01:23:57Z", "author_association": "MEMBER", "body_html": "<p>Thanks for bringing this up, I can understand the confusion.</p>\n<p>To be clear, the intention is that symbols in the <code>tf.contrib.eager</code> namespace can be used in both eager and graph execution, not that they are equivalent to other symbols in the <code>tf</code> namespace. So, <code>tfe.Variable</code> works with both graph and eager execution, but its behavior is not always the same as <code>tf.Variable</code>.</p>\n<p>In fact, <code>tfe.Variable</code> is a different implementation of variables called \"resource variables\" in the implementation (introduced independently of eager execution), which have more clearly defined memory semantics. We're in the process of making resource variables more prevalent (and in fact, they are required for TPUs as well) because of the <a href=\"https://github.com/tensorflow/tensorflow/blob/212ba3e9ef934d0b2a3b09740bd238cda0394fad/tensorflow/python/ops/variables.py#L126\">saner memory model</a>.</p>\n<p>Now, when it comes to <code>feed_dict</code>, the intention there is to be able to feed values for <code>Tensor</code>s, not <code>Variable</code>s. The fact that it works for variables is more of an accident :). We perhaps should make that be an error (at least for resource variables) instead of the seemingly mysterious behavior you see (CC <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5061\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alextp\">@alextp</a> - who is also writing up some documentation around this).</p>\n<p>The program you've described above:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tfe.Variable(<span class=\"pl-c1\">4</span>)\ny <span class=\"pl-k\">=</span> x <span class=\"pl-k\">*</span> x</pre></div>\n<p>is essentially shorthand for the program:</p>\n<div class=\"highlight highlight-source-python\"><pre>x <span class=\"pl-k\">=</span> tfe.Variable(<span class=\"pl-c1\">4</span>)\nx_1 <span class=\"pl-k\">=</span> x.read_value()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Return a Tensor corresponding to the current value of the Variable</span>\ny <span class=\"pl-k\">=</span> x_1 <span class=\"pl-k\">*</span> x_1</pre></div>\n<p>And when expressed like this, you could use <code>feed_dict</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\ntfe <span class=\"pl-k\">=</span> tf.contrib.eager\n\nx <span class=\"pl-k\">=</span> tfe.Variable(<span class=\"pl-c1\">4</span>)\nx_1 <span class=\"pl-k\">=</span> x.read_value()\ny <span class=\"pl-k\">=</span> x_1 <span class=\"pl-k\">*</span> x_1\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n     sess.run(tf.global_variables_initializer())\n     <span class=\"pl-c1\">print</span>(sess.run(y, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>{x_1: <span class=\"pl-c1\">15</span>})) <span class=\"pl-c\"><span class=\"pl-c\">#</span> Will print 225</span></pre></div>\n<p>Though this works, in general, do you typically include variables in the feed_dict?</p>\n<p>I understand this is confusing, hopefully the explanation makes sense.<br>\nThe bug itself isn't about eager, so I'm going to go ahead and adjust the title of the bug to reflect that while we figure out how to more clearly make this an error.</p>\n<p>Hope that sounds reasonable. Thanks!</p>", "body_text": "Thanks for bringing this up, I can understand the confusion.\nTo be clear, the intention is that symbols in the tf.contrib.eager namespace can be used in both eager and graph execution, not that they are equivalent to other symbols in the tf namespace. So, tfe.Variable works with both graph and eager execution, but its behavior is not always the same as tf.Variable.\nIn fact, tfe.Variable is a different implementation of variables called \"resource variables\" in the implementation (introduced independently of eager execution), which have more clearly defined memory semantics. We're in the process of making resource variables more prevalent (and in fact, they are required for TPUs as well) because of the saner memory model.\nNow, when it comes to feed_dict, the intention there is to be able to feed values for Tensors, not Variables. The fact that it works for variables is more of an accident :). We perhaps should make that be an error (at least for resource variables) instead of the seemingly mysterious behavior you see (CC @alextp - who is also writing up some documentation around this).\nThe program you've described above:\nx = tfe.Variable(4)\ny = x * x\nis essentially shorthand for the program:\nx = tfe.Variable(4)\nx_1 = x.read_value()  # Return a Tensor corresponding to the current value of the Variable\ny = x_1 * x_1\nAnd when expressed like this, you could use feed_dict:\nimport tensorflow as tf\ntfe = tf.contrib.eager\n\nx = tfe.Variable(4)\nx_1 = x.read_value()\ny = x_1 * x_1\n\nwith tf.Session() as sess:\n     sess.run(tf.global_variables_initializer())\n     print(sess.run(y, feed_dict={x_1: 15})) # Will print 225\nThough this works, in general, do you typically include variables in the feed_dict?\nI understand this is confusing, hopefully the explanation makes sense.\nThe bug itself isn't about eager, so I'm going to go ahead and adjust the title of the bug to reflect that while we figure out how to more clearly make this an error.\nHope that sounds reasonable. Thanks!", "body": "Thanks for bringing this up, I can understand the confusion.\r\n\r\nTo be clear, the intention is that symbols in the `tf.contrib.eager` namespace can be used in both eager and graph execution, not that they are equivalent to other symbols in the `tf` namespace. So, `tfe.Variable` works with both graph and eager execution, but its behavior is not always the same as `tf.Variable`.\r\n\r\nIn fact, `tfe.Variable` is a different implementation of variables called \"resource variables\" in the implementation (introduced independently of eager execution), which have more clearly defined memory semantics. We're in the process of making resource variables more prevalent (and in fact, they are required for TPUs as well) because of the [saner memory model](https://github.com/tensorflow/tensorflow/blob/212ba3e9ef934d0b2a3b09740bd238cda0394fad/tensorflow/python/ops/variables.py#L126).\r\n\r\nNow, when it comes to `feed_dict`, the intention there is to be able to feed values for `Tensor`s, not `Variable`s. The fact that it works for variables is more of an accident :). We perhaps should make that be an error (at least for resource variables) instead of the seemingly mysterious behavior you see (CC @alextp - who is also writing up some documentation around this).\r\n\r\nThe program you've described above:\r\n```python\r\nx = tfe.Variable(4)\r\ny = x * x\r\n```\r\n\r\nis essentially shorthand for the program:\r\n\r\n```python\r\nx = tfe.Variable(4)\r\nx_1 = x.read_value()  # Return a Tensor corresponding to the current value of the Variable\r\ny = x_1 * x_1\r\n```\r\n\r\nAnd when expressed like this, you could use `feed_dict`:\r\n\r\n```python\r\nimport tensorflow as tf\r\ntfe = tf.contrib.eager\r\n\r\nx = tfe.Variable(4)\r\nx_1 = x.read_value()\r\ny = x_1 * x_1\r\n\r\nwith tf.Session() as sess:\r\n     sess.run(tf.global_variables_initializer())\r\n     print(sess.run(y, feed_dict={x_1: 15})) # Will print 225\r\n```\r\n\r\nThough this works, in general, do you typically include variables in the feed_dict?\r\n\r\nI understand this is confusing, hopefully the explanation makes sense.\r\nThe bug itself isn't about eager, so I'm going to go ahead and adjust the title of the bug to reflect that while we figure out how to more clearly make this an error.\r\n\r\nHope that sounds reasonable. Thanks!"}