{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9254", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9254/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9254/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9254/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9254", "id": 222029751, "node_id": "MDU6SXNzdWUyMjIwMjk3NTE=", "number": 9254, "title": "Reading each filter response from a 4-D Tensor", "user": {"login": "samik1986", "id": 25694249, "node_id": "MDQ6VXNlcjI1Njk0MjQ5", "avatar_url": "https://avatars1.githubusercontent.com/u/25694249?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samik1986", "html_url": "https://github.com/samik1986", "followers_url": "https://api.github.com/users/samik1986/followers", "following_url": "https://api.github.com/users/samik1986/following{/other_user}", "gists_url": "https://api.github.com/users/samik1986/gists{/gist_id}", "starred_url": "https://api.github.com/users/samik1986/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samik1986/subscriptions", "organizations_url": "https://api.github.com/users/samik1986/orgs", "repos_url": "https://api.github.com/users/samik1986/repos", "events_url": "https://api.github.com/users/samik1986/events{/privacy}", "received_events_url": "https://api.github.com/users/samik1986/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-04-16T19:56:57Z", "updated_at": "2017-04-17T02:56:55Z", "closed_at": "2017-04-17T02:56:55Z", "author_association": "NONE", "body_html": "<pre><code>`class MyLayer(Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(MyLayer, self).__init__(**kwargs)\n\n def build(self, input_shape):\n        # Create a trainable weight variable for this layer.\n        self.kernel = self.add_weight(shape=(input_shape[1], self.output_dim),\n                                      initializer='uniform',\n                                      trainable=True)\n        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n\n    def call(self, x):\n        s = x.get_shape()\n        r = K.eval(x)\n        print(r)\n       # Convert to 64 (25 * 25) tensors.\n       # Need to flatten each of these 64 tensors.\n       # write some functions on these 64 tensors.\n       return &lt;tensor [?,64]&gt;`\n</code></pre>\n<p>x is of shape [?,25,25,64]</p>\n<p>I need 64 tensors of [?,25,25]</p>\n<p>Will <code>keras.layers.Flatten()</code> work in the second step.</p>\n<p>Can a Tensor be converted to an numpy array?</p>\n<p>Please help me on this.</p>\n<p>Note: I am using Functional APIs for Keras.</p>", "body_text": "`class MyLayer(Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(MyLayer, self).__init__(**kwargs)\n\n def build(self, input_shape):\n        # Create a trainable weight variable for this layer.\n        self.kernel = self.add_weight(shape=(input_shape[1], self.output_dim),\n                                      initializer='uniform',\n                                      trainable=True)\n        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n\n    def call(self, x):\n        s = x.get_shape()\n        r = K.eval(x)\n        print(r)\n       # Convert to 64 (25 * 25) tensors.\n       # Need to flatten each of these 64 tensors.\n       # write some functions on these 64 tensors.\n       return <tensor [?,64]>`\n\nx is of shape [?,25,25,64]\nI need 64 tensors of [?,25,25]\nWill keras.layers.Flatten() work in the second step.\nCan a Tensor be converted to an numpy array?\nPlease help me on this.\nNote: I am using Functional APIs for Keras.", "body": "```\r\n`class MyLayer(Layer):\r\n    def __init__(self, output_dim, **kwargs):\r\n        self.output_dim = output_dim\r\n        super(MyLayer, self).__init__(**kwargs)\r\n\r\n def build(self, input_shape):\r\n        # Create a trainable weight variable for this layer.\r\n        self.kernel = self.add_weight(shape=(input_shape[1], self.output_dim),\r\n                                      initializer='uniform',\r\n                                      trainable=True)\r\n        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\r\n\r\n    def call(self, x):\r\n        s = x.get_shape()\r\n        r = K.eval(x)\r\n        print(r)\r\n       # Convert to 64 (25 * 25) tensors.\r\n       # Need to flatten each of these 64 tensors.\r\n       # write some functions on these 64 tensors.\r\n       return <tensor [?,64]>`\r\n```\r\n\r\nx is of shape [?,25,25,64]\r\n\r\nI need 64 tensors of [?,25,25]\r\n\r\nWill `keras.layers.Flatten()` work in the second step.\r\n\r\nCan a Tensor be converted to an numpy array?\r\n\r\nPlease help me on this.\r\n\r\nNote: I am using Functional APIs for Keras."}