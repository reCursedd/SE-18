{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/371225854", "html_url": "https://github.com/tensorflow/tensorflow/issues/17233#issuecomment-371225854", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17233", "id": 371225854, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MTIyNTg1NA==", "user": {"login": "niklas88", "id": 264873, "node_id": "MDQ6VXNlcjI2NDg3Mw==", "avatar_url": "https://avatars1.githubusercontent.com/u/264873?v=4", "gravatar_id": "", "url": "https://api.github.com/users/niklas88", "html_url": "https://github.com/niklas88", "followers_url": "https://api.github.com/users/niklas88/followers", "following_url": "https://api.github.com/users/niklas88/following{/other_user}", "gists_url": "https://api.github.com/users/niklas88/gists{/gist_id}", "starred_url": "https://api.github.com/users/niklas88/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/niklas88/subscriptions", "organizations_url": "https://api.github.com/users/niklas88/orgs", "repos_url": "https://api.github.com/users/niklas88/repos", "events_url": "https://api.github.com/users/niklas88/events{/privacy}", "received_events_url": "https://api.github.com/users/niklas88/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-07T17:57:27Z", "updated_at": "2018-03-07T18:02:13Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=986732\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tatianashp\">@tatianashp</a> the problem occurs on nvidia-docker with <code>gcr.io/tensorflow/tensorflow:1.6.0-gpu-py3</code> on an NVIDIA TITAN X (Maxwell and Pascal). Both inside Kubernetes as well as on the Ubuntu 16.04 LTS host + Docker CE.  Driver version is 390.25 but the same happened with an older version already (tried updating today during our investigation). As for the docker image there are almost no other dependencies (gensim + joblib) and those remain the same when changing from 1.5 to 1.6.</p>\n<p>I have spent some time trying to get <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a> 's align_numpy_tf() hack to work but it's a bit hairy because the embeddings' size is taken into account when building the graph and at that point there is no session yet. I got it working with a hack but couldn't really see a performance difference. Still, I think that the very large NumPy array feed is a likely culprit as other models by colleagues don't show a similar degradation but also don't feed large NumPy arrays.</p>\n<p>Note that this is with the embeddings created under a the 'cpu:0' device. When creating on the GPU it takes 1 minute per batch even on 1.5, I'm not sure about 1.6. The loss seems to develop almost identically. Interestingly with 1.5 I see 60-70% utilization in <code>nvidia-smi</code> but with 1.6 it drops to 0-2%. CPU load is 100% with both versions, though on 1.5 when using no GPU it doesn't go beyond 100% while with 1.6 it uses just one core.</p>\n<p>I can try to create a reproducer tomorrow though it will likely need a large download for the embeddings..</p>", "body_text": "@tatianashp the problem occurs on nvidia-docker with gcr.io/tensorflow/tensorflow:1.6.0-gpu-py3 on an NVIDIA TITAN X (Maxwell and Pascal). Both inside Kubernetes as well as on the Ubuntu 16.04 LTS host + Docker CE.  Driver version is 390.25 but the same happened with an older version already (tried updating today during our investigation). As for the docker image there are almost no other dependencies (gensim + joblib) and those remain the same when changing from 1.5 to 1.6.\nI have spent some time trying to get @yaroslavvb 's align_numpy_tf() hack to work but it's a bit hairy because the embeddings' size is taken into account when building the graph and at that point there is no session yet. I got it working with a hack but couldn't really see a performance difference. Still, I think that the very large NumPy array feed is a likely culprit as other models by colleagues don't show a similar degradation but also don't feed large NumPy arrays.\nNote that this is with the embeddings created under a the 'cpu:0' device. When creating on the GPU it takes 1 minute per batch even on 1.5, I'm not sure about 1.6. The loss seems to develop almost identically. Interestingly with 1.5 I see 60-70% utilization in nvidia-smi but with 1.6 it drops to 0-2%. CPU load is 100% with both versions, though on 1.5 when using no GPU it doesn't go beyond 100% while with 1.6 it uses just one core.\nI can try to create a reproducer tomorrow though it will likely need a large download for the embeddings..", "body": "@tatianashp the problem occurs on nvidia-docker with `gcr.io/tensorflow/tensorflow:1.6.0-gpu-py3` on an NVIDIA TITAN X (Maxwell and Pascal). Both inside Kubernetes as well as on the Ubuntu 16.04 LTS host + Docker CE.  Driver version is 390.25 but the same happened with an older version already (tried updating today during our investigation). As for the docker image there are almost no other dependencies (gensim + joblib) and those remain the same when changing from 1.5 to 1.6.\r\n\r\nI have spent some time trying to get @yaroslavvb 's align_numpy_tf() hack to work but it's a bit hairy because the embeddings' size is taken into account when building the graph and at that point there is no session yet. I got it working with a hack but couldn't really see a performance difference. Still, I think that the very large NumPy array feed is a likely culprit as other models by colleagues don't show a similar degradation but also don't feed large NumPy arrays.\r\n\r\nNote that this is with the embeddings created under a the 'cpu:0' device. When creating on the GPU it takes 1 minute per batch even on 1.5, I'm not sure about 1.6. The loss seems to develop almost identically. Interestingly with 1.5 I see 60-70% utilization in `nvidia-smi` but with 1.6 it drops to 0-2%. CPU load is 100% with both versions, though on 1.5 when using no GPU it doesn't go beyond 100% while with 1.6 it uses just one core.\r\n\r\nI can try to create a reproducer tomorrow though it will likely need a large download for the embeddings.."}