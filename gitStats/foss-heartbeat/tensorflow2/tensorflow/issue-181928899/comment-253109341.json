{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/253109341", "html_url": "https://github.com/tensorflow/tensorflow/issues/4867#issuecomment-253109341", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4867", "id": 253109341, "node_id": "MDEyOklzc3VlQ29tbWVudDI1MzEwOTM0MQ==", "user": {"login": "HW-ZZ", "id": 21070954, "node_id": "MDQ6VXNlcjIxMDcwOTU0", "avatar_url": "https://avatars2.githubusercontent.com/u/21070954?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HW-ZZ", "html_url": "https://github.com/HW-ZZ", "followers_url": "https://api.github.com/users/HW-ZZ/followers", "following_url": "https://api.github.com/users/HW-ZZ/following{/other_user}", "gists_url": "https://api.github.com/users/HW-ZZ/gists{/gist_id}", "starred_url": "https://api.github.com/users/HW-ZZ/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HW-ZZ/subscriptions", "organizations_url": "https://api.github.com/users/HW-ZZ/orgs", "repos_url": "https://api.github.com/users/HW-ZZ/repos", "events_url": "https://api.github.com/users/HW-ZZ/events{/privacy}", "received_events_url": "https://api.github.com/users/HW-ZZ/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-12T03:26:07Z", "updated_at": "2016-10-12T03:26:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=23068\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yaroslavvb\">@yaroslavvb</a></p>\n<pre><code>gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n</code></pre>\n<p>But I think this way can't to set on a per-GPU basis.<br>\nIf we need train two different models  on two different GPUs at same time,how can we<br>\nallocate GPU memory.</p>", "body_text": "@yaroslavvb\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n\nBut I think this way can't to set on a per-GPU basis.\nIf we need train two different models  on two different GPUs at same time,how can we\nallocate GPU memory.", "body": "@yaroslavvb \n\n```\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n```\n\nBut I think this way can't to set on a per-GPU basis.\nIf we need train two different models  on two different GPUs at same time,how can we \nallocate GPU memory.\n"}