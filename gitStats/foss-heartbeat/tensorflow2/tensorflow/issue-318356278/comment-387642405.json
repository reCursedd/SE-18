{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/387642405", "html_url": "https://github.com/tensorflow/tensorflow/issues/18919#issuecomment-387642405", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18919", "id": 387642405, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NzY0MjQwNQ==", "user": {"login": "mjuvilla", "id": 8360740, "node_id": "MDQ6VXNlcjgzNjA3NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8360740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjuvilla", "html_url": "https://github.com/mjuvilla", "followers_url": "https://api.github.com/users/mjuvilla/followers", "following_url": "https://api.github.com/users/mjuvilla/following{/other_user}", "gists_url": "https://api.github.com/users/mjuvilla/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjuvilla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjuvilla/subscriptions", "organizations_url": "https://api.github.com/users/mjuvilla/orgs", "repos_url": "https://api.github.com/users/mjuvilla/repos", "events_url": "https://api.github.com/users/mjuvilla/events{/privacy}", "received_events_url": "https://api.github.com/users/mjuvilla/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-09T07:09:24Z", "updated_at": "2018-05-09T07:09:24Z", "author_association": "NONE", "body_html": "<p>Ok, so now the <code>tf.contrib.quantize.create_eval_graph()</code> is working:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8360740/39800010-a5fb7766-5366-11e8-8378-42b87be5c99b.png\"><img src=\"https://user-images.githubusercontent.com/8360740/39800010-a5fb7766-5366-11e8-8378-42b87be5c99b.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>But now I get an error when freezing the model (in the eval graph code, attached below, function <code>convert_variables_to_constants</code>):</p>\n<p><code>tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value weights_quant_2/min [[Node: _retval_weights_quant_2/min_0_16 = _Retval[T=DT_FLOAT, index=16, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights_quant_2/min)]]</code></p>\n<p>Looks like when I perform the restore from the checkpoint, the quantization nodes are not restored (but the weights and biases are correctly restored).</p>\n<p>Here's the new training code:</p>\n<pre lang=\"inputs\" data-meta=\"= tf.placeholder(tf.float32, shape=(1, train_X.shape[1]), name='inputs')\"><code>label = tf.placeholder(tf.float32, shape=(1, num_classes), name='labels')\n\n# First layer\nhid1_size = 1000\nw1 = tf.Variable(tf.random_normal([train_X.shape[1], hid1_size], stddev=0.01), name='w1')\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\ny1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\"), keep_prob=0.5)\n\n# Second layer\nhid2_size = 1000\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\ny2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\"), keep_prob=0.5)\n\n# Output layer\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\n\n# Loss function and optimizer\n# lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label), name=\"loss\")\n\n# Call the training rewrite which rewrites the graph in-place with\n# FakeQuantization nodes and folds batchnorm for training. It is\n# often needed to fine tune a floating point model for quantization\n# with this training tool. When training from scratch, quant_delay\n# can be used to activate quantization after training to converge\n# with the float graph, effectively fine-tuning the model.\ntf.contrib.quantize.create_training_graph(quant_delay=50)\n\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\n# Prediction\npred = tf.nn.softmax(yo, name=\"prediction\")\npred_label = tf.argmax(pred, 1)\ncorrect_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n# Create operation which will initialize all variables\ninit = tf.global_variables_initializer()\n\n# Start a new tensorflow session and initialize variables\nsess = tf.Session()\n\nwriter = tf.summary.FileWriter(\"tensorboard\", sess.graph)\n\nsess.run(init)\n\nsaver = tf.train.Saver()\n\n# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another\n# 50 epochs with a smaller learning rate of 0.01\nfor epoch in range(10):\n    print(\"Epoch: {:3d}\".format(epoch))\n    avg_cost = 0.0\n\n    # For each epoch, we go through all the samples we have.\n    for i in tqdm.tqdm(range(train_X.shape[0])):\n        # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\n        _, c = sess.run([optimizer, loss], feed_dict={inputs: train_X[i, None],\n                                                      label: train_y[i, None]})\n        avg_cost += c\n    avg_cost /= train_X.shape[0]\n\n    # Print the cost in this epcho to the console.\n    if epoch % 10 == 0:\n        print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))\n\ngraph_path = os.path.join(\"models\", \"model.pbtxt\")\ncheckpoint_path = os.path.join(\"models\", \"model.ckpt\")\n\n# Save the checkpoint and eval graph proto to disk for freezing and providing to TFLite.\nwith open(graph_path, 'w') as f:\n    f.write(str(sess.graph.as_graph_def()))\n\nsaver.save(sess, checkpoint_path)\n\nwriter.close()\n</code></pre>\n<p>And the eval graph code:</p>\n<pre><code>inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\n\n# First layer\nhid1_size = 1000\nw1 = tf.Variable(tf.random_normal([num_feat, hid1_size], stddev=0.01), name='w1')\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\ny1 = tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\")\n\n# Second layer\nhid2_size = 1000\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\ny2 = tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\")\n\n# Output layer\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\n\npred = tf.nn.softmax(yo, name=\"prediction\")\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    # Call the eval rewrite which rewrites the graph in-place with\n    # FakeQuantization nodes and fold batchnorm for eval.\n    tf.contrib.quantize.create_eval_graph()\n\n    writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\n\n    saver.restore(sess, \"models/model.ckpt\")\n\n    writer.close()\n\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\n        sess, sess.graph_def, [\"prediction\"])\n\n    tflite_model = tf.contrib.lite.toco_convert(\n        frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.FLOAT)\n\n    open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>Do I need to do something else when saving or restoring the graph parameters?</p>", "body_text": "Ok, so now the tf.contrib.quantize.create_eval_graph() is working:\n\nBut now I get an error when freezing the model (in the eval graph code, attached below, function convert_variables_to_constants):\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value weights_quant_2/min [[Node: _retval_weights_quant_2/min_0_16 = _Retval[T=DT_FLOAT, index=16, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights_quant_2/min)]]\nLooks like when I perform the restore from the checkpoint, the quantization nodes are not restored (but the weights and biases are correctly restored).\nHere's the new training code:\nlabel = tf.placeholder(tf.float32, shape=(1, num_classes), name='labels')\n\n# First layer\nhid1_size = 1000\nw1 = tf.Variable(tf.random_normal([train_X.shape[1], hid1_size], stddev=0.01), name='w1')\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\ny1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\"), keep_prob=0.5)\n\n# Second layer\nhid2_size = 1000\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\ny2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\"), keep_prob=0.5)\n\n# Output layer\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\n\n# Loss function and optimizer\n# lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label), name=\"loss\")\n\n# Call the training rewrite which rewrites the graph in-place with\n# FakeQuantization nodes and folds batchnorm for training. It is\n# often needed to fine tune a floating point model for quantization\n# with this training tool. When training from scratch, quant_delay\n# can be used to activate quantization after training to converge\n# with the float graph, effectively fine-tuning the model.\ntf.contrib.quantize.create_training_graph(quant_delay=50)\n\noptimizer = tf.train.AdamOptimizer().minimize(loss)\n\n# Prediction\npred = tf.nn.softmax(yo, name=\"prediction\")\npred_label = tf.argmax(pred, 1)\ncorrect_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n# Create operation which will initialize all variables\ninit = tf.global_variables_initializer()\n\n# Start a new tensorflow session and initialize variables\nsess = tf.Session()\n\nwriter = tf.summary.FileWriter(\"tensorboard\", sess.graph)\n\nsess.run(init)\n\nsaver = tf.train.Saver()\n\n# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another\n# 50 epochs with a smaller learning rate of 0.01\nfor epoch in range(10):\n    print(\"Epoch: {:3d}\".format(epoch))\n    avg_cost = 0.0\n\n    # For each epoch, we go through all the samples we have.\n    for i in tqdm.tqdm(range(train_X.shape[0])):\n        # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\n        _, c = sess.run([optimizer, loss], feed_dict={inputs: train_X[i, None],\n                                                      label: train_y[i, None]})\n        avg_cost += c\n    avg_cost /= train_X.shape[0]\n\n    # Print the cost in this epcho to the console.\n    if epoch % 10 == 0:\n        print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))\n\ngraph_path = os.path.join(\"models\", \"model.pbtxt\")\ncheckpoint_path = os.path.join(\"models\", \"model.ckpt\")\n\n# Save the checkpoint and eval graph proto to disk for freezing and providing to TFLite.\nwith open(graph_path, 'w') as f:\n    f.write(str(sess.graph.as_graph_def()))\n\nsaver.save(sess, checkpoint_path)\n\nwriter.close()\n\nAnd the eval graph code:\ninputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\n\n# First layer\nhid1_size = 1000\nw1 = tf.Variable(tf.random_normal([num_feat, hid1_size], stddev=0.01), name='w1')\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\ny1 = tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\")\n\n# Second layer\nhid2_size = 1000\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\ny2 = tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\")\n\n# Output layer\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\n\npred = tf.nn.softmax(yo, name=\"prediction\")\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    # Call the eval rewrite which rewrites the graph in-place with\n    # FakeQuantization nodes and fold batchnorm for eval.\n    tf.contrib.quantize.create_eval_graph()\n\n    writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\n\n    saver.restore(sess, \"models/model.ckpt\")\n\n    writer.close()\n\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\n        sess, sess.graph_def, [\"prediction\"])\n\n    tflite_model = tf.contrib.lite.toco_convert(\n        frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.FLOAT)\n\n    open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\n\nDo I need to do something else when saving or restoring the graph parameters?", "body": "Ok, so now the `tf.contrib.quantize.create_eval_graph()` is working:\r\n\r\n![image](https://user-images.githubusercontent.com/8360740/39800010-a5fb7766-5366-11e8-8378-42b87be5c99b.png)\r\n\r\nBut now I get an error when freezing the model (in the eval graph code, attached below, function `convert_variables_to_constants`):\r\n\r\n`tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value weights_quant_2/min\r\n\t [[Node: _retval_weights_quant_2/min_0_16 = _Retval[T=DT_FLOAT, index=16, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](weights_quant_2/min)]]`\r\n\r\nLooks like when I perform the restore from the checkpoint, the quantization nodes are not restored (but the weights and biases are correctly restored).\r\n\r\nHere's the new training code:\r\n\r\n```inputs = tf.placeholder(tf.float32, shape=(1, train_X.shape[1]), name='inputs')\r\nlabel = tf.placeholder(tf.float32, shape=(1, num_classes), name='labels')\r\n\r\n# First layer\r\nhid1_size = 1000\r\nw1 = tf.Variable(tf.random_normal([train_X.shape[1], hid1_size], stddev=0.01), name='w1')\r\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\r\ny1 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\"), keep_prob=0.5)\r\n\r\n# Second layer\r\nhid2_size = 1000\r\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\r\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\r\ny2 = tf.nn.dropout(tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\"), keep_prob=0.5)\r\n\r\n# Output layer\r\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\r\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\r\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\r\n\r\n# Loss function and optimizer\r\n# lr = tf.placeholder(tf.float32, shape=(), name='learning_rate')\r\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=yo, labels=label), name=\"loss\")\r\n\r\n# Call the training rewrite which rewrites the graph in-place with\r\n# FakeQuantization nodes and folds batchnorm for training. It is\r\n# often needed to fine tune a floating point model for quantization\r\n# with this training tool. When training from scratch, quant_delay\r\n# can be used to activate quantization after training to converge\r\n# with the float graph, effectively fine-tuning the model.\r\ntf.contrib.quantize.create_training_graph(quant_delay=50)\r\n\r\noptimizer = tf.train.AdamOptimizer().minimize(loss)\r\n\r\n# Prediction\r\npred = tf.nn.softmax(yo, name=\"prediction\")\r\npred_label = tf.argmax(pred, 1)\r\ncorrect_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(label, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\r\n\r\n# Create operation which will initialize all variables\r\ninit = tf.global_variables_initializer()\r\n\r\n# Start a new tensorflow session and initialize variables\r\nsess = tf.Session()\r\n\r\nwriter = tf.summary.FileWriter(\"tensorboard\", sess.graph)\r\n\r\nsess.run(init)\r\n\r\nsaver = tf.train.Saver()\r\n\r\n# This is the main training loop: we train for 50 epochs with a learning rate of 0.05 and another\r\n# 50 epochs with a smaller learning rate of 0.01\r\nfor epoch in range(10):\r\n    print(\"Epoch: {:3d}\".format(epoch))\r\n    avg_cost = 0.0\r\n\r\n    # For each epoch, we go through all the samples we have.\r\n    for i in tqdm.tqdm(range(train_X.shape[0])):\r\n        # Finally, this is where the magic happens: run our optimizer, feed the current example into X and the current target into Y\r\n        _, c = sess.run([optimizer, loss], feed_dict={inputs: train_X[i, None],\r\n                                                      label: train_y[i, None]})\r\n        avg_cost += c\r\n    avg_cost /= train_X.shape[0]\r\n\r\n    # Print the cost in this epcho to the console.\r\n    if epoch % 10 == 0:\r\n        print(\"Epoch: {:3d}    Train Cost: {:.4f}\".format(epoch, avg_cost))\r\n\r\ngraph_path = os.path.join(\"models\", \"model.pbtxt\")\r\ncheckpoint_path = os.path.join(\"models\", \"model.ckpt\")\r\n\r\n# Save the checkpoint and eval graph proto to disk for freezing and providing to TFLite.\r\nwith open(graph_path, 'w') as f:\r\n    f.write(str(sess.graph.as_graph_def()))\r\n\r\nsaver.save(sess, checkpoint_path)\r\n\r\nwriter.close()\r\n```\r\n\r\nAnd the eval graph code:\r\n\r\n```\r\ninputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\r\n\r\n# First layer\r\nhid1_size = 1000\r\nw1 = tf.Variable(tf.random_normal([num_feat, hid1_size], stddev=0.01), name='w1')\r\nb1 = tf.Variable(tf.constant(0.1, shape=(1, hid1_size)), name='b1')\r\ny1 = tf.nn.relu(tf.add(tf.matmul(inputs, w1), b1, name=\"layer1\"), \"activation1\")\r\n\r\n# Second layer\r\nhid2_size = 1000\r\nw2 = tf.Variable(tf.random_normal([hid1_size, hid2_size], stddev=0.01), name='w2')\r\nb2 = tf.Variable(tf.constant(0.1, shape=(1, hid2_size)), name='b2')\r\ny2 = tf.nn.relu(tf.add(tf.matmul(y1, w2), b2, name=\"layer2\"), name=\"activation2\")\r\n\r\n# Output layer\r\nwo = tf.Variable(tf.random_normal([hid2_size, num_classes], stddev=0.01), name='wo')\r\nbo = tf.Variable(tf.random_normal([1, num_classes]), name='bo')\r\nyo = tf.add(tf.matmul(y2, wo), bo, name=\"logits\")\r\n\r\npred = tf.nn.softmax(yo, name=\"prediction\")\r\n\r\nsaver = tf.train.Saver()\r\n\r\nwith tf.Session() as sess:\r\n    # Call the eval rewrite which rewrites the graph in-place with\r\n    # FakeQuantization nodes and fold batchnorm for eval.\r\n    tf.contrib.quantize.create_eval_graph()\r\n\r\n    writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\r\n\r\n    saver.restore(sess, \"models/model.ckpt\")\r\n\r\n    writer.close()\r\n\r\n    frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n        sess, sess.graph_def, [\"prediction\"])\r\n\r\n    tflite_model = tf.contrib.lite.toco_convert(\r\n        frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.FLOAT)\r\n\r\n    open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nDo I need to do something else when saving or restoring the graph parameters? \r\n"}