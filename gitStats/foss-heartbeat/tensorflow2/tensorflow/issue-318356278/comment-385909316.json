{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/385909316", "html_url": "https://github.com/tensorflow/tensorflow/issues/18919#issuecomment-385909316", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18919", "id": 385909316, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NTkwOTMxNg==", "user": {"login": "mjuvilla", "id": 8360740, "node_id": "MDQ6VXNlcjgzNjA3NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/8360740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjuvilla", "html_url": "https://github.com/mjuvilla", "followers_url": "https://api.github.com/users/mjuvilla/followers", "following_url": "https://api.github.com/users/mjuvilla/following{/other_user}", "gists_url": "https://api.github.com/users/mjuvilla/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjuvilla/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjuvilla/subscriptions", "organizations_url": "https://api.github.com/users/mjuvilla/orgs", "repos_url": "https://api.github.com/users/mjuvilla/repos", "events_url": "https://api.github.com/users/mjuvilla/events{/privacy}", "received_events_url": "https://api.github.com/users/mjuvilla/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-02T08:54:07Z", "updated_at": "2018-05-02T09:55:26Z", "author_association": "NONE", "body_html": "<p>So if I understand correctly, the correct training code is until the <code>saver.save(sess, checkpoint_path)</code> line. Then, I create a new file to create the eval graph and load the trained parameters:</p>\n<pre><code>import tensorflow as tf\n\n\ndef build_eval_model(num_feat, num_classes):\n    inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\n\n    # First layer\n    hid1_size = 128\n    w1 = tf.get_variable(\"w1\", [hid1_size, num_feat])\n    b1 = tf.get_variable(\"b1\", [hid1_size, 1])\n    y1 = tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1, name=\"layer1\"), \"activation1\")\n\n    # Second layer\n    hid2_size = 256\n    w2 = tf.get_variable(\"w2\", [hid2_size, hid1_size])\n    b2 = tf.get_variable(\"b2\", [hid2_size, 1])\n    y2 = tf.nn.relu(tf.add(tf.matmul(w2, y1), b2, name=\"layer2\"), name=\"activation2\")\n\n    # Output layer\n    wo = tf.get_variable(\"wo\", [num_classes, hid2_size])\n    bo = tf.get_variable(\"bo\", [num_classes, 1])\n    yo = tf.transpose(tf.add(tf.matmul(wo, y2), bo), name=\"logits\")\n\n    pred = tf.nn.softmax(yo, name=\"prediction\")\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\n\n        saver.restore(sess, \"models/model.ckpt\")\n\n        # Call the eval rewrite which rewrites the graph in-place with\n        # FakeQuantization nodes and fold batchnorm for eval.\n        tf.contrib.quantize.create_eval_graph()\n\n        writer.close()\n\n        frozen_graphdef = tf.graph_util.convert_variables_to_constants(\n            sess, sess.graph_def, [\"prediction\"])\n        tflite_model = tf.contrib.lite.toco_convert(\n            frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.QUANTIZED_UINT8,\n            quantized_input_stats=[(127.5, 127.5)])\n        open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>This is the eval graph:</p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/8360740/39517277-ae569240-4dff-11e8-8278-f8a68a202e46.png\"><img src=\"https://user-images.githubusercontent.com/8360740/39517277-ae569240-4dff-11e8-8278-f8a68a202e46.png\" alt=\"image\" style=\"max-width:100%;\"></a></p>\n<p>But I still get the same error. Maybe it's because I'm not restoring the quantization nodes, so when I call toco it doesn't know the min/max information? How to load this information?</p>\n<p>I think that this procedure should be explained more thoroughly in the documentation (for example here <a href=\"https://www.tensorflow.org/performance/quantization\" rel=\"nofollow\">https://www.tensorflow.org/performance/quantization</a>). Or is it explained somewhere else?</p>", "body_text": "So if I understand correctly, the correct training code is until the saver.save(sess, checkpoint_path) line. Then, I create a new file to create the eval graph and load the trained parameters:\nimport tensorflow as tf\n\n\ndef build_eval_model(num_feat, num_classes):\n    inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\n\n    # First layer\n    hid1_size = 128\n    w1 = tf.get_variable(\"w1\", [hid1_size, num_feat])\n    b1 = tf.get_variable(\"b1\", [hid1_size, 1])\n    y1 = tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1, name=\"layer1\"), \"activation1\")\n\n    # Second layer\n    hid2_size = 256\n    w2 = tf.get_variable(\"w2\", [hid2_size, hid1_size])\n    b2 = tf.get_variable(\"b2\", [hid2_size, 1])\n    y2 = tf.nn.relu(tf.add(tf.matmul(w2, y1), b2, name=\"layer2\"), name=\"activation2\")\n\n    # Output layer\n    wo = tf.get_variable(\"wo\", [num_classes, hid2_size])\n    bo = tf.get_variable(\"bo\", [num_classes, 1])\n    yo = tf.transpose(tf.add(tf.matmul(wo, y2), bo), name=\"logits\")\n\n    pred = tf.nn.softmax(yo, name=\"prediction\")\n\n    saver = tf.train.Saver()\n\n    with tf.Session() as sess:\n        writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\n\n        saver.restore(sess, \"models/model.ckpt\")\n\n        # Call the eval rewrite which rewrites the graph in-place with\n        # FakeQuantization nodes and fold batchnorm for eval.\n        tf.contrib.quantize.create_eval_graph()\n\n        writer.close()\n\n        frozen_graphdef = tf.graph_util.convert_variables_to_constants(\n            sess, sess.graph_def, [\"prediction\"])\n        tflite_model = tf.contrib.lite.toco_convert(\n            frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.QUANTIZED_UINT8,\n            quantized_input_stats=[(127.5, 127.5)])\n        open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\n\nThis is the eval graph:\n\nBut I still get the same error. Maybe it's because I'm not restoring the quantization nodes, so when I call toco it doesn't know the min/max information? How to load this information?\nI think that this procedure should be explained more thoroughly in the documentation (for example here https://www.tensorflow.org/performance/quantization). Or is it explained somewhere else?", "body": "So if I understand correctly, the correct training code is until the `saver.save(sess, checkpoint_path)` line. Then, I create a new file to create the eval graph and load the trained parameters:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef build_eval_model(num_feat, num_classes):\r\n    inputs = tf.placeholder(tf.float32, shape=(1, num_feat), name='inputs')\r\n\r\n    # First layer\r\n    hid1_size = 128\r\n    w1 = tf.get_variable(\"w1\", [hid1_size, num_feat])\r\n    b1 = tf.get_variable(\"b1\", [hid1_size, 1])\r\n    y1 = tf.nn.relu(tf.add(tf.matmul(w1, tf.transpose(inputs)), b1, name=\"layer1\"), \"activation1\")\r\n\r\n    # Second layer\r\n    hid2_size = 256\r\n    w2 = tf.get_variable(\"w2\", [hid2_size, hid1_size])\r\n    b2 = tf.get_variable(\"b2\", [hid2_size, 1])\r\n    y2 = tf.nn.relu(tf.add(tf.matmul(w2, y1), b2, name=\"layer2\"), name=\"activation2\")\r\n\r\n    # Output layer\r\n    wo = tf.get_variable(\"wo\", [num_classes, hid2_size])\r\n    bo = tf.get_variable(\"bo\", [num_classes, 1])\r\n    yo = tf.transpose(tf.add(tf.matmul(wo, y2), bo), name=\"logits\")\r\n\r\n    pred = tf.nn.softmax(yo, name=\"prediction\")\r\n\r\n    saver = tf.train.Saver()\r\n\r\n    with tf.Session() as sess:\r\n        writer = tf.summary.FileWriter(\"tensorboard_eval\", sess.graph)\r\n\r\n        saver.restore(sess, \"models/model.ckpt\")\r\n\r\n        # Call the eval rewrite which rewrites the graph in-place with\r\n        # FakeQuantization nodes and fold batchnorm for eval.\r\n        tf.contrib.quantize.create_eval_graph()\r\n\r\n        writer.close()\r\n\r\n        frozen_graphdef = tf.graph_util.convert_variables_to_constants(\r\n            sess, sess.graph_def, [\"prediction\"])\r\n        tflite_model = tf.contrib.lite.toco_convert(\r\n            frozen_graphdef, [inputs], [pred], inference_type=tf.contrib.lite.QUANTIZED_UINT8,\r\n            quantized_input_stats=[(127.5, 127.5)])\r\n        open(\"models/converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nThis is the eval graph:\r\n\r\n![image](https://user-images.githubusercontent.com/8360740/39517277-ae569240-4dff-11e8-8278-f8a68a202e46.png)\r\n\r\nBut I still get the same error. Maybe it's because I'm not restoring the quantization nodes, so when I call toco it doesn't know the min/max information? How to load this information?\r\n\r\nI think that this procedure should be explained more thoroughly in the documentation (for example here https://www.tensorflow.org/performance/quantization). Or is it explained somewhere else?\r\n"}