{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/389399933", "html_url": "https://github.com/tensorflow/tensorflow/issues/18919#issuecomment-389399933", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18919", "id": 389399933, "node_id": "MDEyOklzc3VlQ29tbWVudDM4OTM5OTkzMw==", "user": {"login": "nrothGIT", "id": 4956733, "node_id": "MDQ6VXNlcjQ5NTY3MzM=", "avatar_url": "https://avatars3.githubusercontent.com/u/4956733?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nrothGIT", "html_url": "https://github.com/nrothGIT", "followers_url": "https://api.github.com/users/nrothGIT/followers", "following_url": "https://api.github.com/users/nrothGIT/following{/other_user}", "gists_url": "https://api.github.com/users/nrothGIT/gists{/gist_id}", "starred_url": "https://api.github.com/users/nrothGIT/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nrothGIT/subscriptions", "organizations_url": "https://api.github.com/users/nrothGIT/orgs", "repos_url": "https://api.github.com/users/nrothGIT/repos", "events_url": "https://api.github.com/users/nrothGIT/events{/privacy}", "received_events_url": "https://api.github.com/users/nrothGIT/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-16T05:35:25Z", "updated_at": "2018-05-16T05:35:25Z", "author_association": "NONE", "body_html": "<p>I had a related follow up. I am following the pattern shown above. But when I restore a trained graph, and evaluate the 'preds', I seem to get substantially different (and worse) outputs than in my train graph. Is there some extra step I need to take to make the eval graph line up with the train graph for quantization? Or what is the best way to confirm that the eval graph quantization is working?</p>", "body_text": "I had a related follow up. I am following the pattern shown above. But when I restore a trained graph, and evaluate the 'preds', I seem to get substantially different (and worse) outputs than in my train graph. Is there some extra step I need to take to make the eval graph line up with the train graph for quantization? Or what is the best way to confirm that the eval graph quantization is working?", "body": "I had a related follow up. I am following the pattern shown above. But when I restore a trained graph, and evaluate the 'preds', I seem to get substantially different (and worse) outputs than in my train graph. Is there some extra step I need to take to make the eval graph line up with the train graph for quantization? Or what is the best way to confirm that the eval graph quantization is working?"}