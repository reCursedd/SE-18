{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6937", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6937/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6937/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6937/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6937", "id": 201659568, "node_id": "MDU6SXNzdWUyMDE2NTk1Njg=", "number": 6937, "title": "Confusing arg name for sequence_loss", "user": {"login": "Conchylicultor", "id": 9047355, "node_id": "MDQ6VXNlcjkwNDczNTU=", "avatar_url": "https://avatars1.githubusercontent.com/u/9047355?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Conchylicultor", "html_url": "https://github.com/Conchylicultor", "followers_url": "https://api.github.com/users/Conchylicultor/followers", "following_url": "https://api.github.com/users/Conchylicultor/following{/other_user}", "gists_url": "https://api.github.com/users/Conchylicultor/gists{/gist_id}", "starred_url": "https://api.github.com/users/Conchylicultor/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Conchylicultor/subscriptions", "organizations_url": "https://api.github.com/users/Conchylicultor/orgs", "repos_url": "https://api.github.com/users/Conchylicultor/repos", "events_url": "https://api.github.com/users/Conchylicultor/events{/privacy}", "received_events_url": "https://api.github.com/users/Conchylicultor/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-01-18T18:48:19Z", "updated_at": "2017-06-16T18:30:20Z", "closed_at": "2017-06-16T18:30:20Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Sorry if this is noise, but it's just a minor suggestion to make the API better (before the release of TensorFlow 1.0 where it will be much more difficult to change)</p>\n<p>For the function <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py\">sequence_loss</a> on the master branch, the name of the parameter <code>softmax_loss_function</code> seems to imply that only softmax based loss are compatible which is not true (for instance <code>tf.nn.sigmoid_cross_entropy_with_logits</code> works too). Maybe the name was that just to indicate the default behavior but I think it is misleading.</p>\n<p>Why not simply call the parameter <code>loss_function</code> ? It's more representative of what the parameter really does.</p>", "body_text": "Sorry if this is noise, but it's just a minor suggestion to make the API better (before the release of TensorFlow 1.0 where it will be much more difficult to change)\nFor the function sequence_loss on the master branch, the name of the parameter softmax_loss_function seems to imply that only softmax based loss are compatible which is not true (for instance tf.nn.sigmoid_cross_entropy_with_logits works too). Maybe the name was that just to indicate the default behavior but I think it is misleading.\nWhy not simply call the parameter loss_function ? It's more representative of what the parameter really does.", "body": "Sorry if this is noise, but it's just a minor suggestion to make the API better (before the release of TensorFlow 1.0 where it will be much more difficult to change)\r\n\r\nFor the function [sequence_loss](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py) on the master branch, the name of the parameter `softmax_loss_function` seems to imply that only softmax based loss are compatible which is not true (for instance `tf.nn.sigmoid_cross_entropy_with_logits` works too). Maybe the name was that just to indicate the default behavior but I think it is misleading.\r\n\r\nWhy not simply call the parameter `loss_function` ? It's more representative of what the parameter really does."}