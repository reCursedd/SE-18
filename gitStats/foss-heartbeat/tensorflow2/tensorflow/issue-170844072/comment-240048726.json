{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/240048726", "html_url": "https://github.com/tensorflow/tensorflow/issues/3766#issuecomment-240048726", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3766", "id": 240048726, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MDA0ODcyNg==", "user": {"login": "bixiongxu", "id": 20988542, "node_id": "MDQ6VXNlcjIwOTg4NTQy", "avatar_url": "https://avatars1.githubusercontent.com/u/20988542?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bixiongxu", "html_url": "https://github.com/bixiongxu", "followers_url": "https://api.github.com/users/bixiongxu/followers", "following_url": "https://api.github.com/users/bixiongxu/following{/other_user}", "gists_url": "https://api.github.com/users/bixiongxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/bixiongxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bixiongxu/subscriptions", "organizations_url": "https://api.github.com/users/bixiongxu/orgs", "repos_url": "https://api.github.com/users/bixiongxu/repos", "events_url": "https://api.github.com/users/bixiongxu/events{/privacy}", "received_events_url": "https://api.github.com/users/bixiongxu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-16T09:14:04Z", "updated_at": "2016-08-16T09:14:04Z", "author_association": "NONE", "body_html": "<p>I try another partitioner:  <strong>tf.min_max_variable_partitioner(max_partitions=50, axis=0,min_slice_size=8 &lt;&lt; 10)</strong> , got same crash on worker 0.<br>\nI printed the partitioned variables, they seems to be disposed properly, as below:<br>\nsoulmate/proj_w/part_6:0<br>\nsoulmate/proj_w/part_7:0<br>\nsoulmate/proj_w/part_8:0<br>\nsoulmate/proj_w/part_9:0<br>\nsoulmate/proj_w/part_10:0<br>\nsoulmate/proj_w/part_11:0<br>\nsoulmate/proj_w/part_12:0<br>\n.......<br>\n(These are printed after \"with sv.managed_session(server.target) as sess:\", so the session is initialized successfully. )</p>\n<p>Work 0 and Work 1 printed the params with the same name. But still only worker 1 started training and woker 0 crashed.</p>\n<p>According to my tryings, I doubt the root cause is not the 2G limit of protobuf, reasons:</p>\n<ol>\n<li>Only worker 0 crashed. If we hit 2G limit, worker1 should has the same problem. But worker 1 can run normally on big RNN while worker 0 cannot.</li>\n<li>Worker 0 always crash on the first <strong>session.run</strong>, if I set the saver/summary_op/global_step in the supervisor, it will crash on the <strong>prepare_or_wait_for_session</strong> in which session will run global_step.</li>\n<li>Smaller RNN can run fresh params with no problem, but when restoring from ckpt,  worker 0 crashes everytime with same exception, no matter big or small.</li>\n<li>Worker 0 spends 2x time to run every step ( in small RNN ). I suppose worker 0 is doing some extra job or holding a lower priority lock on the params?</li>\n<li>The interval between worker 0 starting and crashing is always about 25 minutes.... so, is there any timeout?</li>\n</ol>\n<p>So the problem might exist in the <strong>extra job</strong> of worker 0, not saver and summary because I have not used them. Do you have some clues?</p>", "body_text": "I try another partitioner:  tf.min_max_variable_partitioner(max_partitions=50, axis=0,min_slice_size=8 << 10) , got same crash on worker 0.\nI printed the partitioned variables, they seems to be disposed properly, as below:\nsoulmate/proj_w/part_6:0\nsoulmate/proj_w/part_7:0\nsoulmate/proj_w/part_8:0\nsoulmate/proj_w/part_9:0\nsoulmate/proj_w/part_10:0\nsoulmate/proj_w/part_11:0\nsoulmate/proj_w/part_12:0\n.......\n(These are printed after \"with sv.managed_session(server.target) as sess:\", so the session is initialized successfully. )\nWork 0 and Work 1 printed the params with the same name. But still only worker 1 started training and woker 0 crashed.\nAccording to my tryings, I doubt the root cause is not the 2G limit of protobuf, reasons:\n\nOnly worker 0 crashed. If we hit 2G limit, worker1 should has the same problem. But worker 1 can run normally on big RNN while worker 0 cannot.\nWorker 0 always crash on the first session.run, if I set the saver/summary_op/global_step in the supervisor, it will crash on the prepare_or_wait_for_session in which session will run global_step.\nSmaller RNN can run fresh params with no problem, but when restoring from ckpt,  worker 0 crashes everytime with same exception, no matter big or small.\nWorker 0 spends 2x time to run every step ( in small RNN ). I suppose worker 0 is doing some extra job or holding a lower priority lock on the params?\nThe interval between worker 0 starting and crashing is always about 25 minutes.... so, is there any timeout?\n\nSo the problem might exist in the extra job of worker 0, not saver and summary because I have not used them. Do you have some clues?", "body": "I try another partitioner:  **tf.min_max_variable_partitioner(max_partitions=50, axis=0,min_slice_size=8 << 10)** , got same crash on worker 0. \nI printed the partitioned variables, they seems to be disposed properly, as below: \nsoulmate/proj_w/part_6:0\nsoulmate/proj_w/part_7:0\nsoulmate/proj_w/part_8:0\nsoulmate/proj_w/part_9:0\nsoulmate/proj_w/part_10:0\nsoulmate/proj_w/part_11:0\nsoulmate/proj_w/part_12:0\n.......\n(These are printed after \"with sv.managed_session(server.target) as sess:\", so the session is initialized successfully. )\n\nWork 0 and Work 1 printed the params with the same name. But still only worker 1 started training and woker 0 crashed. \n\nAccording to my tryings, I doubt the root cause is not the 2G limit of protobuf, reasons: \n1. Only worker 0 crashed. If we hit 2G limit, worker1 should has the same problem. But worker 1 can run normally on big RNN while worker 0 cannot. \n2. Worker 0 always crash on the first **session.run**, if I set the saver/summary_op/global_step in the supervisor, it will crash on the **prepare_or_wait_for_session** in which session will run global_step. \n3. Smaller RNN can run fresh params with no problem, but when restoring from ckpt,  worker 0 crashes everytime with same exception, no matter big or small. \n4. Worker 0 spends 2x time to run every step ( in small RNN ). I suppose worker 0 is doing some extra job or holding a lower priority lock on the params?  \n5. The interval between worker 0 starting and crashing is always about 25 minutes.... so, is there any timeout? \n\nSo the problem might exist in the **extra job** of worker 0, not saver and summary because I have not used them. Do you have some clues? \n"}