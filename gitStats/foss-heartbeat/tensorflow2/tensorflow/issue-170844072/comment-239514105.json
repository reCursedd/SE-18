{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/239514105", "html_url": "https://github.com/tensorflow/tensorflow/issues/3766#issuecomment-239514105", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3766", "id": 239514105, "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTUxNDEwNQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-12T17:49:13Z", "updated_at": "2016-08-12T17:49:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p>The current recommend workaround to the 2GB limit is to use a <a href=\"https://www.tensorflow.org/versions/r0.10/api_docs/python/state_ops.html#variable-partitioners-for-sharding\" rel=\"nofollow\">variable partitioner</a> that splits the variable transfer into multiple smaller transfers.</p>\n<p>Getting an exception in a worker when you call a PS task that it's using is expected behavior. A typical distributed deployment using <code>tf.train.Supervisor</code> (e.g. on Kubernetes) will automatically restart any process when it fails.</p>", "body_text": "The current recommend workaround to the 2GB limit is to use a variable partitioner that splits the variable transfer into multiple smaller transfers.\nGetting an exception in a worker when you call a PS task that it's using is expected behavior. A typical distributed deployment using tf.train.Supervisor (e.g. on Kubernetes) will automatically restart any process when it fails.", "body": "The current recommend workaround to the 2GB limit is to use a [variable partitioner](https://www.tensorflow.org/versions/r0.10/api_docs/python/state_ops.html#variable-partitioners-for-sharding) that splits the variable transfer into multiple smaller transfers.\n\nGetting an exception in a worker when you call a PS task that it's using is expected behavior. A typical distributed deployment using `tf.train.Supervisor` (e.g. on Kubernetes) will automatically restart any process when it fails.\n"}