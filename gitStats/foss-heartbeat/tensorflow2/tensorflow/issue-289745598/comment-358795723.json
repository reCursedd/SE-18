{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358795723", "html_url": "https://github.com/tensorflow/tensorflow/issues/16226#issuecomment-358795723", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16226", "id": 358795723, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODc5NTcyMw==", "user": {"login": "jswelch", "id": 35576504, "node_id": "MDQ6VXNlcjM1NTc2NTA0", "avatar_url": "https://avatars3.githubusercontent.com/u/35576504?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jswelch", "html_url": "https://github.com/jswelch", "followers_url": "https://api.github.com/users/jswelch/followers", "following_url": "https://api.github.com/users/jswelch/following{/other_user}", "gists_url": "https://api.github.com/users/jswelch/gists{/gist_id}", "starred_url": "https://api.github.com/users/jswelch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jswelch/subscriptions", "organizations_url": "https://api.github.com/users/jswelch/orgs", "repos_url": "https://api.github.com/users/jswelch/repos", "events_url": "https://api.github.com/users/jswelch/events{/privacy}", "received_events_url": "https://api.github.com/users/jswelch/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-18T22:00:02Z", "updated_at": "2018-01-18T22:00:02Z", "author_association": "NONE", "body_html": "<p>The use case is running Distributed Tensorflow in a grid or cluster of compute nodes where there will be multiple users submitting work.  In order to start the Distributed Tensorflow job, you need to know the PS and WORK ports up front to launch any of the tasks.  Here is my example below:</p>\n<p>compute1: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=ps --task_index=0<br>\ncompute2: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=1<br>\ncompute3: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=2<br>\ncompute4: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=3</p>\n<p>Trying to avoid the same ports being used by a different user or another application across multiple compute nodes is not easy.   A better request for change might be to have Distributed Tensorflow work similar to MPI (Message Passing Interface) where I believe with MPI the worker tasks start with the port for the Server/PS port and the work task finds an open port and sends it to the Server/PS.</p>\n<p>Is this helpful?</p>", "body_text": "The use case is running Distributed Tensorflow in a grid or cluster of compute nodes where there will be multiple users submitting work.  In order to start the Distributed Tensorflow job, you need to know the PS and WORK ports up front to launch any of the tasks.  Here is my example below:\ncompute1: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=ps --task_index=0\ncompute2: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=1\ncompute3: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=2\ncompute4: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=3\nTrying to avoid the same ports being used by a different user or another application across multiple compute nodes is not easy.   A better request for change might be to have Distributed Tensorflow work similar to MPI (Message Passing Interface) where I believe with MPI the worker tasks start with the port for the Server/PS port and the work task finds an open port and sends it to the Server/PS.\nIs this helpful?", "body": "The use case is running Distributed Tensorflow in a grid or cluster of compute nodes where there will be multiple users submitting work.  In order to start the Distributed Tensorflow job, you need to know the PS and WORK ports up front to launch any of the tasks.  Here is my example below:\r\n\r\ncompute1: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=ps --task_index=0\r\ncompute2: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=1\r\ncompute3: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=2\r\ncompute4: trainer.py --ps_hosts=compute1:52758 --worker_hosts=compute1:52759,compute2:52759,compute3:52759,compute4:52759 --job_name=worker --task_index=3\r\n\r\nTrying to avoid the same ports being used by a different user or another application across multiple compute nodes is not easy.   A better request for change might be to have Distributed Tensorflow work similar to MPI (Message Passing Interface) where I believe with MPI the worker tasks start with the port for the Server/PS port and the work task finds an open port and sends it to the Server/PS.    \r\n\r\nIs this helpful?\r\n"}