{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17155", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17155/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17155/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17155/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17155", "id": 298705811, "node_id": "MDU6SXNzdWUyOTg3MDU4MTE=", "number": 17155, "title": "Memory leak in tf.unique on GPU", "user": {"login": "dantkz", "id": 5220571, "node_id": "MDQ6VXNlcjUyMjA1NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/5220571?v=4", "gravatar_id": "", "url": "https://api.github.com/users/dantkz", "html_url": "https://github.com/dantkz", "followers_url": "https://api.github.com/users/dantkz/followers", "following_url": "https://api.github.com/users/dantkz/following{/other_user}", "gists_url": "https://api.github.com/users/dantkz/gists{/gist_id}", "starred_url": "https://api.github.com/users/dantkz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/dantkz/subscriptions", "organizations_url": "https://api.github.com/users/dantkz/orgs", "repos_url": "https://api.github.com/users/dantkz/repos", "events_url": "https://api.github.com/users/dantkz/events{/privacy}", "received_events_url": "https://api.github.com/users/dantkz/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shivaniag", "id": 16565716, "node_id": "MDQ6VXNlcjE2NTY1NzE2", "avatar_url": "https://avatars1.githubusercontent.com/u/16565716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shivaniag", "html_url": "https://github.com/shivaniag", "followers_url": "https://api.github.com/users/shivaniag/followers", "following_url": "https://api.github.com/users/shivaniag/following{/other_user}", "gists_url": "https://api.github.com/users/shivaniag/gists{/gist_id}", "starred_url": "https://api.github.com/users/shivaniag/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shivaniag/subscriptions", "organizations_url": "https://api.github.com/users/shivaniag/orgs", "repos_url": "https://api.github.com/users/shivaniag/repos", "events_url": "https://api.github.com/users/shivaniag/events{/privacy}", "received_events_url": "https://api.github.com/users/shivaniag/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 9, "created_at": "2018-02-20T18:46:37Z", "updated_at": "2018-11-20T13:26:33Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System 1 information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.4.0</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0/6.0</li>\n<li><strong>GPU model and memory</strong>: GeForce GTX TITAN, 6Gb</li>\n<li><strong>Exact command to reproduce</strong>: n/a</li>\n</ul>\n<h3>System 2 information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.0-dev20180219</li>\n<li><strong>Python version</strong>: 3.6.1</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.0</li>\n<li><strong>GPU model and memory</strong>: TITAN X (Pascal), 12Gb</li>\n<li><strong>Exact command to reproduce</strong>: n/a</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>The <code>tf.unique</code> op leaks memory when it is placed on GPU.<br>\nI wrote a simple script (below) that runs a couple of <code>tf.unique</code> ops. I track the memory usage with <code>psutil.Process(getpid()).memory_info().rss</code> command. I ran the script on System 1 twice: once on CPU and GPU (specified by <code>tf.device</code>), for <code>num_steps=2000</code>. Here is the plot of the memory usage:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/5220571/36442332-583efeb6-166d-11e8-960f-b7bb4990a9a8.png\"><img src=\"https://user-images.githubusercontent.com/5220571/36442332-583efeb6-166d-11e8-960f-b7bb4990a9a8.png\" alt=\"mem_usage1\" style=\"max-width:100%;\"></a></p>\n<p>So, the memory usage of <code>CPU unique</code> is pretty flat, but the <code>GPU unique</code> is inconclusive. Here is the memory usage on System 1 with <code>num_steps=10000</code>:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/5220571/36442382-88e30238-166d-11e8-8a39-624a80676267.png\"><img src=\"https://user-images.githubusercontent.com/5220571/36442382-88e30238-166d-11e8-8a39-624a80676267.png\" alt=\"mem_usage2\" style=\"max-width:100%;\"></a></p>\n<p>Relatively recent version of tensorflow (System 2) also has the problem:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/5220571/36442531-07075100-166e-11e8-84e4-0103c7e4de72.png\"><img src=\"https://user-images.githubusercontent.com/5220571/36442531-07075100-166e-11e8-84e4-0103c7e4de72.png\" alt=\"mem_usage3\" style=\"max-width:100%;\"></a></p>\n<h3>Source code / logs</h3>\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport psutil\nfrom os import getpid\n\nval_num = 8*256*256\nval_dim = 5\nmax_val = 200\nnum_steps = 10000\n\n\ndef main():\n\n    with tf.device(\"/gpu:0\"):\n        x = tf.placeholder(tf.int32, [val_num, val_dim])\n    \n        def tf_unique_row_idxs(inp, max_dim=None, name=''):\n            with tf.variable_scope('tf_unique_row_idxs_'+name) as scope:\n                if not max_dim:\n                    max_dim = inp.get_shape().as_list()[1]\n                new_vals = inp[:,0]\n                new_vals = tf.cast(new_vals, dtype=tf.int32)\n                _, idx = tf.unique(new_vals, out_idx=tf.int32)\n                for j in range(1, max_dim):\n                    new_vals = inp[:,j]\n                    new_vals = tf.cast(new_vals, dtype=tf.int32)\n                    val_min = tf.reduce_min(new_vals)\n                    val_max = tf.reduce_max(new_vals)\n                    idx_shift = val_max - val_min + 1\n                    vals = idx*idx_shift + new_vals - val_min\n                    uvals, idx = tf.unique(vals, out_idx=tf.int32)\n                max_pos = tf.shape(uvals, out_type=tf.int32)[0] + 0\n                return idx, max_pos\n    \n        idxs, max_pos = tf_unique_row_idxs(x)\n    \n    \n    process = psutil.Process(getpid())\n\n    cur_config=tf.ConfigProto(allow_soft_placement=False,log_device_placement=False)\n    sess = tf.Session(config=cur_config)\n    sess.run(tf.global_variables_initializer())\n    \n\n    mem_usage = np.zeros([num_steps], dtype=np.float32)\n\n    np.random.seed(0)\n    for i in range(num_steps):\n        cur_x = np.random.randint(0, max_val, [val_num, val_dim], dtype=np.int32)\n        cur_feed_dict = {x: cur_x}\n        cur_max_pos, cur_idxs = sess.run([max_pos, idxs], feed_dict=cur_feed_dict)\n        mem_usage[i] = process.memory_info().rss/2**30\n        if i%100==0:\n            print(i/num_steps)\n    \n\n    np.savetxt('unique_memlog.txt', mem_usage)\n\nif __name__ == \"__main__\":\n    main()\n\n</code></pre>", "body_text": "System 1 information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.4.0\nPython version: 3.5.2\nBazel version (if compiling from source): n/a\nCUDA/cuDNN version: 8.0/6.0\nGPU model and memory: GeForce GTX TITAN, 6Gb\nExact command to reproduce: n/a\n\nSystem 2 information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.7.0-dev20180219\nPython version: 3.6.1\nBazel version (if compiling from source): n/a\nCUDA/cuDNN version: 9.0/7.0\nGPU model and memory: TITAN X (Pascal), 12Gb\nExact command to reproduce: n/a\n\nDescribe the problem\nThe tf.unique op leaks memory when it is placed on GPU.\nI wrote a simple script (below) that runs a couple of tf.unique ops. I track the memory usage with psutil.Process(getpid()).memory_info().rss command. I ran the script on System 1 twice: once on CPU and GPU (specified by tf.device), for num_steps=2000. Here is the plot of the memory usage:\n\nSo, the memory usage of CPU unique is pretty flat, but the GPU unique is inconclusive. Here is the memory usage on System 1 with num_steps=10000:\n\nRelatively recent version of tensorflow (System 2) also has the problem:\n\nSource code / logs\nimport tensorflow as tf\nimport numpy as np\nimport psutil\nfrom os import getpid\n\nval_num = 8*256*256\nval_dim = 5\nmax_val = 200\nnum_steps = 10000\n\n\ndef main():\n\n    with tf.device(\"/gpu:0\"):\n        x = tf.placeholder(tf.int32, [val_num, val_dim])\n    \n        def tf_unique_row_idxs(inp, max_dim=None, name=''):\n            with tf.variable_scope('tf_unique_row_idxs_'+name) as scope:\n                if not max_dim:\n                    max_dim = inp.get_shape().as_list()[1]\n                new_vals = inp[:,0]\n                new_vals = tf.cast(new_vals, dtype=tf.int32)\n                _, idx = tf.unique(new_vals, out_idx=tf.int32)\n                for j in range(1, max_dim):\n                    new_vals = inp[:,j]\n                    new_vals = tf.cast(new_vals, dtype=tf.int32)\n                    val_min = tf.reduce_min(new_vals)\n                    val_max = tf.reduce_max(new_vals)\n                    idx_shift = val_max - val_min + 1\n                    vals = idx*idx_shift + new_vals - val_min\n                    uvals, idx = tf.unique(vals, out_idx=tf.int32)\n                max_pos = tf.shape(uvals, out_type=tf.int32)[0] + 0\n                return idx, max_pos\n    \n        idxs, max_pos = tf_unique_row_idxs(x)\n    \n    \n    process = psutil.Process(getpid())\n\n    cur_config=tf.ConfigProto(allow_soft_placement=False,log_device_placement=False)\n    sess = tf.Session(config=cur_config)\n    sess.run(tf.global_variables_initializer())\n    \n\n    mem_usage = np.zeros([num_steps], dtype=np.float32)\n\n    np.random.seed(0)\n    for i in range(num_steps):\n        cur_x = np.random.randint(0, max_val, [val_num, val_dim], dtype=np.int32)\n        cur_feed_dict = {x: cur_x}\n        cur_max_pos, cur_idxs = sess.run([max_pos, idxs], feed_dict=cur_feed_dict)\n        mem_usage[i] = process.memory_info().rss/2**30\n        if i%100==0:\n            print(i/num_steps)\n    \n\n    np.savetxt('unique_memlog.txt', mem_usage)\n\nif __name__ == \"__main__\":\n    main()", "body": "### System 1 information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: GeForce GTX TITAN, 6Gb\r\n- **Exact command to reproduce**: n/a\r\n\r\n### System 2 information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0-dev20180219\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: TITAN X (Pascal), 12Gb\r\n- **Exact command to reproduce**: n/a\r\n\r\n### Describe the problem\r\nThe `tf.unique` op leaks memory when it is placed on GPU. \r\nI wrote a simple script (below) that runs a couple of `tf.unique` ops. I track the memory usage with `psutil.Process(getpid()).memory_info().rss` command. I ran the script on System 1 twice: once on CPU and GPU (specified by `tf.device`), for `num_steps=2000`. Here is the plot of the memory usage:\r\n![mem_usage1](https://user-images.githubusercontent.com/5220571/36442332-583efeb6-166d-11e8-960f-b7bb4990a9a8.png)\r\n\r\nSo, the memory usage of `CPU unique` is pretty flat, but the `GPU unique` is inconclusive. Here is the memory usage on System 1 with `num_steps=10000`:\r\n![mem_usage2](https://user-images.githubusercontent.com/5220571/36442382-88e30238-166d-11e8-8a39-624a80676267.png)\r\n\r\nRelatively recent version of tensorflow (System 2) also has the problem:\r\n![mem_usage3](https://user-images.githubusercontent.com/5220571/36442531-07075100-166e-11e8-84e4-0103c7e4de72.png)\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport psutil\r\nfrom os import getpid\r\n\r\nval_num = 8*256*256\r\nval_dim = 5\r\nmax_val = 200\r\nnum_steps = 10000\r\n\r\n\r\ndef main():\r\n\r\n    with tf.device(\"/gpu:0\"):\r\n        x = tf.placeholder(tf.int32, [val_num, val_dim])\r\n    \r\n        def tf_unique_row_idxs(inp, max_dim=None, name=''):\r\n            with tf.variable_scope('tf_unique_row_idxs_'+name) as scope:\r\n                if not max_dim:\r\n                    max_dim = inp.get_shape().as_list()[1]\r\n                new_vals = inp[:,0]\r\n                new_vals = tf.cast(new_vals, dtype=tf.int32)\r\n                _, idx = tf.unique(new_vals, out_idx=tf.int32)\r\n                for j in range(1, max_dim):\r\n                    new_vals = inp[:,j]\r\n                    new_vals = tf.cast(new_vals, dtype=tf.int32)\r\n                    val_min = tf.reduce_min(new_vals)\r\n                    val_max = tf.reduce_max(new_vals)\r\n                    idx_shift = val_max - val_min + 1\r\n                    vals = idx*idx_shift + new_vals - val_min\r\n                    uvals, idx = tf.unique(vals, out_idx=tf.int32)\r\n                max_pos = tf.shape(uvals, out_type=tf.int32)[0] + 0\r\n                return idx, max_pos\r\n    \r\n        idxs, max_pos = tf_unique_row_idxs(x)\r\n    \r\n    \r\n    process = psutil.Process(getpid())\r\n\r\n    cur_config=tf.ConfigProto(allow_soft_placement=False,log_device_placement=False)\r\n    sess = tf.Session(config=cur_config)\r\n    sess.run(tf.global_variables_initializer())\r\n    \r\n\r\n    mem_usage = np.zeros([num_steps], dtype=np.float32)\r\n\r\n    np.random.seed(0)\r\n    for i in range(num_steps):\r\n        cur_x = np.random.randint(0, max_val, [val_num, val_dim], dtype=np.int32)\r\n        cur_feed_dict = {x: cur_x}\r\n        cur_max_pos, cur_idxs = sess.run([max_pos, idxs], feed_dict=cur_feed_dict)\r\n        mem_usage[i] = process.memory_info().rss/2**30\r\n        if i%100==0:\r\n            print(i/num_steps)\r\n    \r\n\r\n    np.savetxt('unique_memlog.txt', mem_usage)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n"}