{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/286001687", "html_url": "https://github.com/tensorflow/tensorflow/issues/2807#issuecomment-286001687", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2807", "id": 286001687, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjAwMTY4Nw==", "user": {"login": "maydaygmail", "id": 3124643, "node_id": "MDQ6VXNlcjMxMjQ2NDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/3124643?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maydaygmail", "html_url": "https://github.com/maydaygmail", "followers_url": "https://api.github.com/users/maydaygmail/followers", "following_url": "https://api.github.com/users/maydaygmail/following{/other_user}", "gists_url": "https://api.github.com/users/maydaygmail/gists{/gist_id}", "starred_url": "https://api.github.com/users/maydaygmail/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maydaygmail/subscriptions", "organizations_url": "https://api.github.com/users/maydaygmail/orgs", "repos_url": "https://api.github.com/users/maydaygmail/repos", "events_url": "https://api.github.com/users/maydaygmail/events{/privacy}", "received_events_url": "https://api.github.com/users/maydaygmail/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-13T02:31:51Z", "updated_at": "2017-03-13T03:03:15Z", "author_association": "NONE", "body_html": "<p>I have the similar problem. I quantify my own cnn model, before quantization, the size of model is 11M, and inference takes 72 ms per 128 small images; after quantization, size become 2.8M, but takes 236ms. I run the experiment in OS X ,2.6 GHz Intel Core i5.</p>", "body_text": "I have the similar problem. I quantify my own cnn model, before quantization, the size of model is 11M, and inference takes 72 ms per 128 small images; after quantization, size become 2.8M, but takes 236ms. I run the experiment in OS X ,2.6 GHz Intel Core i5.", "body": "I have the similar problem. I quantify my own cnn model, before quantization, the size of model is 11M, and inference takes 72 ms per 128 small images; after quantization, size become 2.8M, but takes 236ms. I run the experiment in OS X ,2.6 GHz Intel Core i5. "}