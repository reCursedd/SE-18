{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357905159", "html_url": "https://github.com/tensorflow/tensorflow/issues/2807#issuecomment-357905159", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2807", "id": 357905159, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzkwNTE1OQ==", "user": {"login": "MarkSonn", "id": 7654904, "node_id": "MDQ6VXNlcjc2NTQ5MDQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/7654904?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkSonn", "html_url": "https://github.com/MarkSonn", "followers_url": "https://api.github.com/users/MarkSonn/followers", "following_url": "https://api.github.com/users/MarkSonn/following{/other_user}", "gists_url": "https://api.github.com/users/MarkSonn/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkSonn/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkSonn/subscriptions", "organizations_url": "https://api.github.com/users/MarkSonn/orgs", "repos_url": "https://api.github.com/users/MarkSonn/repos", "events_url": "https://api.github.com/users/MarkSonn/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkSonn/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-16T09:40:54Z", "updated_at": "2018-01-28T15:11:49Z", "author_association": "NONE", "body_html": "<p>Does anyone know which GPUs are optimised for 8 bit calculations? The best info I have found so far is <a href=\"https://www.microway.com/knowledge-center-articles/comparison-of-nvidia-geforce-gpus-and-nvidia-tesla-gpus/\" rel=\"nofollow\">this article</a> which compares the floating point performance between 64 bit and 16 bit operations. I'm sort of extrapolating that GPUs which had a decrease in performance on 16 bits would have a further decrease with 8 bits, and those with an increase <em>might</em> have a further increase on 8 bits. I hope this helps, but I would appreciate confirmation from someone :)</p>", "body_text": "Does anyone know which GPUs are optimised for 8 bit calculations? The best info I have found so far is this article which compares the floating point performance between 64 bit and 16 bit operations. I'm sort of extrapolating that GPUs which had a decrease in performance on 16 bits would have a further decrease with 8 bits, and those with an increase might have a further increase on 8 bits. I hope this helps, but I would appreciate confirmation from someone :)", "body": "Does anyone know which GPUs are optimised for 8 bit calculations? The best info I have found so far is [this article](https://www.microway.com/knowledge-center-articles/comparison-of-nvidia-geforce-gpus-and-nvidia-tesla-gpus/) which compares the floating point performance between 64 bit and 16 bit operations. I'm sort of extrapolating that GPUs which had a decrease in performance on 16 bits would have a further decrease with 8 bits, and those with an increase *might* have a further increase on 8 bits. I hope this helps, but I would appreciate confirmation from someone :)"}