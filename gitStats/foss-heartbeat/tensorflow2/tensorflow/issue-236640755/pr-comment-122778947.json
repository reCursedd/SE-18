{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/122778947", "pull_request_review_id": 44891947, "id": 122778947, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMjc3ODk0Nw==", "diff_hunk": "@@ -0,0 +1,123 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef TENSORFLOW_KERNELS_TILE_FUNCTOR_H_\n+#define TENSORFLOW_KERNELS_TILE_FUNCTOR_H_\n+\n+#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_types.h\"\n+#include \"tensorflow/core/platform/types.h\"\n+\n+namespace tensorflow {\n+\n+namespace {\n+\n+// Helper to compute 'strides' given a tensor 'shape'. I.e.,\n+// strides[i] = prod(shape.dim_size[(i+1):])\n+template <typename Index>\n+void ComputeStride(const TensorShape& shape, Index* strides) {\n+  const int ndims = shape.dims();\n+  Index stride = 1;\n+  for (int i = ndims - 1; i >= 0; --i) {\n+    strides[i] = stride;\n+    stride *= static_cast<Index>(shape.dim_size(i));\n+  }\n+}\n+\n+}  // end namespace\n+\n+namespace internal {\n+\n+// Device-specific naive implementation for tile.\n+template <typename Device, typename T>\n+void TileSimple(const Device& d, Tensor* out, const Tensor& in);\n+\n+template <typename Device, typename T, int NDIM>\n+void TileUsingEigen(const Device& d, Tensor* out, const Tensor& in,\n+                    const gtl::ArraySlice<int32>& broadcast_array) {\n+  auto x = typename TTypes<T, NDIM>::ConstTensor(\n+      reinterpret_cast<const T*>(in.tensor_data().data()),\n+      in.shape().AsEigenDSizes<NDIM>());\n+  auto y = typename TTypes<T, NDIM>::Tensor(\n+      reinterpret_cast<T*>(const_cast<char*>(out->tensor_data().data())),\n+      out->shape().AsEigenDSizes<NDIM>());\n+  Eigen::array<int32, NDIM> b;\n+  for (int i = 0; i < NDIM; ++i) b[i] = broadcast_array[i];\n+  if (Eigen::internal::is_same<Device, Eigen::GpuDevice>::value) {\n+    // Use 32bit indexing to speed up the computations\n+    To32Bit(y).device(d) = To32Bit(x).broadcast(b);\n+  } else {\n+    y.device(d) = x.broadcast(b);\n+  }\n+}\n+\n+template <typename Device, typename T>\n+void TileUsingEigen(const Device& d, Tensor* out, const Tensor& in,\n+                    const gtl::ArraySlice<int32>&) {\n+  auto x = typename TTypes<T, 0>::ConstTensor(\n+      reinterpret_cast<const T*>(in.tensor_data().data()),\n+      in.shape().AsEigenDSizes<0>());\n+  auto y = typename TTypes<T, 0>::Tensor(\n+      reinterpret_cast<T*>(const_cast<char*>(out->tensor_data().data())),\n+      out->shape().AsEigenDSizes<0>());\n+  // In the scalar case we simply copy the input.\n+  y.device(d) = x;\n+}\n+\n+}  // end namespace internal", "path": "tensorflow/core/kernels/tile_functor.h", "position": 72, "original_position": 80, "commit_id": "e640d75bc6dd1f9a3990c4e199d36f67c5f98bcd", "original_commit_id": "87370bc46d4f7192eb780947259acee4b7355914", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "body": "Why are some helper functions in an unnamed namespace and some in `internal`?  Is the distinction significant?", "created_at": "2017-06-19T17:57:54Z", "updated_at": "2017-06-23T03:53:43Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/10793#discussion_r122778947", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10793", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/122778947"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/10793#discussion_r122778947"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10793"}}, "body_html": "<p>Why are some helper functions in an unnamed namespace and some in <code>internal</code>?  Is the distinction significant?</p>", "body_text": "Why are some helper functions in an unnamed namespace and some in internal?  Is the distinction significant?"}