{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/287053547", "html_url": "https://github.com/tensorflow/tensorflow/issues/8351#issuecomment-287053547", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8351", "id": 287053547, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NzA1MzU0Nw==", "user": {"login": "bluekingsong", "id": 2830940, "node_id": "MDQ6VXNlcjI4MzA5NDA=", "avatar_url": "https://avatars2.githubusercontent.com/u/2830940?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bluekingsong", "html_url": "https://github.com/bluekingsong", "followers_url": "https://api.github.com/users/bluekingsong/followers", "following_url": "https://api.github.com/users/bluekingsong/following{/other_user}", "gists_url": "https://api.github.com/users/bluekingsong/gists{/gist_id}", "starred_url": "https://api.github.com/users/bluekingsong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bluekingsong/subscriptions", "organizations_url": "https://api.github.com/users/bluekingsong/orgs", "repos_url": "https://api.github.com/users/bluekingsong/repos", "events_url": "https://api.github.com/users/bluekingsong/events{/privacy}", "received_events_url": "https://api.github.com/users/bluekingsong/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-16T13:17:36Z", "updated_at": "2017-03-16T13:17:36Z", "author_association": "NONE", "body_html": "<p>i solve this problem, by an unusual way.  the  large variable is what i must keep for online inference.  however, i find it is interesting that the meta graph  save duplicate graphs in proto file.  specifically,  it has \"graph_def\" proto and \"serving_graph\" proto,  and i found remove serving_graph won't affect my online inference. also, i found the constant( such as numpy array,  python scalar variables ) used by the graph building process will saved in the meta graph as const tensor, this is the reason which make my meta graph proto very big.  i use tf.assign to inject my numpy array to the tensor variables and then remove the tf.assign op(with the constant tensor in meta graph) from the graph when i export the model ( i don't need the assign op in inference process ).   in this way, i reduce my meta graph to very small.</p>", "body_text": "i solve this problem, by an unusual way.  the  large variable is what i must keep for online inference.  however, i find it is interesting that the meta graph  save duplicate graphs in proto file.  specifically,  it has \"graph_def\" proto and \"serving_graph\" proto,  and i found remove serving_graph won't affect my online inference. also, i found the constant( such as numpy array,  python scalar variables ) used by the graph building process will saved in the meta graph as const tensor, this is the reason which make my meta graph proto very big.  i use tf.assign to inject my numpy array to the tensor variables and then remove the tf.assign op(with the constant tensor in meta graph) from the graph when i export the model ( i don't need the assign op in inference process ).   in this way, i reduce my meta graph to very small.", "body": "i solve this problem, by an unusual way.  the  large variable is what i must keep for online inference.  however, i find it is interesting that the meta graph  save duplicate graphs in proto file.  specifically,  it has \"graph_def\" proto and \"serving_graph\" proto,  and i found remove serving_graph won't affect my online inference. also, i found the constant( such as numpy array,  python scalar variables ) used by the graph building process will saved in the meta graph as const tensor, this is the reason which make my meta graph proto very big.  i use tf.assign to inject my numpy array to the tensor variables and then remove the tf.assign op(with the constant tensor in meta graph) from the graph when i export the model ( i don't need the assign op in inference process ).   in this way, i reduce my meta graph to very small. "}