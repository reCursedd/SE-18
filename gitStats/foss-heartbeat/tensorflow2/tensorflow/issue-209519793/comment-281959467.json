{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/281959467", "html_url": "https://github.com/tensorflow/tensorflow/issues/7785#issuecomment-281959467", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7785", "id": 281959467, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTk1OTQ2Nw==", "user": {"login": "volvador", "id": 15655730, "node_id": "MDQ6VXNlcjE1NjU1NzMw", "avatar_url": "https://avatars1.githubusercontent.com/u/15655730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/volvador", "html_url": "https://github.com/volvador", "followers_url": "https://api.github.com/users/volvador/followers", "following_url": "https://api.github.com/users/volvador/following{/other_user}", "gists_url": "https://api.github.com/users/volvador/gists{/gist_id}", "starred_url": "https://api.github.com/users/volvador/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/volvador/subscriptions", "organizations_url": "https://api.github.com/users/volvador/orgs", "repos_url": "https://api.github.com/users/volvador/repos", "events_url": "https://api.github.com/users/volvador/events{/privacy}", "received_events_url": "https://api.github.com/users/volvador/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-23T10:48:26Z", "updated_at": "2017-02-23T11:00:43Z", "author_association": "NONE", "body_html": "<p>Hello and thanks a lot for the help with this issue,<br>\nI am using tensorflow1.0 and keras 1.2.2 to generate the model. Below is a complete code to reproduce the error. The same error occurs if instead of <code>model.save_weights</code> I use a saver.<br>\nTo test, please start the following three processes</p>\n<pre><code>python test.py --job_name ps\npython test.py --job_name worker --task_index 0\npython test.py --job_name worker --task_index 1\n</code></pre>\n<p>Here is the code of the file test.py in which I catch the exception generated after the save_weights instruction. Notice that the file weights.h5 is indeed produced</p>\n<pre><code>import os\nimport numpy as np\nimport pandas as pd\nimport argparse\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.regularizers import l2\nimport tensorflow as tf\nimport keras\n\nnb_samples = 50\nnb_features = 5\nX_train = np.random.randn(nb_samples * nb_features).reshape((nb_samples, nb_features))\nY_train = np.random.randn(nb_samples).reshape((nb_samples, 1))\n\ndef build_keras_model(input_dim):\n  hidden_dim = 10\n\n  model = Sequential()\n  model.add(Dense(input_dim = input_dim,\n                  output_dim=hidden_dim,\n                  activation='tanh'\n                  ))\n\n  model.add(Dense(output_dim=1, activation='linear'))\n\n  model.compile(loss='mse', optimizer='adam')\n  \n  return model\n\n\n\n\n################################################\n# DISTRIBUTE\n################################################\n\nparser = argparse.ArgumentParser(description='tensorflow')\nparser.add_argument('--job_name', dest='job_name')\nparser.add_argument('--task_index', dest='task_index', default=0)\nargs = parser.parse_args()\n\n\nps_hosts = ['localhost:2222']\nworker_hosts = ['localhost:2223', 'localhost:2224']\njob_name = args.job_name\ntask_index = int(args.task_index)\n\n# Create a cluster from the parameter server and worker hosts.\ncluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n  \nserver = tf.train.Server(cluster,\n                         job_name=job_name,\n                         task_index=task_index,\n                         config=tf.ConfigProto(log_device_placement=True,\n                                               inter_op_parallelism_threads=1,\n                                               intra_op_parallelism_threads=1))\n\n\nif job_name =='ps':\n  server.join()\n\nelse:\n  with tf.device(tf.train.replica_device_setter(\n                              worker_device=\"/job:worker/task:%d\" % task_index,\n                              cluster=cluster)):\n\n    keras.backend.set_learning_phase(1)\n    keras.backend.manual_variable_initialization(True)\n\n    model = build_keras_model(nb_features)\n    preds = model.output\n    targets = tf.placeholder(tf.float32, [None, 1])\n    total_loss = tf.reduce_mean(\n                        keras.objectives.mean_squared_error(targets, preds))\n\n    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n\n    is_chief=(task_index == 0)\n\n    opt = tf.train.AdamOptimizer()\n\n    train_op = opt.minimize(total_loss, global_step=global_step)\n\n    init_op = tf.global_variables_initializer()\n\n\n    sv = tf.train.Supervisor(\n          is_chief=is_chief,\n          logdir=\"/tmp/train_logs\",\n          init_op=init_op,\n          global_step=global_step)\n    \n    print '######################################### ALL CREATED'\n    sess = sv.prepare_or_wait_for_session(server.target)\n    print '#######  SESSION OK ********'\n    local_step = 0\n    while True:\n      train_feed = {model.input: X_train, targets: Y_train}\n\n      _, step = sess.run([train_op, global_step], feed_dict=train_feed)\n      loss = sess.run(total_loss, feed_dict = train_feed)\n      if is_chief:\n        try:\n            print '## Trying to save'\n            model.save_weights('weights.h5')\n        except Exception as e:\n            print e\n            break\n      local_step += 1\n      print 'local_step : ', local_step, 'global_step :', step, 'total_loss:', loss\n\n\n      if step &gt;= 20:\n        break\n\n    # Ask for all the services to stop.\n    sv.stop()\n</code></pre>", "body_text": "Hello and thanks a lot for the help with this issue,\nI am using tensorflow1.0 and keras 1.2.2 to generate the model. Below is a complete code to reproduce the error. The same error occurs if instead of model.save_weights I use a saver.\nTo test, please start the following three processes\npython test.py --job_name ps\npython test.py --job_name worker --task_index 0\npython test.py --job_name worker --task_index 1\n\nHere is the code of the file test.py in which I catch the exception generated after the save_weights instruction. Notice that the file weights.h5 is indeed produced\nimport os\nimport numpy as np\nimport pandas as pd\nimport argparse\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.regularizers import l2\nimport tensorflow as tf\nimport keras\n\nnb_samples = 50\nnb_features = 5\nX_train = np.random.randn(nb_samples * nb_features).reshape((nb_samples, nb_features))\nY_train = np.random.randn(nb_samples).reshape((nb_samples, 1))\n\ndef build_keras_model(input_dim):\n  hidden_dim = 10\n\n  model = Sequential()\n  model.add(Dense(input_dim = input_dim,\n                  output_dim=hidden_dim,\n                  activation='tanh'\n                  ))\n\n  model.add(Dense(output_dim=1, activation='linear'))\n\n  model.compile(loss='mse', optimizer='adam')\n  \n  return model\n\n\n\n\n################################################\n# DISTRIBUTE\n################################################\n\nparser = argparse.ArgumentParser(description='tensorflow')\nparser.add_argument('--job_name', dest='job_name')\nparser.add_argument('--task_index', dest='task_index', default=0)\nargs = parser.parse_args()\n\n\nps_hosts = ['localhost:2222']\nworker_hosts = ['localhost:2223', 'localhost:2224']\njob_name = args.job_name\ntask_index = int(args.task_index)\n\n# Create a cluster from the parameter server and worker hosts.\ncluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n  \nserver = tf.train.Server(cluster,\n                         job_name=job_name,\n                         task_index=task_index,\n                         config=tf.ConfigProto(log_device_placement=True,\n                                               inter_op_parallelism_threads=1,\n                                               intra_op_parallelism_threads=1))\n\n\nif job_name =='ps':\n  server.join()\n\nelse:\n  with tf.device(tf.train.replica_device_setter(\n                              worker_device=\"/job:worker/task:%d\" % task_index,\n                              cluster=cluster)):\n\n    keras.backend.set_learning_phase(1)\n    keras.backend.manual_variable_initialization(True)\n\n    model = build_keras_model(nb_features)\n    preds = model.output\n    targets = tf.placeholder(tf.float32, [None, 1])\n    total_loss = tf.reduce_mean(\n                        keras.objectives.mean_squared_error(targets, preds))\n\n    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n\n    is_chief=(task_index == 0)\n\n    opt = tf.train.AdamOptimizer()\n\n    train_op = opt.minimize(total_loss, global_step=global_step)\n\n    init_op = tf.global_variables_initializer()\n\n\n    sv = tf.train.Supervisor(\n          is_chief=is_chief,\n          logdir=\"/tmp/train_logs\",\n          init_op=init_op,\n          global_step=global_step)\n    \n    print '######################################### ALL CREATED'\n    sess = sv.prepare_or_wait_for_session(server.target)\n    print '#######  SESSION OK ********'\n    local_step = 0\n    while True:\n      train_feed = {model.input: X_train, targets: Y_train}\n\n      _, step = sess.run([train_op, global_step], feed_dict=train_feed)\n      loss = sess.run(total_loss, feed_dict = train_feed)\n      if is_chief:\n        try:\n            print '## Trying to save'\n            model.save_weights('weights.h5')\n        except Exception as e:\n            print e\n            break\n      local_step += 1\n      print 'local_step : ', local_step, 'global_step :', step, 'total_loss:', loss\n\n\n      if step >= 20:\n        break\n\n    # Ask for all the services to stop.\n    sv.stop()", "body": "Hello and thanks a lot for the help with this issue,\r\nI am using tensorflow1.0 and keras 1.2.2 to generate the model. Below is a complete code to reproduce the error. The same error occurs if instead of `model.save_weights` I use a saver. \r\nTo test, please start the following three processes \r\n\r\n    python test.py --job_name ps\r\n    python test.py --job_name worker --task_index 0\r\n    python test.py --job_name worker --task_index 1\r\n\r\nHere is the code of the file test.py in which I catch the exception generated after the save_weights instruction. Notice that the file weights.h5 is indeed produced\r\n\r\n    import os\r\n    import numpy as np\r\n    import pandas as pd\r\n    import argparse\r\n    \r\n    from keras.models import Sequential\r\n    from keras.layers.core import Dense\r\n    from keras.regularizers import l2\r\n    import tensorflow as tf\r\n    import keras\r\n    \r\n    nb_samples = 50\r\n    nb_features = 5\r\n    X_train = np.random.randn(nb_samples * nb_features).reshape((nb_samples, nb_features))\r\n    Y_train = np.random.randn(nb_samples).reshape((nb_samples, 1))\r\n    \r\n    def build_keras_model(input_dim):\r\n      hidden_dim = 10\r\n    \r\n      model = Sequential()\r\n      model.add(Dense(input_dim = input_dim,\r\n                      output_dim=hidden_dim,\r\n                      activation='tanh'\r\n                      ))\r\n    \r\n      model.add(Dense(output_dim=1, activation='linear'))\r\n    \r\n      model.compile(loss='mse', optimizer='adam')\r\n      \r\n      return model\r\n    \r\n    \r\n    \r\n    \r\n    ################################################\r\n    # DISTRIBUTE\r\n    ################################################\r\n    \r\n    parser = argparse.ArgumentParser(description='tensorflow')\r\n    parser.add_argument('--job_name', dest='job_name')\r\n    parser.add_argument('--task_index', dest='task_index', default=0)\r\n    args = parser.parse_args()\r\n    \r\n    \r\n    ps_hosts = ['localhost:2222']\r\n    worker_hosts = ['localhost:2223', 'localhost:2224']\r\n    job_name = args.job_name\r\n    task_index = int(args.task_index)\r\n    \r\n    # Create a cluster from the parameter server and worker hosts.\r\n    cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\r\n      \r\n    server = tf.train.Server(cluster,\r\n                             job_name=job_name,\r\n                             task_index=task_index,\r\n                             config=tf.ConfigProto(log_device_placement=True,\r\n                                                   inter_op_parallelism_threads=1,\r\n                                                   intra_op_parallelism_threads=1))\r\n    \r\n    \r\n    if job_name =='ps':\r\n      server.join()\r\n    \r\n    else:\r\n      with tf.device(tf.train.replica_device_setter(\r\n                                  worker_device=\"/job:worker/task:%d\" % task_index,\r\n                                  cluster=cluster)):\r\n    \r\n        keras.backend.set_learning_phase(1)\r\n        keras.backend.manual_variable_initialization(True)\r\n    \r\n        model = build_keras_model(nb_features)\r\n        preds = model.output\r\n        targets = tf.placeholder(tf.float32, [None, 1])\r\n        total_loss = tf.reduce_mean(\r\n                            keras.objectives.mean_squared_error(targets, preds))\r\n    \r\n        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\r\n    \r\n        is_chief=(task_index == 0)\r\n    \r\n        opt = tf.train.AdamOptimizer()\r\n    \r\n        train_op = opt.minimize(total_loss, global_step=global_step)\r\n    \r\n        init_op = tf.global_variables_initializer()\r\n    \r\n    \r\n        sv = tf.train.Supervisor(\r\n              is_chief=is_chief,\r\n              logdir=\"/tmp/train_logs\",\r\n              init_op=init_op,\r\n              global_step=global_step)\r\n        \r\n        print '######################################### ALL CREATED'\r\n        sess = sv.prepare_or_wait_for_session(server.target)\r\n        print '#######  SESSION OK ********'\r\n        local_step = 0\r\n        while True:\r\n          train_feed = {model.input: X_train, targets: Y_train}\r\n    \r\n          _, step = sess.run([train_op, global_step], feed_dict=train_feed)\r\n          loss = sess.run(total_loss, feed_dict = train_feed)\r\n          if is_chief:\r\n            try:\r\n                print '## Trying to save'\r\n                model.save_weights('weights.h5')\r\n            except Exception as e:\r\n                print e\r\n                break\r\n          local_step += 1\r\n          print 'local_step : ', local_step, 'global_step :', step, 'total_loss:', loss\r\n    \r\n    \r\n          if step >= 20:\r\n            break\r\n    \r\n        # Ask for all the services to stop.\r\n        sv.stop()\r\n"}