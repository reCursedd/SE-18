{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257775728", "html_url": "https://github.com/tensorflow/tensorflow/issues/17#issuecomment-257775728", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17", "id": 257775728, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Nzc3NTcyOA==", "user": {"login": "guschmue", "id": 22941064, "node_id": "MDQ6VXNlcjIyOTQxMDY0", "avatar_url": "https://avatars3.githubusercontent.com/u/22941064?v=4", "gravatar_id": "", "url": "https://api.github.com/users/guschmue", "html_url": "https://github.com/guschmue", "followers_url": "https://api.github.com/users/guschmue/followers", "following_url": "https://api.github.com/users/guschmue/following{/other_user}", "gists_url": "https://api.github.com/users/guschmue/gists{/gist_id}", "starred_url": "https://api.github.com/users/guschmue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/guschmue/subscriptions", "organizations_url": "https://api.github.com/users/guschmue/orgs", "repos_url": "https://api.github.com/users/guschmue/repos", "events_url": "https://api.github.com/users/guschmue/events{/privacy}", "received_events_url": "https://api.github.com/users/guschmue/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-02T05:25:13Z", "updated_at": "2016-11-02T05:25:13Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2515062\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/synap5e\">@synap5e</a> if you run this in a normal tf.Session() a second instance will not work because tf manages all memory on the gpu. You can change the config for Session() like this:<br>\nconfig = tf.ConfigProto()<br>\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.4<br>\nwith tf.Session(config=config) as sess:<br>\n...<br>\nwith that I can run 2 scripts in a loop that hit cudnn. This is the same on linux.<br>\nBut it crashes is different on windows - on linux it gets CUDA_ERROR_OUT_OF_MEMORY, on windows it get CUDNN_STATUS_NOT_INITIALIZED. Going to take a look at this.</p>", "body_text": "@synap5e if you run this in a normal tf.Session() a second instance will not work because tf manages all memory on the gpu. You can change the config for Session() like this:\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.4\nwith tf.Session(config=config) as sess:\n...\nwith that I can run 2 scripts in a loop that hit cudnn. This is the same on linux.\nBut it crashes is different on windows - on linux it gets CUDA_ERROR_OUT_OF_MEMORY, on windows it get CUDNN_STATUS_NOT_INITIALIZED. Going to take a look at this.", "body": "@synap5e if you run this in a normal tf.Session() a second instance will not work because tf manages all memory on the gpu. You can change the config for Session() like this:\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.4\nwith tf.Session(config=config) as sess:\n   ...\nwith that I can run 2 scripts in a loop that hit cudnn. This is the same on linux.\nBut it crashes is different on windows - on linux it gets CUDA_ERROR_OUT_OF_MEMORY, on windows it get CUDNN_STATUS_NOT_INITIALIZED. Going to take a look at this.\n"}