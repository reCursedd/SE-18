{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422062420", "html_url": "https://github.com/tensorflow/tensorflow/issues/3103#issuecomment-422062420", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3103", "id": 422062420, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjA2MjQyMA==", "user": {"login": "eamartin", "id": 287200, "node_id": "MDQ6VXNlcjI4NzIwMA==", "avatar_url": "https://avatars2.githubusercontent.com/u/287200?v=4", "gravatar_id": "", "url": "https://api.github.com/users/eamartin", "html_url": "https://github.com/eamartin", "followers_url": "https://api.github.com/users/eamartin/followers", "following_url": "https://api.github.com/users/eamartin/following{/other_user}", "gists_url": "https://api.github.com/users/eamartin/gists{/gist_id}", "starred_url": "https://api.github.com/users/eamartin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/eamartin/subscriptions", "organizations_url": "https://api.github.com/users/eamartin/orgs", "repos_url": "https://api.github.com/users/eamartin/repos", "events_url": "https://api.github.com/users/eamartin/events{/privacy}", "received_events_url": "https://api.github.com/users/eamartin/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-17T15:28:50Z", "updated_at": "2018-09-17T15:28:50Z", "author_association": "NONE", "body_html": "<p>Are reductions still non-determinstic by default on GPU? If so, can this issue be re-opened? Determinstic computation is critical for reproducibility, and reductions are a critical part of neural nets.</p>\n<p>Finally:<br>\nSeveral comments on this issue and other linked issues mention that \"reductions are non-determinstic for performance\". This is not the case. A reduction tree is both determinstic and generally faster than using atomic adds (which cause non-determinism). <a href=\"https://devblogs.nvidia.com/faster-parallel-reductions-kepler/\" rel=\"nofollow\">https://devblogs.nvidia.com/faster-parallel-reductions-kepler/</a> describes reduction trees, shows that reduction tree + very limited use of atomic add is the fastest option, but that reduction trees (determinstic) is only marginally slower.<br>\nLast I checked (quite a while ago), the TF reduction implementation exclusively used atomics and no reduction tree, so a switch to a reduction tree only implementation would provide a performance boost. My guess is that atomics were used for the TF implementation not for performance but because the implementation with atomics is somewhat simpler to write.</p>", "body_text": "Are reductions still non-determinstic by default on GPU? If so, can this issue be re-opened? Determinstic computation is critical for reproducibility, and reductions are a critical part of neural nets.\nFinally:\nSeveral comments on this issue and other linked issues mention that \"reductions are non-determinstic for performance\". This is not the case. A reduction tree is both determinstic and generally faster than using atomic adds (which cause non-determinism). https://devblogs.nvidia.com/faster-parallel-reductions-kepler/ describes reduction trees, shows that reduction tree + very limited use of atomic add is the fastest option, but that reduction trees (determinstic) is only marginally slower.\nLast I checked (quite a while ago), the TF reduction implementation exclusively used atomics and no reduction tree, so a switch to a reduction tree only implementation would provide a performance boost. My guess is that atomics were used for the TF implementation not for performance but because the implementation with atomics is somewhat simpler to write.", "body": "Are reductions still non-determinstic by default on GPU? If so, can this issue be re-opened? Determinstic computation is critical for reproducibility, and reductions are a critical part of neural nets.\r\n\r\nFinally:\r\nSeveral comments on this issue and other linked issues mention that \"reductions are non-determinstic for performance\". This is not the case. A reduction tree is both determinstic and generally faster than using atomic adds (which cause non-determinism). https://devblogs.nvidia.com/faster-parallel-reductions-kepler/ describes reduction trees, shows that reduction tree + very limited use of atomic add is the fastest option, but that reduction trees (determinstic) is only marginally slower.\r\nLast I checked (quite a while ago), the TF reduction implementation exclusively used atomics and no reduction tree, so a switch to a reduction tree only implementation would provide a performance boost. My guess is that atomics were used for the TF implementation not for performance but because the implementation with atomics is somewhat simpler to write."}