{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/286302405", "html_url": "https://github.com/tensorflow/tensorflow/issues/3103#issuecomment-286302405", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3103", "id": 286302405, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjMwMjQwNQ==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-14T02:21:58Z", "updated_at": "2017-03-14T02:24:40Z", "author_association": "CONTRIBUTOR", "body_html": "<p>As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> mentioned earlier, anything using cuda atomics is non-deterministic, so a way to narrow it down is to see which CuDNN algorithms use CUDA atomics. For CPU ops, the way to check might be to track down parallel ops (see which ops use tensorflow/core/util/work_sharder.cc) and check that result is independent of the order in which individual work shards complete. Note that there are more tricky cases of non-determinism, for instance same sequence of SSE instructions can give different results on rerun, so to get a stronger guarantee of determinism you need to disable multi-threading and special instruction sets: <a href=\"http://blog.nag.com/2011/02/wandering-precision.html\" rel=\"nofollow\">http://blog.nag.com/2011/02/wandering-precision.html</a></p>", "body_text": "As @zheng-xq mentioned earlier, anything using cuda atomics is non-deterministic, so a way to narrow it down is to see which CuDNN algorithms use CUDA atomics. For CPU ops, the way to check might be to track down parallel ops (see which ops use tensorflow/core/util/work_sharder.cc) and check that result is independent of the order in which individual work shards complete. Note that there are more tricky cases of non-determinism, for instance same sequence of SSE instructions can give different results on rerun, so to get a stronger guarantee of determinism you need to disable multi-threading and special instruction sets: http://blog.nag.com/2011/02/wandering-precision.html", "body": "As @zheng-xq mentioned earlier, anything using cuda atomics is non-deterministic, so a way to narrow it down is to see which CuDNN algorithms use CUDA atomics. For CPU ops, the way to check might be to track down parallel ops (see which ops use tensorflow/core/util/work_sharder.cc) and check that result is independent of the order in which individual work shards complete. Note that there are more tricky cases of non-determinism, for instance same sequence of SSE instructions can give different results on rerun, so to get a stronger guarantee of determinism you need to disable multi-threading and special instruction sets: http://blog.nag.com/2011/02/wandering-precision.html\r\n\r\n"}