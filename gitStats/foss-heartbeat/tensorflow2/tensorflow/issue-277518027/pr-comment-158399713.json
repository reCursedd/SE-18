{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/158399713", "pull_request_review_id": 85139445, "id": 158399713, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1ODM5OTcxMw==", "diff_hunk": "@@ -0,0 +1,32 @@\n+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\n+\"\"\"Gradients for operators defined in manip_ops.py.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import manip_ops\n+\n+\n+@ops.RegisterGradient(\"Roll\")\n+def _RollGrad(op, grad):\n+  # The gradient should be just the roll reversed", "path": "tensorflow/python/ops/manip_grad.py", "position": null, "original_position": 28, "commit_id": "70fc4c06e907b5578d3345a08967714bfd96f0de", "original_commit_id": "225f72c87a435201e1e2c4c9a8675b3795f68f2b", "user": {"login": "yzhwang", "id": 1002405, "node_id": "MDQ6VXNlcjEwMDI0MDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1002405?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yzhwang", "html_url": "https://github.com/yzhwang", "followers_url": "https://api.github.com/users/yzhwang/followers", "following_url": "https://api.github.com/users/yzhwang/following{/other_user}", "gists_url": "https://api.github.com/users/yzhwang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yzhwang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yzhwang/subscriptions", "organizations_url": "https://api.github.com/users/yzhwang/orgs", "repos_url": "https://api.github.com/users/yzhwang/repos", "events_url": "https://api.github.com/users/yzhwang/events{/privacy}", "received_events_url": "https://api.github.com/users/yzhwang/received_events", "type": "User", "site_admin": false}, "body": "The gradient __is__ the reversed roll of the output. Because roll op can be written as matrix multiplication then it can be proved the gradient is the multiplication of the roll op output and the transpose matrix of the original matrix used for roll, which is a reversed roll. You do not need to put too much details here, but you need to be sure that it __is__ the reversed roll of the output. So please change the comment here.", "created_at": "2017-12-21T23:14:23Z", "updated_at": "2018-01-25T23:18:34Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14953#discussion_r158399713", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14953", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/158399713"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14953#discussion_r158399713"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14953"}}, "body_html": "<p>The gradient <strong>is</strong> the reversed roll of the output. Because roll op can be written as matrix multiplication then it can be proved the gradient is the multiplication of the roll op output and the transpose matrix of the original matrix used for roll, which is a reversed roll. You do not need to put too much details here, but you need to be sure that it <strong>is</strong> the reversed roll of the output. So please change the comment here.</p>", "body_text": "The gradient is the reversed roll of the output. Because roll op can be written as matrix multiplication then it can be proved the gradient is the multiplication of the roll op output and the transpose matrix of the original matrix used for roll, which is a reversed roll. You do not need to put too much details here, but you need to be sure that it is the reversed roll of the output. So please change the comment here."}