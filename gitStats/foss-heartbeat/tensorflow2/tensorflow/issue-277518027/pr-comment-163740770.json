{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163740770", "pull_request_review_id": 91402364, "id": 163740770, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE2Mzc0MDc3MA==", "diff_hunk": "@@ -0,0 +1,481 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <functional>\n+#include <memory>\n+\n+#include \"tensorflow/core/common_runtime/device.h\"\n+#include \"tensorflow/core/common_runtime/device_factory.h\"\n+#include \"tensorflow/core/common_runtime/kernel_benchmark_testlib.h\"\n+#include \"tensorflow/core/framework/allocator.h\"\n+#include \"tensorflow/core/framework/fake_input.h\"\n+#include \"tensorflow/core/framework/node_def_builder.h\"\n+#include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/types.h\"\n+#include \"tensorflow/core/framework/types.pb.h\"\n+#include \"tensorflow/core/kernels/ops_testutil.h\"\n+#include \"tensorflow/core/kernels/ops_util.h\"\n+#include \"tensorflow/core/lib/io/path.h\"\n+#include \"tensorflow/core/lib/strings/strcat.h\"\n+#include \"tensorflow/core/platform/test.h\"\n+#include \"tensorflow/core/platform/test_benchmark.h\"\n+\n+namespace tensorflow {\n+namespace {\n+\n+class RollOpTest : public OpsTestBase {\n+ protected:\n+  void MakeOp(DataType data_type, DataType index_type) {\n+    TF_ASSERT_OK(NodeDefBuilder(\"myop\", \"Roll\")\n+                     .Input(FakeInput(data_type))\n+                     .Input(FakeInput(index_type))\n+                     .Input(FakeInput(index_type))\n+                     .Finalize(node_def()));\n+    TF_ASSERT_OK(InitOp());\n+  }\n+};\n+\n+TEST_F(RollOpTest, ScalarIndices) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({5}), {0, 1, 2, 3, 4});\n+  AddInputFromArray<int32>(TensorShape({}), {3});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({5}));\n+  test::FillValues<float>(&expected, {2, 3, 4, 0, 1});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, ScalarIndices_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(TensorShape({5}), {\"a\", \"b\", \"c\", \"d\", \"e\"});\n+  AddInputFromArray<int32>(TensorShape({}), {3});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({5}));\n+  test::FillValues<string>(&expected, {\"c\", \"d\", \"e\", \"a\", \"b\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, ScalarIndices_Complex) {\n+  MakeOp(DT_COMPLEX64, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<std::complex<float>>(\n+      TensorShape({5}), {std::complex<float>(0, 10), std::complex<float>(1, 11),\n+                         std::complex<float>(2, 12), std::complex<float>(3, 13),\n+                         std::complex<float>(4, 14)});\n+  AddInputFromArray<int32>(TensorShape({}), {3});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_COMPLEX64, TensorShape({5}));\n+  test::FillValues<std::complex<float>>(\n+      &expected, {std::complex<float>(2, 12), std::complex<float>(3, 13),\n+                  std::complex<float>(4, 14), std::complex<float>(0, 10),\n+                  std::complex<float>(1, 11)});\n+  test::ExpectTensorEqual<std::complex<float>>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_TwoD32) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({3, 5}),\n+                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14});\n+  AddInputFromArray<int32>(TensorShape({2}), {2, -1});\n+  AddInputFromArray<int32>(TensorShape({2}), {0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({3, 5}));\n+  test::FillValues<float>(&expected,\n+                          {6, 7, 8, 9, 5, 11, 12, 13, 14, 10, 1, 2, 3, 4, 0});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_TwoD32_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(TensorShape({3, 5}),\n+                            {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\",\n+                             \"k\", \"l\", \"m\", \"n\", \"o\"});\n+  AddInputFromArray<int32>(TensorShape({2}), {2, -1});\n+  AddInputFromArray<int32>(TensorShape({2}), {0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({3, 5}));\n+  test::FillValues<string>(&expected, {\"g\", \"h\", \"i\", \"j\", \"f\", \"l\", \"m\", \"n\",\n+                                       \"o\", \"k\", \"b\", \"c\", \"d\", \"e\", \"a\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_ThreeD32) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({2, 2, 3}),\n+                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11});\n+  AddInputFromArray<int32>(TensorShape({3}), {1, -1, -1});\n+  AddInputFromArray<int32>(TensorShape({3}), {0, 1, 2});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 3}));\n+  test::FillValues<float>(&expected, {10, 11, 9, 7, 8, 6, 4, 5, 3, 1, 2, 0});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_ThreeD32_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(\n+      TensorShape({2, 2, 3}),\n+      {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\"});\n+  AddInputFromArray<int32>(TensorShape({3}), {1, -1, -1});\n+  AddInputFromArray<int32>(TensorShape({3}), {0, 1, 2});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({2, 2, 3}));\n+  test::FillValues<string>(\n+      &expected, {\"k\", \"l\", \"j\", \"h\", \"i\", \"g\", \"e\", \"f\", \"d\", \"b\", \"c\", \"a\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_TwoD64) {\n+  MakeOp(DT_FLOAT, DT_INT64);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({5, 3}),\n+                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14});\n+  AddInputFromArray<int64>(TensorShape({2}), {-1, 4});\n+  AddInputFromArray<int64>(TensorShape({2}), {0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({5, 3}));\n+  test::FillValues<float>(&expected,\n+                          {5, 3, 4, 8, 6, 7, 11, 9, 10, 14, 12, 13, 2, 0, 1});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_TwoD64_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT64);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(TensorShape({5, 3}),\n+                            {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\",\n+                             \"k\", \"l\", \"m\", \"n\", \"o\"});\n+  AddInputFromArray<int64>(TensorShape({2}), {-1, 4});\n+  AddInputFromArray<int64>(TensorShape({2}), {0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({5, 3}));\n+  test::FillValues<string>(&expected, {\"f\", \"d\", \"e\", \"i\", \"g\", \"h\", \"l\", \"j\",\n+                                       \"k\", \"o\", \"m\", \"n\", \"c\", \"a\", \"b\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_ThreeD64) {\n+  MakeOp(DT_FLOAT, DT_INT64);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({4, 1, 3}),\n+                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11});\n+  AddInputFromArray<int64>(TensorShape({3}), {4, 3, 2});\n+  AddInputFromArray<int64>(TensorShape({3}), {0, 1, 2});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({4, 1, 3}));\n+  test::FillValues<float>(&expected, {1, 2, 0, 4, 5, 3, 7, 8, 6, 10, 11, 9});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Simple_ThreeD64_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT64);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(\n+      TensorShape({4, 1, 3}),\n+      {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\"});\n+  AddInputFromArray<int64>(TensorShape({3}), {4, 3, 2});\n+  AddInputFromArray<int64>(TensorShape({3}), {0, 1, 2});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({4, 1, 3}));\n+  test::FillValues<string>(\n+      &expected, {\"b\", \"c\", \"a\", \"e\", \"f\", \"d\", \"h\", \"i\", \"g\", \"k\", \"l\", \"j\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, ZeroShift_ThreeD32) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({2, 2, 3}),\n+                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11});\n+  AddInputFromArray<int32>(TensorShape({3}), {0, 0, 0});\n+  AddInputFromArray<int32>(TensorShape({3}), {0, 1, 2});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 3}));\n+  test::FillValues<float>(&expected, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, ZeroShift_ThreeD32_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(\n+      TensorShape({2, 2, 3}),\n+      {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\"});\n+  AddInputFromArray<int32>(TensorShape({3}), {0, 0, 0});\n+  AddInputFromArray<int32>(TensorShape({3}), {0, 1, 2});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({2, 2, 3}));\n+  test::FillValues<string>(\n+      &expected, {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, ZeroSize_ThreeD32) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({5, 0, 0}), {});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({5, 0, 0}));\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, ZeroSize_ThreeD32_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(TensorShape({5, 0, 0}), {});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({5, 0, 0}));\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, OneSize_ThreeD32) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({1, 1, 1}), {5});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1}));\n+  test::FillValues<float>(&expected, {5});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, OneSize_ThreeD32_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(TensorShape({1, 1, 1}), {\"a\"});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({1, 1, 1}));\n+  test::FillValues<string>(&expected, {\"a\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, DuplicateShifts_TwoD32) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({3, 5}),\n+                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14});\n+  AddInputFromArray<int32>(TensorShape({4}), {-2, 2, -1, 1});\n+  AddInputFromArray<int32>(TensorShape({4}), {1, 0, 0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_FLOAT, TensorShape({3, 5}));\n+  test::FillValues<float>(&expected,\n+                          {11, 12, 13, 14, 10, 1, 2, 3, 4, 0, 6, 7, 8, 9, 5});\n+  test::ExpectTensorEqual<float>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, DuplicateShifts_TwoD32_NoMemcpy) {\n+  MakeOp(DT_STRING, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<string>(TensorShape({3, 5}),\n+                            {\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\",\n+                             \"k\", \"l\", \"m\", \"n\", \"o\"});\n+  AddInputFromArray<int32>(TensorShape({4}), {-2, 2, -1, 1});\n+  AddInputFromArray<int32>(TensorShape({4}), {1, 0, 0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  // Check the output.\n+  Tensor expected(allocator(), DT_STRING, TensorShape({3, 5}));\n+  test::FillValues<string>(&expected, {\"l\", \"m\", \"n\", \"o\", \"k\", \"b\", \"c\", \"d\",\n+                                       \"e\", \"a\", \"g\", \"h\", \"i\", \"j\", \"f\"});\n+  test::ExpectTensorEqual<string>(expected, *GetOutput(0));\n+}\n+\n+TEST_F(RollOpTest, Error_InputMustBeVectorOrHigher) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({}), {7});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({}), {0});\n+  Status s = RunOpKernel();\n+  EXPECT_TRUE(StringPiece(s.ToString()).contains(\"input must be 1-D or higher\"))\n+      << s;\n+}\n+\n+TEST_F(RollOpTest, Error_AxisMustBeScalarOrVector) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({2, 2}), {1, 2, 3, 4});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({1, 2}), {0, 1});\n+  Status s = RunOpKernel();\n+  EXPECT_TRUE(StringPiece(s.ToString())\n+                  .contains(\"axis must be a scalar or a 1-D vector\"))\n+      << s;\n+}\n+\n+TEST_F(RollOpTest, Error_ShiftMustBeScalarOrVector) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({2, 2}), {1, 2, 3, 4});\n+  AddInputFromArray<int32>(TensorShape({1, 2}), {0, 1});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  Status s = RunOpKernel();\n+  EXPECT_TRUE(StringPiece(s.ToString())\n+                  .contains(\"shift must be a scalar or a 1-D vector\"))\n+      << s;\n+}\n+\n+TEST_F(RollOpTest, Error_ShiftAndAxisMustBeSameSize) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({2, 2}), {1, 2, 3, 4});\n+  AddInputFromArray<int32>(TensorShape({1}), {1});\n+  AddInputFromArray<int32>(TensorShape({2}), {0, 1});\n+  Status s = RunOpKernel();\n+  EXPECT_TRUE(StringPiece(s.ToString())\n+                  .contains(\"shift and axis must have the same size\"))\n+      << s;\n+}\n+\n+TEST_F(RollOpTest, Error_AxisOutOfRange) {\n+  MakeOp(DT_FLOAT, DT_INT32);\n+\n+  // Feed and run\n+  AddInputFromArray<float>(TensorShape({4}), {1, 2, 3, 4});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  AddInputFromArray<int32>(TensorShape({}), {1});\n+  Status s = RunOpKernel();\n+  EXPECT_TRUE(StringPiece(s.ToString()).contains(\"is out of range\")) << s;\n+}\n+\n+static Graph* RollGraph(const TensorShape& shape, int isd) {", "path": "tensorflow/core/kernels/roll_op_test.cc", "position": null, "original_position": 429, "commit_id": "70fc4c06e907b5578d3345a08967714bfd96f0de", "original_commit_id": "b27dd611240188f367a3089215095a4fd0a73c11", "user": {"login": "kobejean", "id": 3527868, "node_id": "MDQ6VXNlcjM1Mjc4Njg=", "avatar_url": "https://avatars2.githubusercontent.com/u/3527868?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kobejean", "html_url": "https://github.com/kobejean", "followers_url": "https://api.github.com/users/kobejean/followers", "following_url": "https://api.github.com/users/kobejean/following{/other_user}", "gists_url": "https://api.github.com/users/kobejean/gists{/gist_id}", "starred_url": "https://api.github.com/users/kobejean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kobejean/subscriptions", "organizations_url": "https://api.github.com/users/kobejean/orgs", "repos_url": "https://api.github.com/users/kobejean/repos", "events_url": "https://api.github.com/users/kobejean/events{/privacy}", "received_events_url": "https://api.github.com/users/kobejean/received_events", "type": "User", "site_admin": false}, "body": "I'll add some comments to clarify. This also stands for inner shift dimension. Basically I shift the isd and all outer dimensions. When I benchmark with a 2-D tensor if isd=0 then since dimension 1 is on the inside of dimension 0, dimension 1 will not be shifted and dimension 0 will. If isd=1 then both dimension 1 and 0 get shifted. This allows me to compare performance between just shifting the outer dimension and shifting all dimensions.", "created_at": "2018-01-25T03:11:22Z", "updated_at": "2018-01-25T23:18:34Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/14953#discussion_r163740770", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14953", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/163740770"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/14953#discussion_r163740770"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/14953"}}, "body_html": "<p>I'll add some comments to clarify. This also stands for inner shift dimension. Basically I shift the isd and all outer dimensions. When I benchmark with a 2-D tensor if isd=0 then since dimension 1 is on the inside of dimension 0, dimension 1 will not be shifted and dimension 0 will. If isd=1 then both dimension 1 and 0 get shifted. This allows me to compare performance between just shifting the outer dimension and shifting all dimensions.</p>", "body_text": "I'll add some comments to clarify. This also stands for inner shift dimension. Basically I shift the isd and all outer dimensions. When I benchmark with a 2-D tensor if isd=0 then since dimension 1 is on the inside of dimension 0, dimension 1 will not be shifted and dimension 0 will. If isd=1 then both dimension 1 and 0 get shifted. This allows me to compare performance between just shifting the outer dimension and shifting all dimensions.", "in_reply_to_id": 163700911}