{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326841407", "html_url": "https://github.com/tensorflow/tensorflow/issues/12773#issuecomment-326841407", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12773", "id": 326841407, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjg0MTQwNw==", "user": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-04T00:12:29Z", "updated_at": "2017-09-04T00:13:06Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1112263\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/facaiy\">@facaiy</a> I agree. It seems the except clause of maybe_download_and_extract_dataset does print the URL and the directory, in case the user wants to manually run wget or simply rm the file and try again. Although it might not be super noticeable since it appears to be a log and throw.</p>\n<p>This might be worth worrying about if it was production code. For example, I worked on Bazel's downloader. We went to indescribable lengths to make it download files in the most reliable, secure, redundant, and high performance manner possible. But I think a little bit of less sophistication makes sense here, to keep the example code simple, and make it easier for some of our users who have to do the download in a more manual way.</p>\n<p>Thank you for the report.</p>", "body_text": "@facaiy I agree. It seems the except clause of maybe_download_and_extract_dataset does print the URL and the directory, in case the user wants to manually run wget or simply rm the file and try again. Although it might not be super noticeable since it appears to be a log and throw.\nThis might be worth worrying about if it was production code. For example, I worked on Bazel's downloader. We went to indescribable lengths to make it download files in the most reliable, secure, redundant, and high performance manner possible. But I think a little bit of less sophistication makes sense here, to keep the example code simple, and make it easier for some of our users who have to do the download in a more manual way.\nThank you for the report.", "body": "@facaiy I agree. It seems the except clause of maybe_download_and_extract_dataset does print the URL and the directory, in case the user wants to manually run wget or simply rm the file and try again. Although it might not be super noticeable since it appears to be a log and throw.\r\n\r\nThis might be worth worrying about if it was production code. For example, I worked on Bazel's downloader. We went to indescribable lengths to make it download files in the most reliable, secure, redundant, and high performance manner possible. But I think a little bit of less sophistication makes sense here, to keep the example code simple, and make it easier for some of our users who have to do the download in a more manual way.\r\n\r\nThank you for the report."}