{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18292", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18292/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18292/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18292/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18292", "id": 311918915, "node_id": "MDU6SXNzdWUzMTE5MTg5MTU=", "number": 18292, "title": "Memory leak with py_func", "user": {"login": "voegtlel", "id": 5764745, "node_id": "MDQ6VXNlcjU3NjQ3NDU=", "avatar_url": "https://avatars0.githubusercontent.com/u/5764745?v=4", "gravatar_id": "", "url": "https://api.github.com/users/voegtlel", "html_url": "https://github.com/voegtlel", "followers_url": "https://api.github.com/users/voegtlel/followers", "following_url": "https://api.github.com/users/voegtlel/following{/other_user}", "gists_url": "https://api.github.com/users/voegtlel/gists{/gist_id}", "starred_url": "https://api.github.com/users/voegtlel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/voegtlel/subscriptions", "organizations_url": "https://api.github.com/users/voegtlel/orgs", "repos_url": "https://api.github.com/users/voegtlel/repos", "events_url": "https://api.github.com/users/voegtlel/events{/privacy}", "received_events_url": "https://api.github.com/users/voegtlel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 7, "created_at": "2018-04-06T10:03:50Z", "updated_at": "2018-06-30T22:38:46Z", "closed_at": "2018-06-30T22:38:40Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes (see below)</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.0</li>\n<li><strong>Python version</strong>: 3.6.4 64bit</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0</li>\n<li><strong>GPU model and memory</strong>: GeForce 1080 Ti</li>\n<li><strong>Exact command to reproduce</strong>: (see below)</li>\n</ul>\n<h3>Issue</h3>\n<p><code>py_func</code> which has a python function referencing the graph (might be an unobvious reference, see below) results in the graph never being garbage collected. If you know about this issue usually it can be worked around, but in general it's a pitfall which should be fixed in the code (see below for suggestion).</p>\n<h3>Source Code Example</h3>\n<p>The following source code produces the leak. If you comment out <code>py_func.graph = graph</code> you will see that \"Deleted MyPyFunc\" will be printed.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> gc\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">MyPyFunc</span>:\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">self</span>.graph <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__call__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>):\n        <span class=\"pl-k\">return</span> inputs\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__del__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>):\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Deleted MyPyFunc<span class=\"pl-pds\">\"</span></span>)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run_graph</span>():\n    graph <span class=\"pl-k\">=</span> tf.Graph()\n    <span class=\"pl-k\">with</span> graph.as_default():\n        inputs <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">0</span>)\n        py_func <span class=\"pl-k\">=</span> MyPyFunc()\n        op <span class=\"pl-k\">=</span> tf.py_func(py_func, [inputs], [inputs.dtype])\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Comment this out to fix the leak</span>\n        py_func.graph <span class=\"pl-k\">=</span> graph\n\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">graph</span><span class=\"pl-k\">=</span>graph) <span class=\"pl-k\">as</span> sess:\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Result:<span class=\"pl-pds\">\"</span></span>, sess.run(op))\n\n\nrun_graph()\ngc.collect()\nrun_graph()\ngc.collect()</pre></div>\n<h3>Analysis</h3>\n<p>The issue originates from <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L181\">script_ops.py:181</a>. Here, all <code>py_func</code>s get registered globally, i.e. these will only be deleted when <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L186\"><code>CleanupFunc</code></a> is garbage collected. It is instantiated at <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L222\">script_ops.py:222</a> and stored in the graph when <code>py_func</code> is called. The idea is, that the <code>CleanupFunc.__del__</code> method is called when the graph is garbage collected, which in turn will delete the reference to the python function, so it can get garbage collected as well.</p>\n<p>In the example, <code>MyPyFunc</code> contains a reference to the graph. By calling <code>py_func</code> the reference to <code>MyPyFunc</code> is stored globally in <code>_py_funcs = FuncRegistry()</code>. That means the graph is referenced globally, so it will never get garbage collected, which in turn means that the <code>CleanupFunc.__del__</code> will never be called, so <code>MyPyFunc</code> will never be deleted from <code>_py_funcs</code>.</p>\n<h3>Importance</h3>\n<p>Consider the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">MyOp</span>:\n    <span class=\"pl-k\">def</span> <span class=\"pl-c1\">__init__</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>):\n        <span class=\"pl-c1\">self</span>.op <span class=\"pl-k\">=</span> tf.py_func(<span class=\"pl-c1\">self</span>._py_func, [inputs], [inputs.dtype])\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">_py_func</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">inputs</span>):\n        <span class=\"pl-k\">return</span> inputs</pre></div>\n<p>This looks like valid code, but having <code>MyOp.op</code> in your graph will make the graph leak. The problem lies in the fact that <code>_py_func</code> has is bound to the <code>MyOp</code> instance which contains a reference to a TensorFlow op which in turn has a reference to the graph (for the remaining inference see above). This is a big issue, because <code>tf.estimator.train_and_evaluate</code> creates a lot of graphs during training (i.e. when it switches between training and evaluation a new graph is created).</p>\n<h3>Suggestion</h3>\n<p>Instead of globally storing references to the functions and keys to them, they might be better stored in the graph directly. This also prevents them from being deleted while the graph exists. Thus they are only cyclic references in the graph and can be garbage collected with the graph. Instead of storing<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L232\"><code>graph._cleanup_py_funcs_used_in_graph.append(cleanup)</code></a>, the function should be stored directly like <code>graph._py_funcs_used_in_graph.append(func)</code>.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below)\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.7.0\nPython version: 3.6.4 64bit\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.0\nGPU model and memory: GeForce 1080 Ti\nExact command to reproduce: (see below)\n\nIssue\npy_func which has a python function referencing the graph (might be an unobvious reference, see below) results in the graph never being garbage collected. If you know about this issue usually it can be worked around, but in general it's a pitfall which should be fixed in the code (see below for suggestion).\nSource Code Example\nThe following source code produces the leak. If you comment out py_func.graph = graph you will see that \"Deleted MyPyFunc\" will be printed.\nimport gc\nimport tensorflow as tf\n\n\nclass MyPyFunc:\n    def __init__(self):\n        self.graph = None\n\n    def __call__(self, inputs):\n        return inputs\n\n    def __del__(self):\n        print(\"Deleted MyPyFunc\")\n\n\ndef run_graph():\n    graph = tf.Graph()\n    with graph.as_default():\n        inputs = tf.constant(0)\n        py_func = MyPyFunc()\n        op = tf.py_func(py_func, [inputs], [inputs.dtype])\n        # Comment this out to fix the leak\n        py_func.graph = graph\n\n    with tf.Session(graph=graph) as sess:\n        print(\"Result:\", sess.run(op))\n\n\nrun_graph()\ngc.collect()\nrun_graph()\ngc.collect()\nAnalysis\nThe issue originates from script_ops.py:181. Here, all py_funcs get registered globally, i.e. these will only be deleted when CleanupFunc is garbage collected. It is instantiated at script_ops.py:222 and stored in the graph when py_func is called. The idea is, that the CleanupFunc.__del__ method is called when the graph is garbage collected, which in turn will delete the reference to the python function, so it can get garbage collected as well.\nIn the example, MyPyFunc contains a reference to the graph. By calling py_func the reference to MyPyFunc is stored globally in _py_funcs = FuncRegistry(). That means the graph is referenced globally, so it will never get garbage collected, which in turn means that the CleanupFunc.__del__ will never be called, so MyPyFunc will never be deleted from _py_funcs.\nImportance\nConsider the following:\nclass MyOp:\n    def __init__(self, inputs):\n        self.op = tf.py_func(self._py_func, [inputs], [inputs.dtype])\n\n    def _py_func(self, inputs):\n        return inputs\nThis looks like valid code, but having MyOp.op in your graph will make the graph leak. The problem lies in the fact that _py_func has is bound to the MyOp instance which contains a reference to a TensorFlow op which in turn has a reference to the graph (for the remaining inference see above). This is a big issue, because tf.estimator.train_and_evaluate creates a lot of graphs during training (i.e. when it switches between training and evaluation a new graph is created).\nSuggestion\nInstead of globally storing references to the functions and keys to them, they might be better stored in the graph directly. This also prevents them from being deleted while the graph exists. Thus they are only cyclic references in the graph and can be garbage collected with the graph. Instead of storing\ngraph._cleanup_py_funcs_used_in_graph.append(cleanup), the function should be stored directly like graph._py_funcs_used_in_graph.append(func).", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 3.6.4 64bit\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GeForce 1080 Ti\r\n- **Exact command to reproduce**: (see below)\r\n\r\n### Issue\r\n`py_func` which has a python function referencing the graph (might be an unobvious reference, see below) results in the graph never being garbage collected. If you know about this issue usually it can be worked around, but in general it's a pitfall which should be fixed in the code (see below for suggestion).\r\n\r\n### Source Code Example\r\n\r\nThe following source code produces the leak. If you comment out `py_func.graph = graph` you will see that \"Deleted MyPyFunc\" will be printed.\r\n```py\r\nimport gc\r\nimport tensorflow as tf\r\n\r\n\r\nclass MyPyFunc:\r\n    def __init__(self):\r\n        self.graph = None\r\n\r\n    def __call__(self, inputs):\r\n        return inputs\r\n\r\n    def __del__(self):\r\n        print(\"Deleted MyPyFunc\")\r\n\r\n\r\ndef run_graph():\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        inputs = tf.constant(0)\r\n        py_func = MyPyFunc()\r\n        op = tf.py_func(py_func, [inputs], [inputs.dtype])\r\n        # Comment this out to fix the leak\r\n        py_func.graph = graph\r\n\r\n    with tf.Session(graph=graph) as sess:\r\n        print(\"Result:\", sess.run(op))\r\n\r\n\r\nrun_graph()\r\ngc.collect()\r\nrun_graph()\r\ngc.collect()\r\n```\r\n\r\n### Analysis\r\nThe issue originates from [script_ops.py:181](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L181). Here, all `py_func`s get registered globally, i.e. these will only be deleted when [`CleanupFunc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L186) is garbage collected. It is instantiated at [script_ops.py:222](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L222) and stored in the graph when `py_func` is called. The idea is, that the `CleanupFunc.__del__` method is called when the graph is garbage collected, which in turn will delete the reference to the python function, so it can get garbage collected as well.\r\n\r\nIn the example, `MyPyFunc` contains a reference to the graph. By calling `py_func` the reference to `MyPyFunc` is stored globally in `_py_funcs = FuncRegistry()`. That means the graph is referenced globally, so it will never get garbage collected, which in turn means that the `CleanupFunc.__del__` will never be called, so `MyPyFunc` will never be deleted from `_py_funcs`.\r\n\r\n### Importance\r\nConsider the following:\r\n```py\r\nclass MyOp:\r\n    def __init__(self, inputs):\r\n        self.op = tf.py_func(self._py_func, [inputs], [inputs.dtype])\r\n\r\n    def _py_func(self, inputs):\r\n        return inputs\r\n```\r\nThis looks like valid code, but having `MyOp.op` in your graph will make the graph leak. The problem lies in the fact that `_py_func` has is bound to the `MyOp` instance which contains a reference to a TensorFlow op which in turn has a reference to the graph (for the remaining inference see above). This is a big issue, because `tf.estimator.train_and_evaluate` creates a lot of graphs during training (i.e. when it switches between training and evaluation a new graph is created).\r\n\r\n### Suggestion\r\nInstead of globally storing references to the functions and keys to them, they might be better stored in the graph directly. This also prevents them from being deleted while the graph exists. Thus they are only cyclic references in the graph and can be garbage collected with the graph. Instead of storing\r\n[`graph._cleanup_py_funcs_used_in_graph.append(cleanup)`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L232), the function should be stored directly like `graph._py_funcs_used_in_graph.append(func)`."}