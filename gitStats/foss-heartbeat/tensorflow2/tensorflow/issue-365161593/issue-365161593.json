{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22623", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22623/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22623/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22623/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22623", "id": 365161593, "node_id": "MDU6SXNzdWUzNjUxNjE1OTM=", "number": 22623, "title": "Almost 2GB GPU memory missing in Tensorflow as compared to what nvidia-smi reports", "user": {"login": "maxlawwk", "id": 42733740, "node_id": "MDQ6VXNlcjQyNzMzNzQw", "avatar_url": "https://avatars1.githubusercontent.com/u/42733740?v=4", "gravatar_id": "", "url": "https://api.github.com/users/maxlawwk", "html_url": "https://github.com/maxlawwk", "followers_url": "https://api.github.com/users/maxlawwk/followers", "following_url": "https://api.github.com/users/maxlawwk/following{/other_user}", "gists_url": "https://api.github.com/users/maxlawwk/gists{/gist_id}", "starred_url": "https://api.github.com/users/maxlawwk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/maxlawwk/subscriptions", "organizations_url": "https://api.github.com/users/maxlawwk/orgs", "repos_url": "https://api.github.com/users/maxlawwk/repos", "events_url": "https://api.github.com/users/maxlawwk/events{/privacy}", "received_events_url": "https://api.github.com/users/maxlawwk/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097547538, "node_id": "MDU6TGFiZWwxMDk3NTQ3NTM4", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:gpu", "name": "comp:gpu", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-09-29T19:45:48Z", "updated_at": "2018-11-08T03:49:31Z", "closed_at": "2018-11-08T03:49:31Z", "author_association": "NONE", "body_html": "<p>I have a 11GB 1080Ti GPU, NVidia-smi reports 11264MiB memory, Tensorflow reports 9.1GiB memory only.</p>\n<p>I understand that stackoverflow may be a better option to raise this question, but I believe this issue could be a bug or incompatibility among Windows 10, NVidia driver and Tensorflow.</p>\n<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nProblem starts to happen when enabling the GPU in python:<br>\nimport tensorflow as tf<br>\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)<br>\nconfig = tf.ConfigProto(gpu_options=gpu_options)<br>\nsession = tf.Session(config=config)</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nWindows 10</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\nTensorflow installed from binary</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>:<br>\nprint(tf.<strong>version</strong>)<br>\n1.10.0</p>\n</li>\n<li>\n<p><strong>Python version</strong>:<br>\npython --version<br>\nPython 3.6.6</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>:<br>\nnvcc: NVIDIA (R) Cuda compiler driver<br>\nCuda compilation tools, release 9.0, V9.0.176<br>\nNVIDIA-SMI 388.13                 Driver Version: 388.13</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:<br>\nEVGA 1080 Ti 11GB memory</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>:<br>\nimport tensorflow as tf<br>\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)<br>\nconfig = tf.ConfigProto(gpu_options=gpu_options)<br>\nsession = tf.Session(config=config)</p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>I couldn't find similar situation online. After a fresh boot, with the 1080Ti connecting to NO monitor (Intel 4600HD act as the primary display), NVIDIA-SMI reports no process occupying the memory, Tensorflow still reports much less memory than NVIDIA-SMI.</p>\n<p>Below are the output after issuing the tensorflow-start script with GPU support, and the outputs of the nvidia-smi command. The free GPU memory is 9.1GiB only in tensorflow as compared to 11GB by nvidia-smi. Tensorflow does attempt to allocate 11GiB memory because of per_process_gpu_memory_fraction=1, but cuda reports out of memory error. Using the Allow_growth option won't break the 9.1GiB limits. After launching tensorflow with GPU support, nvidia-smi reports 9460MiB / 11264MiB of memory usage.</p>\n<p>*************************************Output from tensorflow ***********************************<br>\nT:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2<br>\n2018-09-30 03:14:36.523917: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties:<br>\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582<br>\npciBusID: 0000:01:00.0<br>\ntotalMemory: 11.00GiB freeMemory: 9.10GiB<br>\n2018-09-30 03:14:36.528039: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0<br>\n2018-09-30 03:14:37.821700: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:<br>\n2018-09-30 03:14:37.824541: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0<br>\n2018-09-30 03:14:37.826779: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N<br>\n2018-09-30 03:14:37.828695: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11264 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)<br>\n2018-09-30 03:14:37.835373: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:903] failed to allocate 11.00G (11811160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY<br>\n2018-09-30 03:14:37.838382: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:903] failed to allocate 9.90G (10630043648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY</p>\n<p>**************************nvidia-smi output before launching tensorflow **************************<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 388.13                 Driver Version: 388.13                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0 Off |                  N/A |<br>\n|  9%   55C    P0    60W / 250W |    132MiB / 11264MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|  No running processes found                                                 |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>**************************nvidia-smi output after launching tensorflow **************************<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 388.13                 Driver Version: 388.13                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0 Off |                  N/A |<br>\n| 10%   55C    P2    57W / 250W |   9460MiB / 11264MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0     18556      C   ...cal\\Programs\\Python\\Python36\\python.exe N/A      |<br>\n+-----------------------------------------------------------------------------+</p>", "body_text": "I have a 11GB 1080Ti GPU, NVidia-smi reports 11264MiB memory, Tensorflow reports 9.1GiB memory only.\nI understand that stackoverflow may be a better option to raise this question, but I believe this issue could be a bug or incompatibility among Windows 10, NVidia driver and Tensorflow.\nSystem information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nProblem starts to happen when enabling the GPU in python:\nimport tensorflow as tf\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\nconfig = tf.ConfigProto(gpu_options=gpu_options)\nsession = tf.Session(config=config)\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nWindows 10\n\n\nTensorFlow installed from (source or binary):\nTensorflow installed from binary\n\n\nTensorFlow version (use command below):\nprint(tf.version)\n1.10.0\n\n\nPython version:\npython --version\nPython 3.6.6\n\n\nCUDA/cuDNN version:\nnvcc: NVIDIA (R) Cuda compiler driver\nCuda compilation tools, release 9.0, V9.0.176\nNVIDIA-SMI 388.13                 Driver Version: 388.13\n\n\nGPU model and memory:\nEVGA 1080 Ti 11GB memory\n\n\nExact command to reproduce:\nimport tensorflow as tf\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\nconfig = tf.ConfigProto(gpu_options=gpu_options)\nsession = tf.Session(config=config)\n\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nI couldn't find similar situation online. After a fresh boot, with the 1080Ti connecting to NO monitor (Intel 4600HD act as the primary display), NVIDIA-SMI reports no process occupying the memory, Tensorflow still reports much less memory than NVIDIA-SMI.\nBelow are the output after issuing the tensorflow-start script with GPU support, and the outputs of the nvidia-smi command. The free GPU memory is 9.1GiB only in tensorflow as compared to 11GB by nvidia-smi. Tensorflow does attempt to allocate 11GiB memory because of per_process_gpu_memory_fraction=1, but cuda reports out of memory error. Using the Allow_growth option won't break the 9.1GiB limits. After launching tensorflow with GPU support, nvidia-smi reports 9460MiB / 11264MiB of memory usage.\n*************************************Output from tensorflow ***********************************\nT:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-09-30 03:14:36.523917: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties:\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\npciBusID: 0000:01:00.0\ntotalMemory: 11.00GiB freeMemory: 9.10GiB\n2018-09-30 03:14:36.528039: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0\n2018-09-30 03:14:37.821700: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-09-30 03:14:37.824541: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0\n2018-09-30 03:14:37.826779: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N\n2018-09-30 03:14:37.828695: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11264 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-09-30 03:14:37.835373: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:903] failed to allocate 11.00G (11811160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n2018-09-30 03:14:37.838382: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:903] failed to allocate 9.90G (10630043648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n**************************nvidia-smi output before launching tensorflow **************************\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 388.13                 Driver Version: 388.13                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0 Off |                  N/A |\n|  9%   55C    P0    60W / 250W |    132MiB / 11264MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n**************************nvidia-smi output after launching tensorflow **************************\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 388.13                 Driver Version: 388.13                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0 Off |                  N/A |\n| 10%   55C    P2    57W / 250W |   9460MiB / 11264MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0     18556      C   ...cal\\Programs\\Python\\Python36\\python.exe N/A      |\n+-----------------------------------------------------------------------------+", "body": "I have a 11GB 1080Ti GPU, NVidia-smi reports 11264MiB memory, Tensorflow reports 9.1GiB memory only. \r\n\r\nI understand that stackoverflow may be a better option to raise this question, but I believe this issue could be a bug or incompatibility among Windows 10, NVidia driver and Tensorflow. \r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nProblem starts to happen when enabling the GPU in python:\r\n    import tensorflow as tf\r\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\r\n    config = tf.ConfigProto(gpu_options=gpu_options)\r\n    session = tf.Session(config=config)\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nTensorflow installed from binary\r\n- **TensorFlow version (use command below)**:\r\nprint(tf.__version__)\r\n1.10.0\r\n\r\n- **Python version**:\r\npython --version\r\nPython 3.6.6\r\n\r\n- **CUDA/cuDNN version**:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCuda compilation tools, release 9.0, V9.0.176\r\nNVIDIA-SMI 388.13                 Driver Version: 388.13\r\n\r\n\r\n- **GPU model and memory**:\r\nEVGA 1080 Ti 11GB memory\r\n\r\n- **Exact command to reproduce**:\r\n    import tensorflow as tf\r\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\r\n    config = tf.ConfigProto(gpu_options=gpu_options)\r\n    session = tf.Session(config=config)\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI couldn't find similar situation online. After a fresh boot, with the 1080Ti connecting to NO monitor (Intel 4600HD act as the primary display), NVIDIA-SMI reports no process occupying the memory, Tensorflow still reports much less memory than NVIDIA-SMI.\r\n\r\nBelow are the output after issuing the tensorflow-start script with GPU support, and the outputs of the nvidia-smi command. The free GPU memory is 9.1GiB only in tensorflow as compared to 11GB by nvidia-smi. Tensorflow does attempt to allocate 11GiB memory because of per_process_gpu_memory_fraction=1, but cuda reports out of memory error. Using the Allow_growth option won't break the 9.1GiB limits. After launching tensorflow with GPU support, nvidia-smi reports 9460MiB / 11264MiB of memory usage.\r\n\r\n*************************************Output from tensorflow ***********************************\r\nT:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-09-30 03:14:36.523917: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1405] Found device 0 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 11.00GiB freeMemory: 9.10GiB\r\n2018-09-30 03:14:36.528039: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-09-30 03:14:37.821700: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-30 03:14:37.824541: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971]      0 \r\n2018-09-30 03:14:37.826779: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:984] 0:   N \r\n2018-09-30 03:14:37.828695: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11264 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-09-30 03:14:37.835373: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:903] failed to allocate 11.00G (11811160064 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2018-09-30 03:14:37.838382: E T:\\src\\github\\tensorflow\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:903] failed to allocate 9.90G (10630043648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n\r\n**************************nvidia-smi output before launching tensorflow **************************\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 388.13                 Driver Version: 388.13                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0 Off |                  N/A |\r\n|  9%   55C    P0    60W / 250W |    132MiB / 11264MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n**************************nvidia-smi output after launching tensorflow **************************\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 388.13                 Driver Version: 388.13                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108... WDDM  | 00000000:01:00.0 Off |                  N/A |\r\n| 10%   55C    P2    57W / 250W |   9460MiB / 11264MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     18556      C   ...cal\\Programs\\Python\\Python36\\python.exe N/A      |\r\n+-----------------------------------------------------------------------------+"}