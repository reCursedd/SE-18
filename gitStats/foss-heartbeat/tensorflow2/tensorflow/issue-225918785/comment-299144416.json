{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/299144416", "html_url": "https://github.com/tensorflow/tensorflow/pull/9622#issuecomment-299144416", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9622", "id": 299144416, "node_id": "MDEyOklzc3VlQ29tbWVudDI5OTE0NDQxNg==", "user": {"login": "qjivy", "id": 24410810, "node_id": "MDQ6VXNlcjI0NDEwODEw", "avatar_url": "https://avatars2.githubusercontent.com/u/24410810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qjivy", "html_url": "https://github.com/qjivy", "followers_url": "https://api.github.com/users/qjivy/followers", "following_url": "https://api.github.com/users/qjivy/following{/other_user}", "gists_url": "https://api.github.com/users/qjivy/gists{/gist_id}", "starred_url": "https://api.github.com/users/qjivy/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qjivy/subscriptions", "organizations_url": "https://api.github.com/users/qjivy/orgs", "repos_url": "https://api.github.com/users/qjivy/repos", "events_url": "https://api.github.com/users/qjivy/events{/privacy}", "received_events_url": "https://api.github.com/users/qjivy/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-04T10:05:11Z", "updated_at": "2017-05-04T10:05:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hi Andrew,<br>\nGreat thanks to your data! Yes, it's seems the result is not quite agreed with what I get on the quantized VGG16 model.<br>\nBut could I get to know more about the benchmark models you had used? I mean could I get access to the \u201cfacenet-v8-stripped\u201d/\u201cinception-v1\u201d and so on models you used to do test?  Because I'm quite interested to look into the regression reason.<br>\nAs the parallelization for the FC layers can only bring benefits to those with big weights matrix, it's reasonable that models don't has such attribute would go worse with this patch.</p>\n<p>At the moment, I only have two models, one is VGG16, the other is  from <a href=\"https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\" rel=\"nofollow\">https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip</a> -O tensorflow/examples/label_image/data/inception_dec_2015.zip</p>\n<p>The performance of this inception model is not enhanced by the patch because the FC layers are so small comparing to VGG16. One is (m:1, n:1024, k:2048) and the other is (m:1, n\uff1a1008, k\uff1a1024)\u3002</p>\n<p>How about the idea of adding some decision code here to judge whether a FC layers should be parallelized?</p>\n<p>Thanks again!</p>\n<p>Ji</p>", "body_text": "Hi Andrew,\nGreat thanks to your data! Yes, it's seems the result is not quite agreed with what I get on the quantized VGG16 model.\nBut could I get to know more about the benchmark models you had used? I mean could I get access to the \u201cfacenet-v8-stripped\u201d/\u201cinception-v1\u201d and so on models you used to do test?  Because I'm quite interested to look into the regression reason.\nAs the parallelization for the FC layers can only bring benefits to those with big weights matrix, it's reasonable that models don't has such attribute would go worse with this patch.\nAt the moment, I only have two models, one is VGG16, the other is  from https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip -O tensorflow/examples/label_image/data/inception_dec_2015.zip\nThe performance of this inception model is not enhanced by the patch because the FC layers are so small comparing to VGG16. One is (m:1, n:1024, k:2048) and the other is (m:1, n\uff1a1008, k\uff1a1024)\u3002\nHow about the idea of adding some decision code here to judge whether a FC layers should be parallelized?\nThanks again!\nJi", "body": "Hi Andrew,\r\nGreat thanks to your data! Yes, it's seems the result is not quite agreed with what I get on the quantized VGG16 model.\r\nBut could I get to know more about the benchmark models you had used? I mean could I get access to the \u201cfacenet-v8-stripped\u201d/\u201cinception-v1\u201d and so on models you used to do test?  Because I'm quite interested to look into the regression reason. \r\nAs the parallelization for the FC layers can only bring benefits to those with big weights matrix, it's reasonable that models don't has such attribute would go worse with this patch.\r\n\r\nAt the moment, I only have two models, one is VGG16, the other is  from https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip -O tensorflow/examples/label_image/data/inception_dec_2015.zip\r\n\r\nThe performance of this inception model is not enhanced by the patch because the FC layers are so small comparing to VGG16. One is (m:1, n:1024, k:2048) and the other is (m:1, n\uff1a1008, k\uff1a1024)\u3002 \r\n\r\nHow about the idea of adding some decision code here to judge whether a FC layers should be parallelized? \r\n\r\nThanks again!\r\n\r\nJi"}