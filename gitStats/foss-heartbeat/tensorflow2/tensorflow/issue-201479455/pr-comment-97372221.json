{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/97372221", "pull_request_review_id": 17979351, "id": 97372221, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk3MzcyMjIx", "diff_hunk": "@@ -0,0 +1,561 @@\n+/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifdef INTEL_MKL\n+// This module implements node merging optimization on the graph.\n+// We process the nodes in the graph in reverse postorder\n+// (i.e. inputs before their downstream dependencies).\n+//\n+#include <set>\n+#include <vector>\n+#include <queue>\n+#include <utility>\n+#include <algorithm>\n+#include \"tensorflow/core/graph/mkl_optimizer_merge.h\"\n+\n+#include \"tensorflow/core/framework/node_def_util.h\"\n+#include \"tensorflow/core/graph/algorithm.h\"\n+#include \"tensorflow/core/graph/node_builder.h\"\n+#include \"tensorflow/core/lib/gtl/map_util.h\"\n+#include \"tensorflow/core/lib/hash/hash.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/common_runtime/function.h\"\n+\n+namespace tensorflow {\n+\n+static void FillInputs(const Node* n,\n+                       gtl::InlinedVector<Node*, 4>* control_edges,\n+                       gtl::InlinedVector<std::pair<Node*, int>, 4>* in) {\n+  DCHECK_EQ(in->size(), n->num_inputs());\n+  control_edges->clear();\n+  for (const Edge* e : n->in_edges()) {\n+    if (e->IsControlEdge()) {\n+      control_edges->push_back(e->src());\n+    } else {\n+      (*in)[e->dst_input()] = std::make_pair(e->src(), e->src_output());\n+    }\n+  }\n+  std::sort(control_edges->begin(), control_edges->end());\n+  if (n->op_def().is_commutative()) {\n+    // For commutative inputs, we sort the input by the input Node*\n+    // to get a canonical ordering (so that add(a,b) and add(b, a) will\n+    // hash to the same value if is_commutative is true for 'add').\n+    std::sort(in->begin(), in->end());\n+  }\n+}\n+\n+///////////////////////////////////////////////////////////////////////////////\n+//              Functions related to node merging\n+///////////////////////////////////////////////////////////////////////////////\n+\n+/*\n+  Return a node that can be merged with Node a\n+\n+  Returns pointer to the node if we can find such a\n+  node. Otherwise, it returns NULL.\n+*/\n+Node* NodeMergeRewritePass::FindNodeForMerge(const Node* a) const {\n+  // Search for all matching mergeinfo.\n+  // We allow more than one match for extensibility.\n+  std::vector<const MergeInfo*> matching_mi;\n+  for (auto mi = minfo_.cbegin(); mi != minfo_.cend(); ++mi) {\n+    if (a->type_string() == mi->succ) {\n+      matching_mi.push_back(&*mi);\n+    }\n+  }\n+\n+  VLOG(1) << \"FindNodeForMerge: \" << a->type_string();\n+\n+  for (const MergeInfo *mi : matching_mi) {\n+    const int N_in = a->num_inputs();\n+    if (mi->op >= N_in) {\n+      // NOTE: This should be again an assert. But we skip such case.\n+      continue;\n+    }\n+\n+    // Get the control edges and input of node\n+    gtl::InlinedVector<Node*, 4> a_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> a_in(N_in);\n+    FillInputs(a, &a_control_edges, &a_in);\n+\n+    // Get operand op of the operator\n+    Node *b = nullptr;\n+    b = a_in[mi->op].first;\n+    if (b == nullptr || (b->type_string() != mi->pred)) {\n+      // NOTE: Should the first check be assert?\n+      continue;\n+    }\n+\n+    VLOG(1) << \"     FindNode: \" << b->type_string();\n+\n+    gtl::InlinedVector<Node*, 4> b_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> b_in(N_in);\n+    FillInputs(b, &b_control_edges, &b_in);\n+\n+    // Shouldn't merge if a and b have different control edges.\n+    if (a_control_edges != b_control_edges) {\n+      continue;\n+    } else {\n+      // We found a match.\n+      return b;\n+    }\n+  }\n+\n+  return nullptr;\n+}\n+\n+\n+/*\n+  Merge predecessor node with its successor.\n+  Currently, we support merging Conv2D with AddBias, and\n+  MatMul with Add node.\n+\n+  Returns true, if merging is successful and supported.\n+  Returns false otherwise.\n+*/\n+bool NodeMergeRewritePass::MergeNode(std::unique_ptr<Graph>* g,\n+                                     Node* succ, Node* pred) {\n+  if (succ == NULL || pred == NULL)\n+    return false;\n+\n+  bool result = false;\n+\n+  if (succ->type_string() == csinfo_.biasadd &&\n+      pred->type_string() == csinfo_.conv2d) {\n+    // 1. Get all attributes from input nodes.\n+    DataType T_pred, T_succ;\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"T\", &T_pred));\n+    TF_CHECK_OK(GetNodeAttr(succ->def(), \"T\", &T_succ));\n+    if (T_pred != T_succ) {\n+      return false;\n+    }\n+\n+    string padding;\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"padding\", &padding));\n+\n+    std::vector<int32> strides;\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"strides\", &strides));\n+\n+    // We check to ensure that data formats of both succ and pred are same.\n+    // We expect them to be same, so we can enforce this as assert.\n+    // But assert can be too strict, so we enforce this as a check.\n+    // If the check fails, then we do not merge two nodes.\n+    string data_format_pred, data_format_succ;\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"data_format\", &data_format_pred));\n+    TF_CHECK_OK(GetNodeAttr(succ->def(), \"data_format\", &data_format_succ));\n+    if (data_format_pred != data_format_succ)\n+    return false;\n+\n+    bool use_cudnn_on_gnu;\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"use_cudnn_on_gpu\",\n+                            &use_cudnn_on_gnu));\n+\n+    // Groups attribute may not be there on the input node. So we do not\n+    // check for error in GetNodeAttr call.\n+    int groups = 1;\n+    GetNodeAttr(pred->def(), \"groups\", &groups);\n+\n+    // 2. Get inputs from both the nodes.\n+    // Find the 2 inputs from the conv and the bias from the add Bias.\n+    Node *oper1 = NULL, *oper2 = NULL, *oper3 = NULL;\n+\n+    const int succ_num = succ->num_inputs();\n+    gtl::InlinedVector<Node*, 4> succ_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> succ_in(succ_num);\n+    FillInputs(succ, &succ_control_edges, &succ_in);\n+\n+    const int pred_num = pred->num_inputs();\n+    gtl::InlinedVector<Node*, 4> pred_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> pred_in(pred_num);\n+    FillInputs(pred, &pred_control_edges, &pred_in);\n+\n+    // We need to ensure that there is only 1 edge between Conv2D and AddBias.\n+    // Otherwise, merging is semantically incorrect.\n+    if (pred->out_edges().size() != 1) {\n+      return false;\n+    }\n+\n+    for (const Edge *e : pred->out_edges()) {\n+      if (e->dst() != succ) {\n+        return false;\n+      }\n+    }\n+\n+    // Get operand 0, 1 of conv2D\n+    oper1 = pred_in[0].first;\n+    oper2 = pred_in[1].first;\n+    // Get operand 1 of add_bias\n+    oper3 = succ_in[1].first;\n+\n+    Node* ret;\n+    TF_CHECK_OK(NodeBuilder((*g)->NewName(\"n\"), csinfo_.conv2dwithbias)\n+    .Input(oper1)\n+    .Input(oper2)\n+    .Input(oper3)\n+    .Attr(\"T\", T_pred)\n+    .Attr(\"strides\", strides)\n+    .Attr(\"padding\", padding)\n+    .Attr(\"data_format\", data_format_pred)\n+    .Attr(\"use_cudnn_on_gpu\", use_cudnn_on_gnu)\n+    .Attr(\"groups\", groups)\n+    .Finalize(&**g, &ret));\n+\n+    CHECK_NOTNULL(ret);\n+\n+    for (const Edge* e : succ->out_edges()) {\n+      (*g)->AddEdge(ret, e->src_output(), e->dst(), e->dst_input());\n+    }\n+\n+    (*g)->RemoveNode(succ);\n+    (*g)->RemoveNode(pred);\n+\n+    result = true;\n+  } else if (succ->type_string() == csinfo_.add &&\n+             pred->type_string() == csinfo_.matmul) {\n+    // 1. Get all attributes from input nodes.\n+    DataType T_pred, T_succ;\n+    bool transpose_a, transpose_b;\n+\n+    // Check for type (T).\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"T\", &T_pred));\n+    TF_CHECK_OK(GetNodeAttr(succ->def(), \"T\", &T_succ));\n+    if (T_pred != T_succ) {\n+      return false;\n+    }\n+\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"transpose_a\", &transpose_a));\n+    TF_CHECK_OK(GetNodeAttr(pred->def(), \"transpose_b\", &transpose_b));\n+\n+    // NOTE: what about succ_is_sparse and pred_is_sparse attributes of\n+    // matmul? Those are not represented in matmulmkl.\n+\n+    // 2. Get inputs from both the nodes.\n+    const int succ_num = succ->num_inputs(); /* this must be 2. */\n+    gtl::InlinedVector<Node*, 4> succ_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> succ_in(succ_num);\n+    FillInputs(succ, &succ_control_edges, &succ_in);\n+\n+    const int pred_num = pred->num_inputs(); /* this must be 2. */\n+    gtl::InlinedVector<Node*, 4> pred_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> pred_in(pred_num);\n+    FillInputs(pred, &pred_control_edges, &pred_in);\n+\n+    // MatMul may have more than 1 successor. In such case, we merge\n+    // matmul and add only if successor of matmul is shape (2 outgoing\n+    // edges from MatMul).\n+    bool shape_node_found = false;\n+    if (pred->out_edges().size() == 2) {\n+      for (const Edge *e : pred->out_edges()) {\n+        if (e->dst() != succ && e->dst()->type_string() != \"Shape\")\n+          return false;\n+      }\n+      shape_node_found = true;\n+    } else if (pred->out_edges().size() == 1) {\n+      // Or we may have a case that there is only 1 edge between MatMul\n+      // and Add. Otherwise, merging is semantically incorrect.\n+      // No-op here.\n+    } else {\n+      // For any other case, we do not merge.\n+      return false;\n+    }\n+\n+    // Find the inputs from add and matmul.\n+    Node *mm_op1 = NULL, *mm_op2 = NULL, *bias = NULL;\n+    mm_op1 = pred_in[0].first;  // 1st operand of matmul\n+    mm_op2 = pred_in[1].first;  // 2nd operand of matmul\n+    bias   = succ_in[1].first;  // bias is 2nd operand of Add\n+\n+    if (mm_op1 == NULL || mm_op2 == NULL || bias == NULL) {\n+      result = false;\n+    } else {\n+      Node* ret;\n+      TF_CHECK_OK(NodeBuilder((*g)->NewName(\"n\"), csinfo_.matmulmkl)\n+        .Input(mm_op1)\n+        .Input(mm_op2)\n+        .Input(bias)\n+        .Attr(\"T\", T_pred)\n+        .Attr(\"transpose_a\", transpose_a)\n+        .Attr(\"transpose_b\", transpose_b)\n+        .Finalize(&**g, &ret));\n+\n+      CHECK_NOTNULL(ret);\n+\n+      for (const Edge* e : succ->out_edges()) {\n+        (*g)->AddEdge(ret, e->src_output(), e->dst(), e->dst_input());\n+      }\n+\n+      // This is to add edge from matmulmkl to shape, corresponding to\n+      // the edge from matmul to shape.\n+      if (shape_node_found == true) {\n+        for (const Edge* e : pred->out_edges()) {\n+          (*g)->AddEdge(ret, e->src_output(), e->dst(), e->dst_input());\n+        }\n+      }\n+\n+      (*g)->RemoveNode(succ);\n+      (*g)->RemoveNode(pred);\n+\n+      result = true;\n+    }\n+  }\n+\n+  return result;\n+}\n+\n+///////////////////////////////////////////////////////////////////////////////\n+//              Functions related to node rewriting\n+///////////////////////////////////////////////////////////////////////////////\n+\n+bool NodeMergeRewritePass::RewriteNode(std::unique_ptr<Graph>* g, Node *n) {\n+  if (n == nullptr)\n+    return false;\n+\n+  // Get the matching rewriteinfo for the node\n+  const Node *fwdn = nullptr;\n+  const RewriteInfo* ri = FindMatchingRewriteInfo(n, &fwdn);\n+  if (ri == nullptr || fwdn == nullptr) {\n+    VLOG(1) << \"Rewriteinfo not found for: \" << n->type_string();\n+    return false;\n+  }\n+\n+  VLOG(1) << \"Rewrite called for: \" << n->type_string();\n+\n+  if (n->type_string() == csinfo_.biasaddgrad &&\n+      ri->node       == csinfo_.biasaddgrad    &&\n+      (ri->rewrite   == csinfo_.conv2dwithbiasbackpropbias ||\n+       ri->rewrite   == csinfo_.biasaddgrad)) {\n+    DataType T; string data_format;\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"T\", &T));\n+    TF_CHECK_OK(GetNodeAttr(n->def(), \"data_format\", &data_format));\n+\n+    int n_num = n->num_inputs();  // this must be 1.\n+    CHECK_EQ(n_num, 1);\n+\n+    gtl::InlinedVector<Node*, 4> n_control_edges;\n+    gtl::InlinedVector<std::pair<Node*, int>, 4> n_in(n_num);\n+    FillInputs(n, &n_control_edges, &n_in);\n+\n+    Node *ret = nullptr, *op = n_in[0].first;\n+\n+    if (ri->rewrite == csinfo_.conv2dwithbiasbackpropbias) {\n+      // Get strides info from Conv2D (node in the forward pass that this\n+      // node corresponds to).\n+      std::vector<int32> strides;\n+      TF_CHECK_OK(GetNodeAttr(fwdn->def(), \"strides\", &strides));\n+\n+      // We use same name as original node name as there may be fetchoutputs\n+      // associated with it.\n+      TF_CHECK_OK(NodeBuilder(n->name(), ri->rewrite)\n+       .Input(op)\n+       .Attr(\"T\", T)\n+       .Attr(\"data_format\", data_format)\n+       .Attr(\"strides\", strides)\n+       .Finalize(&**g, &ret));\n+    } else if (ri->rewrite == csinfo_.biasaddgrad) {\n+      TF_CHECK_OK(NodeBuilder(n->name(), ri->rewrite)\n+       .Input(op)\n+       .Attr(\"T\", T)\n+       .Attr(\"data_format\", data_format)\n+       .Finalize(&**g, &ret));\n+    } else {\n+      return false;\n+    }\n+\n+    CHECK_NOTNULL(ret);\n+\n+    // Incoming edges are fixed, we will fix the outgoing edges now.\n+    for (const Edge* e : n->out_edges()) {\n+      (*g)->AddEdge(ret, e->src_output(), e->dst(), e->dst_input());\n+    }\n+\n+    VLOG(1) << \"Rewrite node: \" << n->type_string() << \" successful\";\n+    (*g)->RemoveNode(n);\n+    return true;\n+  } else {\n+    VLOG(1) << \"Unsupported node: \" << n->type_string() << \" for rewrite\";\n+  }\n+  return false;\n+}\n+\n+const NodeMergeRewritePass::RewriteInfo*\n+NodeMergeRewritePass::FindMatchingRewriteInfo(const Node *n,\n+                                              const Node **fwdn) const {\n+  CHECK_NOTNULL(n);\n+  CHECK_NOTNULL(fwdn);\n+  *fwdn = nullptr;\n+\n+  // Search for matching rewriteinfo based on node name.\n+  // There could be more than one matching rewriteinfos.\n+  std::vector<const RewriteInfo*> matching_ri;\n+  for (auto ri = rinfo_.cbegin(); ri != rinfo_.cend(); ++ri) {\n+    if (n->type_string() == ri->node) {\n+      matching_ri.push_back(&*ri);\n+    }\n+  }\n+\n+  VLOG(1) << \"Searching graph for: \" << n->type_string() << \" in backwards.\";\n+\n+  // Now we will check for forward op name for rewrite info in data\n+  // flow graph.\n+  // Get the max hops we should search for the fwd node\n+  // We are now going to search (breadth-first) backwards in data\n+  // dependence graph (for up to max hops) from n for the node\n+  // specified in fwd.\n+  // queue to maintain nodes to be visited and depth info for\n+  // breadth-first search\n+  std::queue<std::pair<const Node *, int>> nqueue;\n+  const Node *curr_node = n;\n+  int curr_depth = 0;\n+  nqueue.push(std::make_pair(curr_node, curr_depth));\n+\n+  while (curr_depth < NODEMERGE_CONTEXT_MAXDEPTH && !nqueue.empty()) {\n+    std::pair<const Node *, int> curr_pair = nqueue.front();\n+    nqueue.pop();\n+\n+    std::set<const Node*> visited_nodes;\n+    curr_node  = curr_pair.first;\n+    curr_depth = curr_pair.second;\n+    DCHECK_NE(curr_node, nullptr);\n+\n+    VLOG(1) << \"Visiting node: \" << curr_node->type_string()\n+            << \" at depth: \" << curr_depth\n+            << \" for node: \" << n->type_string();\n+\n+    // If we find a match, we return immediately with the matching rewrite\n+    // info.\n+    for (const RewriteInfo *ri : matching_ri) {\n+      if (curr_node->type_string() == ri->cinfo.fwd) {\n+        *fwdn = curr_node;\n+        return ri;\n+      }\n+    }\n+\n+    // Else we explore backward edges from current node.\n+    // Add the source nodes of all incoming edges of the node to the queue.\n+    for (const Edge *e : curr_node->in_edges()) {\n+      // We do not visit already visited node.\n+      if (visited_nodes.find(e->src()) == visited_nodes.end()) {\n+         // Depth of these nodes is 1 more than the depth of current node.\n+         nqueue.push(std::make_pair(e->src(), curr_depth+1));\n+         visited_nodes.insert(e->src());\n+      }\n+    }\n+  } /* while */\n+\n+  return nullptr;\n+}\n+\n+bool NodeMergeRewritePass::IsApplicableRewriteNode(const Node *n) const {\n+  CHECK_NOTNULL(n);\n+\n+  // Search for matching rewriteinfo\n+  // Even if we find one match, we return true.\n+  bool match_found = false;\n+  for (const RewriteInfo &ri : rinfo_) {\n+    if (n->type_string() == ri.node) {\n+      match_found = true;\n+      break;\n+    }\n+  }\n+\n+  return match_found;\n+}\n+\n+bool NodeMergeRewritePass::DoNodeMerge(std::unique_ptr<Graph>* g) {\n+  bool result = false;\n+  CHECK_NOTNULL(g);\n+\n+  DumpGraph(\"Before OptimizeMerge\", &**g);\n+\n+  std::vector<Node*> order;\n+  GetReversePostOrder(**g, &order);\n+  std::vector<std::pair<Node*, Node*>> to_be_merged;\n+  std::vector<Node*> to_be_rewritten;\n+\n+  VLOG(1) << \"Running NodeMerge Optimization\";\n+\n+  for (Node* n : order) {\n+    if (!n->IsOp()) continue;\n+    Node *n1 = nullptr;\n+    if ((n1 = FindNodeForMerge(n)) != nullptr) {\n+      VLOG(1) << \"Scheduled nodes \" << n->name() << \" and \"\n+              << n1->name() << \" for merging\";\n+      to_be_merged.push_back(std::make_pair(n, n1));\n+    } else if (IsApplicableRewriteNode(n)) {\n+      VLOG(1) << \"Scheduled node \" << n->name() << \" for rewrite\";\n+      to_be_rewritten.push_back(n);\n+    }\n+  }\n+\n+  for (std::pair < Node*, Node* > i : to_be_merged) {\n+    // Even if MergeNode merges single pair of nodes, we\n+    // need to return true.\n+    string n1name = i.first->name();\n+    string n2name = i.second->name();\n+    if (MergeNode(g, i.first, i.second)) {\n+      VLOG(1) << \"Merged nodes \" << n1name << \" and \" << n2name;\n+      result = true;\n+    }\n+  }\n+\n+  DumpGraph(\"After OptimizeMerge(nodemerge)\", &**g);\n+\n+  for (Node* i : to_be_rewritten) {\n+    string name = i->name();\n+    if (RewriteNode(g, i)) {\n+      VLOG(1) << \"Rewrite node: \" << name << \" successful.\";\n+      result = true;\n+    }\n+  }\n+\n+  DumpGraph(\"After OptimizeMerge(noderewrite)\", &**g);\n+\n+  return result;\n+}\n+\n+///////////////////////////////////////////////////////////////////////////////\n+//              Run function for the pass\n+///////////////////////////////////////////////////////////////////////////////\n+\n+bool OptimizeNodeMerge(std::unique_ptr<Graph>* g) {\n+  // Get the ownership of the graph.\n+  NodeMergeRewritePass *pass = new NodeMergeRewritePass();", "path": "tensorflow/core/graph/mkl_optimizer_merge.cc", "position": null, "original_position": 535, "commit_id": "59ce7353e2e69a03eb65c7953b0c1e970b1a465b", "original_commit_id": "267b6ce6aab30dac150e88a76e220bd6db24522a", "user": {"login": "andydavis1", "id": 15696327, "node_id": "MDQ6VXNlcjE1Njk2MzI3", "avatar_url": "https://avatars0.githubusercontent.com/u/15696327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andydavis1", "html_url": "https://github.com/andydavis1", "followers_url": "https://api.github.com/users/andydavis1/followers", "following_url": "https://api.github.com/users/andydavis1/following{/other_user}", "gists_url": "https://api.github.com/users/andydavis1/gists{/gist_id}", "starred_url": "https://api.github.com/users/andydavis1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andydavis1/subscriptions", "organizations_url": "https://api.github.com/users/andydavis1/orgs", "repos_url": "https://api.github.com/users/andydavis1/repos", "events_url": "https://api.github.com/users/andydavis1/events{/privacy}", "received_events_url": "https://api.github.com/users/andydavis1/received_events", "type": "User", "site_admin": false}, "body": "Does this need to be allocated on the heap?", "created_at": "2017-01-23T17:33:37Z", "updated_at": "2017-02-03T22:04:44Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6921#discussion_r97372221", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6921", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/97372221"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6921#discussion_r97372221"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6921"}}, "body_html": "<p>Does this need to be allocated on the heap?</p>", "body_text": "Does this need to be allocated on the heap?"}