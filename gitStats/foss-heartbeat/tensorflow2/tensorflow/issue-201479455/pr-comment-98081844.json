{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/98081844", "pull_request_review_id": 18713353, "id": 98081844, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDk4MDgxODQ0", "diff_hunk": "@@ -30,188 +30,13 @@ limitations under the License.\n \n namespace tensorflow {\n \n-// How many hops do we search for matching node in the backward dataflow graph?\n-// We use maxhop of 10 based on empirical observations. Also, these are\n-// maxhops in backward data-flow graph. Since input of forward nodes (Conv2D)\n-// directly goes to backward nodes, we do not expect the hop-distance\n-// would be more than few nodes.\n-#define NODEMERGE_CONTEXT_MAXDEPTH 10\n-\n-// This optimization pass performs two tasks: merge\n-// nodes in the forward pass, and rewrite the gradient ops\n-// corresponding to merged forward ops.\n-//\n-// Merging nodes in the graph: Currently, it merges Conv2D+AddBias\n-// and MatMul+AddBias nodes together.\n-//\n-// Rewriting nodes in the graph:\n-// This is neded in order to optimize gradient ops of\n-// Conv2D+AddBias and MatMul+AddBias. Gradient op of\n-// both the Conv2D and MatMul is BiasAddGrad, and we\n-// need to rewrite BiasAddGrad into Conv2D-specific BiasAddGrad,\n-// and MatMul-specific BiasAddGrad. This is context-specific\n-// optimization, where the context is the forward operator\n-// that the BiasAddGrad corresponds to.\n+// Interface to invoke the pass for unit test\n //\n-class NodeMergeRewritePass : public GraphOptimizationPass {\n- public:\n-  NodeMergeRewritePass() {\n-    csinfo_.conv2d                     = \"Conv2D\";\n-    csinfo_.conv2dwithbias             = \"Conv2DWithBias\";\n-    csinfo_.conv2dwithbiasbackpropbias = \"Conv2DWithBiasBackpropBias\";\n-    csinfo_.biasadd                    = \"BiasAdd\";\n-    csinfo_.matmul                     = \"MatMul\";\n-    csinfo_.matmulmkl                  = \"MatMulMkl\";\n-    csinfo_.add                        = \"Add\";\n-    csinfo_.biasaddgrad                = \"BiasAddGrad\";\n-\n-    minfo_.push_back({csinfo_.conv2d, csinfo_.biasadd, 0,\n-                      csinfo_.conv2dwithbias});\n-    // NOTE: We no longer use this optimization now.\n-    // minfo_.push_back({csinfo_.matmul, csinfo_.add, 0,\n-    //                csinfo_.matmulmkl});\n-\n-    // We use maxhop of 10 based on emperical observations. Also, these are\n-    // maxhops in backward data-flow graph. Since input of forward nodes\n-    // (Conv2D) directly goes to backward nodes, we do not expect the\n-    // hop-distance would be more than few nodes.\n-    rinfo_.push_back({csinfo_.biasaddgrad, csinfo_.conv2dwithbiasbackpropbias,\n-                  {csinfo_.conv2dwithbias, NODEMERGE_CONTEXT_MAXDEPTH}});\n-    rinfo_.push_back({csinfo_.biasaddgrad, csinfo_.conv2dwithbiasbackpropbias,\n-                  {csinfo_.conv2d, NODEMERGE_CONTEXT_MAXDEPTH}});\n-    // For now, we are rewriting BiasAddGrad to BiasAddGrad for MatMul. This is\n-    // because we do not have a separate Op for MatMulwithBias.\n-    rinfo_.push_back({csinfo_.biasaddgrad, csinfo_.biasaddgrad,\n-                      {csinfo_.matmul, NODEMERGE_CONTEXT_MAXDEPTH}});\n-    rinfo_.push_back({csinfo_.biasaddgrad, csinfo_.biasaddgrad,\n-                      {csinfo_.matmulmkl, NODEMERGE_CONTEXT_MAXDEPTH}});\n-  }\n-\n-  Status Run(const GraphOptimizationPassOptions& options);\n-\n-  /*\n-   * Helper function which does most of heavy lifting for node merge\n-   *\n-   * Extracts common functionality between Run public interface and\n-   * test interface.\n-   *\n-   * @return true, if and only if graph is mutated; false otherwise.\n-   */\n-  bool DoNodeMerge(std::unique_ptr<Graph>* g);\n-\n- private:\n-  /// Structure to specify information used in node merge\n-  typedef struct {\n-    string pred;  // Predecessor node string\n-    string succ;  // Successor node string\n-    int    op;    // What operand no the predecessor node corresponds\n-                  // to successor node?\n-    string newnode;  // Name of the node after merge\n-  } MergeInfo;\n-\n-  /// Structure to specify information used in node rewrite\n-  typedef struct {\n-    string node;  // Name of the node to be rewritten\n-    string rewrite;  // New name of the node after rewrite\n-    typedef struct {\n-        string fwd;  // Node name in forward pass that this node\n-                       // corresponds to\n-        int maxhop;  // Maximum number of hops the mfwd_ is located\n-                         // from this node. If mfwd_ is farther than mmaxhop_\n-                         // then we do not rewrite the node.\n-    } ContextInfo;\n-    ContextInfo cinfo;  // Context for rewrite\n-  } RewriteInfo;\n-\n-  /// Structure to store all constant strings\n-  typedef struct {\n-    string conv2d;\n-    string conv2dwithbias;\n-    string conv2dwithbiasbackpropbias;\n-    string biasadd;\n-\n-    string matmul;\n-    string matmulmkl;\n-    string add;\n-\n-    string biasaddgrad;\n-  } ConstStringInfo;\n-\n-  ConstStringInfo csinfo_;\n-  std::vector<MergeInfo> minfo_;\n-  std::vector<RewriteInfo> rinfo_;\n-\n- private:\n-  /*\n-   *  Return a node that can be merged with input node\n-   *\n-   *  @return pointer to the node if we can find such a\n-   *  node. Otherwise, it returns NULL.\n-   */\n-  Node* FindNodeForMerge(const Node* a) const;\n-\n-  /*\n-   *  Merge predecessor node with its successor.\n-   *  Currently, we support merging Conv2D with AddBias, and\n-   *  MatMul with Add node.\n-   *\n-   *  Input nodes succ and pred may be deleted if the call to\n-   *  this function is successful. Attempt to use the pointers\n-   *  after the call to function may result is undefined behaviors.\n-   *\n-   *  @input g - input graph, succ - successor node, pred - predecessor node\n-   *  @return true, if merging is successful and supported.\n-   *           Returns false otherwise.\n-   */\n-  bool MergeNode(std::unique_ptr<Graph>* g, Node *succ, Node *pred);\n-\n-  /*\n-   *  Can the input node (n) be rewritten via rewrite node method?\n-   *\n-   *  @return true, if it can be rewritten; false, otherwise.\n-   *          In case of true, returns context ID of the matching context.\n-   */\n-  bool IsApplicableRewriteNode(const Node *n) const;\n-\n-  /*\n-   * Rewrite input node to its corresponding node specified in rewrite info.\n-   *\n-   * Input node may be deleted in case of rewrite. Attempt to use the node\n-   * after the call can result in undefined behaviors.\n-   *\n-   * @input  g - input graph, n - Node to be rewritten\n-   * @return true, if the input node can be rewritten; false, otherwise.\n-   *         Graph is updated in case the input node can be rewritten.\n-   *         Otherwise, it is not updated.\n-   */\n-  bool RewriteNode(std::unique_ptr<Graph>* g, Node *n);\n-\n-  /*\n-   * Helper function that searches the matching rewriteinfo for the node.\n-   * Implements depth-first search in the data dependence graph for the\n-   * gradient op in backward direction.\n-   *\n-   * @input n - Node (gradient op) whose rewriteinfo is to be searched,\n-   *        fwdn - pointer to node from the forward pass that this node\n-   *        belongs to\n-   * @return Matching rewriteinfo in case a match is found; null otherwise.\n-   */\n-  const RewriteInfo* FindMatchingRewriteInfo(const Node *n,\n-                                             const Node **fwdn) const;\n-};\n-\n-/*\n- * Interface to invoke the pass for unit test\n- */\n+// Returns true if and only if 'g' is mutated.", "path": "tensorflow/core/graph/mkl_optimizer_merge.h", "position": null, "original_position": 189, "commit_id": "59ce7353e2e69a03eb65c7953b0c1e970b1a465b", "original_commit_id": "045e26a166cee9ecdd5232138655cbea876b6096", "user": {"login": "andydavis1", "id": 15696327, "node_id": "MDQ6VXNlcjE1Njk2MzI3", "avatar_url": "https://avatars0.githubusercontent.com/u/15696327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andydavis1", "html_url": "https://github.com/andydavis1", "followers_url": "https://api.github.com/users/andydavis1/followers", "following_url": "https://api.github.com/users/andydavis1/following{/other_user}", "gists_url": "https://api.github.com/users/andydavis1/gists{/gist_id}", "starred_url": "https://api.github.com/users/andydavis1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andydavis1/subscriptions", "organizations_url": "https://api.github.com/users/andydavis1/orgs", "repos_url": "https://api.github.com/users/andydavis1/repos", "events_url": "https://api.github.com/users/andydavis1/events{/privacy}", "received_events_url": "https://api.github.com/users/andydavis1/received_events", "type": "User", "site_admin": false}, "body": "You could put a little wrapper class in the header and still leave most of the implementation in the .cc file. If you choose to keep things as they are, then please prefix the method below with Test_ if it is to be used only by unit tests.", "created_at": "2017-01-26T20:15:16Z", "updated_at": "2017-02-03T22:04:44Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/6921#discussion_r98081844", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6921", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/98081844"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/6921#discussion_r98081844"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/6921"}}, "body_html": "<p>You could put a little wrapper class in the header and still leave most of the implementation in the .cc file. If you choose to keep things as they are, then please prefix the method below with Test_ if it is to be used only by unit tests.</p>", "body_text": "You could put a little wrapper class in the header and still leave most of the implementation in the .cc file. If you choose to keep things as they are, then please prefix the method below with Test_ if it is to be used only by unit tests."}