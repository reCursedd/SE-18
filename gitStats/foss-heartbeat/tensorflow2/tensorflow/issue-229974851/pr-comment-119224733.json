{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/119224733", "pull_request_review_id": 41085177, "id": 119224733, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExOTIyNDczMw==", "diff_hunk": "@@ -47,16 +129,22 @@ struct CudaLaunchConfig {\n // memory-limited.\n inline CudaLaunchConfig GetCudaLaunchConfig(int work_element_count,\n                                             const GPUDevice& d) {\n+  CudaLaunchConfig config;\n+\n+  // in case of invalid input, return the default value config, which has all -1\n+  if (work_element_count <= 0) {\n+    return config;\n+  }", "path": "tensorflow/core/util/cuda_kernel_helper.h", "position": 106, "original_position": 106, "commit_id": "7405ef3598bf8a255f1b027448f887d6ff8bafe3", "original_commit_id": "ee579ed5814b7854cf95e0bc65707e3d810a72d4", "user": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "body": "The original code ends up creating a config with virtual_thread_count=0, I think. I'm guessing that the original author thought that returning such a config is fine in this case, since presumably the caller will subsequently call CUDA_1D_KERNEL_LOOP(i, n)   with n==0 which becomes a noop. @zheng-xq can you advice?\r\n\r\n", "created_at": "2017-05-30T21:50:46Z", "updated_at": "2017-06-06T06:12:28Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/10032#discussion_r119224733", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10032", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/119224733"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/10032#discussion_r119224733"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10032"}}, "body_html": "<p>The original code ends up creating a config with virtual_thread_count=0, I think. I'm guessing that the original author thought that returning such a config is fine in this case, since presumably the caller will subsequently call CUDA_1D_KERNEL_LOOP(i, n)   with n==0 which becomes a noop. <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> can you advice?</p>", "body_text": "The original code ends up creating a config with virtual_thread_count=0, I think. I'm guessing that the original author thought that returning such a config is fine in this case, since presumably the caller will subsequently call CUDA_1D_KERNEL_LOOP(i, n)   with n==0 which becomes a noop. @zheng-xq can you advice?", "in_reply_to_id": 118830040}