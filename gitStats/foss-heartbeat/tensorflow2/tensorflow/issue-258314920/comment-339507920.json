{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/339507920", "html_url": "https://github.com/tensorflow/tensorflow/issues/13101#issuecomment-339507920", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13101", "id": 339507920, "node_id": "MDEyOklzc3VlQ29tbWVudDMzOTUwNzkyMA==", "user": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-10-25T23:48:17Z", "updated_at": "2017-10-25T23:48:33Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=966348\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/tillahoffmann\">@tillahoffmann</a> give <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/batching.py\">map_and_batch</a>, providing identity for the map, a try. <code>Dataset.batch()</code> is serializing memory copies during batch creation, which can affect performance for large batches. <code>Dataset.map_and_batch()</code> is doing the memory copies in parallel.</p>", "body_text": "@tillahoffmann give map_and_batch, providing identity for the map, a try. Dataset.batch() is serializing memory copies during batch creation, which can affect performance for large batches. Dataset.map_and_batch() is doing the memory copies in parallel.", "body": "@tillahoffmann give [map_and_batch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/batching.py), providing identity for the map, a try. `Dataset.batch()` is serializing memory copies during batch creation, which can affect performance for large batches. `Dataset.map_and_batch()` is doing the memory copies in parallel."}