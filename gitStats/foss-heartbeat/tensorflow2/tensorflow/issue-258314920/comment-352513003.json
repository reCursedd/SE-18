{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/352513003", "html_url": "https://github.com/tensorflow/tensorflow/issues/13101#issuecomment-352513003", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13101", "id": 352513003, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjUxMzAwMw==", "user": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-18T18:15:23Z", "updated_at": "2017-12-18T18:15:23Z", "author_association": "MEMBER", "body_html": "<p>I commented on the Stack Overflow thread; if possible, moving expensive processing from a <code>generator</code> to a <code>map</code> will make it possible to parallelize the processing. I find that preferrable to creating multiple identical generators and combining them using <code>interleave</code>.</p>\n<p>On a related note, the extreme version of the approach discussed on the Stack Overflow page is to replace  <code>tf.data.Dataset.from_generator</code> with <code>tf.data.Dataset.range(N).map(...)</code> where <code>map(n)</code> generates the <code>n</code>-th element. If possible, this will maximize the opportunity for parallelism as the only computation that needs to be serialized is the generation of the <code>map</code> function inputs.</p>", "body_text": "I commented on the Stack Overflow thread; if possible, moving expensive processing from a generator to a map will make it possible to parallelize the processing. I find that preferrable to creating multiple identical generators and combining them using interleave.\nOn a related note, the extreme version of the approach discussed on the Stack Overflow page is to replace  tf.data.Dataset.from_generator with tf.data.Dataset.range(N).map(...) where map(n) generates the n-th element. If possible, this will maximize the opportunity for parallelism as the only computation that needs to be serialized is the generation of the map function inputs.", "body": "I commented on the Stack Overflow thread; if possible, moving expensive processing from a `generator` to a `map` will make it possible to parallelize the processing. I find that preferrable to creating multiple identical generators and combining them using `interleave`.\r\n\r\nOn a related note, the extreme version of the approach discussed on the Stack Overflow page is to replace  `tf.data.Dataset.from_generator` with `tf.data.Dataset.range(N).map(...)` where `map(n)` generates the `n`-th element. If possible, this will maximize the opportunity for parallelism as the only computation that needs to be serialized is the generation of the `map` function inputs."}