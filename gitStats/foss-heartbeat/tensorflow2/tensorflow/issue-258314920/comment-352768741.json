{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/352768741", "html_url": "https://github.com/tensorflow/tensorflow/issues/13101#issuecomment-352768741", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13101", "id": 352768741, "node_id": "MDEyOklzc3VlQ29tbWVudDM1Mjc2ODc0MQ==", "user": {"login": "boeddeker", "id": 13744128, "node_id": "MDQ6VXNlcjEzNzQ0MTI4", "avatar_url": "https://avatars3.githubusercontent.com/u/13744128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boeddeker", "html_url": "https://github.com/boeddeker", "followers_url": "https://api.github.com/users/boeddeker/followers", "following_url": "https://api.github.com/users/boeddeker/following{/other_user}", "gists_url": "https://api.github.com/users/boeddeker/gists{/gist_id}", "starred_url": "https://api.github.com/users/boeddeker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boeddeker/subscriptions", "organizations_url": "https://api.github.com/users/boeddeker/orgs", "repos_url": "https://api.github.com/users/boeddeker/repos", "events_url": "https://api.github.com/users/boeddeker/events{/privacy}", "received_events_url": "https://api.github.com/users/boeddeker/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-19T14:24:37Z", "updated_at": "2017-12-19T14:24:37Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I am not sure if I understand your question correctly.</p>\n<p>My example does not contain <code>data.prefetch</code> and <code>dataset.batch % num_parallel_calls</code> is <code>1</code>.<br>\nMy experiments showed that the iterator items are independent of the value <code>num_parallel_calls</code>.<br>\nThe only reason that I can find for <code>dataset.batch % num_parallel_calls == 0</code> is when you are only interested in a single call and does not want to burn/waste computation power and/or RAM.</p>\n<p><code>map</code> caches the not required calculations for the next batch.</p>\n<p>Here an example what I understand that happens:<br>\n<code>num_parallel_calls == 4</code><br>\n<code>batch == 9</code><br>\nlaunch <code>__getitem__[i] for i in [0, 1, 2, 3]</code><br>\nwait until all <code>__getitem__</code> calls finished, launch <code>__getitem__[i] for i in [4, 5, 6, 7] </code><br>\nwait until all <code>__getitem__</code> calls finished, launch <code>__getitem__[i] for i in [8, 9, 10, 11] </code><br>\nwait until <code>__getitem__[8]</code> finished than build a batch<br>\nNote: In the background the remaining calls to <code>__getitem__</code> may still compute)</p>\n<p>nest session run<br>\nwait until all <code>__getitem__</code> calls finished<br>\nwait until all <code>__getitem__</code> calls finished, launch <code>__getitem__[i] for i in [12, 13, 14, 15]</code><br>\n...</p>", "body_text": "I am not sure if I understand your question correctly.\nMy example does not contain data.prefetch and dataset.batch % num_parallel_calls is 1.\nMy experiments showed that the iterator items are independent of the value num_parallel_calls.\nThe only reason that I can find for dataset.batch % num_parallel_calls == 0 is when you are only interested in a single call and does not want to burn/waste computation power and/or RAM.\nmap caches the not required calculations for the next batch.\nHere an example what I understand that happens:\nnum_parallel_calls == 4\nbatch == 9\nlaunch __getitem__[i] for i in [0, 1, 2, 3]\nwait until all __getitem__ calls finished, launch __getitem__[i] for i in [4, 5, 6, 7] \nwait until all __getitem__ calls finished, launch __getitem__[i] for i in [8, 9, 10, 11] \nwait until __getitem__[8] finished than build a batch\nNote: In the background the remaining calls to __getitem__ may still compute)\nnest session run\nwait until all __getitem__ calls finished\nwait until all __getitem__ calls finished, launch __getitem__[i] for i in [12, 13, 14, 15]\n...", "body": "I am not sure if I understand your question correctly.\r\n\r\nMy example does not contain `data.prefetch` and `dataset.batch % num_parallel_calls` is `1`.\r\nMy experiments showed that the iterator items are independent of the value `num_parallel_calls`.\r\nThe only reason that I can find for `dataset.batch % num_parallel_calls == 0` is when you are only interested in a single call and does not want to burn/waste computation power and/or RAM.\r\n\r\n`map` caches the not required calculations for the next batch.\r\n\r\nHere an example what I understand that happens:\r\n`num_parallel_calls == 4`\r\n`batch == 9`\r\nlaunch `__getitem__[i] for i in [0, 1, 2, 3]`\r\nwait until all `__getitem__` calls finished, launch `__getitem__[i] for i in [4, 5, 6, 7] `\r\nwait until all `__getitem__` calls finished, launch `__getitem__[i] for i in [8, 9, 10, 11] `\r\nwait until `__getitem__[8]` finished than build a batch\r\nNote: In the background the remaining calls to `__getitem__` may still compute)\r\n\r\nnest session run\r\nwait until all `__getitem__` calls finished\r\nwait until all `__getitem__` calls finished, launch `__getitem__[i] for i in [12, 13, 14, 15]`\r\n... \r\n"}