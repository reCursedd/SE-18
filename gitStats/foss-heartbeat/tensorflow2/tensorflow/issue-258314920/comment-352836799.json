{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/352836799", "html_url": "https://github.com/tensorflow/tensorflow/issues/13101#issuecomment-352836799", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13101", "id": 352836799, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MjgzNjc5OQ==", "user": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-19T17:56:22Z", "updated_at": "2017-12-19T17:57:07Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=13744128\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/boeddeker\">@boeddeker</a> your understanding is almost complete ... the only difference is that in reality there is no barrier of size <code>num_parallel_calls</code>. The <code>__getitem__[i + num_parallel_calls]</code> call is launched only after the <code>__getitem__[i]</code> call finishes but possibly before the <code>__getitem__[i + 1]</code> call finishes. Internally, the <code>map</code> implementation has <code>num_parallel_calls</code> \"slots\" that are used for storing (and possibly prefetching) the invocation results.</p>", "body_text": "@boeddeker your understanding is almost complete ... the only difference is that in reality there is no barrier of size num_parallel_calls. The __getitem__[i + num_parallel_calls] call is launched only after the __getitem__[i] call finishes but possibly before the __getitem__[i + 1] call finishes. Internally, the map implementation has num_parallel_calls \"slots\" that are used for storing (and possibly prefetching) the invocation results.", "body": "@boeddeker your understanding is almost complete ... the only difference is that in reality there is no barrier of size `num_parallel_calls`. The `__getitem__[i + num_parallel_calls]` call is launched only after the `__getitem__[i]` call finishes but possibly before the `__getitem__[i + 1]` call finishes. Internally, the `map` implementation has `num_parallel_calls` \"slots\" that are used for storing (and possibly prefetching) the invocation results."}