{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/343169532", "html_url": "https://github.com/tensorflow/tensorflow/issues/8182#issuecomment-343169532", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8182", "id": 343169532, "node_id": "MDEyOklzc3VlQ29tbWVudDM0MzE2OTUzMg==", "user": {"login": "mschulkind", "id": 523089, "node_id": "MDQ6VXNlcjUyMzA4OQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/523089?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mschulkind", "html_url": "https://github.com/mschulkind", "followers_url": "https://api.github.com/users/mschulkind/followers", "following_url": "https://api.github.com/users/mschulkind/following{/other_user}", "gists_url": "https://api.github.com/users/mschulkind/gists{/gist_id}", "starred_url": "https://api.github.com/users/mschulkind/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mschulkind/subscriptions", "organizations_url": "https://api.github.com/users/mschulkind/orgs", "repos_url": "https://api.github.com/users/mschulkind/repos", "events_url": "https://api.github.com/users/mschulkind/events{/privacy}", "received_events_url": "https://api.github.com/users/mschulkind/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-09T14:24:40Z", "updated_at": "2017-11-09T14:24:40Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think fixing the problem is fairly easy, although since <code>QueueRunner</code> isn't really designed for this, it's slightly messy, but better than the current situation. The problem right now is that the <code>top_queue</code> is closed as soon as the input to <code>bucket_sequence_by_length</code> runs dry, and then nobody ever closes the <code>bucket_queues</code>, but it wouldn't even matter, since by then, the <code>top_queue</code> is already closed.</p>\n<p>This seems to fix the problem:</p>\n<pre><code>    queue_runner.add_queue_runner(\n      queue_runner.QueueRunner(\n          bucket_queues[0], enqueues_to_top,\n          close_op=top_queue.close(),\n          queue_closed_exception_types=(errors.OutOfRangeError,\n                                        errors.CancelledError)))\n    queue_runner.add_queue_runner(\n        queue_runner.QueueRunner(\n            top_queue,\n            bucket_enqueue_ops,\n            close_op=control_flow_ops.group(*[q.close() for q in bucket_queues]),\n            queue_closed_exception_types=(errors.OutOfRangeError,\n                                          errors.CancelledError)))\n</code></pre>\n<p>Basically, instead of closing <code>top_queue</code> when the overall input runs dry, this closes all of the bucket queues, so they then start feeding their last batches. It also uses only one <code>QueueRunner</code> for the <code>enqueues_to_top</code>, so that after all of them individually run dry, the <code>top_queue</code> is finally closed.</p>", "body_text": "I think fixing the problem is fairly easy, although since QueueRunner isn't really designed for this, it's slightly messy, but better than the current situation. The problem right now is that the top_queue is closed as soon as the input to bucket_sequence_by_length runs dry, and then nobody ever closes the bucket_queues, but it wouldn't even matter, since by then, the top_queue is already closed.\nThis seems to fix the problem:\n    queue_runner.add_queue_runner(\n      queue_runner.QueueRunner(\n          bucket_queues[0], enqueues_to_top,\n          close_op=top_queue.close(),\n          queue_closed_exception_types=(errors.OutOfRangeError,\n                                        errors.CancelledError)))\n    queue_runner.add_queue_runner(\n        queue_runner.QueueRunner(\n            top_queue,\n            bucket_enqueue_ops,\n            close_op=control_flow_ops.group(*[q.close() for q in bucket_queues]),\n            queue_closed_exception_types=(errors.OutOfRangeError,\n                                          errors.CancelledError)))\n\nBasically, instead of closing top_queue when the overall input runs dry, this closes all of the bucket queues, so they then start feeding their last batches. It also uses only one QueueRunner for the enqueues_to_top, so that after all of them individually run dry, the top_queue is finally closed.", "body": "I think fixing the problem is fairly easy, although since `QueueRunner` isn't really designed for this, it's slightly messy, but better than the current situation. The problem right now is that the `top_queue` is closed as soon as the input to `bucket_sequence_by_length` runs dry, and then nobody ever closes the `bucket_queues`, but it wouldn't even matter, since by then, the `top_queue` is already closed.\r\n\r\nThis seems to fix the problem:\r\n```\r\n    queue_runner.add_queue_runner(\r\n      queue_runner.QueueRunner(\r\n          bucket_queues[0], enqueues_to_top,\r\n          close_op=top_queue.close(),\r\n          queue_closed_exception_types=(errors.OutOfRangeError,\r\n                                        errors.CancelledError)))\r\n    queue_runner.add_queue_runner(\r\n        queue_runner.QueueRunner(\r\n            top_queue,\r\n            bucket_enqueue_ops,\r\n            close_op=control_flow_ops.group(*[q.close() for q in bucket_queues]),\r\n            queue_closed_exception_types=(errors.OutOfRangeError,\r\n                                          errors.CancelledError)))\r\n```\r\n\r\nBasically, instead of closing `top_queue` when the overall input runs dry, this closes all of the bucket queues, so they then start feeding their last batches. It also uses only one `QueueRunner` for the `enqueues_to_top`, so that after all of them individually run dry, the `top_queue` is finally closed."}