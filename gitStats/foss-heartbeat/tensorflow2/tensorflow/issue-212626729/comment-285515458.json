{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/285515458", "html_url": "https://github.com/tensorflow/tensorflow/issues/8182#issuecomment-285515458", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8182", "id": 285515458, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NTUxNTQ1OA==", "user": {"login": "nOkuda", "id": 1238620, "node_id": "MDQ6VXNlcjEyMzg2MjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1238620?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nOkuda", "html_url": "https://github.com/nOkuda", "followers_url": "https://api.github.com/users/nOkuda/followers", "following_url": "https://api.github.com/users/nOkuda/following{/other_user}", "gists_url": "https://api.github.com/users/nOkuda/gists{/gist_id}", "starred_url": "https://api.github.com/users/nOkuda/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nOkuda/subscriptions", "organizations_url": "https://api.github.com/users/nOkuda/orgs", "repos_url": "https://api.github.com/users/nOkuda/repos", "events_url": "https://api.github.com/users/nOkuda/events{/privacy}", "received_events_url": "https://api.github.com/users/nOkuda/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-09T23:15:41Z", "updated_at": "2017-03-09T23:15:41Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6020988\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/joel-shor\">@joel-shor</a> Sorry about not making a better bit of code.  I was originally thinking that the problem was arising from reading tensorflow records or chaining together multiple queues.  But the new minimal working example definitely supports the hypothesis you chose to point out.</p>\n<p>Updated minimal working example:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-c1\">LAST_RUNNER</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>batch_dequeue<span class=\"pl-pds\">'</span></span>\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>():\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n        examples_queue <span class=\"pl-k\">=</span> tf.train.string_input_producer(\n            [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>1500<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1700<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>10<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>5<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>1<span class=\"pl-pds\">'</span></span>],\n            <span class=\"pl-v\">num_epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>,\n            <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>examples_queue<span class=\"pl-pds\">'</span></span>)\n        example_dq <span class=\"pl-k\">=</span> examples_queue.dequeue()\n\n        batch_max_lens, batches <span class=\"pl-k\">=</span> \\\n            tf.contrib.training.bucket_by_sequence_length(\n                tf.string_to_number(example_dq, <span class=\"pl-v\">out_type</span><span class=\"pl-k\">=</span>tf.int32),\n                [example_dq],\n                <span class=\"pl-c1\">5</span>,\n                [<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">200</span>, <span class=\"pl-c1\">300</span>, <span class=\"pl-c1\">400</span>, <span class=\"pl-c1\">500</span>, <span class=\"pl-c1\">1000</span>],\n                <span class=\"pl-v\">allow_smaller_final_batch</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n                <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">LAST_RUNNER</span>)\n\n        init <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n        sess.run(init)\n        sess.run(tf.local_variables_initializer())\n\n        coord <span class=\"pl-k\">=</span> tf.train.Coordinator()\n        threads <span class=\"pl-k\">=</span> tf.train.start_queue_runners(<span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord)\n        working <span class=\"pl-k\">=</span> <span class=\"pl-c1\">True</span>\n        i <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>\n\n        fetch <span class=\"pl-k\">=</span> {\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>batch_max_lens<span class=\"pl-pds\">'</span></span>: batch_max_lens,\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>batches<span class=\"pl-pds\">'</span></span>: batches}\n\n        <span class=\"pl-k\">while</span> working:\n            <span class=\"pl-k\">try</span>:\n                i <span class=\"pl-k\">+=</span> <span class=\"pl-c1\">1</span>\n                fetched <span class=\"pl-k\">=</span> sess.run(fetch)\n                <span class=\"pl-c1\">print</span>(i, fetched[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>batch_max_lens<span class=\"pl-pds\">'</span></span>])\n            <span class=\"pl-k\">except</span> tf.errors.OutOfRangeError <span class=\"pl-k\">as</span> err:\n                coord.request_stop()\n                working <span class=\"pl-k\">=</span> <span class=\"pl-c1\">False</span>\n\n        coord.join(threads)\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    main()</pre></div>", "body_text": "@joel-shor Sorry about not making a better bit of code.  I was originally thinking that the problem was arising from reading tensorflow records or chaining together multiple queues.  But the new minimal working example definitely supports the hypothesis you chose to point out.\nUpdated minimal working example:\nimport argparse\nimport tensorflow as tf\n\n\nLAST_RUNNER = 'batch_dequeue'\n\n\ndef main():\n    with tf.Session() as sess:\n        examples_queue = tf.train.string_input_producer(\n            ['1500', '1700', '10', '5', '1'],\n            num_epochs=1,\n            name='examples_queue')\n        example_dq = examples_queue.dequeue()\n\n        batch_max_lens, batches = \\\n            tf.contrib.training.bucket_by_sequence_length(\n                tf.string_to_number(example_dq, out_type=tf.int32),\n                [example_dq],\n                5,\n                [100, 200, 300, 400, 500, 1000],\n                allow_smaller_final_batch=True,\n                name=LAST_RUNNER)\n\n        init = tf.global_variables_initializer()\n        sess.run(init)\n        sess.run(tf.local_variables_initializer())\n\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(coord=coord)\n        working = True\n        i = 0\n\n        fetch = {\n            'batch_max_lens': batch_max_lens,\n            'batches': batches}\n\n        while working:\n            try:\n                i += 1\n                fetched = sess.run(fetch)\n                print(i, fetched['batch_max_lens'])\n            except tf.errors.OutOfRangeError as err:\n                coord.request_stop()\n                working = False\n\n        coord.join(threads)\n\n\nif __name__ == '__main__':\n    main()", "body": "@joel-shor Sorry about not making a better bit of code.  I was originally thinking that the problem was arising from reading tensorflow records or chaining together multiple queues.  But the new minimal working example definitely supports the hypothesis you chose to point out.\r\n\r\nUpdated minimal working example:\r\n```Python\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\n\r\nLAST_RUNNER = 'batch_dequeue'\r\n\r\n\r\ndef main():\r\n    with tf.Session() as sess:\r\n        examples_queue = tf.train.string_input_producer(\r\n            ['1500', '1700', '10', '5', '1'],\r\n            num_epochs=1,\r\n            name='examples_queue')\r\n        example_dq = examples_queue.dequeue()\r\n\r\n        batch_max_lens, batches = \\\r\n            tf.contrib.training.bucket_by_sequence_length(\r\n                tf.string_to_number(example_dq, out_type=tf.int32),\r\n                [example_dq],\r\n                5,\r\n                [100, 200, 300, 400, 500, 1000],\r\n                allow_smaller_final_batch=True,\r\n                name=LAST_RUNNER)\r\n\r\n        init = tf.global_variables_initializer()\r\n        sess.run(init)\r\n        sess.run(tf.local_variables_initializer())\r\n\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(coord=coord)\r\n        working = True\r\n        i = 0\r\n\r\n        fetch = {\r\n            'batch_max_lens': batch_max_lens,\r\n            'batches': batches}\r\n\r\n        while working:\r\n            try:\r\n                i += 1\r\n                fetched = sess.run(fetch)\r\n                print(i, fetched['batch_max_lens'])\r\n            except tf.errors.OutOfRangeError as err:\r\n                coord.request_stop()\r\n                working = False\r\n\r\n        coord.join(threads)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```"}