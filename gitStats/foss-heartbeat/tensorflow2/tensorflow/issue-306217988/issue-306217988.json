{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17803", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17803/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17803/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17803/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17803", "id": 306217988, "node_id": "MDU6SXNzdWUzMDYyMTc5ODg=", "number": 17803, "title": "tf throws some errors in estimator.train function when I droped additional column in input_fn", "user": {"login": "klyan", "id": 7780254, "node_id": "MDQ6VXNlcjc3ODAyNTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/7780254?v=4", "gravatar_id": "", "url": "https://api.github.com/users/klyan", "html_url": "https://github.com/klyan", "followers_url": "https://api.github.com/users/klyan/followers", "following_url": "https://api.github.com/users/klyan/following{/other_user}", "gists_url": "https://api.github.com/users/klyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/klyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/klyan/subscriptions", "organizations_url": "https://api.github.com/users/klyan/orgs", "repos_url": "https://api.github.com/users/klyan/repos", "events_url": "https://api.github.com/users/klyan/events{/privacy}", "received_events_url": "https://api.github.com/users/klyan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-03-18T06:55:37Z", "updated_at": "2018-05-07T08:25:54Z", "closed_at": "2018-05-07T08:25:54Z", "author_association": "NONE", "body_html": "<p><code>sample_weight</code> is instance-based weight, which i wanted to pass to <code>tf.losses.sparse_softmax_cross_entropy</code>,  so I droped this column in the features. However, I still got some errors. If i removed the <code>sample_weight</code> column in <code>data_train</code>, it's OK !</p>\n<p>`<br>\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=True)</p>\n<p>classifier.train(input_fn=train_input_fn)  #, steps=500)</p>\n<p>def my_model(features, labels, mode, params):</p>\n<pre><code>if 'order_weight' in features.keys():\n    sample_weight = features.pop('sample_weight')\n\nnet = tf.feature_column.input_layer(features, params['feature_columns'])\n\nfor units in params['hidden_units']:\n    net = tf.layers.dense(net, units=units, activation=params[\"activation\"])\n\nlogits = tf.layers.dense(net, params['n_classes'], activation=None)\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\n        'probabilities': tf.nn.softmax(logits),\n        'logits': logits\n    }\n    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\nloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\nmetrics_auc = tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])\nmetrics = {'auc': metrics_auc}          #tf.summary.scalar('auc', metrics_auc)\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n\n# Create training op.\nassert mode == tf.estimator.ModeKeys.TRAIN\noptimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) \nreturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n</code></pre>\n<p>`</p>", "body_text": "sample_weight is instance-based weight, which i wanted to pass to tf.losses.sparse_softmax_cross_entropy,  so I droped this column in the features. However, I still got some errors. If i removed the sample_weight column in data_train, it's OK !\n`\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=True)\nclassifier.train(input_fn=train_input_fn)  #, steps=500)\ndef my_model(features, labels, mode, params):\nif 'order_weight' in features.keys():\n    sample_weight = features.pop('sample_weight')\n\nnet = tf.feature_column.input_layer(features, params['feature_columns'])\n\nfor units in params['hidden_units']:\n    net = tf.layers.dense(net, units=units, activation=params[\"activation\"])\n\nlogits = tf.layers.dense(net, params['n_classes'], activation=None)\n\nif mode == tf.estimator.ModeKeys.PREDICT:\n    predictions = {\n        'probabilities': tf.nn.softmax(logits),\n        'logits': logits\n    }\n    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\nloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\nmetrics_auc = tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])\nmetrics = {'auc': metrics_auc}          #tf.summary.scalar('auc', metrics_auc)\nif mode == tf.estimator.ModeKeys.EVAL:\n    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n\n# Create training op.\nassert mode == tf.estimator.ModeKeys.TRAIN\noptimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) \nreturn tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\n`", "body": "\r\n`sample_weight` is instance-based weight, which i wanted to pass to `tf.losses.sparse_softmax_cross_entropy`,  so I droped this column in the features. However, I still got some errors. If i removed the `sample_weight` column in `data_train`, it's OK !\r\n\r\n\r\n`\r\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(x=data_train, y=data_train_click, batch_size = 1024, num_epochs=1, shuffle=True)\r\n\r\nclassifier.train(input_fn=train_input_fn)  #, steps=500)\r\n\r\n   def my_model(features, labels, mode, params):\r\n\r\n    if 'order_weight' in features.keys():\r\n        sample_weight = features.pop('sample_weight')\r\n\r\n    net = tf.feature_column.input_layer(features, params['feature_columns'])\r\n\r\n    for units in params['hidden_units']:\r\n        net = tf.layers.dense(net, units=units, activation=params[\"activation\"])\r\n\r\n    logits = tf.layers.dense(net, params['n_classes'], activation=None)\r\n\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            'probabilities': tf.nn.softmax(logits),\r\n            'logits': logits\r\n        }\r\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n    metrics_auc = tf.metrics.auc(labels=labels, predictions=tf.nn.softmax(logits)[:,1])\r\n    metrics = {'auc': metrics_auc}          #tf.summary.scalar('auc', metrics_auc)\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\r\n\r\n    # Create training op.\r\n    assert mode == tf.estimator.ModeKeys.TRAIN\r\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\r\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step()) \r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n`"}