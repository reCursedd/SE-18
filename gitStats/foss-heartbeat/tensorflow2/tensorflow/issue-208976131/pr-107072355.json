{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7710", "id": 107072355, "node_id": "MDExOlB1bGxSZXF1ZXN0MTA3MDcyMzU1", "html_url": "https://github.com/tensorflow/tensorflow/pull/7710", "diff_url": "https://github.com/tensorflow/tensorflow/pull/7710.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/7710.patch", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7710", "number": 7710, "state": "closed", "locked": false, "title": "[WIP] MPI Support for Tensor data communication", "user": {"login": "jbedorf", "id": 1643141, "node_id": "MDQ6VXNlcjE2NDMxNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1643141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbedorf", "html_url": "https://github.com/jbedorf", "followers_url": "https://api.github.com/users/jbedorf/followers", "following_url": "https://api.github.com/users/jbedorf/following{/other_user}", "gists_url": "https://api.github.com/users/jbedorf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbedorf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbedorf/subscriptions", "organizations_url": "https://api.github.com/users/jbedorf/orgs", "repos_url": "https://api.github.com/users/jbedorf/repos", "events_url": "https://api.github.com/users/jbedorf/events{/privacy}", "received_events_url": "https://api.github.com/users/jbedorf/received_events", "type": "User", "site_admin": false}, "body": "This adds a second communication path to the distributed TensorFlow implementation, next to the gRPC communication path. This new communication path uses the Message Passing Interface (MPI) API to handle communication between processes allowing TensorFlow to take advantage of modern high performance networks such as Infiniband.\r\nThis pull request is used to start a discussion about this implementation, any draw backs, alternatives and requests for feedback and participation from the open source community.\r\n\r\n\r\n**The current pull request makes the following changes**\r\n- A new communication path has been added for sending and receiving Tensors between distinct processes.\r\n- This new communication path uses the MPI API to handle setting up the connections and the data transfer.\r\n- When using a CUDA-Aware (and/or GPUDirect RDMA) MPI implementation this path works for both CPU and GPU based Tensor data. \r\n\r\nThis new path is implemented by modifying the current 'send' and 'receive' operations. The original gRPC code stays in place and is responsible for setting up connections and all non-tensordata communications. \r\nAlthough MPI supports one sided RDMA operations, this example implementation uses plain blocking send/receive operations. This because the current TensorFlow (memory) model makes it difficult to efficiently implement the communication using MPI_Get/MPI_Put (see below). \r\n\r\n\r\n**Usage**\r\nIn order to setup the required MPI environment the Python instances have to be launched using 'mpirun'. An example launch script, which does not modify the original TF script, is supplied in: tensorflow/tools/dist_test/mpi/start-openmpi.sh\r\n\r\nThe launching can be done differently if one handles the task type/id selection inside the TF python script, by either reading the environment variables as set by mpirun or by using the mpi4py Python library to retrieve process IDs and hostnames. \r\n\r\nThe MPI execution path can be disabled by setting the environment variable 'MPI_PATH_DISABLED' to 1, like:\r\nexport MPI_PATH_DISABLED=1\r\n\r\n\r\n**MPI Requirements**\r\n- The MPI implementation should be built with support for MPI_THREAD_MULTIPLE\r\n- To enable this path for GPU data, the MPI implementation should be built with CUDA support (CUDA-Aware MPI)\r\n- Tested using OpenMPI-2.0.1 \r\n- Currently the path to the OpenMPI library is hard-coded in the \"third_party/gpus/crosstool/CROSSTOOL.tpl\" file, this should be made an option in the configure code. \r\n\r\n\r\n**Implementation details**\r\n\r\n\r\n**MPI process ID mapping to gRPC names**\r\nTo handle communication between processes MPI identifies processes using a unique process-ID. TensorFlow uses gRPC which uses names based on things like 'worker', 'gpu', 'task'. To enable the MPI path in co-existence with the gRPC communication stack the names of the gRPC 'server' are mapped to the unique MPI IDs during the initialization of the gRPC stack. This conversion is then available once the tensor-data will be communicated.\r\n\r\n\r\n**Send details**\r\nThe original 'send' operation places a tensor in a table which is then picked up by the gRPC thread once a request for that data arrives. In the MPI path we place an MPI_Send call which will block until the matching MPI_Recv call is made on the receiving side. By making a hash of the tensor description we create a unique combination of sending-process/tensor-id which will be matched by the receiving process. This enables multiple tensors to be in flight from a single process using different send threads. Sending is a two-step process, the first message contains the properties of the Tensor (data type & shape) followed by a message containing the actual data. \r\nThe send call is intercept in the file: 'tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc'\r\nIn this function: BaseRemoteRendezvous::Send\r\nThe code verifies that the destination is a different process from the sending process, if this is the case (and the implementation is enabled at run-time) then it will enter the new 'SendToRemote' functions.  Otherwise it will progress through the original code.\r\nTo keep the changes as organized as possible, the actual implementation of the sending-functions are in:  tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc\r\nThe other file modifications are required to get the path enabled through out the calling stack.\r\n\r\n**Receive details**\r\nThe original 'receive' operation requests a named-tensor from a remote process by placing a request through the gRPC stack. In the MPI path this request has been replaced by a set of receive calls that match the send operations. If there is no matching send operation yet, then the path will block until the sending process has arrived at the same point. The send and receive operations are matched using a hash of the requested tensor name. \r\nThe first message will describe the tensor, this description is passed on to the memory allocation functions after which the actual tensor data flows directly into the newly allocated memory buffer.\r\nAll the modified receive functionality is in: tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc\r\nBy inheriting the 'GrpcRemoteWorker' and replacing the 'RecvTensorAsync' function. \r\n\r\nNote: It is possible that a tensor with the same name is send (received) multiple times between the same set of processes. This is not a problem as messages are handled as unique units and have unique follow up IDs (based on thread IDs).\r\n\r\n\r\n**TensorFlow limitations**\r\n- Memory is constantly being (de)allocated in between iterations. This hinders the performance when using Infiniband connections as memory buffers must be pinned/mapped before they can be used. This can impact the effective bandwidth by a factor 3 as this pinning is a relatively costly operation. \r\n- It would be more efficient if memory buffers for the same tensors would be reused/retained in between iterations, this makes the pinning of memory buffers a one-time occurrence. It also allows for the removal of the allocation step in the 'receive' functions.\r\n\r\n\r\nMinds.ai\r\nJeroen B\u00e9dorf", "created_at": "2017-02-20T20:33:02Z", "updated_at": "2017-05-04T21:51:52Z", "closed_at": "2017-05-04T21:51:52Z", "merged_at": null, "merge_commit_sha": "40d557874efd4263345963527fdcdb00486d7571", "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "requested_reviewers": [], "requested_teams": [], "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}, {"id": 474725938, "node_id": "MDU6TGFiZWw0NzQ3MjU5Mzg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stalled", "name": "stalled", "color": "d4c5f9", "default": false}, {"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "milestone": null, "commits_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7710/commits", "review_comments_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7710/comments", "review_comment_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7710/comments", "statuses_url": "https://api.github.com/repos/tensorflow/tensorflow/statuses/b43d22ed0ecd59779a97ad2d07048ff128658990", "head": {"label": "jbedorf:MPIV1", "ref": "MPIV1", "sha": "b43d22ed0ecd59779a97ad2d07048ff128658990", "user": {"login": "jbedorf", "id": 1643141, "node_id": "MDQ6VXNlcjE2NDMxNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1643141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbedorf", "html_url": "https://github.com/jbedorf", "followers_url": "https://api.github.com/users/jbedorf/followers", "following_url": "https://api.github.com/users/jbedorf/following{/other_user}", "gists_url": "https://api.github.com/users/jbedorf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbedorf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbedorf/subscriptions", "organizations_url": "https://api.github.com/users/jbedorf/orgs", "repos_url": "https://api.github.com/users/jbedorf/repos", "events_url": "https://api.github.com/users/jbedorf/events{/privacy}", "received_events_url": "https://api.github.com/users/jbedorf/received_events", "type": "User", "site_admin": false}, "repo": {"id": 79781984, "node_id": "MDEwOlJlcG9zaXRvcnk3OTc4MTk4NA==", "name": "tensorflow", "full_name": "jbedorf/tensorflow", "private": false, "owner": {"login": "jbedorf", "id": 1643141, "node_id": "MDQ6VXNlcjE2NDMxNDE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1643141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jbedorf", "html_url": "https://github.com/jbedorf", "followers_url": "https://api.github.com/users/jbedorf/followers", "following_url": "https://api.github.com/users/jbedorf/following{/other_user}", "gists_url": "https://api.github.com/users/jbedorf/gists{/gist_id}", "starred_url": "https://api.github.com/users/jbedorf/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jbedorf/subscriptions", "organizations_url": "https://api.github.com/users/jbedorf/orgs", "repos_url": "https://api.github.com/users/jbedorf/repos", "events_url": "https://api.github.com/users/jbedorf/events{/privacy}", "received_events_url": "https://api.github.com/users/jbedorf/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/jbedorf/tensorflow", "description": "Computation using data flow graphs for scalable machine learning", "fork": true, "url": "https://api.github.com/repos/jbedorf/tensorflow", "forks_url": "https://api.github.com/repos/jbedorf/tensorflow/forks", "keys_url": "https://api.github.com/repos/jbedorf/tensorflow/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/jbedorf/tensorflow/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/jbedorf/tensorflow/teams", "hooks_url": "https://api.github.com/repos/jbedorf/tensorflow/hooks", "issue_events_url": "https://api.github.com/repos/jbedorf/tensorflow/issues/events{/number}", "events_url": "https://api.github.com/repos/jbedorf/tensorflow/events", "assignees_url": "https://api.github.com/repos/jbedorf/tensorflow/assignees{/user}", "branches_url": "https://api.github.com/repos/jbedorf/tensorflow/branches{/branch}", "tags_url": "https://api.github.com/repos/jbedorf/tensorflow/tags", "blobs_url": "https://api.github.com/repos/jbedorf/tensorflow/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/jbedorf/tensorflow/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/jbedorf/tensorflow/git/refs{/sha}", "trees_url": "https://api.github.com/repos/jbedorf/tensorflow/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/jbedorf/tensorflow/statuses/{sha}", "languages_url": "https://api.github.com/repos/jbedorf/tensorflow/languages", "stargazers_url": "https://api.github.com/repos/jbedorf/tensorflow/stargazers", "contributors_url": "https://api.github.com/repos/jbedorf/tensorflow/contributors", "subscribers_url": "https://api.github.com/repos/jbedorf/tensorflow/subscribers", "subscription_url": "https://api.github.com/repos/jbedorf/tensorflow/subscription", "commits_url": "https://api.github.com/repos/jbedorf/tensorflow/commits{/sha}", "git_commits_url": "https://api.github.com/repos/jbedorf/tensorflow/git/commits{/sha}", "comments_url": "https://api.github.com/repos/jbedorf/tensorflow/comments{/number}", "issue_comment_url": "https://api.github.com/repos/jbedorf/tensorflow/issues/comments{/number}", "contents_url": "https://api.github.com/repos/jbedorf/tensorflow/contents/{+path}", "compare_url": "https://api.github.com/repos/jbedorf/tensorflow/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/jbedorf/tensorflow/merges", "archive_url": "https://api.github.com/repos/jbedorf/tensorflow/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/jbedorf/tensorflow/downloads", "issues_url": "https://api.github.com/repos/jbedorf/tensorflow/issues{/number}", "pulls_url": "https://api.github.com/repos/jbedorf/tensorflow/pulls{/number}", "milestones_url": "https://api.github.com/repos/jbedorf/tensorflow/milestones{/number}", "notifications_url": "https://api.github.com/repos/jbedorf/tensorflow/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/jbedorf/tensorflow/labels{/name}", "releases_url": "https://api.github.com/repos/jbedorf/tensorflow/releases{/id}", "deployments_url": "https://api.github.com/repos/jbedorf/tensorflow/deployments", "created_at": "2017-01-23T07:47:28Z", "updated_at": "2017-01-23T07:47:51Z", "pushed_at": "2017-11-15T15:52:40Z", "git_url": "git://github.com/jbedorf/tensorflow.git", "ssh_url": "git@github.com:jbedorf/tensorflow.git", "clone_url": "https://github.com/jbedorf/tensorflow.git", "svn_url": "https://github.com/jbedorf/tensorflow", "homepage": "http://tensorflow.org", "size": 135467, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 0, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master"}}, "base": {"label": "tensorflow:master", "ref": "master", "sha": "06be849aa2bbd0208c0a2f5eb0fd0b7719e84774", "user": {"login": "tensorflow", "id": 15658638, "node_id": "MDEyOk9yZ2FuaXphdGlvbjE1NjU4NjM4", "avatar_url": "https://avatars1.githubusercontent.com/u/15658638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorflow", "html_url": "https://github.com/tensorflow", "followers_url": "https://api.github.com/users/tensorflow/followers", "following_url": "https://api.github.com/users/tensorflow/following{/other_user}", "gists_url": "https://api.github.com/users/tensorflow/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorflow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorflow/subscriptions", "organizations_url": "https://api.github.com/users/tensorflow/orgs", "repos_url": "https://api.github.com/users/tensorflow/repos", "events_url": "https://api.github.com/users/tensorflow/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorflow/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 45717250, "node_id": "MDEwOlJlcG9zaXRvcnk0NTcxNzI1MA==", "name": "tensorflow", "full_name": "tensorflow/tensorflow", "private": false, "owner": {"login": "tensorflow", "id": 15658638, "node_id": "MDEyOk9yZ2FuaXphdGlvbjE1NjU4NjM4", "avatar_url": "https://avatars1.githubusercontent.com/u/15658638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorflow", "html_url": "https://github.com/tensorflow", "followers_url": "https://api.github.com/users/tensorflow/followers", "following_url": "https://api.github.com/users/tensorflow/following{/other_user}", "gists_url": "https://api.github.com/users/tensorflow/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorflow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorflow/subscriptions", "organizations_url": "https://api.github.com/users/tensorflow/orgs", "repos_url": "https://api.github.com/users/tensorflow/repos", "events_url": "https://api.github.com/users/tensorflow/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorflow/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/tensorflow/tensorflow", "description": "An Open Source Machine Learning Framework for Everyone", "fork": false, "url": "https://api.github.com/repos/tensorflow/tensorflow", "forks_url": "https://api.github.com/repos/tensorflow/tensorflow/forks", "keys_url": "https://api.github.com/repos/tensorflow/tensorflow/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/tensorflow/tensorflow/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/tensorflow/tensorflow/teams", "hooks_url": "https://api.github.com/repos/tensorflow/tensorflow/hooks", "issue_events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/events{/number}", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/events", "assignees_url": "https://api.github.com/repos/tensorflow/tensorflow/assignees{/user}", "branches_url": "https://api.github.com/repos/tensorflow/tensorflow/branches{/branch}", "tags_url": "https://api.github.com/repos/tensorflow/tensorflow/tags", "blobs_url": "https://api.github.com/repos/tensorflow/tensorflow/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/tensorflow/tensorflow/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/tensorflow/tensorflow/git/refs{/sha}", "trees_url": "https://api.github.com/repos/tensorflow/tensorflow/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/tensorflow/tensorflow/statuses/{sha}", "languages_url": "https://api.github.com/repos/tensorflow/tensorflow/languages", "stargazers_url": "https://api.github.com/repos/tensorflow/tensorflow/stargazers", "contributors_url": "https://api.github.com/repos/tensorflow/tensorflow/contributors", "subscribers_url": "https://api.github.com/repos/tensorflow/tensorflow/subscribers", "subscription_url": "https://api.github.com/repos/tensorflow/tensorflow/subscription", "commits_url": "https://api.github.com/repos/tensorflow/tensorflow/commits{/sha}", "git_commits_url": "https://api.github.com/repos/tensorflow/tensorflow/git/commits{/sha}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/comments{/number}", "issue_comment_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments{/number}", "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/{+path}", "compare_url": "https://api.github.com/repos/tensorflow/tensorflow/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/tensorflow/tensorflow/merges", "archive_url": "https://api.github.com/repos/tensorflow/tensorflow/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/tensorflow/tensorflow/downloads", "issues_url": "https://api.github.com/repos/tensorflow/tensorflow/issues{/number}", "pulls_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls{/number}", "milestones_url": "https://api.github.com/repos/tensorflow/tensorflow/milestones{/number}", "notifications_url": "https://api.github.com/repos/tensorflow/tensorflow/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/labels{/name}", "releases_url": "https://api.github.com/repos/tensorflow/tensorflow/releases{/id}", "deployments_url": "https://api.github.com/repos/tensorflow/tensorflow/deployments", "created_at": "2015-11-07T01:19:20Z", "updated_at": "2018-11-24T19:34:08Z", "pushed_at": "2018-11-24T18:40:19Z", "git_url": "git://github.com/tensorflow/tensorflow.git", "ssh_url": "git@github.com:tensorflow/tensorflow.git", "clone_url": "https://github.com/tensorflow/tensorflow.git", "svn_url": "https://github.com/tensorflow/tensorflow", "homepage": "https://tensorflow.org", "size": 284546, "stargazers_count": 115176, "watchers_count": 115176, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "forks_count": 69944, "mirror_url": null, "archived": false, "open_issues_count": 1759, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "forks": 69944, "open_issues": 1759, "watchers": 115176, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7710"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/7710"}, "issue": {"href": "https://api.github.com/repos/tensorflow/tensorflow/issues/7710"}, "comments": {"href": "https://api.github.com/repos/tensorflow/tensorflow/issues/7710/comments"}, "review_comments": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7710/comments"}, "review_comment": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7710/commits"}, "statuses": {"href": "https://api.github.com/repos/tensorflow/tensorflow/statuses/b43d22ed0ecd59779a97ad2d07048ff128658990"}}, "author_association": "CONTRIBUTOR", "body_html": "<p>This adds a second communication path to the distributed TensorFlow implementation, next to the gRPC communication path. This new communication path uses the Message Passing Interface (MPI) API to handle communication between processes allowing TensorFlow to take advantage of modern high performance networks such as Infiniband.<br>\nThis pull request is used to start a discussion about this implementation, any draw backs, alternatives and requests for feedback and participation from the open source community.</p>\n<p><strong>The current pull request makes the following changes</strong></p>\n<ul>\n<li>A new communication path has been added for sending and receiving Tensors between distinct processes.</li>\n<li>This new communication path uses the MPI API to handle setting up the connections and the data transfer.</li>\n<li>When using a CUDA-Aware (and/or GPUDirect RDMA) MPI implementation this path works for both CPU and GPU based Tensor data.</li>\n</ul>\n<p>This new path is implemented by modifying the current 'send' and 'receive' operations. The original gRPC code stays in place and is responsible for setting up connections and all non-tensordata communications.<br>\nAlthough MPI supports one sided RDMA operations, this example implementation uses plain blocking send/receive operations. This because the current TensorFlow (memory) model makes it difficult to efficiently implement the communication using MPI_Get/MPI_Put (see below).</p>\n<p><strong>Usage</strong><br>\nIn order to setup the required MPI environment the Python instances have to be launched using 'mpirun'. An example launch script, which does not modify the original TF script, is supplied in: tensorflow/tools/dist_test/mpi/start-openmpi.sh</p>\n<p>The launching can be done differently if one handles the task type/id selection inside the TF python script, by either reading the environment variables as set by mpirun or by using the mpi4py Python library to retrieve process IDs and hostnames.</p>\n<p>The MPI execution path can be disabled by setting the environment variable 'MPI_PATH_DISABLED' to 1, like:<br>\nexport MPI_PATH_DISABLED=1</p>\n<p><strong>MPI Requirements</strong></p>\n<ul>\n<li>The MPI implementation should be built with support for MPI_THREAD_MULTIPLE</li>\n<li>To enable this path for GPU data, the MPI implementation should be built with CUDA support (CUDA-Aware MPI)</li>\n<li>Tested using OpenMPI-2.0.1</li>\n<li>Currently the path to the OpenMPI library is hard-coded in the \"third_party/gpus/crosstool/CROSSTOOL.tpl\" file, this should be made an option in the configure code.</li>\n</ul>\n<p><strong>Implementation details</strong></p>\n<p><strong>MPI process ID mapping to gRPC names</strong><br>\nTo handle communication between processes MPI identifies processes using a unique process-ID. TensorFlow uses gRPC which uses names based on things like 'worker', 'gpu', 'task'. To enable the MPI path in co-existence with the gRPC communication stack the names of the gRPC 'server' are mapped to the unique MPI IDs during the initialization of the gRPC stack. This conversion is then available once the tensor-data will be communicated.</p>\n<p><strong>Send details</strong><br>\nThe original 'send' operation places a tensor in a table which is then picked up by the gRPC thread once a request for that data arrives. In the MPI path we place an MPI_Send call which will block until the matching MPI_Recv call is made on the receiving side. By making a hash of the tensor description we create a unique combination of sending-process/tensor-id which will be matched by the receiving process. This enables multiple tensors to be in flight from a single process using different send threads. Sending is a two-step process, the first message contains the properties of the Tensor (data type &amp; shape) followed by a message containing the actual data.<br>\nThe send call is intercept in the file: 'tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc'<br>\nIn this function: BaseRemoteRendezvous::Send<br>\nThe code verifies that the destination is a different process from the sending process, if this is the case (and the implementation is enabled at run-time) then it will enter the new 'SendToRemote' functions.  Otherwise it will progress through the original code.<br>\nTo keep the changes as organized as possible, the actual implementation of the sending-functions are in:  tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc<br>\nThe other file modifications are required to get the path enabled through out the calling stack.</p>\n<p><strong>Receive details</strong><br>\nThe original 'receive' operation requests a named-tensor from a remote process by placing a request through the gRPC stack. In the MPI path this request has been replaced by a set of receive calls that match the send operations. If there is no matching send operation yet, then the path will block until the sending process has arrived at the same point. The send and receive operations are matched using a hash of the requested tensor name.<br>\nThe first message will describe the tensor, this description is passed on to the memory allocation functions after which the actual tensor data flows directly into the newly allocated memory buffer.<br>\nAll the modified receive functionality is in: tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc<br>\nBy inheriting the 'GrpcRemoteWorker' and replacing the 'RecvTensorAsync' function.</p>\n<p>Note: It is possible that a tensor with the same name is send (received) multiple times between the same set of processes. This is not a problem as messages are handled as unique units and have unique follow up IDs (based on thread IDs).</p>\n<p><strong>TensorFlow limitations</strong></p>\n<ul>\n<li>Memory is constantly being (de)allocated in between iterations. This hinders the performance when using Infiniband connections as memory buffers must be pinned/mapped before they can be used. This can impact the effective bandwidth by a factor 3 as this pinning is a relatively costly operation.</li>\n<li>It would be more efficient if memory buffers for the same tensors would be reused/retained in between iterations, this makes the pinning of memory buffers a one-time occurrence. It also allows for the removal of the allocation step in the 'receive' functions.</li>\n</ul>\n<p>Minds.ai<br>\nJeroen B\u00e9dorf</p>", "body_text": "This adds a second communication path to the distributed TensorFlow implementation, next to the gRPC communication path. This new communication path uses the Message Passing Interface (MPI) API to handle communication between processes allowing TensorFlow to take advantage of modern high performance networks such as Infiniband.\nThis pull request is used to start a discussion about this implementation, any draw backs, alternatives and requests for feedback and participation from the open source community.\nThe current pull request makes the following changes\n\nA new communication path has been added for sending and receiving Tensors between distinct processes.\nThis new communication path uses the MPI API to handle setting up the connections and the data transfer.\nWhen using a CUDA-Aware (and/or GPUDirect RDMA) MPI implementation this path works for both CPU and GPU based Tensor data.\n\nThis new path is implemented by modifying the current 'send' and 'receive' operations. The original gRPC code stays in place and is responsible for setting up connections and all non-tensordata communications.\nAlthough MPI supports one sided RDMA operations, this example implementation uses plain blocking send/receive operations. This because the current TensorFlow (memory) model makes it difficult to efficiently implement the communication using MPI_Get/MPI_Put (see below).\nUsage\nIn order to setup the required MPI environment the Python instances have to be launched using 'mpirun'. An example launch script, which does not modify the original TF script, is supplied in: tensorflow/tools/dist_test/mpi/start-openmpi.sh\nThe launching can be done differently if one handles the task type/id selection inside the TF python script, by either reading the environment variables as set by mpirun or by using the mpi4py Python library to retrieve process IDs and hostnames.\nThe MPI execution path can be disabled by setting the environment variable 'MPI_PATH_DISABLED' to 1, like:\nexport MPI_PATH_DISABLED=1\nMPI Requirements\n\nThe MPI implementation should be built with support for MPI_THREAD_MULTIPLE\nTo enable this path for GPU data, the MPI implementation should be built with CUDA support (CUDA-Aware MPI)\nTested using OpenMPI-2.0.1\nCurrently the path to the OpenMPI library is hard-coded in the \"third_party/gpus/crosstool/CROSSTOOL.tpl\" file, this should be made an option in the configure code.\n\nImplementation details\nMPI process ID mapping to gRPC names\nTo handle communication between processes MPI identifies processes using a unique process-ID. TensorFlow uses gRPC which uses names based on things like 'worker', 'gpu', 'task'. To enable the MPI path in co-existence with the gRPC communication stack the names of the gRPC 'server' are mapped to the unique MPI IDs during the initialization of the gRPC stack. This conversion is then available once the tensor-data will be communicated.\nSend details\nThe original 'send' operation places a tensor in a table which is then picked up by the gRPC thread once a request for that data arrives. In the MPI path we place an MPI_Send call which will block until the matching MPI_Recv call is made on the receiving side. By making a hash of the tensor description we create a unique combination of sending-process/tensor-id which will be matched by the receiving process. This enables multiple tensors to be in flight from a single process using different send threads. Sending is a two-step process, the first message contains the properties of the Tensor (data type & shape) followed by a message containing the actual data.\nThe send call is intercept in the file: 'tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc'\nIn this function: BaseRemoteRendezvous::Send\nThe code verifies that the destination is a different process from the sending process, if this is the case (and the implementation is enabled at run-time) then it will enter the new 'SendToRemote' functions.  Otherwise it will progress through the original code.\nTo keep the changes as organized as possible, the actual implementation of the sending-functions are in:  tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc\nThe other file modifications are required to get the path enabled through out the calling stack.\nReceive details\nThe original 'receive' operation requests a named-tensor from a remote process by placing a request through the gRPC stack. In the MPI path this request has been replaced by a set of receive calls that match the send operations. If there is no matching send operation yet, then the path will block until the sending process has arrived at the same point. The send and receive operations are matched using a hash of the requested tensor name.\nThe first message will describe the tensor, this description is passed on to the memory allocation functions after which the actual tensor data flows directly into the newly allocated memory buffer.\nAll the modified receive functionality is in: tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc\nBy inheriting the 'GrpcRemoteWorker' and replacing the 'RecvTensorAsync' function.\nNote: It is possible that a tensor with the same name is send (received) multiple times between the same set of processes. This is not a problem as messages are handled as unique units and have unique follow up IDs (based on thread IDs).\nTensorFlow limitations\n\nMemory is constantly being (de)allocated in between iterations. This hinders the performance when using Infiniband connections as memory buffers must be pinned/mapped before they can be used. This can impact the effective bandwidth by a factor 3 as this pinning is a relatively costly operation.\nIt would be more efficient if memory buffers for the same tensors would be reused/retained in between iterations, this makes the pinning of memory buffers a one-time occurrence. It also allows for the removal of the allocation step in the 'receive' functions.\n\nMinds.ai\nJeroen B\u00e9dorf", "merged": false, "mergeable": false, "rebaseable": false, "mergeable_state": "dirty", "merged_by": null, "comments": 13, "review_comments": 19, "maintainer_can_modify": false, "commits": 12, "additions": 635, "deletions": 97, "changed_files": 18}