{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425604804", "html_url": "https://github.com/tensorflow/tensorflow/issues/22304#issuecomment-425604804", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22304", "id": 425604804, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTYwNDgwNA==", "user": {"login": "xu-song", "id": 13825126, "node_id": "MDQ6VXNlcjEzODI1MTI2", "avatar_url": "https://avatars3.githubusercontent.com/u/13825126?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xu-song", "html_url": "https://github.com/xu-song", "followers_url": "https://api.github.com/users/xu-song/followers", "following_url": "https://api.github.com/users/xu-song/following{/other_user}", "gists_url": "https://api.github.com/users/xu-song/gists{/gist_id}", "starred_url": "https://api.github.com/users/xu-song/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xu-song/subscriptions", "organizations_url": "https://api.github.com/users/xu-song/orgs", "repos_url": "https://api.github.com/users/xu-song/repos", "events_url": "https://api.github.com/users/xu-song/events{/privacy}", "received_events_url": "https://api.github.com/users/xu-song/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-29T01:30:23Z", "updated_at": "2018-09-29T01:49:13Z", "author_association": "NONE", "body_html": "<h1>simple example</h1>\n<p>this is a simple example, which get <code>result = a*b+1</code></p>\n<h2>python - save model</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> demo.py</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> os\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    train_dir <span class=\"pl-k\">=</span> os.path.join(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>demo_model/<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>demo<span class=\"pl-pds\">\"</span></span>)\n\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n        a <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>)\n        b <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>)\n        y <span class=\"pl-k\">=</span> tf.Variable(tf.ones(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>y<span class=\"pl-pds\">'</span></span>)\n        res <span class=\"pl-k\">=</span> tf.add(tf.multiply(a, b), y, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>res<span class=\"pl-pds\">'</span></span>)\n\n    config <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n        feed_dict <span class=\"pl-k\">=</span> {a:<span class=\"pl-c1\">2</span>, b:<span class=\"pl-c1\">3</span>}\n        fetch_list <span class=\"pl-k\">=</span> [res]\n        sess.run(tf.global_variables_initializer())\n        saver <span class=\"pl-k\">=</span> tf.train.Saver()\n\n        res <span class=\"pl-k\">=</span> sess.run(<span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict, <span class=\"pl-v\">fetches</span><span class=\"pl-k\">=</span>fetch_list)\n        saver.save(sess, train_dir)\n\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>result: <span class=\"pl-pds\">\"</span></span>, res[<span class=\"pl-c1\">0</span>])</pre></div>\n<div class=\"highlight highlight-source-shell\"><pre>$ python demo.py \n2018-09-29 09:35:28.855859: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>result: <span class=\"pl-pds\">'</span></span>, array([7], dtype=int32))</pre></div>\n<h2>python - restore</h2>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> demo-restore.py</span>\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    config <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">allow_soft_placement</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n        saver <span class=\"pl-k\">=</span> tf.train.import_meta_graph(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>demo_model/demo.meta<span class=\"pl-pds\">'</span></span>)\n        saver.restore(sess, tf.train.latest_checkpoint(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>demo_model/<span class=\"pl-pds\">'</span></span>))\n        graph <span class=\"pl-k\">=</span> tf.get_default_graph()\n        a <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>a:0<span class=\"pl-pds\">\"</span></span>)\n        b <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>b:0<span class=\"pl-pds\">\"</span></span>)\n        feed_dict <span class=\"pl-k\">=</span> {a: <span class=\"pl-c1\">2</span>, b: <span class=\"pl-c1\">3</span>}\n\n        op_to_restore <span class=\"pl-k\">=</span> graph.get_tensor_by_name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>res:0<span class=\"pl-pds\">\"</span></span>)\n        <span class=\"pl-c1\">print</span>(sess.run(<span class=\"pl-v\">fetches</span><span class=\"pl-k\">=</span>op_to_restore, <span class=\"pl-v\">feed_dict</span><span class=\"pl-k\">=</span>feed_dict))</pre></div>\n<pre><code>$ python demo-restore.py\n[7]\n</code></pre>\n<h2>C++ restore model</h2>\n<div class=\"highlight highlight-source-c\"><pre><span class=\"pl-c\"><span class=\"pl-c\">//</span> demo.cc</span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">&lt;</span>iostream<span class=\"pl-pds\">&gt;</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/public/session.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/protobuf/meta_graph.pb.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/cc/client/client_session.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/cc/ops/standard_ops.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/tensor.h<span class=\"pl-pds\">\"</span></span>\n\nusing namespace std;\nusing namespace tensorflow;\n\n<span class=\"pl-k\">int</span> <span class=\"pl-en\">main</span>()\n{\n    <span class=\"pl-k\">const</span> string pathToGraph = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>demo_model/demo.meta<span class=\"pl-pds\">\"</span></span>;\n    <span class=\"pl-k\">const</span> string checkpointPath = <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>demo_model/demo<span class=\"pl-pds\">\"</span></span>;\n    SessionOptions options;\n    options.<span class=\"pl-smi\">config</span>.<span class=\"pl-c1\">set_allow_soft_placement</span>(<span class=\"pl-c1\">true</span>);   <span class=\"pl-c\"><span class=\"pl-c\">//</span> this line does not work</span>\n    <span class=\"pl-k\">auto</span> session = <span class=\"pl-c1\">NewSession</span>(options); \n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span>    auto session = NewSession(SessionOptions());</span>\n    <span class=\"pl-k\">if</span> (session == nullptr)\n    {\n        throw <span class=\"pl-smi\">runtime_error</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Could not create Tensorflow session.<span class=\"pl-pds\">\"</span></span>);\n    }\n\n    Status status;\n    MetaGraphDef graph_def;\n    status = <span class=\"pl-c1\">ReadBinaryProto</span>(<span class=\"pl-c1\">Env::Default</span>(), pathToGraph, &amp;graph_def);\n    <span class=\"pl-k\">if</span> (!status.<span class=\"pl-c1\">ok</span>())\n    {\n        throw <span class=\"pl-smi\">runtime_error</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error reading graph definition from <span class=\"pl-pds\">\"</span></span> + pathToGraph + <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>: <span class=\"pl-pds\">\"</span></span> + status.<span class=\"pl-c1\">ToString</span>());\n    }\n\n   <span class=\"pl-c\"><span class=\"pl-c\">//</span> restore graph</span>\n    status = session-&gt;<span class=\"pl-c1\">Create</span>(graph_def.<span class=\"pl-c1\">graph_def</span>());\n    <span class=\"pl-k\">if</span> (!status.<span class=\"pl-c1\">ok</span>())\n    {\n        throw <span class=\"pl-smi\">runtime_error</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error creating graph: <span class=\"pl-pds\">\"</span></span> + status.<span class=\"pl-c1\">ToString</span>());\n    }\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span>  restore checkpoint </span>\n    Tensor <span class=\"pl-smi\">checkpointPathTensor</span>(DT_STRING, <span class=\"pl-c1\">TensorShape</span>());\n    checkpointPathTensor.<span class=\"pl-smi\">scalar</span>&lt;std::string&gt;()() = checkpointPath;\n    status = session-&gt;<span class=\"pl-c1\">Run</span>(\n            {{ graph_def.<span class=\"pl-c1\">saver_def</span>().<span class=\"pl-c1\">filename_tensor_name</span>(), checkpointPathTensor },},\n            {},\n            {graph_def.<span class=\"pl-c1\">saver_def</span>().<span class=\"pl-c1\">restore_op_name</span>()},\n            nullptr);\n    <span class=\"pl-k\">if</span> (!status.<span class=\"pl-c1\">ok</span>())\n    {\n        throw <span class=\"pl-smi\">runtime_error</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error loading checkpoint from <span class=\"pl-pds\">\"</span></span> + checkpointPath + <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>: <span class=\"pl-pds\">\"</span></span> + status.<span class=\"pl-c1\">ToString</span>());\n    }\n\n    std::vector&lt;std::pair&lt;string, Tensor&gt;&gt; input;\n    Tensor <span class=\"pl-smi\">a</span>(tensorflow::DT_INT32, <span class=\"pl-c1\">tensorflow::TensorShape</span>({<span class=\"pl-c1\">1</span>}));\n    Tensor <span class=\"pl-smi\">b</span>(tensorflow::DT_INT32, <span class=\"pl-c1\">tensorflow::TensorShape</span>({<span class=\"pl-c1\">1</span>}));\n\n    <span class=\"pl-k\">auto</span> a_map = a.<span class=\"pl-smi\">tensor</span>&lt;<span class=\"pl-k\">int</span>,<span class=\"pl-c1\">1</span>&gt;();\n    <span class=\"pl-c1\">a_map</span>(<span class=\"pl-c1\">0</span>) = <span class=\"pl-c1\">2</span>;\n    <span class=\"pl-k\">auto</span> b_map = b.<span class=\"pl-smi\">tensor</span>&lt;<span class=\"pl-k\">int</span>,<span class=\"pl-c1\">1</span>&gt;();\n    <span class=\"pl-c1\">b_map</span>(<span class=\"pl-c1\">0</span>) = <span class=\"pl-c1\">3</span>;\n    input.<span class=\"pl-c1\">emplace_back</span>(<span class=\"pl-c1\">std::string</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>a<span class=\"pl-pds\">\"</span></span>), a);\n    input.<span class=\"pl-c1\">emplace_back</span>(<span class=\"pl-c1\">std::string</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>b<span class=\"pl-pds\">\"</span></span>), b);\n\n   <span class=\"pl-c\"><span class=\"pl-c\">//</span>   run session</span>\n    std::vector&lt;tensorflow::Tensor&gt; answer;\n    status = session-&gt;<span class=\"pl-c1\">Run</span>(input, {<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>res<span class=\"pl-pds\">\"</span></span>}, {}, &amp;answer);\n\n    Tensor result = answer[<span class=\"pl-c1\">0</span>];\n    <span class=\"pl-k\">auto</span> result_map = result.<span class=\"pl-smi\">tensor</span>&lt;<span class=\"pl-k\">int</span>,<span class=\"pl-c1\">1</span>&gt;();\n    cout&lt;&lt;<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>result: <span class=\"pl-pds\">\"</span></span>&lt;&lt;<span class=\"pl-c1\">result_map</span>(<span class=\"pl-c1\">0</span>)&lt;&lt;endl;\n\n    <span class=\"pl-k\">return</span> <span class=\"pl-c1\">0</span>;\n}</pre></div>\n<h2>error - in cpu</h2>\n<pre><code>./demo\nlibc++abi.dylib: terminating with uncaught exception of type std::runtime_error: Error creating graph: \nInvalid argument: Cannot assign a device for operation 'y': Operation was explicitly assigned to \n/device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the \ndevice specification refers to a valid device.\n\t [[Node: y = VariableV2[_output_shapes=[[1]], container=\"\", dtype=DT_INT32, shape=[1], \nshared_name=\"\", _device=\"/device:GPU:0\"]()]]\nAbort trap: 6\n</code></pre>\n<h2>no error  - in gpu</h2>", "body_text": "simple example\nthis is a simple example, which get result = a*b+1\npython - save model\n# demo.py\nimport tensorflow as tf\nimport os\n\nif __name__ == '__main__':\n    train_dir = os.path.join('demo_model/', \"demo\")\n\n    with tf.device('/gpu:0'):\n        a = tf.placeholder(dtype=tf.int32, shape=None, name='a')\n        b = tf.placeholder(dtype=tf.int32, shape=None, name='b')\n        y = tf.Variable(tf.ones(shape=[1], dtype=tf.int32), dtype=tf.int32, name='y')\n        res = tf.add(tf.multiply(a, b), y, name='res')\n\n    config = tf.ConfigProto(allow_soft_placement=True)\n    with tf.Session(config=config) as sess:\n        feed_dict = {a:2, b:3}\n        fetch_list = [res]\n        sess.run(tf.global_variables_initializer())\n        saver = tf.train.Saver()\n\n        res = sess.run(feed_dict=feed_dict, fetches=fetch_list)\n        saver.save(sess, train_dir)\n\n        print(\"result: \", res[0])\n$ python demo.py \n2018-09-29 09:35:28.855859: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n('result: ', array([7], dtype=int32))\npython - restore\n# demo-restore.py\nimport tensorflow as tf\nimport os\nimport numpy as np\n\nif __name__ == '__main__':\n    config = tf.ConfigProto(allow_soft_placement=True)\n    with tf.Session(config=config) as sess:\n        saver = tf.train.import_meta_graph('demo_model/demo.meta')\n        saver.restore(sess, tf.train.latest_checkpoint('demo_model/'))\n        graph = tf.get_default_graph()\n        a = graph.get_tensor_by_name(\"a:0\")\n        b = graph.get_tensor_by_name(\"b:0\")\n        feed_dict = {a: 2, b: 3}\n\n        op_to_restore = graph.get_tensor_by_name(\"res:0\")\n        print(sess.run(fetches=op_to_restore, feed_dict=feed_dict))\n$ python demo-restore.py\n[7]\n\nC++ restore model\n// demo.cc\n#include <iostream>\n#include \"tensorflow/core/public/session.h\"\n#include \"tensorflow/core/protobuf/meta_graph.pb.h\"\n#include \"tensorflow/cc/client/client_session.h\"\n#include \"tensorflow/cc/ops/standard_ops.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n\nusing namespace std;\nusing namespace tensorflow;\n\nint main()\n{\n    const string pathToGraph = \"demo_model/demo.meta\";\n    const string checkpointPath = \"demo_model/demo\";\n    SessionOptions options;\n    options.config.set_allow_soft_placement(true);   // this line does not work\n    auto session = NewSession(options); \n\n//    auto session = NewSession(SessionOptions());\n    if (session == nullptr)\n    {\n        throw runtime_error(\"Could not create Tensorflow session.\");\n    }\n\n    Status status;\n    MetaGraphDef graph_def;\n    status = ReadBinaryProto(Env::Default(), pathToGraph, &graph_def);\n    if (!status.ok())\n    {\n        throw runtime_error(\"Error reading graph definition from \" + pathToGraph + \": \" + status.ToString());\n    }\n\n   // restore graph\n    status = session->Create(graph_def.graph_def());\n    if (!status.ok())\n    {\n        throw runtime_error(\"Error creating graph: \" + status.ToString());\n    }\n\n    //  restore checkpoint \n    Tensor checkpointPathTensor(DT_STRING, TensorShape());\n    checkpointPathTensor.scalar<std::string>()() = checkpointPath;\n    status = session->Run(\n            {{ graph_def.saver_def().filename_tensor_name(), checkpointPathTensor },},\n            {},\n            {graph_def.saver_def().restore_op_name()},\n            nullptr);\n    if (!status.ok())\n    {\n        throw runtime_error(\"Error loading checkpoint from \" + checkpointPath + \": \" + status.ToString());\n    }\n\n    std::vector<std::pair<string, Tensor>> input;\n    Tensor a(tensorflow::DT_INT32, tensorflow::TensorShape({1}));\n    Tensor b(tensorflow::DT_INT32, tensorflow::TensorShape({1}));\n\n    auto a_map = a.tensor<int,1>();\n    a_map(0) = 2;\n    auto b_map = b.tensor<int,1>();\n    b_map(0) = 3;\n    input.emplace_back(std::string(\"a\"), a);\n    input.emplace_back(std::string(\"b\"), b);\n\n   //   run session\n    std::vector<tensorflow::Tensor> answer;\n    status = session->Run(input, {\"res\"}, {}, &answer);\n\n    Tensor result = answer[0];\n    auto result_map = result.tensor<int,1>();\n    cout<<\"result: \"<<result_map(0)<<endl;\n\n    return 0;\n}\nerror - in cpu\n./demo\nlibc++abi.dylib: terminating with uncaught exception of type std::runtime_error: Error creating graph: \nInvalid argument: Cannot assign a device for operation 'y': Operation was explicitly assigned to \n/device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the \ndevice specification refers to a valid device.\n\t [[Node: y = VariableV2[_output_shapes=[[1]], container=\"\", dtype=DT_INT32, shape=[1], \nshared_name=\"\", _device=\"/device:GPU:0\"]()]]\nAbort trap: 6\n\nno error  - in gpu", "body": "# simple example\r\n\r\nthis is a simple example, which get `result = a*b+1`\r\n\r\n## python - save model\r\n```py\r\n# demo.py\r\nimport tensorflow as tf\r\nimport os\r\n\r\nif __name__ == '__main__':\r\n    train_dir = os.path.join('demo_model/', \"demo\")\r\n\r\n    with tf.device('/gpu:0'):\r\n        a = tf.placeholder(dtype=tf.int32, shape=None, name='a')\r\n        b = tf.placeholder(dtype=tf.int32, shape=None, name='b')\r\n        y = tf.Variable(tf.ones(shape=[1], dtype=tf.int32), dtype=tf.int32, name='y')\r\n        res = tf.add(tf.multiply(a, b), y, name='res')\r\n\r\n    config = tf.ConfigProto(allow_soft_placement=True)\r\n    with tf.Session(config=config) as sess:\r\n        feed_dict = {a:2, b:3}\r\n        fetch_list = [res]\r\n        sess.run(tf.global_variables_initializer())\r\n        saver = tf.train.Saver()\r\n\r\n        res = sess.run(feed_dict=feed_dict, fetches=fetch_list)\r\n        saver.save(sess, train_dir)\r\n\r\n        print(\"result: \", res[0])\r\n```\r\n\r\n```sh\r\n$ python demo.py \r\n2018-09-29 09:35:28.855859: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n('result: ', array([7], dtype=int32))\r\n```\r\n\r\n## python - restore\r\n```py\r\n# demo-restore.py\r\nimport tensorflow as tf\r\nimport os\r\nimport numpy as np\r\n\r\nif __name__ == '__main__':\r\n    config = tf.ConfigProto(allow_soft_placement=True)\r\n    with tf.Session(config=config) as sess:\r\n        saver = tf.train.import_meta_graph('demo_model/demo.meta')\r\n        saver.restore(sess, tf.train.latest_checkpoint('demo_model/'))\r\n        graph = tf.get_default_graph()\r\n        a = graph.get_tensor_by_name(\"a:0\")\r\n        b = graph.get_tensor_by_name(\"b:0\")\r\n        feed_dict = {a: 2, b: 3}\r\n\r\n        op_to_restore = graph.get_tensor_by_name(\"res:0\")\r\n        print(sess.run(fetches=op_to_restore, feed_dict=feed_dict))\r\n```\r\n\r\n```\r\n$ python demo-restore.py\r\n[7]\r\n```\r\n\r\n## C++ restore model\r\n```c\r\n// demo.cc\r\n#include <iostream>\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/protobuf/meta_graph.pb.h\"\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\nusing namespace std;\r\nusing namespace tensorflow;\r\n\r\nint main()\r\n{\r\n    const string pathToGraph = \"demo_model/demo.meta\";\r\n    const string checkpointPath = \"demo_model/demo\";\r\n    SessionOptions options;\r\n    options.config.set_allow_soft_placement(true);   // this line does not work\r\n    auto session = NewSession(options); \r\n\r\n//    auto session = NewSession(SessionOptions());\r\n    if (session == nullptr)\r\n    {\r\n        throw runtime_error(\"Could not create Tensorflow session.\");\r\n    }\r\n\r\n    Status status;\r\n    MetaGraphDef graph_def;\r\n    status = ReadBinaryProto(Env::Default(), pathToGraph, &graph_def);\r\n    if (!status.ok())\r\n    {\r\n        throw runtime_error(\"Error reading graph definition from \" + pathToGraph + \": \" + status.ToString());\r\n    }\r\n\r\n   // restore graph\r\n    status = session->Create(graph_def.graph_def());\r\n    if (!status.ok())\r\n    {\r\n        throw runtime_error(\"Error creating graph: \" + status.ToString());\r\n    }\r\n\r\n    //  restore checkpoint \r\n    Tensor checkpointPathTensor(DT_STRING, TensorShape());\r\n    checkpointPathTensor.scalar<std::string>()() = checkpointPath;\r\n    status = session->Run(\r\n            {{ graph_def.saver_def().filename_tensor_name(), checkpointPathTensor },},\r\n            {},\r\n            {graph_def.saver_def().restore_op_name()},\r\n            nullptr);\r\n    if (!status.ok())\r\n    {\r\n        throw runtime_error(\"Error loading checkpoint from \" + checkpointPath + \": \" + status.ToString());\r\n    }\r\n\r\n    std::vector<std::pair<string, Tensor>> input;\r\n    Tensor a(tensorflow::DT_INT32, tensorflow::TensorShape({1}));\r\n    Tensor b(tensorflow::DT_INT32, tensorflow::TensorShape({1}));\r\n\r\n    auto a_map = a.tensor<int,1>();\r\n    a_map(0) = 2;\r\n    auto b_map = b.tensor<int,1>();\r\n    b_map(0) = 3;\r\n    input.emplace_back(std::string(\"a\"), a);\r\n    input.emplace_back(std::string(\"b\"), b);\r\n\r\n   //   run session\r\n    std::vector<tensorflow::Tensor> answer;\r\n    status = session->Run(input, {\"res\"}, {}, &answer);\r\n\r\n    Tensor result = answer[0];\r\n    auto result_map = result.tensor<int,1>();\r\n    cout<<\"result: \"<<result_map(0)<<endl;\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\n## error - in cpu\r\n\r\n```\r\n./demo\r\nlibc++abi.dylib: terminating with uncaught exception of type std::runtime_error: Error creating graph: \r\nInvalid argument: Cannot assign a device for operation 'y': Operation was explicitly assigned to \r\n/device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the \r\ndevice specification refers to a valid device.\r\n\t [[Node: y = VariableV2[_output_shapes=[[1]], container=\"\", dtype=DT_INT32, shape=[1], \r\nshared_name=\"\", _device=\"/device:GPU:0\"]()]]\r\nAbort trap: 6\r\n```\r\n\r\n## no error  - in gpu\r\n"}