{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21041", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21041/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21041/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21041/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21041", "id": 343478477, "node_id": "MDU6SXNzdWUzNDM0Nzg0Nzc=", "number": 21041, "title": "tensorflow_lite  Prelu unsupport dims->size = 2", "user": {"login": "iChiaGuo", "id": 13581022, "node_id": "MDQ6VXNlcjEzNTgxMDIy", "avatar_url": "https://avatars3.githubusercontent.com/u/13581022?v=4", "gravatar_id": "", "url": "https://api.github.com/users/iChiaGuo", "html_url": "https://github.com/iChiaGuo", "followers_url": "https://api.github.com/users/iChiaGuo/followers", "following_url": "https://api.github.com/users/iChiaGuo/following{/other_user}", "gists_url": "https://api.github.com/users/iChiaGuo/gists{/gist_id}", "starred_url": "https://api.github.com/users/iChiaGuo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/iChiaGuo/subscriptions", "organizations_url": "https://api.github.com/users/iChiaGuo/orgs", "repos_url": "https://api.github.com/users/iChiaGuo/repos", "events_url": "https://api.github.com/users/iChiaGuo/events{/privacy}", "received_events_url": "https://api.github.com/users/iChiaGuo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "miaout17", "id": 22063, "node_id": "MDQ6VXNlcjIyMDYz", "avatar_url": "https://avatars0.githubusercontent.com/u/22063?v=4", "gravatar_id": "", "url": "https://api.github.com/users/miaout17", "html_url": "https://github.com/miaout17", "followers_url": "https://api.github.com/users/miaout17/followers", "following_url": "https://api.github.com/users/miaout17/following{/other_user}", "gists_url": "https://api.github.com/users/miaout17/gists{/gist_id}", "starred_url": "https://api.github.com/users/miaout17/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/miaout17/subscriptions", "organizations_url": "https://api.github.com/users/miaout17/orgs", "repos_url": "https://api.github.com/users/miaout17/repos", "events_url": "https://api.github.com/users/miaout17/events{/privacy}", "received_events_url": "https://api.github.com/users/miaout17/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-07-23T03:50:33Z", "updated_at": "2018-08-03T22:39:41Z", "closed_at": "2018-08-03T22:39:41Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:Yes, I write own model define, loss and training codes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: iPhone 6s</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary, pip install</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.3.0</li>\n<li><strong>Python version</strong>:3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:0.10.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 4.9.4</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>:GeForce GTX 1060</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>In tensorflow_lite demo tflite_simple_example,I use my Rnet.tflite ,I get error as follow<br>\nif (interpreter-&gt;AllocateTensors() != kTfLiteOk) {<br>\nNSLog(@\"Failed to allocate tensors.\");<br>\nexit(-1);<br>\n}<br>\nerror:tensorflow/contrib/lite/kernels/activations.cc:171 input-&gt;dims-&gt;size != 4 (2 != 4)</p>\n<p>In activations.cc I find  PreluPrepare()  TF_LITE_ENSURE_EQ(context, input-&gt;dims-&gt;size, 4); my  input-&gt;dims-&gt;size =2</p>\n<p>TfLiteStatus PreluPrepare(TfLiteContext* context, TfLiteNode* node) {<br>\nTF_LITE_ENSURE_EQ(context, NumInputs(node), 2);<br>\nTF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);<br>\nconst TfLiteTensor* input = GetInput(context, node, 0);<br>\nTfLiteTensor* output = GetOutput(context, node, 0);<br>\nconst TfLiteTensor* alpha = GetInput(context, node, 1);</p>\n<p>output-&gt;type = input-&gt;type;</p>\n<p>// Currently only Float32 is supported<br>\n// TODO(ycling): Support other data types.<br>\nTF_LITE_ENSURE_EQ(context, input-&gt;type, kTfLiteFloat32);<br>\nTF_LITE_ENSURE_EQ(context, alpha-&gt;type, kTfLiteFloat32);</p>\n<p>// Currently, only support 4D <code>input</code> and 3D <code>alpha</code> with shape<br>\n// (1, 1, channels).<br>\n// TODO(impjdi): Support other cases where <code>alpha</code> is broadcastable<br>\n// to <code>input</code>.<br>\nTF_LITE_ENSURE_EQ(context, input-&gt;dims-&gt;size, 4);<br>\nTF_LITE_ENSURE_EQ(context, alpha-&gt;dims-&gt;size, 3);<br>\nTF_LITE_ENSURE_EQ(context, alpha-&gt;dims-&gt;data[0], 1);<br>\nTF_LITE_ENSURE_EQ(context, alpha-&gt;dims-&gt;data[1], 1);<br>\nTF_LITE_ENSURE_EQ(context, alpha-&gt;dims-&gt;data[2], input-&gt;dims-&gt;data[3]);</p>\n<p>return context-&gt;ResizeTensor(context, output,<br>\nTfLiteIntArrayCopy(input-&gt;dims));<br>\n}</p>\n<h3>Source code / logs</h3>\n<p>input = Input(shape=[24, 24, 3],batch_shape=[1,24, 24, 3])<br>\nx = Conv2D(28, (3, 3), strides=1, padding='valid', name='conv1')(input)<br>\nx = PReLU(shared_axes=[1, 2], name='prelu1')(x)<br>\nx = MaxPool2D(pool_size=3,strides=2, padding='same')(x)</p>\n<p>x = Conv2D(48, (3, 3), strides=1, padding='valid', name='conv2')(x)<br>\nx = PReLU(shared_axes=[1, 2], name='prelu2')(x)<br>\nx = MaxPool2D(pool_size=3, strides=2)(x)</p>\n<p>x = Conv2D(64, (2, 2), strides=1, padding='valid', name='conv3')(x)<br>\nx = PReLU(shared_axes=[1, 2], name='prelu3')(x)<br>\nx = Permute((3, 2, 1))(x)<br>\nx = Flatten()(x)<br>\nx = Dense(128, name='conv4')(x)<br>\nx = PReLU( name='prelu4')(x)<br>\nclassifier = Dense(2, activation='softmax', name='conv5-1')(x)<br>\nbbox_regress = Dense(4, name='conv5-2')(x)<br>\nmodel = Model([input], [classifier, bbox_regress])<br>\nmodel.load_weights(weight_path, by_name=True)</p>\n<p>x = PReLU( name='prelu4')(x)    input x-&gt;dims-&gt;size =2</p>\n<p>How can I slove this problem?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes, I write own model define, loss and training codes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 6s\nTensorFlow installed from (source or binary): binary, pip install\nTensorFlow version (use command below):1.3.0\nPython version:3.5\nBazel version (if compiling from source):0.10.0\nGCC/Compiler version (if compiling from source): 4.9.4\nCUDA/cuDNN version: 8.0\nGPU model and memory:GeForce GTX 1060\nExact command to reproduce:\n\nDescribe the problem\nIn tensorflow_lite demo tflite_simple_example,I use my Rnet.tflite ,I get error as follow\nif (interpreter->AllocateTensors() != kTfLiteOk) {\nNSLog(@\"Failed to allocate tensors.\");\nexit(-1);\n}\nerror:tensorflow/contrib/lite/kernels/activations.cc:171 input->dims->size != 4 (2 != 4)\nIn activations.cc I find  PreluPrepare()  TF_LITE_ENSURE_EQ(context, input->dims->size, 4); my  input->dims->size =2\nTfLiteStatus PreluPrepare(TfLiteContext* context, TfLiteNode* node) {\nTF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\nTF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\nconst TfLiteTensor* input = GetInput(context, node, 0);\nTfLiteTensor* output = GetOutput(context, node, 0);\nconst TfLiteTensor* alpha = GetInput(context, node, 1);\noutput->type = input->type;\n// Currently only Float32 is supported\n// TODO(ycling): Support other data types.\nTF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);\nTF_LITE_ENSURE_EQ(context, alpha->type, kTfLiteFloat32);\n// Currently, only support 4D input and 3D alpha with shape\n// (1, 1, channels).\n// TODO(impjdi): Support other cases where alpha is broadcastable\n// to input.\nTF_LITE_ENSURE_EQ(context, input->dims->size, 4);\nTF_LITE_ENSURE_EQ(context, alpha->dims->size, 3);\nTF_LITE_ENSURE_EQ(context, alpha->dims->data[0], 1);\nTF_LITE_ENSURE_EQ(context, alpha->dims->data[1], 1);\nTF_LITE_ENSURE_EQ(context, alpha->dims->data[2], input->dims->data[3]);\nreturn context->ResizeTensor(context, output,\nTfLiteIntArrayCopy(input->dims));\n}\nSource code / logs\ninput = Input(shape=[24, 24, 3],batch_shape=[1,24, 24, 3])\nx = Conv2D(28, (3, 3), strides=1, padding='valid', name='conv1')(input)\nx = PReLU(shared_axes=[1, 2], name='prelu1')(x)\nx = MaxPool2D(pool_size=3,strides=2, padding='same')(x)\nx = Conv2D(48, (3, 3), strides=1, padding='valid', name='conv2')(x)\nx = PReLU(shared_axes=[1, 2], name='prelu2')(x)\nx = MaxPool2D(pool_size=3, strides=2)(x)\nx = Conv2D(64, (2, 2), strides=1, padding='valid', name='conv3')(x)\nx = PReLU(shared_axes=[1, 2], name='prelu3')(x)\nx = Permute((3, 2, 1))(x)\nx = Flatten()(x)\nx = Dense(128, name='conv4')(x)\nx = PReLU( name='prelu4')(x)\nclassifier = Dense(2, activation='softmax', name='conv5-1')(x)\nbbox_regress = Dense(4, name='conv5-2')(x)\nmodel = Model([input], [classifier, bbox_regress])\nmodel.load_weights(weight_path, by_name=True)\nx = PReLU( name='prelu4')(x)    input x->dims->size =2\nHow can I slove this problem?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes, I write own model define, loss and training codes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: iPhone 6s\r\n- **TensorFlow installed from (source or binary)**: binary, pip install\r\n- **TensorFlow version (use command below)**:1.3.0\r\n- **Python version**:3.5\r\n- **Bazel version (if compiling from source)**:0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 4.9.4\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**:GeForce GTX 1060\r\n- **Exact command to reproduce**:\r\n### Describe the problem\r\n In tensorflow_lite demo tflite_simple_example,I use my Rnet.tflite ,I get error as follow\r\n  if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n    NSLog(@\"Failed to allocate tensors.\");\r\n    exit(-1);\r\n  }\r\nerror:tensorflow/contrib/lite/kernels/activations.cc:171 input->dims->size != 4 (2 != 4)\r\n\r\nIn activations.cc I find  PreluPrepare()  TF_LITE_ENSURE_EQ(context, input->dims->size, 4); my  input->dims->size =2\r\n\r\n  TfLiteStatus PreluPrepare(TfLiteContext* context, TfLiteNode* node) {\r\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\r\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\r\n  const TfLiteTensor* input = GetInput(context, node, 0);\r\n  TfLiteTensor* output = GetOutput(context, node, 0);\r\n  const TfLiteTensor* alpha = GetInput(context, node, 1);\r\n\r\n  output->type = input->type;\r\n\r\n  // Currently only Float32 is supported\r\n  // TODO(ycling): Support other data types.\r\n  TF_LITE_ENSURE_EQ(context, input->type, kTfLiteFloat32);\r\n  TF_LITE_ENSURE_EQ(context, alpha->type, kTfLiteFloat32);\r\n\r\n  // Currently, only support 4D `input` and 3D `alpha` with shape\r\n  // (1, 1, channels).\r\n  // TODO(impjdi): Support other cases where `alpha` is broadcastable\r\n  // to `input`.\r\n  TF_LITE_ENSURE_EQ(context, input->dims->size, 4);\r\n  TF_LITE_ENSURE_EQ(context, alpha->dims->size, 3);\r\n  TF_LITE_ENSURE_EQ(context, alpha->dims->data[0], 1);\r\n  TF_LITE_ENSURE_EQ(context, alpha->dims->data[1], 1);\r\n  TF_LITE_ENSURE_EQ(context, alpha->dims->data[2], input->dims->data[3]);\r\n\r\n  return context->ResizeTensor(context, output,\r\n                               TfLiteIntArrayCopy(input->dims));\r\n}\r\n\r\n### Source code / logs\r\ninput = Input(shape=[24, 24, 3],batch_shape=[1,24, 24, 3])\r\nx = Conv2D(28, (3, 3), strides=1, padding='valid', name='conv1')(input)\r\nx = PReLU(shared_axes=[1, 2], name='prelu1')(x)\r\nx = MaxPool2D(pool_size=3,strides=2, padding='same')(x)\r\n\r\nx = Conv2D(48, (3, 3), strides=1, padding='valid', name='conv2')(x)\r\nx = PReLU(shared_axes=[1, 2], name='prelu2')(x)\r\nx = MaxPool2D(pool_size=3, strides=2)(x)\r\n\r\nx = Conv2D(64, (2, 2), strides=1, padding='valid', name='conv3')(x)\r\nx = PReLU(shared_axes=[1, 2], name='prelu3')(x)\r\nx = Permute((3, 2, 1))(x)\r\nx = Flatten()(x)\r\nx = Dense(128, name='conv4')(x)\r\nx = PReLU( name='prelu4')(x)\r\nclassifier = Dense(2, activation='softmax', name='conv5-1')(x)\r\nbbox_regress = Dense(4, name='conv5-2')(x)\r\nmodel = Model([input], [classifier, bbox_regress])\r\nmodel.load_weights(weight_path, by_name=True)\r\n\r\n\r\nx = PReLU( name='prelu4')(x)    input x->dims->size =2\r\n\r\nHow can I slove this problem?\r\n"}