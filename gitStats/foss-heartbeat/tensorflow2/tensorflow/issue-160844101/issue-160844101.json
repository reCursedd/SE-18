{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2925", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2925/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2925/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2925/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/2925", "id": 160844101, "node_id": "MDU6SXNzdWUxNjA4NDQxMDE=", "number": 2925, "title": "Always bind \"localhost\" when starting workers", "user": {"login": "tobegit3hub", "id": 2715000, "node_id": "MDQ6VXNlcjI3MTUwMDA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2715000?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tobegit3hub", "html_url": "https://github.com/tobegit3hub", "followers_url": "https://api.github.com/users/tobegit3hub/followers", "following_url": "https://api.github.com/users/tobegit3hub/following{/other_user}", "gists_url": "https://api.github.com/users/tobegit3hub/gists{/gist_id}", "starred_url": "https://api.github.com/users/tobegit3hub/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tobegit3hub/subscriptions", "organizations_url": "https://api.github.com/users/tobegit3hub/orgs", "repos_url": "https://api.github.com/users/tobegit3hub/repos", "events_url": "https://api.github.com/users/tobegit3hub/events{/privacy}", "received_events_url": "https://api.github.com/users/tobegit3hub/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-06-17T09:08:40Z", "updated_at": "2016-06-21T03:26:07Z", "closed_at": "2016-06-21T03:26:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Now we have tried distributed TensorFlow and run multiple workers. It works but we found that it always bind \"localhost\" when I would like to bind one of my NICs.</p>\n<p>Is it the bug? Or do I miss something because I found nothing to configure it in any document.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 16.04</p>\n<p>Installed version of CUDA and cuDNN:  No</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>Which pip package you installed.</li>\n</ol>\n<pre><code>root@100cd4fb5bca:/notebooks# pip --version\npip 8.1.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)\n</code></pre>\n<ol>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<pre><code>root@100cd4fb5bca:/notebooks# python -c \"import tensorflow; print(tensorflow.__version__)\"\n0.8.0\n</code></pre>\n<h3>Steps to reproduce</h3>\n<ol>\n<li>docker run -it tensorflow/tensorflow bash</li>\n<li>Write the server code of <code>one_worker.py</code>.</li>\n<li><code>python ./one_worker.py</code></li>\n</ol>\n<pre><code>root@100cd4fb5bca:/notebooks# cat one_worker.py\nimport tensorflow as tf\n\nworker1 = \"www.a.com:2222\"\nworker_hosts = [worker1]\n\ncluster_spec = tf.train.ClusterSpec({\"worker\": worker_hosts})\n\nserver = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0)\n\nserver.join()\n</code></pre>\n<h3>Logs or other output that would be helpful</h3>\n<pre><code>root@100cd4fb5bca:/notebooks# python ./one_worker.py\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -&gt; {localhost:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222\n</code></pre>", "body_text": "Now we have tried distributed TensorFlow and run multiple workers. It works but we found that it always bind \"localhost\" when I would like to bind one of my NICs.\nIs it the bug? Or do I miss something because I found nothing to configure it in any document.\nEnvironment info\nOperating System: Ubuntu 16.04\nInstalled version of CUDA and cuDNN:  No\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\n\nroot@100cd4fb5bca:/notebooks# pip --version\npip 8.1.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)\n\n\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\nroot@100cd4fb5bca:/notebooks# python -c \"import tensorflow; print(tensorflow.__version__)\"\n0.8.0\n\nSteps to reproduce\n\ndocker run -it tensorflow/tensorflow bash\nWrite the server code of one_worker.py.\npython ./one_worker.py\n\nroot@100cd4fb5bca:/notebooks# cat one_worker.py\nimport tensorflow as tf\n\nworker1 = \"www.a.com:2222\"\nworker_hosts = [worker1]\n\ncluster_spec = tf.train.ClusterSpec({\"worker\": worker_hosts})\n\nserver = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0)\n\nserver.join()\n\nLogs or other output that would be helpful\nroot@100cd4fb5bca:/notebooks# python ./one_worker.py\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222", "body": "Now we have tried distributed TensorFlow and run multiple workers. It works but we found that it always bind \"localhost\" when I would like to bind one of my NICs.\n\nIs it the bug? Or do I miss something because I found nothing to configure it in any document.\n### Environment info\n\nOperating System: Ubuntu 16.04\n\nInstalled version of CUDA and cuDNN:  No\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\n```\nroot@100cd4fb5bca:/notebooks# pip --version\npip 8.1.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)\n```\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\nroot@100cd4fb5bca:/notebooks# python -c \"import tensorflow; print(tensorflow.__version__)\"\n0.8.0\n```\n### Steps to reproduce\n1. docker run -it tensorflow/tensorflow bash\n2. Write the server code of `one_worker.py`.\n3. `python ./one_worker.py`\n\n```\nroot@100cd4fb5bca:/notebooks# cat one_worker.py\nimport tensorflow as tf\n\nworker1 = \"www.a.com:2222\"\nworker_hosts = [worker1]\n\ncluster_spec = tf.train.ClusterSpec({\"worker\": worker_hosts})\n\nserver = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0)\n\nserver.join()\n```\n### Logs or other output that would be helpful\n\n```\nroot@100cd4fb5bca:/notebooks# python ./one_worker.py\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2222}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222\n```\n"}