{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227326013", "html_url": "https://github.com/tensorflow/tensorflow/issues/2925#issuecomment-227326013", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2925", "id": 227326013, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzMyNjAxMw==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-21T02:42:35Z", "updated_at": "2016-06-21T02:42:35Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>If the server.target has to be localhost:$post, the client has to be in the same host with the worker. Is that right?</p>\n</blockquote>\n<p>No, the client and worker do not have to be on the same host. The <code>tf.train.Server</code> class is a Python wrapper for a server in the <em>local process</em>, so it always binds to a port on <code>localhost</code>. (It ignores the hostname that you specify for the corresponding task in the <code>tf.train.ClusterSpec</code>, so that you can use the same <code>ClusterSpec</code> in all processes.)</p>\n<p>The client only needs to create a <code>tf.Session</code>, and does not need to create a <code>tf.train.Server</code> (though it can if you like). For example, you can run a server on <code>\"www.a.com\"</code> that listens on port 2222, and connect to it from another machine by creating a <code>tf.Session(\"grpc://www.a.com:2222\")</code>.</p>", "body_text": "If the server.target has to be localhost:$post, the client has to be in the same host with the worker. Is that right?\n\nNo, the client and worker do not have to be on the same host. The tf.train.Server class is a Python wrapper for a server in the local process, so it always binds to a port on localhost. (It ignores the hostname that you specify for the corresponding task in the tf.train.ClusterSpec, so that you can use the same ClusterSpec in all processes.)\nThe client only needs to create a tf.Session, and does not need to create a tf.train.Server (though it can if you like). For example, you can run a server on \"www.a.com\" that listens on port 2222, and connect to it from another machine by creating a tf.Session(\"grpc://www.a.com:2222\").", "body": "> If the server.target has to be localhost:$post, the client has to be in the same host with the worker. Is that right?\n\nNo, the client and worker do not have to be on the same host. The `tf.train.Server` class is a Python wrapper for a server in the _local process_, so it always binds to a port on `localhost`. (It ignores the hostname that you specify for the corresponding task in the `tf.train.ClusterSpec`, so that you can use the same `ClusterSpec` in all processes.)\n\nThe client only needs to create a `tf.Session`, and does not need to create a `tf.train.Server` (though it can if you like). For example, you can run a server on `\"www.a.com\"` that listens on port 2222, and connect to it from another machine by creating a `tf.Session(\"grpc://www.a.com:2222\")`.\n"}