{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/166143215", "html_url": "https://github.com/tensorflow/tensorflow/issues/537#issuecomment-166143215", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/537", "id": 166143215, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NjE0MzIxNQ==", "user": {"login": "cinjon", "id": 615351, "node_id": "MDQ6VXNlcjYxNTM1MQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/615351?v=4", "gravatar_id": "", "url": "https://api.github.com/users/cinjon", "html_url": "https://github.com/cinjon", "followers_url": "https://api.github.com/users/cinjon/followers", "following_url": "https://api.github.com/users/cinjon/following{/other_user}", "gists_url": "https://api.github.com/users/cinjon/gists{/gist_id}", "starred_url": "https://api.github.com/users/cinjon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/cinjon/subscriptions", "organizations_url": "https://api.github.com/users/cinjon/orgs", "repos_url": "https://api.github.com/users/cinjon/repos", "events_url": "https://api.github.com/users/cinjon/events{/privacy}", "received_events_url": "https://api.github.com/users/cinjon/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-20T18:23:31Z", "updated_at": "2015-12-20T18:23:31Z", "author_association": "NONE", "body_html": "<p>Hey Lukasz, I just had some time to try this out and I'm still getting the Under-Sharing error. This makes sense because the scope change you're suggesting takes place in a superset scope of the attention module. So when we set the reuse=True and the module introduces a new variable\u00a0name (given in the <code>with tf.variable_scope(module, reuse=None)</code>), it throws the error.</p>\n<p>If I instead turn off the reuse=True in model_with_buckets, then we get an Over-Sharing error in the embedding wrapper. This also makes sense because of the <code>vs.get_variable_scope().reuse_variables()</code> in ops/rnn.py.</p>\n<p>It seems like there isn't a way to break the reuse contract in a sub scope. Is that right? If so, is there a way to satisfy this without passing the variables through to the right function / making a separate attention module?</p>", "body_text": "Hey Lukasz, I just had some time to try this out and I'm still getting the Under-Sharing error. This makes sense because the scope change you're suggesting takes place in a superset scope of the attention module. So when we set the reuse=True and the module introduces a new variable\u00a0name (given in the with tf.variable_scope(module, reuse=None)), it throws the error.\nIf I instead turn off the reuse=True in model_with_buckets, then we get an Over-Sharing error in the embedding wrapper. This also makes sense because of the vs.get_variable_scope().reuse_variables() in ops/rnn.py.\nIt seems like there isn't a way to break the reuse contract in a sub scope. Is that right? If so, is there a way to satisfy this without passing the variables through to the right function / making a separate attention module?", "body": "Hey Lukasz, I just had some time to try this out and I'm still getting the Under-Sharing error. This makes sense because the scope change you're suggesting takes place in a superset scope of the attention module. So when we set the reuse=True and the module introduces a new variable\u00a0name (given in the `with tf.variable_scope(module, reuse=None)`), it throws the error.\n\nIf I instead turn off the reuse=True in model_with_buckets, then we get an Over-Sharing error in the embedding wrapper. This also makes sense because of the `vs.get_variable_scope().reuse_variables()` in ops/rnn.py.\n\nIt seems like there isn't a way to break the reuse contract in a sub scope. Is that right? If so, is there a way to satisfy this without passing the variables through to the right function / making a separate attention module?\n"}