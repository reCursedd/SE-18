{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/310676020", "html_url": "https://github.com/tensorflow/tensorflow/issues/10703#issuecomment-310676020", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10703", "id": 310676020, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMDY3NjAyMA==", "user": {"login": "adityaatluri", "id": 2188479, "node_id": "MDQ6VXNlcjIxODg0Nzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/2188479?v=4", "gravatar_id": "", "url": "https://api.github.com/users/adityaatluri", "html_url": "https://github.com/adityaatluri", "followers_url": "https://api.github.com/users/adityaatluri/followers", "following_url": "https://api.github.com/users/adityaatluri/following{/other_user}", "gists_url": "https://api.github.com/users/adityaatluri/gists{/gist_id}", "starred_url": "https://api.github.com/users/adityaatluri/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/adityaatluri/subscriptions", "organizations_url": "https://api.github.com/users/adityaatluri/orgs", "repos_url": "https://api.github.com/users/adityaatluri/repos", "events_url": "https://api.github.com/users/adityaatluri/events{/privacy}", "received_events_url": "https://api.github.com/users/adityaatluri/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-23T14:12:09Z", "updated_at": "2017-06-23T14:12:29Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=49262\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jart\">@jart</a> ,<br>\nWe are focusing on supporting XLA first. We want to move away from using HCC (device code compiler for ROCm) and use just LLVM, libraries and runtime to run TF code. The file <code>cuda_configure.bzl</code> seems have <code>nvcc</code> specific functions, but for rocm support we want just host compiler (g++/clang++) build functions. Will this make the problem trivial?<br>\nPS: Can you re-open the issue?</p>", "body_text": "Hi @jart ,\nWe are focusing on supporting XLA first. We want to move away from using HCC (device code compiler for ROCm) and use just LLVM, libraries and runtime to run TF code. The file cuda_configure.bzl seems have nvcc specific functions, but for rocm support we want just host compiler (g++/clang++) build functions. Will this make the problem trivial?\nPS: Can you re-open the issue?", "body": "Hi @jart ,\r\nWe are focusing on supporting XLA first. We want to move away from using HCC (device code compiler for ROCm) and use just LLVM, libraries and runtime to run TF code. The file `cuda_configure.bzl` seems have `nvcc` specific functions, but for rocm support we want just host compiler (g++/clang++) build functions. Will this make the problem trivial?\r\nPS: Can you re-open the issue?"}