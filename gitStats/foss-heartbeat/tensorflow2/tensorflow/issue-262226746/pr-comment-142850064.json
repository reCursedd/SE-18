{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/142850064", "pull_request_review_id": 67271158, "id": 142850064, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE0Mjg1MDA2NA==", "diff_hunk": "@@ -1258,3 +1258,101 @@ def sampled_softmax_loss(weights,\n       labels=labels, logits=logits)\n   # sampled_losses is a [batch_size] tensor.\n   return sampled_losses\n+\n+\n+def sampled_sparse_softmax_loss(weights,\n+                                biases,\n+                                labels,\n+                                inputs,\n+                                num_sampled,\n+                                num_classes,\n+                                sampled_values=None,\n+                                remove_accidental_hits=True,\n+                                partition_strategy=\"mod\",\n+                                name=\"sampled_sparse_softmax_loss\"):\n+  \"\"\"Computes and returns the sampled sparse softmax training loss.\n+\n+  This is a faster way to train a softmax classifier over a huge number of\n+  classes.\n+\n+  This operation is for training only.  It is generally an underestimate of\n+  the full softmax loss.\n+\n+  A common use case is to use this method for training, and calculate the full\n+  softmax loss for evaluation or inference. In this case, you must set\n+  `partition_strategy=\"div\"` for the two losses to be consistent, as in the\n+  following example:\n+\n+  ```python\n+  if mode == \"train\":\n+    loss = tf.nn.sampled_sparse_softmax_loss(\n+        weights=weights,\n+        biases=biases,\n+        labels=labels,\n+        inputs=inputs,\n+        ...,\n+        partition_strategy=\"div\")\n+  elif mode == \"eval\":\n+    logits = tf.matmul(inputs, tf.transpose(weights))\n+    logits = tf.nn.bias_add(logits, biases)\n+    labels_one_hot = tf.one_hot(labels, n_classes)\n+    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n+        labels=labels_one_hot,\n+        logits=logits)\n+  ```\n+\n+  See our [Candidate Sampling Algorithms Reference]\n+  (https://www.tensorflow.org/extras/candidate_sampling.pdf)\n+\n+  Also see Section 3 of [Jean et al., 2014](http://arxiv.org/abs/1412.2007)\n+  ([pdf](http://arxiv.org/pdf/1412.2007.pdf)) for the math.\n+\n+  Args:\n+    weights: A `Tensor` of shape `[num_classes, dim]`, or a list of `Tensor`", "path": "tensorflow/python/ops/nn_impl.py", "position": null, "original_position": 54, "commit_id": "7ba5810c105640f218993d989142d7e91da6703e", "original_commit_id": "00343a48d39d9ff74ceb662c5140048295f2610a", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "Tensor or variable?", "created_at": "2017-10-05T05:25:44Z", "updated_at": "2017-11-14T17:48:45Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/13453#discussion_r142850064", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13453", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/142850064"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/13453#discussion_r142850064"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/13453"}}, "body_html": "<p>Tensor or variable?</p>", "body_text": "Tensor or variable?"}