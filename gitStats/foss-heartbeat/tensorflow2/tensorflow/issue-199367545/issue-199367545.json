{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6714", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6714/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6714/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6714/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6714", "id": 199367545, "node_id": "MDU6SXNzdWUxOTkzNjc1NDU=", "number": 6714, "title": "TFSlim: evaluate multiple validation batches using `evaluation_loop`", "user": {"login": "kencoken", "id": 1108445, "node_id": "MDQ6VXNlcjExMDg0NDU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1108445?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kencoken", "html_url": "https://github.com/kencoken", "followers_url": "https://api.github.com/users/kencoken/followers", "following_url": "https://api.github.com/users/kencoken/following{/other_user}", "gists_url": "https://api.github.com/users/kencoken/gists{/gist_id}", "starred_url": "https://api.github.com/users/kencoken/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kencoken/subscriptions", "organizations_url": "https://api.github.com/users/kencoken/orgs", "repos_url": "https://api.github.com/users/kencoken/repos", "events_url": "https://api.github.com/users/kencoken/events{/privacy}", "received_events_url": "https://api.github.com/users/kencoken/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2017-01-07T15:34:33Z", "updated_at": "2017-06-16T21:38:29Z", "closed_at": "2017-06-16T21:38:29Z", "author_association": "NONE", "body_html": "<p>I'm trying to use placeholders for training with TF-Slim, as my training + evaluation data comes from outside of TF World. I've now got training working by using the workaround described in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"198365963\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/6604\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/6604/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/6604\">#6604</a> and keeping track of the last training batch to supply in the feed dict when calling <code>sess.run(summary_op)</code>.</p>\n<p>However, evaluation using <code>evaluation_loop</code> over multiple batches seems to not be possible. There are <code>summary_op_feed_dict</code> and <code>eval_op_feed_dict</code> arguments to the <code>evaluation_loop</code> function, but if I understand correctly, if I set <code>num_evals</code> &gt; 1, then the same feed dict (+ data) will be used for every evaluation.</p>\n<p>I'm happy add this functionality and issue a PR \u2013 is it true that right now the ability to evaluate over multiple validation batches using placeholders is not implemented? I'm using TF 12.1.</p>", "body_text": "I'm trying to use placeholders for training with TF-Slim, as my training + evaluation data comes from outside of TF World. I've now got training working by using the workaround described in #6604 and keeping track of the last training batch to supply in the feed dict when calling sess.run(summary_op).\nHowever, evaluation using evaluation_loop over multiple batches seems to not be possible. There are summary_op_feed_dict and eval_op_feed_dict arguments to the evaluation_loop function, but if I understand correctly, if I set num_evals > 1, then the same feed dict (+ data) will be used for every evaluation.\nI'm happy add this functionality and issue a PR \u2013 is it true that right now the ability to evaluate over multiple validation batches using placeholders is not implemented? I'm using TF 12.1.", "body": "I'm trying to use placeholders for training with TF-Slim, as my training + evaluation data comes from outside of TF World. I've now got training working by using the workaround described in #6604 and keeping track of the last training batch to supply in the feed dict when calling `sess.run(summary_op)`.\r\n\r\nHowever, evaluation using `evaluation_loop` over multiple batches seems to not be possible. There are `summary_op_feed_dict` and `eval_op_feed_dict` arguments to the `evaluation_loop` function, but if I understand correctly, if I set `num_evals` > 1, then the same feed dict (+ data) will be used for every evaluation.\r\n\r\nI'm happy add this functionality and issue a PR \u2013 is it true that right now the ability to evaluate over multiple validation batches using placeholders is not implemented? I'm using TF 12.1."}