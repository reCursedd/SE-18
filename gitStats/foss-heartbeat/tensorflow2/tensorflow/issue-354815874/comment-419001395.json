{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/419001395", "html_url": "https://github.com/tensorflow/tensorflow/issues/21929#issuecomment-419001395", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21929", "id": 419001395, "node_id": "MDEyOklzc3VlQ29tbWVudDQxOTAwMTM5NQ==", "user": {"login": "AzizCode92", "id": 19540527, "node_id": "MDQ6VXNlcjE5NTQwNTI3", "avatar_url": "https://avatars2.githubusercontent.com/u/19540527?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AzizCode92", "html_url": "https://github.com/AzizCode92", "followers_url": "https://api.github.com/users/AzizCode92/followers", "following_url": "https://api.github.com/users/AzizCode92/following{/other_user}", "gists_url": "https://api.github.com/users/AzizCode92/gists{/gist_id}", "starred_url": "https://api.github.com/users/AzizCode92/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AzizCode92/subscriptions", "organizations_url": "https://api.github.com/users/AzizCode92/orgs", "repos_url": "https://api.github.com/users/AzizCode92/repos", "events_url": "https://api.github.com/users/AzizCode92/events{/privacy}", "received_events_url": "https://api.github.com/users/AzizCode92/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-06T07:57:46Z", "updated_at": "2018-09-06T07:59:30Z", "author_association": "NONE", "body_html": "<p>Thank you for pointing that out. Actually, I'm using a validation to tune the training learning rate. If the next two validation losses are worse than the actual validation loss, the training rate will be divided by two.<br>\nSo, even taking this in account the accuracy is still way worse than the one I have without layer_normlaization.</p>", "body_text": "Thank you for pointing that out. Actually, I'm using a validation to tune the training learning rate. If the next two validation losses are worse than the actual validation loss, the training rate will be divided by two.\nSo, even taking this in account the accuracy is still way worse than the one I have without layer_normlaization.", "body": "Thank you for pointing that out. Actually, I'm using a validation to tune the training learning rate. If the next two validation losses are worse than the actual validation loss, the training rate will be divided by two.\r\nSo, even taking this in account the accuracy is still way worse than the one I have without layer_normlaization."}