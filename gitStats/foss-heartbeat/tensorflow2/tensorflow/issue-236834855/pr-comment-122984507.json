{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/122984507", "pull_request_review_id": 45145769, "id": 122984507, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEyMjk4NDUwNw==", "diff_hunk": "@@ -125,6 +125,46 @@ struct EluGrad {\n   }\n };\n \n+// Functor used by SeluOp to do the computations.\n+template <typename Device, typename T>\n+struct Selu {\n+  // Computes Selu activation.\n+  //\n+  // features: any shape.\n+  // activations: same shape as \"features\".\n+  void operator()(const Device& d, typename TTypes<T>::ConstTensor features,\n+                  typename TTypes<T>::Tensor activations) {\n+    // features.constant(?)\n+    const auto scale = static_cast<T>(1.0507009873554804934193349852946);\n+    const auto alpha = static_cast<T>(1.6732632423543772848170429916717);\n+    const auto one = static_cast<T>(1);\n+    const auto zero = static_cast<T>(0);\n+    activations.device(d) =\n+        (features < zero)\n+            .select(scale * alpha * (features.exp() - features.constant(one)),\n+                    scale * features);\n+  }\n+};\n+\n+// Functor used by SeluGradOp to do the computations.\n+template <typename Device, typename T>\n+struct SeluGrad {\n+  // Computes SeluGrad backprops.\n+  //\n+  // gradients: gradients backpropagated to the Selu op.\n+  // activations: outputs of the Selu op.\n+  // backprops: gradients to backpropagate to the Selu inputs.\n+  void operator()(const Device& d, typename TTypes<T>::ConstTensor gradients,\n+                  typename TTypes<T>::ConstTensor activations,\n+                  typename TTypes<T>::Tensor backprops) {\n+    const auto scale = static_cast<T>(1.0507009873554804934193349852946);\n+    const auto alpha = static_cast<T>(1.6732632423543772848170429916717);\n+    backprops.device(d) =\n+        (activations < static_cast<T>(0)).select(\n+            gradients * (activations + scale * alpha), gradients * scale);", "path": "tensorflow/core/kernels/relu_op_functor.h", "position": null, "original_position": 40, "commit_id": "97bafa09a7403db67facb78757ec35eaca1215bb", "original_commit_id": "2950431bc6984c2d6b294eedacf649ab629a448f", "user": {"login": "futurely", "id": 9004594, "node_id": "MDQ6VXNlcjkwMDQ1OTQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/9004594?v=4", "gravatar_id": "", "url": "https://api.github.com/users/futurely", "html_url": "https://github.com/futurely", "followers_url": "https://api.github.com/users/futurely/followers", "following_url": "https://api.github.com/users/futurely/following{/other_user}", "gists_url": "https://api.github.com/users/futurely/gists{/gist_id}", "starred_url": "https://api.github.com/users/futurely/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/futurely/subscriptions", "organizations_url": "https://api.github.com/users/futurely/orgs", "repos_url": "https://api.github.com/users/futurely/repos", "events_url": "https://api.github.com/users/futurely/events{/privacy}", "received_events_url": "https://api.github.com/users/futurely/received_events", "type": "User", "site_admin": false}, "body": "It's a [complicated issue](http://www.gotw.ca/gotw/081.htm).\r\n\r\n`gradients * (activations + static_cast<T>(1.7580993408473768599402175208123)), gradients * static_cast<T>(1.0507009873554804934193349852946));` has no ambiguities.", "created_at": "2017-06-20T14:03:04Z", "updated_at": "2017-07-25T15:03:45Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/10818#discussion_r122984507", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10818", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/122984507"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/10818#discussion_r122984507"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10818"}}, "body_html": "<p>It's a <a href=\"http://www.gotw.ca/gotw/081.htm\" rel=\"nofollow\">complicated issue</a>.</p>\n<p><code>gradients * (activations + static_cast&lt;T&gt;(1.7580993408473768599402175208123)), gradients * static_cast&lt;T&gt;(1.0507009873554804934193349852946));</code> has no ambiguities.</p>", "body_text": "It's a complicated issue.\ngradients * (activations + static_cast<T>(1.7580993408473768599402175208123)), gradients * static_cast<T>(1.0507009873554804934193349852946)); has no ambiguities.", "in_reply_to_id": 122979723}