{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10818", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10818/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10818/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10818/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/10818", "id": 236834855, "node_id": "MDExOlB1bGxSZXF1ZXN0MTI2MjYyMjg1", "number": 10818, "title": "Implemented selu activation #10612", "user": {"login": "lakshayg", "id": 7976315, "node_id": "MDQ6VXNlcjc5NzYzMTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/7976315?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lakshayg", "html_url": "https://github.com/lakshayg", "followers_url": "https://api.github.com/users/lakshayg/followers", "following_url": "https://api.github.com/users/lakshayg/following{/other_user}", "gists_url": "https://api.github.com/users/lakshayg/gists{/gist_id}", "starred_url": "https://api.github.com/users/lakshayg/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lakshayg/subscriptions", "organizations_url": "https://api.github.com/users/lakshayg/orgs", "repos_url": "https://api.github.com/users/lakshayg/repos", "events_url": "https://api.github.com/users/lakshayg/events{/privacy}", "received_events_url": "https://api.github.com/users/lakshayg/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 390482148, "node_id": "MDU6TGFiZWwzOTA0ODIxNDg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/awaiting%20review", "name": "awaiting review", "color": "fef2c0", "default": false}, {"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 26, "created_at": "2017-06-19T09:45:26Z", "updated_at": "2017-08-22T12:07:22Z", "closed_at": "2017-07-26T04:48:02Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/10818", "html_url": "https://github.com/tensorflow/tensorflow/pull/10818", "diff_url": "https://github.com/tensorflow/tensorflow/pull/10818.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/10818.patch"}, "body_html": "<p>This pull request implements the SELU activation function. The activation function works properly when training a simple MLP for digit recognition. But, the following test fails: <code>//tensorflow/python/kernel_tests:relu_op_test</code>. This happens due to large error when checking the gradient of gradient. The log is show below:</p>\n<pre><code>======================================================================\nFAIL: testGradGradFloat32 (__main__.SeluTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 375, in testGradGradFloat32\n    self.assertLess(err, 1e-4)\nAssertionError: 0.080660700798034668 not less than 0.0001\n\n======================================================================\nFAIL: testGradGradFloat64 (__main__.SeluTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 393, in testGradGradFloat64\n    self.assertLess(err, 1e-6)\nAssertionError: 0.080654564805808127 not less than 1e-06\n\n----------------------------------------------------------------------\nRan 30 tests in 0.377s\n\nFAILED (failures=2)\nelu (float32) gradient of gradient err =  1.90436840057e-05\nelu (float64) gradient of gradient err =  1.50806227728e-07\nelu (float32) gradient err =  1.90436840057e-05\nelu (float64) gradient err =  1.50806227728e-07\nrelu6 (float32) gradient err =  0.0\nrelu6 (float64) gradient err =  0.0\nrelu (float32) gradient of gradient err =  0.0\nrelu (float64) gradient of gradient err =  0.0\nrelu (float32) gradient err =  1.29342079163e-05\nrelu (float64) gradient err =  8.881784197e-16\nselu (float32) gradient of gradient err =  0.080660700798\nselu (float64) gradient of gradient err =  0.0806545648058\nselu (float32) gradient err =  4.69088554382e-05\nselu (float64) gradient err =  2.65132328758e-07\n</code></pre>\n<p>Any help in resolving this issue is appreciated.</p>", "body_text": "This pull request implements the SELU activation function. The activation function works properly when training a simple MLP for digit recognition. But, the following test fails: //tensorflow/python/kernel_tests:relu_op_test. This happens due to large error when checking the gradient of gradient. The log is show below:\n======================================================================\nFAIL: testGradGradFloat32 (__main__.SeluTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 375, in testGradGradFloat32\n    self.assertLess(err, 1e-4)\nAssertionError: 0.080660700798034668 not less than 0.0001\n\n======================================================================\nFAIL: testGradGradFloat64 (__main__.SeluTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 393, in testGradGradFloat64\n    self.assertLess(err, 1e-6)\nAssertionError: 0.080654564805808127 not less than 1e-06\n\n----------------------------------------------------------------------\nRan 30 tests in 0.377s\n\nFAILED (failures=2)\nelu (float32) gradient of gradient err =  1.90436840057e-05\nelu (float64) gradient of gradient err =  1.50806227728e-07\nelu (float32) gradient err =  1.90436840057e-05\nelu (float64) gradient err =  1.50806227728e-07\nrelu6 (float32) gradient err =  0.0\nrelu6 (float64) gradient err =  0.0\nrelu (float32) gradient of gradient err =  0.0\nrelu (float64) gradient of gradient err =  0.0\nrelu (float32) gradient err =  1.29342079163e-05\nrelu (float64) gradient err =  8.881784197e-16\nselu (float32) gradient of gradient err =  0.080660700798\nselu (float64) gradient of gradient err =  0.0806545648058\nselu (float32) gradient err =  4.69088554382e-05\nselu (float64) gradient err =  2.65132328758e-07\n\nAny help in resolving this issue is appreciated.", "body": "This pull request implements the SELU activation function. The activation function works properly when training a simple MLP for digit recognition. But, the following test fails: `//tensorflow/python/kernel_tests:relu_op_test`. This happens due to large error when checking the gradient of gradient. The log is show below:\r\n\r\n```\r\n======================================================================\r\nFAIL: testGradGradFloat32 (__main__.SeluTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 375, in testGradGradFloat32\r\n    self.assertLess(err, 1e-4)\r\nAssertionError: 0.080660700798034668 not less than 0.0001\r\n\r\n======================================================================\r\nFAIL: testGradGradFloat64 (__main__.SeluTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/lakshayg/.cache/bazel/_bazel_lakshayg/51c9ff9b2a8e10dfb691d982f11ff475/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/python/kernel_tests/relu_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/relu_op_test.py\", line 393, in testGradGradFloat64\r\n    self.assertLess(err, 1e-6)\r\nAssertionError: 0.080654564805808127 not less than 1e-06\r\n\r\n----------------------------------------------------------------------\r\nRan 30 tests in 0.377s\r\n\r\nFAILED (failures=2)\r\nelu (float32) gradient of gradient err =  1.90436840057e-05\r\nelu (float64) gradient of gradient err =  1.50806227728e-07\r\nelu (float32) gradient err =  1.90436840057e-05\r\nelu (float64) gradient err =  1.50806227728e-07\r\nrelu6 (float32) gradient err =  0.0\r\nrelu6 (float64) gradient err =  0.0\r\nrelu (float32) gradient of gradient err =  0.0\r\nrelu (float64) gradient of gradient err =  0.0\r\nrelu (float32) gradient err =  1.29342079163e-05\r\nrelu (float64) gradient err =  8.881784197e-16\r\nselu (float32) gradient of gradient err =  0.080660700798\r\nselu (float64) gradient of gradient err =  0.0806545648058\r\nselu (float32) gradient err =  4.69088554382e-05\r\nselu (float64) gradient err =  2.65132328758e-07\r\n```\r\nAny help in resolving this issue is appreciated."}