{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262916087", "html_url": "https://github.com/tensorflow/tensorflow/issues/5745#issuecomment-262916087", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5745", "id": 262916087, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjkxNjA4Nw==", "user": {"login": "DavidNorman", "id": 606831, "node_id": "MDQ6VXNlcjYwNjgzMQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/606831?v=4", "gravatar_id": "", "url": "https://api.github.com/users/DavidNorman", "html_url": "https://github.com/DavidNorman", "followers_url": "https://api.github.com/users/DavidNorman/followers", "following_url": "https://api.github.com/users/DavidNorman/following{/other_user}", "gists_url": "https://api.github.com/users/DavidNorman/gists{/gist_id}", "starred_url": "https://api.github.com/users/DavidNorman/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/DavidNorman/subscriptions", "organizations_url": "https://api.github.com/users/DavidNorman/orgs", "repos_url": "https://api.github.com/users/DavidNorman/repos", "events_url": "https://api.github.com/users/DavidNorman/events{/privacy}", "received_events_url": "https://api.github.com/users/DavidNorman/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-25T09:35:03Z", "updated_at": "2016-11-25T09:35:03Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Thanks for the info.  The whole placement / constant folding doesn't work for me because I am not supporting integer maths ops, but I am supporting integer constants.  Because some of the constants feed 2 nodes, they are not placed with the maths ops on the CPU (even though both maths ops are on the CPU).  Consequently I have ops that do nothing but feed _Send nodes.</p>\n<p>I have worked around that though.</p>\n<p>The other problem I had is when I was hoping to claim that I supported all integer ops on the card, and then hope that constant folding killed them off. This doesn't work because constant folding collapses constant trees, but does not kill off the nodes if there is a control edge holding the tree in place.  See the other issue as to why I think that this is wrong:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/issues/5543\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5543/hovercard\">Constant folding / control edge issue</a></p>\n<p>It sounds like I should be aiming to use XLA instead of the normal system.  Is XLA going to take a normal graph, and somehow transform it into primitives that the device claims that it can support? Or will the user have to write the graph using a new set of primitives?</p>", "body_text": "Thanks for the info.  The whole placement / constant folding doesn't work for me because I am not supporting integer maths ops, but I am supporting integer constants.  Because some of the constants feed 2 nodes, they are not placed with the maths ops on the CPU (even though both maths ops are on the CPU).  Consequently I have ops that do nothing but feed _Send nodes.\nI have worked around that though.\nThe other problem I had is when I was hoping to claim that I supported all integer ops on the card, and then hope that constant folding killed them off. This doesn't work because constant folding collapses constant trees, but does not kill off the nodes if there is a control edge holding the tree in place.  See the other issue as to why I think that this is wrong:\nConstant folding / control edge issue\nIt sounds like I should be aiming to use XLA instead of the normal system.  Is XLA going to take a normal graph, and somehow transform it into primitives that the device claims that it can support? Or will the user have to write the graph using a new set of primitives?", "body": "Thanks for the info.  The whole placement / constant folding doesn't work for me because I am not supporting integer maths ops, but I am supporting integer constants.  Because some of the constants feed 2 nodes, they are not placed with the maths ops on the CPU (even though both maths ops are on the CPU).  Consequently I have ops that do nothing but feed _Send nodes.\r\n\r\nI have worked around that though.\r\n\r\nThe other problem I had is when I was hoping to claim that I supported all integer ops on the card, and then hope that constant folding killed them off. This doesn't work because constant folding collapses constant trees, but does not kill off the nodes if there is a control edge holding the tree in place.  See the other issue as to why I think that this is wrong:\r\n\r\n[Constant folding / control edge issue](https://github.com/tensorflow/tensorflow/issues/5543)\r\n\r\nIt sounds like I should be aiming to use XLA instead of the normal system.  Is XLA going to take a normal graph, and somehow transform it into primitives that the device claims that it can support? Or will the user have to write the graph using a new set of primitives?\r\n\r\n\r\n\r\n"}