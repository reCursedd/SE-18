{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/394558271", "html_url": "https://github.com/tensorflow/tensorflow/issues/18906#issuecomment-394558271", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18906", "id": 394558271, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NDU1ODI3MQ==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-05T02:13:41Z", "updated_at": "2018-06-05T02:13:41Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=36706320\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mirekphd\">@mirekphd</a><br>\nSorry for the slow response. Every PR for TensorFlow is unit tested across every platform we support and then internally run against an even large set of tests.  Adding another version of CUDA expands the matrix and we are currently using hundreds of GPUs just for the unit testing much less performance testing.  CUDA 9.1 ended up being a slight perf regression depending on how you look at the results and what is compared.  I like all the builds people do to try out new things.</p>\n<p>NVIDIA's official DGX-1 also was not upgraded and still, as of today, only supports CUDA 9.0 with the official image.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=10285869\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fo40225\">@fo40225</a> You likely figured this out but you can just use the CUDA 9.0 cuDNN with CUDA 9.1.  That is what NVIDIA suggested when I saw that a few days back.  I would not bother with CUDA 9.1.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=463063\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ViktorM\">@ViktorM</a>  1.9 will be CUDA 9.0.  CUDA 9.1 seems to have a perf regression (check out my updated original post above) or I might have pushed for the upgrade after the driver for CUDA 9.2 was newer than I expected.  I am still working on NCCL 2.x as that provides a nice boost, but there are some license issues to work out.</p>\n<p><strong>Note</strong>:  I think it is cool other people post how to compile.  The community likely does a better job than I would as I take short cuts and have some weird preferences as to how I like to install things.  I also only do linux and old python (<a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=4967343\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/patrikhuber\">@patrikhuber</a> :-))  What I can do in the future is post how I compiled along with the sha-hash or branch where I did so.  Far from perfect and if other people are ahead of me that is great.  I have a small insight.  TensorFlow is part of the Brain team at Google.  While some might upgrade to the latest versions of cuDNN and such, it is not something I hear people talking about.  I am still hopeful that CUDA 10 will bring a new approach to drivers that makes it easier for us to roll out minor CUDA bumps with less pain.</p>\n<p><strong>As a random note.</strong>  I strongly suggest using Docker.  I use to deal with all of these different versions of CUDA in python virtual environments.  I feel kind of silly having not moved to docker sooner.  So much better.</p>", "body_text": "@mirekphd\nSorry for the slow response. Every PR for TensorFlow is unit tested across every platform we support and then internally run against an even large set of tests.  Adding another version of CUDA expands the matrix and we are currently using hundreds of GPUs just for the unit testing much less performance testing.  CUDA 9.1 ended up being a slight perf regression depending on how you look at the results and what is compared.  I like all the builds people do to try out new things.\nNVIDIA's official DGX-1 also was not upgraded and still, as of today, only supports CUDA 9.0 with the official image.\n@fo40225 You likely figured this out but you can just use the CUDA 9.0 cuDNN with CUDA 9.1.  That is what NVIDIA suggested when I saw that a few days back.  I would not bother with CUDA 9.1.\n@ViktorM  1.9 will be CUDA 9.0.  CUDA 9.1 seems to have a perf regression (check out my updated original post above) or I might have pushed for the upgrade after the driver for CUDA 9.2 was newer than I expected.  I am still working on NCCL 2.x as that provides a nice boost, but there are some license issues to work out.\nNote:  I think it is cool other people post how to compile.  The community likely does a better job than I would as I take short cuts and have some weird preferences as to how I like to install things.  I also only do linux and old python (@patrikhuber :-))  What I can do in the future is post how I compiled along with the sha-hash or branch where I did so.  Far from perfect and if other people are ahead of me that is great.  I have a small insight.  TensorFlow is part of the Brain team at Google.  While some might upgrade to the latest versions of cuDNN and such, it is not something I hear people talking about.  I am still hopeful that CUDA 10 will bring a new approach to drivers that makes it easier for us to roll out minor CUDA bumps with less pain.\nAs a random note.  I strongly suggest using Docker.  I use to deal with all of these different versions of CUDA in python virtual environments.  I feel kind of silly having not moved to docker sooner.  So much better.", "body": "@mirekphd \r\nSorry for the slow response. Every PR for TensorFlow is unit tested across every platform we support and then internally run against an even large set of tests.  Adding another version of CUDA expands the matrix and we are currently using hundreds of GPUs just for the unit testing much less performance testing.  CUDA 9.1 ended up being a slight perf regression depending on how you look at the results and what is compared.  I like all the builds people do to try out new things.\r\n\r\nNVIDIA's official DGX-1 also was not upgraded and still, as of today, only supports CUDA 9.0 with the official image.\r\n\r\n@fo40225 You likely figured this out but you can just use the CUDA 9.0 cuDNN with CUDA 9.1.  That is what NVIDIA suggested when I saw that a few days back.  I would not bother with CUDA 9.1.\r\n\r\n@ViktorM  1.9 will be CUDA 9.0.  CUDA 9.1 seems to have a perf regression (check out my updated original post above) or I might have pushed for the upgrade after the driver for CUDA 9.2 was newer than I expected.  I am still working on NCCL 2.x as that provides a nice boost, but there are some license issues to work out.\r\n\r\n**Note**:  I think it is cool other people post how to compile.  The community likely does a better job than I would as I take short cuts and have some weird preferences as to how I like to install things.  I also only do linux and old python (@patrikhuber :-))  What I can do in the future is post how I compiled along with the sha-hash or branch where I did so.  Far from perfect and if other people are ahead of me that is great.  I have a small insight.  TensorFlow is part of the Brain team at Google.  While some might upgrade to the latest versions of cuDNN and such, it is not something I hear people talking about.  I am still hopeful that CUDA 10 will bring a new approach to drivers that makes it easier for us to roll out minor CUDA bumps with less pain.  \r\n\r\n**As a random note.**  I strongly suggest using Docker.  I use to deal with all of these different versions of CUDA in python virtual environments.  I feel kind of silly having not moved to docker sooner.  So much better.  \r\n\r\n"}