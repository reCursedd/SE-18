{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/156169886", "html_url": "https://github.com/tensorflow/tensorflow/issues/164#issuecomment-156169886", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/164", "id": 156169886, "node_id": "MDEyOklzc3VlQ29tbWVudDE1NjE2OTg4Ng==", "user": {"login": "jeffreyadean", "id": 8585436, "node_id": "MDQ6VXNlcjg1ODU0MzY=", "avatar_url": "https://avatars3.githubusercontent.com/u/8585436?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jeffreyadean", "html_url": "https://github.com/jeffreyadean", "followers_url": "https://api.github.com/users/jeffreyadean/followers", "following_url": "https://api.github.com/users/jeffreyadean/following{/other_user}", "gists_url": "https://api.github.com/users/jeffreyadean/gists{/gist_id}", "starred_url": "https://api.github.com/users/jeffreyadean/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jeffreyadean/subscriptions", "organizations_url": "https://api.github.com/users/jeffreyadean/orgs", "repos_url": "https://api.github.com/users/jeffreyadean/repos", "events_url": "https://api.github.com/users/jeffreyadean/events{/privacy}", "received_events_url": "https://api.github.com/users/jeffreyadean/received_events", "type": "User", "site_admin": false}, "created_at": "2015-11-12T17:13:11Z", "updated_at": "2015-11-12T17:13:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>This is something we are actively working on, although it is in the early stages.  It is discussed briefly in the second-to-last paragraph of the Future Work section of the white paper at <a href=\"http://tensorflow.org/whitepaper2015.pdf\" rel=\"nofollow\">http://tensorflow.org/whitepaper2015.pdf</a>:</p>\n<p>\"We also have a number of concrete directions to improve the performance of TensorFlow. One such direction is our initial work on a just-in-time compiler that can take a subgraph of a TensorFlow execution, perhaps with some runtime profiling information about the typical sizes and shapes of tensors, and can generate an optimized routine for this subgraph. This compiler will understand the semantics of perform a number of optimizations such as loop fusion, blocking and tiling for locality, specialization for particular shapes and sizes, etc.\"</p>", "body_text": "This is something we are actively working on, although it is in the early stages.  It is discussed briefly in the second-to-last paragraph of the Future Work section of the white paper at http://tensorflow.org/whitepaper2015.pdf:\n\"We also have a number of concrete directions to improve the performance of TensorFlow. One such direction is our initial work on a just-in-time compiler that can take a subgraph of a TensorFlow execution, perhaps with some runtime profiling information about the typical sizes and shapes of tensors, and can generate an optimized routine for this subgraph. This compiler will understand the semantics of perform a number of optimizations such as loop fusion, blocking and tiling for locality, specialization for particular shapes and sizes, etc.\"", "body": "This is something we are actively working on, although it is in the early stages.  It is discussed briefly in the second-to-last paragraph of the Future Work section of the white paper at http://tensorflow.org/whitepaper2015.pdf:\n\n\"We also have a number of concrete directions to improve the performance of TensorFlow. One such direction is our initial work on a just-in-time compiler that can take a subgraph of a TensorFlow execution, perhaps with some runtime profiling information about the typical sizes and shapes of tensors, and can generate an optimized routine for this subgraph. This compiler will understand the semantics of perform a number of optimizations such as loop fusion, blocking and tiling for locality, specialization for particular shapes and sizes, etc.\"\n"}