{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23612", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23612/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23612/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23612/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23612", "id": 379008421, "node_id": "MDU6SXNzdWUzNzkwMDg0MjE=", "number": 23612, "title": "ValueError: No gradients provided for any variable when using custom raw_rnn", "user": {"login": "ztwe", "id": 7899459, "node_id": "MDQ6VXNlcjc4OTk0NTk=", "avatar_url": "https://avatars1.githubusercontent.com/u/7899459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ztwe", "html_url": "https://github.com/ztwe", "followers_url": "https://api.github.com/users/ztwe/followers", "following_url": "https://api.github.com/users/ztwe/following{/other_user}", "gists_url": "https://api.github.com/users/ztwe/gists{/gist_id}", "starred_url": "https://api.github.com/users/ztwe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ztwe/subscriptions", "organizations_url": "https://api.github.com/users/ztwe/orgs", "repos_url": "https://api.github.com/users/ztwe/repos", "events_url": "https://api.github.com/users/ztwe/events{/privacy}", "received_events_url": "https://api.github.com/users/ztwe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-11-09T03:26:06Z", "updated_at": "2018-11-09T12:46:14Z", "closed_at": "2018-11-09T12:46:14Z", "author_association": "NONE", "body_html": "<p><strong>System: ubuntu 16.04<br>\nDocker: nvidia-gpu<br>\nAnaconda: 5.1<br>\ntensorflow:1.9</strong></p>\n<p>I use custom raw_rnn to implement the graph shown as following:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/7899459/48241311-494a8e80-e411-11e8-9235-735a8f8f8653.png\"><img src=\"https://user-images.githubusercontent.com/7899459/48241311-494a8e80-e411-11e8-9235-735a8f8f8653.png\" alt=\"rnn\" style=\"max-width:100%;\"></a></p>\n<p>The code of custom raw_rnn is shown as following:</p>\n<pre><code>def loop_rnn(num_lstm_units, image_embeddings, class_num, batch_size, initializer_scale):\n    initializer = tf.random_uniform_initializer(\n        minval=-initializer_scale,\n        maxval=initializer_scale)\n\n    with tf.variable_scope(\"lstm\", initializer=initializer, reuse=tf.AUTO_REUSE) as lstm_scope:\n        lstm_cell = tf.contrib.rnn.BasicLSTMCell(\n            num_units=num_lstm_units, state_is_tuple=True)\n\n        zero_state = lstm_cell.zero_state(\n            batch_size=image_embeddings.get_shape()[0], dtype=tf.float32)\n\n        K = 5\n        C = 80\n        max_time = K + 1\n\n        temp_variable = (tf.TensorArray(size=K, dtype=tf.float32),\n                         tf.TensorArray(size=max_time, dtype=tf.float32))\n        temp_variable[1].write(0, [[[1., 0., 0.], [0., 1., 0.]] for i in range(batch_size)])\n\n        lstm_input_size = 14\n        zk_size = 4096\n\n        initial_state = zero_state\n\n        output_dim = 4096\n\n        fc_weight_initializer = tf.zeros_initializer()\n        fc_bias_initializer = tf.constant_initializer([1., 0., 0., 0., 1., 0.])\n\n        def loop_fn(time, cell_output, cell_state, loop_state):\n            if cell_output is None:\n                next_cell_state = initial_state\n                emit_output = tf.zeros([output_dim])\n            else:\n                next_cell_state = cell_state\n                emit_output = cell_output\n                # The graph after LSTM  #\n                z_k = tf.contrib.layers.fully_connected(\n                    inputs=cell_state,\n                    num_outputs=zk_size,\n                    activation_fn=tf.nn.relu,\n                    weights_initializer=initializer)\n\n                if time != 0:\n                    temp_variable[0].write([time - 1],\n                              tf.contrib.layers.fully_connected(\n                                  inputs=z_k[0],\n                                  num_outputs=class_num,\n                                  activation_fn=None,\n                                  weights_initializer=initializer))\n\n                if time != max_time:\n                    M = tf.reshape(\n                        tf.contrib.layers.fully_connected(\n                            inputs=z_k[0],\n                            num_outputs=max_time,\n                            activation_fn=None,\n                            weights_initializer=fc_weight_initializer,\n                            biases_initializer=fc_bias_initializer),\n                        [batch_size, 2, 3])\n                    tf.assign(M[:, 0, 1], (tf.convert_to_tensor(0.)))\n                    tf.assign(M[:, 1, 0], (tf.convert_to_tensor(0.)))\n                    temp_variable[1].write(time, M)\n               # The graph after LSTM  #\n\n            # The graph before LSTM  #\n            if time != max_time:\n                f_k_origin = stn.spatial_transformer_network(image_embeddings, temp_variable[1].read(time))\n                f_k = tf.layers.max_pooling2d(f_k_origin, pool_size=[2, 2], strides=2, padding='SAME')\n\n                with tf.variable_scope(\"fc_1\") as fc_1_scope:\n                    f_k = tf.contrib.layers.fully_connected(\n                    inputs=tf.reshape(f_k, [batch_size, int(lstm_input_size * lstm_input_size / 4 * 512)]),\n                    num_outputs=4096,\n                    activation_fn=None,\n                    weights_initializer=initializer,\n                    scope=fc_1_scope)\n            # The graph before LSTM  #\n\n            elements_finished = (time &gt;= max_time)\n\n            if time == max_time:\n                next_in = None\n            else:\n                next_in = f_k\n\n            next_input = next_in\n\n            next_loop_state = temp_variable\n            return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n\n        outputs_ta, last_state, loop_state_ta = tf.nn.raw_rnn(lstm_cell, loop_fn)\n        scores_result = loop_state_ta[0].stack()\n        M_result = loop_state_ta[1].stack()\n\n        return scores_result, M_result\n</code></pre>\n<p>The error info is shown as following:</p>\n<pre><code>Traceback (most recent call last):\n  File \"train.py\", line 125, in &lt;module&gt;\n    tf.app.run()\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"train.py\", line 107, in main\n    optimizer=training_config.optimizer)\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 297, in optimize_loss\n    name=\"train\")\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 583, in apply_gradients\n    ([str(v) for _, _, v in converted_grads_and_vars],))\nValueError: No gradients provided for any variable: [\"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fc_1/weights:0' shape=(25088, 4096) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fc_1/biases:0' shape=(4096,) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/basic_lstm_cell/kernel:0' shape=(8192, 16384) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/basic_lstm_cell/bias:0' shape=(16384,) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fully_connected/weights:0' shape=(4096, 4096) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fully_connected/biases:0' shape=(4096,) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fully_connected_1/weights:0' shape=(4096, 80) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fully_connected_1/biases:0' shape=(80,) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fully_connected_2/weights:0' shape=(4096, 6) dtype=float32_ref&gt;)&gt;\", \"&lt;_RefVariableProcessor(&lt;tf.Variable 'lstm/rnn/fully_connected_2/biases:0' shape=(6,) dtype=float32_ref&gt;)&gt;\"].\n</code></pre>\n<p><strong>When I look into the graph using tensorboard, it's strange that there are two STN, fc_1, max_pool, basic_lstm_cell, fully_connected, fully_connected_1, fully_connected_2. Why do these ops have double? Does it result in the problem?</strong></p>\n<p><a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/7899459/48241504-32f10280-e412-11e8-922e-fb08ef0102c2.png\"><img src=\"https://user-images.githubusercontent.com/7899459/48241504-32f10280-e412-11e8-922e-fb08ef0102c2.png\" alt=\"rdar_graph\" style=\"max-width:100%;\"></a></p>", "body_text": "System: ubuntu 16.04\nDocker: nvidia-gpu\nAnaconda: 5.1\ntensorflow:1.9\nI use custom raw_rnn to implement the graph shown as following:\n\nThe code of custom raw_rnn is shown as following:\ndef loop_rnn(num_lstm_units, image_embeddings, class_num, batch_size, initializer_scale):\n    initializer = tf.random_uniform_initializer(\n        minval=-initializer_scale,\n        maxval=initializer_scale)\n\n    with tf.variable_scope(\"lstm\", initializer=initializer, reuse=tf.AUTO_REUSE) as lstm_scope:\n        lstm_cell = tf.contrib.rnn.BasicLSTMCell(\n            num_units=num_lstm_units, state_is_tuple=True)\n\n        zero_state = lstm_cell.zero_state(\n            batch_size=image_embeddings.get_shape()[0], dtype=tf.float32)\n\n        K = 5\n        C = 80\n        max_time = K + 1\n\n        temp_variable = (tf.TensorArray(size=K, dtype=tf.float32),\n                         tf.TensorArray(size=max_time, dtype=tf.float32))\n        temp_variable[1].write(0, [[[1., 0., 0.], [0., 1., 0.]] for i in range(batch_size)])\n\n        lstm_input_size = 14\n        zk_size = 4096\n\n        initial_state = zero_state\n\n        output_dim = 4096\n\n        fc_weight_initializer = tf.zeros_initializer()\n        fc_bias_initializer = tf.constant_initializer([1., 0., 0., 0., 1., 0.])\n\n        def loop_fn(time, cell_output, cell_state, loop_state):\n            if cell_output is None:\n                next_cell_state = initial_state\n                emit_output = tf.zeros([output_dim])\n            else:\n                next_cell_state = cell_state\n                emit_output = cell_output\n                # The graph after LSTM  #\n                z_k = tf.contrib.layers.fully_connected(\n                    inputs=cell_state,\n                    num_outputs=zk_size,\n                    activation_fn=tf.nn.relu,\n                    weights_initializer=initializer)\n\n                if time != 0:\n                    temp_variable[0].write([time - 1],\n                              tf.contrib.layers.fully_connected(\n                                  inputs=z_k[0],\n                                  num_outputs=class_num,\n                                  activation_fn=None,\n                                  weights_initializer=initializer))\n\n                if time != max_time:\n                    M = tf.reshape(\n                        tf.contrib.layers.fully_connected(\n                            inputs=z_k[0],\n                            num_outputs=max_time,\n                            activation_fn=None,\n                            weights_initializer=fc_weight_initializer,\n                            biases_initializer=fc_bias_initializer),\n                        [batch_size, 2, 3])\n                    tf.assign(M[:, 0, 1], (tf.convert_to_tensor(0.)))\n                    tf.assign(M[:, 1, 0], (tf.convert_to_tensor(0.)))\n                    temp_variable[1].write(time, M)\n               # The graph after LSTM  #\n\n            # The graph before LSTM  #\n            if time != max_time:\n                f_k_origin = stn.spatial_transformer_network(image_embeddings, temp_variable[1].read(time))\n                f_k = tf.layers.max_pooling2d(f_k_origin, pool_size=[2, 2], strides=2, padding='SAME')\n\n                with tf.variable_scope(\"fc_1\") as fc_1_scope:\n                    f_k = tf.contrib.layers.fully_connected(\n                    inputs=tf.reshape(f_k, [batch_size, int(lstm_input_size * lstm_input_size / 4 * 512)]),\n                    num_outputs=4096,\n                    activation_fn=None,\n                    weights_initializer=initializer,\n                    scope=fc_1_scope)\n            # The graph before LSTM  #\n\n            elements_finished = (time >= max_time)\n\n            if time == max_time:\n                next_in = None\n            else:\n                next_in = f_k\n\n            next_input = next_in\n\n            next_loop_state = temp_variable\n            return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n\n        outputs_ta, last_state, loop_state_ta = tf.nn.raw_rnn(lstm_cell, loop_fn)\n        scores_result = loop_state_ta[0].stack()\n        M_result = loop_state_ta[1].stack()\n\n        return scores_result, M_result\n\nThe error info is shown as following:\nTraceback (most recent call last):\n  File \"train.py\", line 125, in <module>\n    tf.app.run()\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"train.py\", line 107, in main\n    optimizer=training_config.optimizer)\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 297, in optimize_loss\n    name=\"train\")\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 583, in apply_gradients\n    ([str(v) for _, _, v in converted_grads_and_vars],))\nValueError: No gradients provided for any variable: [\"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fc_1/weights:0' shape=(25088, 4096) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fc_1/biases:0' shape=(4096,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/basic_lstm_cell/kernel:0' shape=(8192, 16384) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/basic_lstm_cell/bias:0' shape=(16384,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected/weights:0' shape=(4096, 4096) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected/biases:0' shape=(4096,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_1/weights:0' shape=(4096, 80) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_1/biases:0' shape=(80,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_2/weights:0' shape=(4096, 6) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_2/biases:0' shape=(6,) dtype=float32_ref>)>\"].\n\nWhen I look into the graph using tensorboard, it's strange that there are two STN, fc_1, max_pool, basic_lstm_cell, fully_connected, fully_connected_1, fully_connected_2. Why do these ops have double? Does it result in the problem?", "body": "**System: ubuntu 16.04\r\nDocker: nvidia-gpu\r\nAnaconda: 5.1\r\ntensorflow:1.9**\r\n\r\nI use custom raw_rnn to implement the graph shown as following:\r\n![rnn](https://user-images.githubusercontent.com/7899459/48241311-494a8e80-e411-11e8-9235-735a8f8f8653.png)\r\n\r\nThe code of custom raw_rnn is shown as following:\r\n\r\n```\r\ndef loop_rnn(num_lstm_units, image_embeddings, class_num, batch_size, initializer_scale):\r\n    initializer = tf.random_uniform_initializer(\r\n        minval=-initializer_scale,\r\n        maxval=initializer_scale)\r\n\r\n    with tf.variable_scope(\"lstm\", initializer=initializer, reuse=tf.AUTO_REUSE) as lstm_scope:\r\n        lstm_cell = tf.contrib.rnn.BasicLSTMCell(\r\n            num_units=num_lstm_units, state_is_tuple=True)\r\n\r\n        zero_state = lstm_cell.zero_state(\r\n            batch_size=image_embeddings.get_shape()[0], dtype=tf.float32)\r\n\r\n        K = 5\r\n        C = 80\r\n        max_time = K + 1\r\n\r\n        temp_variable = (tf.TensorArray(size=K, dtype=tf.float32),\r\n                         tf.TensorArray(size=max_time, dtype=tf.float32))\r\n        temp_variable[1].write(0, [[[1., 0., 0.], [0., 1., 0.]] for i in range(batch_size)])\r\n\r\n        lstm_input_size = 14\r\n        zk_size = 4096\r\n\r\n        initial_state = zero_state\r\n\r\n        output_dim = 4096\r\n\r\n        fc_weight_initializer = tf.zeros_initializer()\r\n        fc_bias_initializer = tf.constant_initializer([1., 0., 0., 0., 1., 0.])\r\n\r\n        def loop_fn(time, cell_output, cell_state, loop_state):\r\n            if cell_output is None:\r\n                next_cell_state = initial_state\r\n                emit_output = tf.zeros([output_dim])\r\n            else:\r\n                next_cell_state = cell_state\r\n                emit_output = cell_output\r\n                # The graph after LSTM  #\r\n                z_k = tf.contrib.layers.fully_connected(\r\n                    inputs=cell_state,\r\n                    num_outputs=zk_size,\r\n                    activation_fn=tf.nn.relu,\r\n                    weights_initializer=initializer)\r\n\r\n                if time != 0:\r\n                    temp_variable[0].write([time - 1],\r\n                              tf.contrib.layers.fully_connected(\r\n                                  inputs=z_k[0],\r\n                                  num_outputs=class_num,\r\n                                  activation_fn=None,\r\n                                  weights_initializer=initializer))\r\n\r\n                if time != max_time:\r\n                    M = tf.reshape(\r\n                        tf.contrib.layers.fully_connected(\r\n                            inputs=z_k[0],\r\n                            num_outputs=max_time,\r\n                            activation_fn=None,\r\n                            weights_initializer=fc_weight_initializer,\r\n                            biases_initializer=fc_bias_initializer),\r\n                        [batch_size, 2, 3])\r\n                    tf.assign(M[:, 0, 1], (tf.convert_to_tensor(0.)))\r\n                    tf.assign(M[:, 1, 0], (tf.convert_to_tensor(0.)))\r\n                    temp_variable[1].write(time, M)\r\n               # The graph after LSTM  #\r\n\r\n            # The graph before LSTM  #\r\n            if time != max_time:\r\n                f_k_origin = stn.spatial_transformer_network(image_embeddings, temp_variable[1].read(time))\r\n                f_k = tf.layers.max_pooling2d(f_k_origin, pool_size=[2, 2], strides=2, padding='SAME')\r\n\r\n                with tf.variable_scope(\"fc_1\") as fc_1_scope:\r\n                    f_k = tf.contrib.layers.fully_connected(\r\n                    inputs=tf.reshape(f_k, [batch_size, int(lstm_input_size * lstm_input_size / 4 * 512)]),\r\n                    num_outputs=4096,\r\n                    activation_fn=None,\r\n                    weights_initializer=initializer,\r\n                    scope=fc_1_scope)\r\n            # The graph before LSTM  #\r\n\r\n            elements_finished = (time >= max_time)\r\n\r\n            if time == max_time:\r\n                next_in = None\r\n            else:\r\n                next_in = f_k\r\n\r\n            next_input = next_in\r\n\r\n            next_loop_state = temp_variable\r\n            return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\r\n\r\n        outputs_ta, last_state, loop_state_ta = tf.nn.raw_rnn(lstm_cell, loop_fn)\r\n        scores_result = loop_state_ta[0].stack()\r\n        M_result = loop_state_ta[1].stack()\r\n\r\n        return scores_result, M_result\r\n```\r\n\r\nThe error info is shown as following:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 125, in <module>\r\n    tf.app.run()\r\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"train.py\", line 107, in main\r\n    optimizer=training_config.optimizer)\r\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 297, in optimize_loss\r\n    name=\"train\")\r\n  File \"/home/trainer/anaconda3/envs/tf19_py36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 583, in apply_gradients\r\n    ([str(v) for _, _, v in converted_grads_and_vars],))\r\nValueError: No gradients provided for any variable: [\"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fc_1/weights:0' shape=(25088, 4096) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fc_1/biases:0' shape=(4096,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/basic_lstm_cell/kernel:0' shape=(8192, 16384) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/basic_lstm_cell/bias:0' shape=(16384,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected/weights:0' shape=(4096, 4096) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected/biases:0' shape=(4096,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_1/weights:0' shape=(4096, 80) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_1/biases:0' shape=(80,) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_2/weights:0' shape=(4096, 6) dtype=float32_ref>)>\", \"<_RefVariableProcessor(<tf.Variable 'lstm/rnn/fully_connected_2/biases:0' shape=(6,) dtype=float32_ref>)>\"].\r\n```\r\n\r\n**When I look into the graph using tensorboard, it's strange that there are two STN, fc_1, max_pool, basic_lstm_cell, fully_connected, fully_connected_1, fully_connected_2. Why do these ops have double? Does it result in the problem?**\r\n\r\n![rdar_graph](https://user-images.githubusercontent.com/7899459/48241504-32f10280-e412-11e8-922e-fb08ef0102c2.png)\r\n "}