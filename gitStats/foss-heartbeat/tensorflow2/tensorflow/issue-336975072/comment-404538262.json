{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/404538262", "html_url": "https://github.com/tensorflow/tensorflow/pull/20412#issuecomment-404538262", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20412", "id": 404538262, "node_id": "MDEyOklzc3VlQ29tbWVudDQwNDUzODI2Mg==", "user": {"login": "bioothod", "id": 1847575, "node_id": "MDQ6VXNlcjE4NDc1NzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1847575?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bioothod", "html_url": "https://github.com/bioothod", "followers_url": "https://api.github.com/users/bioothod/followers", "following_url": "https://api.github.com/users/bioothod/following{/other_user}", "gists_url": "https://api.github.com/users/bioothod/gists{/gist_id}", "starred_url": "https://api.github.com/users/bioothod/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bioothod/subscriptions", "organizations_url": "https://api.github.com/users/bioothod/orgs", "repos_url": "https://api.github.com/users/bioothod/repos", "events_url": "https://api.github.com/users/bioothod/events{/privacy}", "received_events_url": "https://api.github.com/users/bioothod/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-12T14:47:25Z", "updated_at": "2018-07-12T15:04:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p>That's not quite what I'm working with, problem with GPU placement happens when you load new graph from protobuf and run in in go.</p>\n<p>I've made a simple example repo to highlight the problem: <a href=\"https://github.com/bioothod/golang_gpu_example\">https://github.com/bioothod/golang_gpu_example</a></p>\n<p>If you clone it into <code>$GOPATH/src</code> and run following commands, then you will find the problem:</p>\n<pre><code>$ cd golang_gpu_example\n$ python3 ./make_graph.py --output test.pb \n$ go build\n$ ./gpu ./test.pb \n2018-07-12 15:40:27.892564: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n2018-07-12 15:40:28.025248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325\npciBusID: 0000:65:00.0\ntotalMemory: 10.91GiB freeMemory: 9.21GiB\n2018-07-12 15:40:28.025276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n2018-07-12 15:40:28.212742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-07-12 15:40:28.212771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n2018-07-12 15:40:28.212778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n2018-07-12 15:40:28.212941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8900 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\n2018-07-12 15:40:28.294047: I tensorflow/core/common_runtime/direct_session.cc:288] Device mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\n\noutput/op: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n2018-07-12 15:40:28.294321: I tensorflow/core/common_runtime/placer.cc:886] output/op: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0\ninput/ph0: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\n2018-07-12 15:40:28.294335: I tensorflow/core/common_runtime/placer.cc:886] input/ph0: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0\ninput/ph1: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\n2018-07-12 15:40:28.294341: I tensorflow/core/common_runtime/placer.cc:886] input/ph1: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0\nop: [[3 4 5] [6 8 10] [9 12 15]]\n</code></pre>\n<p>This happens not all the time though, with this particular graph it is always on CPU, but <code>op = tf.reduce_sum(ph0 * ph1, axis=1, name='output/op')</code> runs on GPU. With my rather large graphs it is always on CPU.</p>\n<p>Forcing graph to run on GPU with CPU-only kernels should not be a problem - it is not a real force, but only a hint, and it would be rather great if TF emits some kind of warning in this case. Yet it is MUCH better than running on CPU when all the kernels do have GPU implementations.</p>", "body_text": "That's not quite what I'm working with, problem with GPU placement happens when you load new graph from protobuf and run in in go.\nI've made a simple example repo to highlight the problem: https://github.com/bioothod/golang_gpu_example\nIf you clone it into $GOPATH/src and run following commands, then you will find the problem:\n$ cd golang_gpu_example\n$ python3 ./make_graph.py --output test.pb \n$ go build\n$ ./gpu ./test.pb \n2018-07-12 15:40:27.892564: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n2018-07-12 15:40:28.025248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325\npciBusID: 0000:65:00.0\ntotalMemory: 10.91GiB freeMemory: 9.21GiB\n2018-07-12 15:40:28.025276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n2018-07-12 15:40:28.212742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-07-12 15:40:28.212771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n2018-07-12 15:40:28.212778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n2018-07-12 15:40:28.212941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8900 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\nDevice mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\n2018-07-12 15:40:28.294047: I tensorflow/core/common_runtime/direct_session.cc:288] Device mapping:\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\n\noutput/op: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n2018-07-12 15:40:28.294321: I tensorflow/core/common_runtime/placer.cc:886] output/op: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0\ninput/ph0: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\n2018-07-12 15:40:28.294335: I tensorflow/core/common_runtime/placer.cc:886] input/ph0: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0\ninput/ph1: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\n2018-07-12 15:40:28.294341: I tensorflow/core/common_runtime/placer.cc:886] input/ph1: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0\nop: [[3 4 5] [6 8 10] [9 12 15]]\n\nThis happens not all the time though, with this particular graph it is always on CPU, but op = tf.reduce_sum(ph0 * ph1, axis=1, name='output/op') runs on GPU. With my rather large graphs it is always on CPU.\nForcing graph to run on GPU with CPU-only kernels should not be a problem - it is not a real force, but only a hint, and it would be rather great if TF emits some kind of warning in this case. Yet it is MUCH better than running on CPU when all the kernels do have GPU implementations.", "body": "That's not quite what I'm working with, problem with GPU placement happens when you load new graph from protobuf and run in in go.\r\n\r\nI've made a simple example repo to highlight the problem: https://github.com/bioothod/golang_gpu_example\r\n\r\nIf you clone it into `$GOPATH/src` and run following commands, then you will find the problem:\r\n```\r\n$ cd golang_gpu_example\r\n$ python3 ./make_graph.py --output test.pb \r\n$ go build\r\n$ ./gpu ./test.pb \r\n2018-07-12 15:40:27.892564: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n2018-07-12 15:40:28.025248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325\r\npciBusID: 0000:65:00.0\r\ntotalMemory: 10.91GiB freeMemory: 9.21GiB\r\n2018-07-12 15:40:28.025276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2018-07-12 15:40:28.212742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-07-12 15:40:28.212771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \r\n2018-07-12 15:40:28.212778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \r\n2018-07-12 15:40:28.212941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8900 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\r\n2018-07-12 15:40:28.294047: I tensorflow/core/common_runtime/direct_session.cc:288] Device mapping:\r\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\r\n\r\noutput/op: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\r\n2018-07-12 15:40:28.294321: I tensorflow/core/common_runtime/placer.cc:886] output/op: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0\r\ninput/ph0: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\r\n2018-07-12 15:40:28.294335: I tensorflow/core/common_runtime/placer.cc:886] input/ph0: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0\r\ninput/ph1: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\r\n2018-07-12 15:40:28.294341: I tensorflow/core/common_runtime/placer.cc:886] input/ph1: (Placeholder)/job:localhost/replica:0/task:0/device:CPU:0\r\nop: [[3 4 5] [6 8 10] [9 12 15]]\r\n```\r\n\r\nThis happens not all the time though, with this particular graph it is always on CPU, but `op = tf.reduce_sum(ph0 * ph1, axis=1, name='output/op')` runs on GPU. With my rather large graphs it is always on CPU.\r\n\r\nForcing graph to run on GPU with CPU-only kernels should not be a problem - it is not a real force, but only a hint, and it would be rather great if TF emits some kind of warning in this case. Yet it is MUCH better than running on CPU when all the kernels do have GPU implementations.\r\n"}