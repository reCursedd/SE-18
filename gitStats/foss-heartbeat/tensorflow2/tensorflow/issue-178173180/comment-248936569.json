{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/248936569", "html_url": "https://github.com/tensorflow/tensorflow/issues/4498#issuecomment-248936569", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4498", "id": 248936569, "node_id": "MDEyOklzc3VlQ29tbWVudDI0ODkzNjU2OQ==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-09-22T15:24:33Z", "updated_at": "2016-09-22T15:24:33Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15835199\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/JianbangZ\">@JianbangZ</a> What's the duration of each step when running on a single process, and what's the size of the model that's being retrieved on each step? What batch size are you using? For Inception in the default configuration, I wouldn't expect it to saturate 40GbE, because the computation will be the bottleneck.</p>\n<p>And just to confirm, are you running 0.10 or 0.10rc0 (because there were several performance fixes after the release candidate)?</p>", "body_text": "@JianbangZ What's the duration of each step when running on a single process, and what's the size of the model that's being retrieved on each step? What batch size are you using? For Inception in the default configuration, I wouldn't expect it to saturate 40GbE, because the computation will be the bottleneck.\nAnd just to confirm, are you running 0.10 or 0.10rc0 (because there were several performance fixes after the release candidate)?", "body": "@JianbangZ What's the duration of each step when running on a single process, and what's the size of the model that's being retrieved on each step? What batch size are you using? For Inception in the default configuration, I wouldn't expect it to saturate 40GbE, because the computation will be the bottleneck.\n\nAnd just to confirm, are you running 0.10 or 0.10rc0 (because there were several performance fixes after the release candidate)?\n"}