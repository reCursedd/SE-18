{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/303783466", "html_url": "https://github.com/tensorflow/tensorflow/issues/9837#issuecomment-303783466", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9837", "id": 303783466, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzc4MzQ2Ng==", "user": {"login": "theflofly", "id": 3902382, "node_id": "MDQ6VXNlcjM5MDIzODI=", "avatar_url": "https://avatars1.githubusercontent.com/u/3902382?v=4", "gravatar_id": "", "url": "https://api.github.com/users/theflofly", "html_url": "https://github.com/theflofly", "followers_url": "https://api.github.com/users/theflofly/followers", "following_url": "https://api.github.com/users/theflofly/following{/other_user}", "gists_url": "https://api.github.com/users/theflofly/gists{/gist_id}", "starred_url": "https://api.github.com/users/theflofly/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/theflofly/subscriptions", "organizations_url": "https://api.github.com/users/theflofly/orgs", "repos_url": "https://api.github.com/users/theflofly/repos", "events_url": "https://api.github.com/users/theflofly/events{/privacy}", "received_events_url": "https://api.github.com/users/theflofly/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-24T16:47:43Z", "updated_at": "2017-05-26T07:07:59Z", "author_association": "CONTRIBUTOR", "body_html": "<p>My observations until now.</p>\n<p>In python the Optimizer class provides a minimize method that calls compute_gradient and apply_gradient. compute_gradient adds the gradient ops to the graph, apply_gradient adds the apply ops to the graph and return an operation that applies the gradients.</p>\n<p>The mains files are:</p>\n<ul>\n<li>optimizer.py</li>\n<li>gradient_descent.py</li>\n<li>gradients_impl.py</li>\n</ul>\n<p>In C++ some gradient operations are implemented. There is also a SymbolicGradientBuilder that applies the gradient operations to the graph. The missing part is the applying of the gradients.</p>\n<p>The steps would be:</p>\n<ul>\n<li>Create the Optimizer and GradientDescentOptimizer class</li>\n<li>Use the SymbolicGradientBuilder in the ComputeGradient method</li>\n<li>Add apply operations to the graph and return an operation in the ApplyGradient method</li>\n<li>Combine both methods in the minimize method</li>\n<li>Unit tests</li>\n</ul>\n<p>What do you think?</p>", "body_text": "My observations until now.\nIn python the Optimizer class provides a minimize method that calls compute_gradient and apply_gradient. compute_gradient adds the gradient ops to the graph, apply_gradient adds the apply ops to the graph and return an operation that applies the gradients.\nThe mains files are:\n\noptimizer.py\ngradient_descent.py\ngradients_impl.py\n\nIn C++ some gradient operations are implemented. There is also a SymbolicGradientBuilder that applies the gradient operations to the graph. The missing part is the applying of the gradients.\nThe steps would be:\n\nCreate the Optimizer and GradientDescentOptimizer class\nUse the SymbolicGradientBuilder in the ComputeGradient method\nAdd apply operations to the graph and return an operation in the ApplyGradient method\nCombine both methods in the minimize method\nUnit tests\n\nWhat do you think?", "body": "My observations until now.\r\n\r\nIn python the Optimizer class provides a minimize method that calls compute_gradient and apply_gradient. compute_gradient adds the gradient ops to the graph, apply_gradient adds the apply ops to the graph and return an operation that applies the gradients.\r\n\r\nThe mains files are:\r\n* optimizer.py\r\n* gradient_descent.py\r\n* gradients_impl.py\r\n\r\nIn C++ some gradient operations are implemented. There is also a SymbolicGradientBuilder that applies the gradient operations to the graph. The missing part is the applying of the gradients.\r\n\r\nThe steps would be:\r\n* Create the Optimizer and GradientDescentOptimizer class\r\n* Use the SymbolicGradientBuilder in the ComputeGradient method\r\n* Add apply operations to the graph and return an operation in the ApplyGradient method\r\n* Combine both methods in the minimize method\r\n* Unit tests\r\n\r\nWhat do you think?"}