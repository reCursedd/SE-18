{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3463", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3463/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3463/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3463/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3463", "id": 167080895, "node_id": "MDU6SXNzdWUxNjcwODA4OTU=", "number": 3463, "title": "Dev request -- LSTM RNN", "user": {"login": "KendallWeihe", "id": 3602993, "node_id": "MDQ6VXNlcjM2MDI5OTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3602993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KendallWeihe", "html_url": "https://github.com/KendallWeihe", "followers_url": "https://api.github.com/users/KendallWeihe/followers", "following_url": "https://api.github.com/users/KendallWeihe/following{/other_user}", "gists_url": "https://api.github.com/users/KendallWeihe/gists{/gist_id}", "starred_url": "https://api.github.com/users/KendallWeihe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KendallWeihe/subscriptions", "organizations_url": "https://api.github.com/users/KendallWeihe/orgs", "repos_url": "https://api.github.com/users/KendallWeihe/repos", "events_url": "https://api.github.com/users/KendallWeihe/events{/privacy}", "received_events_url": "https://api.github.com/users/KendallWeihe/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-07-22T16:16:33Z", "updated_at": "2016-08-08T17:41:58Z", "closed_at": "2016-08-08T17:41:58Z", "author_association": "NONE", "body_html": "<p>I previously <a href=\"https://github.com/tensorflow/tensorflow/issues/3278\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/3278/hovercard\">posted</a> about processing 3D data in an LSTM network with Tensorflow. It turns out Grid LSTM networks are what would work best. Already applied in contrib gridd_rnn.py. <a href=\"http://arxiv.org/abs/1507.01526\" rel=\"nofollow\">This</a> paper (Grid LSTM) outlines Grid LSTM, but they also mentioned something I found to be a great idea.</p>\n<p>I don't believe there is a way for Tensorflow to currently support this natively.</p>\n<p>The idea goes, in between each LSTM RNN step, instead of simply passing outputs to the next step, outputs are first passed through a single layer MLP. In other words there is a <code>tf.matmul</code> in between each step.</p>\n<p>What do you think? It seems like a simple enough feature to implement in the <code>RNN</code> initialization.</p>", "body_text": "I previously posted about processing 3D data in an LSTM network with Tensorflow. It turns out Grid LSTM networks are what would work best. Already applied in contrib gridd_rnn.py. This paper (Grid LSTM) outlines Grid LSTM, but they also mentioned something I found to be a great idea.\nI don't believe there is a way for Tensorflow to currently support this natively.\nThe idea goes, in between each LSTM RNN step, instead of simply passing outputs to the next step, outputs are first passed through a single layer MLP. In other words there is a tf.matmul in between each step.\nWhat do you think? It seems like a simple enough feature to implement in the RNN initialization.", "body": "I previously [posted](https://github.com/tensorflow/tensorflow/issues/3278) about processing 3D data in an LSTM network with Tensorflow. It turns out Grid LSTM networks are what would work best. Already applied in contrib gridd_rnn.py. [This](http://arxiv.org/abs/1507.01526) paper (Grid LSTM) outlines Grid LSTM, but they also mentioned something I found to be a great idea.\n\nI don't believe there is a way for Tensorflow to currently support this natively. \n\nThe idea goes, in between each LSTM RNN step, instead of simply passing outputs to the next step, outputs are first passed through a single layer MLP. In other words there is a `tf.matmul` in between each step.\n\nWhat do you think? It seems like a simple enough feature to implement in the `RNN` initialization. \n"}