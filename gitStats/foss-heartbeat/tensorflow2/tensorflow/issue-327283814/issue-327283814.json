{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19617", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19617/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19617/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19617/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19617", "id": 327283814, "node_id": "MDU6SXNzdWUzMjcyODM4MTQ=", "number": 19617, "title": "Model_Average_optimizer Use Problems in got multiple values for keyword argument 'dtype'", "user": {"login": "yunyin", "id": 9065977, "node_id": "MDQ6VXNlcjkwNjU5Nzc=", "avatar_url": "https://avatars3.githubusercontent.com/u/9065977?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yunyin", "html_url": "https://github.com/yunyin", "followers_url": "https://api.github.com/users/yunyin/followers", "following_url": "https://api.github.com/users/yunyin/following{/other_user}", "gists_url": "https://api.github.com/users/yunyin/gists{/gist_id}", "starred_url": "https://api.github.com/users/yunyin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yunyin/subscriptions", "organizations_url": "https://api.github.com/users/yunyin/orgs", "repos_url": "https://api.github.com/users/yunyin/repos", "events_url": "https://api.github.com/users/yunyin/events{/privacy}", "received_events_url": "https://api.github.com/users/yunyin/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 11, "created_at": "2018-05-29T11:42:23Z", "updated_at": "2018-05-31T13:17:37Z", "closed_at": "2018-05-31T13:17:37Z", "author_association": "NONE", "body_html": "<p>I used <code>Model_Average_optimizer</code> and some problems occured:<br><br>\nthe code is used more likely as <code>model_average_optimizer_test.py</code>.<br><br>\nI find this error is occured in <code>init ModelAverageOptimizer</code> to create local_step. And this problem is more likely some problems with device_setter.<br><br>\nBut I don't know why. Could someone help me?<br></p>\n<p>Have I written custom code: Yes<br>\nOS Platform and Distribution: Linux n10-044-067 4.4.0-33.bm.1-amd64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Thu, 22 Jun 2017 11:19:55 +0800 x86_64 GNU/Linux<br>\nTensorFlow installed from: Anaconda2.5, pip install tensorflow_gpu<br>\nTensorFlow version: 1.8.0<br>\nBazel version: N/A<br>\nCUDA/cuDNN version: CUDA-9.0, cuDNN-7.1.2(installed in anaconda2.5 also)<br>\nGPU model and memory: GeForce GTX 1080<br>\nExact command to reproduce:</p>\n<pre><code>~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=0\n~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=1\n~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=server --task_id=0\n</code></pre>\n<p>You may notice the errors below is occured when one worker init class <code>ModelAverageOptimizer</code></p>\n<p>Traceback (most recent call last):</p>\n<pre><code>File \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 112, in tf.app.run()\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\n_sys.exit(main(argv))\nFile \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 109, in main\ntest()\nFile \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 84, in test\ninterval_steps=3)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py\", line 139, in init name=\"local_step\")\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\nconstraint=constraint)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\nconstraint=constraint)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\nreturn custom_getter(**custom_getter_kwargs)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py\", line 92, in call\nreturn getter(name, trainable, collections, *args, **kwargs)\nTypeError: _true_getter() got multiple values for keyword argument 'dtype'\n</code></pre>\n<p>The code is below:</p>\n<pre><code>import os\nimport time\nimport json\nimport copy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.contrib.opt.python.training import model_average_optimizer\n \nflags = tf.flags\nflags.DEFINE_string(\"server_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\nflags.DEFINE_string(\"worker_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\nflags.DEFINE_string(\"job_name\", \"\", \"Either 'server' of 'worker'\")\nflags.DEFINE_integer(\"task_id\", 0, \"Task Id for Each workers\")\n \nFLAGS = flags.FLAGS\ntf.logging.set_verbosity(tf.logging.INFO)\n \ndef workers_ps_creator(args):\n    ps_hosts = args.server_hosts.split(\",\")\n    worker_hosts = args.worker_hosts.split(\",\")\n    num_workers = len(worker_hosts)\n \n    cluster = tf.train.ClusterSpec({\"ps\": ps_hosts,\"worker\": worker_hosts})\n    gpu_options = tf.GPUOptions(allocator_type='BFC', allow_growth=True)\n    if args.job_name == \"server\":\n        server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),\n            job_name='ps',\n            task_index=args.task_id,\n            default_session_config=tf.ConfigProto(gpu_options=gpu_options, device_count={\"GPU\":0}),\n            protocol=\"grpc\")\n    elif args.job_name == \"worker\":\n        server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),\n                job_name=\"worker\",\n                task_index=args.task_id,\n                default_session_config = tf.ConfigProto(gpu_options=gpu_options),\n                protocol=\"grpc\")\n    server = tf.train.Server(server_def)\n    return server, cluster, num_workers, gpu_options\n \ndef Model(opt):\n    if FLAGS.task_id == 0:\n        var_0 = tf.get_variable(initializer = 0.0, name = 'v0')\n        var_1 = tf.get_variable(initializer = 1.0, name = 'v1')\n        grads_0 = constant_op.constant(-1.0)\n        grads_1 = constant_op.constant(-1.0)\n    else:\n        var_0 = tf.get_variable(initializer = 7.0, name = 'v0')\n        var_1 = tf.get_variable(initializer = 8.0, name = 'v1')\n        grads_0 = constant_op.constant(-2.0)\n        grads_1 = constant_op.constant(-2.0)\n    train_op = opt.apply_gradients([[grads_0, var_0], [grads_1, var_1]],\n            global_step = tf.train.get_or_create_global_step())\n    return train_op\n \ndef test():\n    server, cluster, num_workers, gpu_options = workers_ps_creator(FLAGS)\n    if FLAGS.job_name == \"server\":\n        server.join()\n    elif FLAGS.job_name == \"worker\":\n        is_chief = (FLAGS.task_id == 0)\n        #Between-graph replication\n        worker_device = \"/job:worker/task:%d\" % (FLAGS.task_id)\n        ma_custom = model_average_optimizer.ModelAverageCustomGetter(worker_device=worker_device)\n        from tensorflow.python.training import device_setter\n        with tf.device(\n            device_setter.replica_device_setter(\n                cluster=cluster,\n                worker_device=worker_device,\n                ps_device=\"/job:ps\")), \\\n            tf.variable_scope(\"\", custom_getter=ma_custom):\n            #create model\n            lr = tf.Variable(1, trainable=False)\n            opt = tf.train.GradientDescentOptimizer(lr)\n            sync_opt = model_average_optimizer.ModelAverageOptimizer(\n                        opt=opt,\n                        num_worker=num_workers,\n                        ma_custom_getter=ma_custom,\n                        is_chief=is_chief,\n                        interval_steps=3)\n            tf.logging.info('model start')\n            train_model = Model(sync_opt)\n            tf.logging.info('model end')\n            ma_hook = sync_opt.make_session_run_hook()\n        sess_config = tf.ConfigProto(gpu_options=gpu_options)\n        sess_config.log_device_placement = False\n        sess_config.allow_soft_placement = True\n  \n        all_hooks = [ma_hook]\n \n        tf.logging.info('Start Sess')\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                is_chief=is_chief,\n                hooks=all_hooks) as sess:\n            tf.logging.info(\"is chief: %s, len: %s\", is_chief, num_workers)\n            for i in range(4):\n                sess.run(train_op)\n                pp1 = sess.run(tf.get_default_graph().get_tensor_by_name('v0:0'))\n                pp2 = sess.run(tf.get_default_graph().get_tensor_by_name('v1:0'))\n                tf.logging.info(\"%d %.2f %.2f\" % (FLAGS.task_id, pp1, pp2))\n        sv.stop()\n        tf.logging.info(\"done\")\n</code></pre>", "body_text": "I used Model_Average_optimizer and some problems occured:\nthe code is used more likely as model_average_optimizer_test.py.\nI find this error is occured in init ModelAverageOptimizer to create local_step. And this problem is more likely some problems with device_setter.\nBut I don't know why. Could someone help me?\nHave I written custom code: Yes\nOS Platform and Distribution: Linux n10-044-067 4.4.0-33.bm.1-amd64 #1 SMP Thu, 22 Jun 2017 11:19:55 +0800 x86_64 GNU/Linux\nTensorFlow installed from: Anaconda2.5, pip install tensorflow_gpu\nTensorFlow version: 1.8.0\nBazel version: N/A\nCUDA/cuDNN version: CUDA-9.0, cuDNN-7.1.2(installed in anaconda2.5 also)\nGPU model and memory: GeForce GTX 1080\nExact command to reproduce:\n~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=0\n~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=1\n~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=server --task_id=0\n\nYou may notice the errors below is occured when one worker init class ModelAverageOptimizer\nTraceback (most recent call last):\nFile \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 112, in tf.app.run()\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\n_sys.exit(main(argv))\nFile \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 109, in main\ntest()\nFile \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 84, in test\ninterval_steps=3)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py\", line 139, in init name=\"local_step\")\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\nconstraint=constraint)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\nconstraint=constraint)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\nreturn custom_getter(**custom_getter_kwargs)\nFile \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py\", line 92, in call\nreturn getter(name, trainable, collections, *args, **kwargs)\nTypeError: _true_getter() got multiple values for keyword argument 'dtype'\n\nThe code is below:\nimport os\nimport time\nimport json\nimport copy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.contrib.opt.python.training import model_average_optimizer\n \nflags = tf.flags\nflags.DEFINE_string(\"server_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\nflags.DEFINE_string(\"worker_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\nflags.DEFINE_string(\"job_name\", \"\", \"Either 'server' of 'worker'\")\nflags.DEFINE_integer(\"task_id\", 0, \"Task Id for Each workers\")\n \nFLAGS = flags.FLAGS\ntf.logging.set_verbosity(tf.logging.INFO)\n \ndef workers_ps_creator(args):\n    ps_hosts = args.server_hosts.split(\",\")\n    worker_hosts = args.worker_hosts.split(\",\")\n    num_workers = len(worker_hosts)\n \n    cluster = tf.train.ClusterSpec({\"ps\": ps_hosts,\"worker\": worker_hosts})\n    gpu_options = tf.GPUOptions(allocator_type='BFC', allow_growth=True)\n    if args.job_name == \"server\":\n        server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),\n            job_name='ps',\n            task_index=args.task_id,\n            default_session_config=tf.ConfigProto(gpu_options=gpu_options, device_count={\"GPU\":0}),\n            protocol=\"grpc\")\n    elif args.job_name == \"worker\":\n        server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),\n                job_name=\"worker\",\n                task_index=args.task_id,\n                default_session_config = tf.ConfigProto(gpu_options=gpu_options),\n                protocol=\"grpc\")\n    server = tf.train.Server(server_def)\n    return server, cluster, num_workers, gpu_options\n \ndef Model(opt):\n    if FLAGS.task_id == 0:\n        var_0 = tf.get_variable(initializer = 0.0, name = 'v0')\n        var_1 = tf.get_variable(initializer = 1.0, name = 'v1')\n        grads_0 = constant_op.constant(-1.0)\n        grads_1 = constant_op.constant(-1.0)\n    else:\n        var_0 = tf.get_variable(initializer = 7.0, name = 'v0')\n        var_1 = tf.get_variable(initializer = 8.0, name = 'v1')\n        grads_0 = constant_op.constant(-2.0)\n        grads_1 = constant_op.constant(-2.0)\n    train_op = opt.apply_gradients([[grads_0, var_0], [grads_1, var_1]],\n            global_step = tf.train.get_or_create_global_step())\n    return train_op\n \ndef test():\n    server, cluster, num_workers, gpu_options = workers_ps_creator(FLAGS)\n    if FLAGS.job_name == \"server\":\n        server.join()\n    elif FLAGS.job_name == \"worker\":\n        is_chief = (FLAGS.task_id == 0)\n        #Between-graph replication\n        worker_device = \"/job:worker/task:%d\" % (FLAGS.task_id)\n        ma_custom = model_average_optimizer.ModelAverageCustomGetter(worker_device=worker_device)\n        from tensorflow.python.training import device_setter\n        with tf.device(\n            device_setter.replica_device_setter(\n                cluster=cluster,\n                worker_device=worker_device,\n                ps_device=\"/job:ps\")), \\\n            tf.variable_scope(\"\", custom_getter=ma_custom):\n            #create model\n            lr = tf.Variable(1, trainable=False)\n            opt = tf.train.GradientDescentOptimizer(lr)\n            sync_opt = model_average_optimizer.ModelAverageOptimizer(\n                        opt=opt,\n                        num_worker=num_workers,\n                        ma_custom_getter=ma_custom,\n                        is_chief=is_chief,\n                        interval_steps=3)\n            tf.logging.info('model start')\n            train_model = Model(sync_opt)\n            tf.logging.info('model end')\n            ma_hook = sync_opt.make_session_run_hook()\n        sess_config = tf.ConfigProto(gpu_options=gpu_options)\n        sess_config.log_device_placement = False\n        sess_config.allow_soft_placement = True\n  \n        all_hooks = [ma_hook]\n \n        tf.logging.info('Start Sess')\n        with tf.train.MonitoredTrainingSession(master=server.target,\n                is_chief=is_chief,\n                hooks=all_hooks) as sess:\n            tf.logging.info(\"is chief: %s, len: %s\", is_chief, num_workers)\n            for i in range(4):\n                sess.run(train_op)\n                pp1 = sess.run(tf.get_default_graph().get_tensor_by_name('v0:0'))\n                pp2 = sess.run(tf.get_default_graph().get_tensor_by_name('v1:0'))\n                tf.logging.info(\"%d %.2f %.2f\" % (FLAGS.task_id, pp1, pp2))\n        sv.stop()\n        tf.logging.info(\"done\")", "body": "I used `Model_Average_optimizer` and some problems occured:<br>\r\nthe code is used more likely as `model_average_optimizer_test.py`.<br>\r\nI find this error is occured in `init ModelAverageOptimizer` to create local_step. And this problem is more likely some problems with device_setter.<br>\r\nBut I don't know why. Could someone help me?<br>\r\n\r\nHave I written custom code: Yes\r\nOS Platform and Distribution: Linux n10-044-067 4.4.0-33.bm.1-amd64 #1 SMP Thu, 22 Jun 2017 11:19:55 +0800 x86_64 GNU/Linux\r\nTensorFlow installed from: Anaconda2.5, pip install tensorflow_gpu\r\nTensorFlow version: 1.8.0\r\nBazel version: N/A\r\nCUDA/cuDNN version: CUDA-9.0, cuDNN-7.1.2(installed in anaconda2.5 also)\r\nGPU model and memory: GeForce GTX 1080\r\nExact command to reproduce:\r\n\r\n    ~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=0\r\n    ~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=1\r\n    ~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=server --task_id=0\r\n\r\nYou may notice the errors below is occured when one worker init class `ModelAverageOptimizer`\r\n\r\nTraceback (most recent call last):\r\n\r\n    File \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 112, in tf.app.run()\r\n    File \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n    File \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 109, in main\r\n    test()\r\n    File \"/data00/home/wupeihao/ma_test/src/rnnlm.py\", line 84, in test\r\n    interval_steps=3)\r\n    File \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py\", line 139, in init name=\"local_step\")\r\n    File \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\r\n    constraint=constraint)\r\n    File \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\r\n    constraint=constraint)\r\n    File \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\r\n    return custom_getter(**custom_getter_kwargs)\r\n    File \"/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py\", line 92, in call\r\n    return getter(name, trainable, collections, *args, **kwargs)\r\n    TypeError: _true_getter() got multiple values for keyword argument 'dtype'\r\n\r\nThe code is below:\r\n    \r\n    import os\r\n    import time\r\n    import json\r\n    import copy\r\n    import numpy as np\r\n    import tensorflow as tf\r\n    from tensorflow.python.framework import ops\r\n    from tensorflow.python.framework import constant_op\r\n    from tensorflow.contrib.opt.python.training import model_average_optimizer\r\n     \r\n    flags = tf.flags\r\n    flags.DEFINE_string(\"server_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\r\n    flags.DEFINE_string(\"worker_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\r\n    flags.DEFINE_string(\"job_name\", \"\", \"Either 'server' of 'worker'\")\r\n    flags.DEFINE_integer(\"task_id\", 0, \"Task Id for Each workers\")\r\n     \r\n    FLAGS = flags.FLAGS\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n     \r\n    def workers_ps_creator(args):\r\n        ps_hosts = args.server_hosts.split(\",\")\r\n        worker_hosts = args.worker_hosts.split(\",\")\r\n        num_workers = len(worker_hosts)\r\n     \r\n        cluster = tf.train.ClusterSpec({\"ps\": ps_hosts,\"worker\": worker_hosts})\r\n        gpu_options = tf.GPUOptions(allocator_type='BFC', allow_growth=True)\r\n        if args.job_name == \"server\":\r\n            server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),\r\n                job_name='ps',\r\n                task_index=args.task_id,\r\n                default_session_config=tf.ConfigProto(gpu_options=gpu_options, device_count={\"GPU\":0}),\r\n                protocol=\"grpc\")\r\n        elif args.job_name == \"worker\":\r\n            server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),\r\n                    job_name=\"worker\",\r\n                    task_index=args.task_id,\r\n                    default_session_config = tf.ConfigProto(gpu_options=gpu_options),\r\n                    protocol=\"grpc\")\r\n        server = tf.train.Server(server_def)\r\n        return server, cluster, num_workers, gpu_options\r\n     \r\n    def Model(opt):\r\n        if FLAGS.task_id == 0:\r\n            var_0 = tf.get_variable(initializer = 0.0, name = 'v0')\r\n            var_1 = tf.get_variable(initializer = 1.0, name = 'v1')\r\n            grads_0 = constant_op.constant(-1.0)\r\n            grads_1 = constant_op.constant(-1.0)\r\n        else:\r\n            var_0 = tf.get_variable(initializer = 7.0, name = 'v0')\r\n            var_1 = tf.get_variable(initializer = 8.0, name = 'v1')\r\n            grads_0 = constant_op.constant(-2.0)\r\n            grads_1 = constant_op.constant(-2.0)\r\n        train_op = opt.apply_gradients([[grads_0, var_0], [grads_1, var_1]],\r\n                global_step = tf.train.get_or_create_global_step())\r\n        return train_op\r\n     \r\n    def test():\r\n        server, cluster, num_workers, gpu_options = workers_ps_creator(FLAGS)\r\n        if FLAGS.job_name == \"server\":\r\n            server.join()\r\n        elif FLAGS.job_name == \"worker\":\r\n            is_chief = (FLAGS.task_id == 0)\r\n            #Between-graph replication\r\n            worker_device = \"/job:worker/task:%d\" % (FLAGS.task_id)\r\n            ma_custom = model_average_optimizer.ModelAverageCustomGetter(worker_device=worker_device)\r\n            from tensorflow.python.training import device_setter\r\n            with tf.device(\r\n                device_setter.replica_device_setter(\r\n                    cluster=cluster,\r\n                    worker_device=worker_device,\r\n                    ps_device=\"/job:ps\")), \\\r\n                tf.variable_scope(\"\", custom_getter=ma_custom):\r\n                #create model\r\n                lr = tf.Variable(1, trainable=False)\r\n                opt = tf.train.GradientDescentOptimizer(lr)\r\n                sync_opt = model_average_optimizer.ModelAverageOptimizer(\r\n                            opt=opt,\r\n                            num_worker=num_workers,\r\n                            ma_custom_getter=ma_custom,\r\n                            is_chief=is_chief,\r\n                            interval_steps=3)\r\n                tf.logging.info('model start')\r\n                train_model = Model(sync_opt)\r\n                tf.logging.info('model end')\r\n                ma_hook = sync_opt.make_session_run_hook()\r\n            sess_config = tf.ConfigProto(gpu_options=gpu_options)\r\n            sess_config.log_device_placement = False\r\n            sess_config.allow_soft_placement = True\r\n      \r\n            all_hooks = [ma_hook]\r\n     \r\n            tf.logging.info('Start Sess')\r\n            with tf.train.MonitoredTrainingSession(master=server.target,\r\n                    is_chief=is_chief,\r\n                    hooks=all_hooks) as sess:\r\n                tf.logging.info(\"is chief: %s, len: %s\", is_chief, num_workers)\r\n                for i in range(4):\r\n                    sess.run(train_op)\r\n                    pp1 = sess.run(tf.get_default_graph().get_tensor_by_name('v0:0'))\r\n                    pp2 = sess.run(tf.get_default_graph().get_tensor_by_name('v1:0'))\r\n                    tf.logging.info(\"%d %.2f %.2f\" % (FLAGS.task_id, pp1, pp2))\r\n            sv.stop()\r\n            tf.logging.info(\"done\")"}