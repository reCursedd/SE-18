{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/326856199", "html_url": "https://github.com/tensorflow/tensorflow/issues/12727#issuecomment-326856199", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12727", "id": 326856199, "node_id": "MDEyOklzc3VlQ29tbWVudDMyNjg1NjE5OQ==", "user": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-04T03:04:57Z", "updated_at": "2017-09-04T03:04:57Z", "author_association": "MEMBER", "body_html": "<p>It's not possible to use <code>with tf.device('/gpu:0'):</code> to wrap an entire model to have it execute purely on the GPU. TensorFlow actually schedules to the GPU automatically, when it makes sense to do so.</p>\n<p>There are actually a significant number of ops that only have CPU kernels. The ops that have both CPU and GPU kernels are mostly the ones that would stand to gain from the number crunching GPUs provide.</p>\n<p>If the cost of copying memory between CPU and GPU is an issue, you might be able to find help redesigning your model to work around that on Stack Overflow.</p>", "body_text": "It's not possible to use with tf.device('/gpu:0'): to wrap an entire model to have it execute purely on the GPU. TensorFlow actually schedules to the GPU automatically, when it makes sense to do so.\nThere are actually a significant number of ops that only have CPU kernels. The ops that have both CPU and GPU kernels are mostly the ones that would stand to gain from the number crunching GPUs provide.\nIf the cost of copying memory between CPU and GPU is an issue, you might be able to find help redesigning your model to work around that on Stack Overflow.", "body": "It's not possible to use `with tf.device('/gpu:0'):` to wrap an entire model to have it execute purely on the GPU. TensorFlow actually schedules to the GPU automatically, when it makes sense to do so.\r\n\r\nThere are actually a significant number of ops that only have CPU kernels. The ops that have both CPU and GPU kernels are mostly the ones that would stand to gain from the number crunching GPUs provide.\r\n\r\nIf the cost of copying memory between CPU and GPU is an issue, you might be able to find help redesigning your model to work around that on Stack Overflow."}