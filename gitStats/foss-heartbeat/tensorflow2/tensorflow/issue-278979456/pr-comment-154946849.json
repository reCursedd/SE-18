{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/154946849", "pull_request_review_id": 81184458, "id": 154946849, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE1NDk0Njg0OQ==", "diff_hunk": "@@ -0,0 +1,467 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdarg>\n+#include <cstdio>\n+#include <cstdlib>\n+#include <fstream>\n+#include <iostream>\n+#include <memory>\n+#include <queue>\n+#include <sstream>\n+#include <string>\n+#include <unordered_set>\n+#include <vector>\n+\n+#include <fcntl.h>\n+#include <getopt.h>\n+#include <sys/time.h>\n+#include <sys/types.h>\n+#include <sys/uio.h>\n+#include <unistd.h>\n+\n+#include \"tensorflow/contrib/lite/kernels/register.h\"\n+#include \"tensorflow/contrib/lite/model.h\"\n+#include \"tensorflow/contrib/lite/optional_debug_tools.h\"\n+#include \"tensorflow/contrib/lite/string_util.h\"\n+\n+#define LOG(x) std::cerr\n+#define CHECK(x)                  \\\n+  if (!(x)) {                     \\\n+    LOG(ERROR) << #x << \"failed\"; \\\n+    exit(1);                      \\\n+  }\n+\n+namespace tensorflow {\n+namespace label_image_tflite {\n+\n+using std::string;\n+\n+bool verbose = false;\n+bool accel = true;\n+bool input_floating = false;\n+int loop_count = 1;\n+\n+float input_mean = 127.5f;\n+float input_std = 127.5f;\n+\n+double get_us(struct timeval t) { return (t.tv_sec * 1000000 + t.tv_usec); }\n+\n+// Takes a file name, and loads a list of labels from it, one per line, and\n+// returns a vector of the strings. It pads with empty strings so the length\n+// of the result is a multiple of 16, because our model expects that.\n+TfLiteStatus ReadLabelsFile(const string& file_name,\n+                            std::vector<string>* result,\n+                            size_t* found_label_count) {\n+  std::ifstream file(file_name);\n+  if (!file) {\n+    LOG(FATAL) << \"Labels file \" << file_name << \" not found\\n\";\n+    return kTfLiteError;\n+  }\n+  result->clear();\n+  string line;\n+  while (std::getline(file, line)) {\n+    result->push_back(line);\n+  }\n+  *found_label_count = result->size();\n+  const int padding = 16;\n+  while (result->size() % padding) {\n+    result->emplace_back();\n+  }\n+  return kTfLiteOk;\n+}\n+\n+// Returns the top N confidence values over threshold in the provided vector,\n+// sorted by confidence in descending order.\n+template <class T>\n+static void get_top_n(std::unique_ptr<tflite::Interpreter>& interpreter,\n+                      const int prediction_size, const size_t num_results,\n+                      const float threshold,\n+                      std::vector<std::pair<float, int>>* top_results) {\n+  T* prediction = interpreter->typed_output_tensor<T>(0);\n+\n+  // Will contain top N results in ascending order.\n+  std::priority_queue<std::pair<float, int>, std::vector<std::pair<float, int>>,\n+                      std::greater<std::pair<float, int>>>\n+      top_result_pq;\n+\n+  const long count = prediction_size;\n+  for (int i = 0; i < count; ++i) {\n+    float value;\n+    if (input_floating)\n+      value = prediction[i];\n+    else\n+      value = prediction[i] / 255.0;\n+    // Only add it if it beats the threshold and has a chance at being in\n+    // the top N.\n+    if (value < threshold) {\n+      continue;\n+    }\n+\n+    top_result_pq.push(std::pair<float, int>(value, i));\n+\n+    // If at capacity, kick the smallest value out.\n+    if (top_result_pq.size() > num_results) {\n+      top_result_pq.pop();\n+    }\n+  }\n+\n+  // Copy to output vector and reverse into descending order.\n+  while (!top_result_pq.empty()) {\n+    top_results->push_back(top_result_pq.top());\n+    top_result_pq.pop();\n+  }\n+  std::reverse(top_results->begin(), top_results->end());\n+}\n+\n+uint8_t* decode_bmp(const uint8_t* input, const int row_size,\n+                    uint8_t* const output, const int width, const int height,\n+                    const int channels, bool top_down) {\n+  for (int i = 0; i < height; i++) {\n+    int src_pos;\n+    int dst_pos;\n+\n+    for (int j = 0; j < width; j++) {\n+      if (!top_down) {\n+        src_pos = ((height - 1 - i) * row_size) + j * channels;\n+      } else {\n+        src_pos = i * row_size + j * channels;\n+      }\n+\n+      dst_pos = (i * width + j) * channels;\n+\n+      switch (channels) {\n+        case 1:\n+          output[dst_pos] = input[src_pos];\n+          break;\n+        case 3:\n+          // BGR -> RGB\n+          output[dst_pos] = input[src_pos + 2];\n+          output[dst_pos + 1] = input[src_pos + 1];\n+          output[dst_pos + 2] = input[src_pos];\n+          break;\n+        case 4:\n+          // BGRA -> RGBA\n+          output[dst_pos] = input[src_pos + 2];\n+          output[dst_pos + 1] = input[src_pos + 1];\n+          output[dst_pos + 2] = input[src_pos];\n+          output[dst_pos + 3] = input[src_pos + 3];\n+          break;\n+        default:\n+          LOG(FATAL) << \"Unexpected number of channels: \" << channels;\n+          break;\n+      }\n+    }\n+  }\n+\n+  return output;\n+}\n+\n+uint8_t* read_bmp(const std::string& input_bmp_name, int& width, int& height,\n+                  int& channels) {\n+  int begin, end;\n+\n+  std::ifstream file(input_bmp_name, std::ios::in | std::ios::binary);\n+  if (!file) {\n+    LOG(FATAL) << \"input file \" << input_bmp_name << \" not found\\n\";\n+    exit(-1);\n+  }\n+\n+  begin = file.tellg();\n+  file.seekg(0, std::ios::end);\n+  end = file.tellg();\n+  size_t len = end - begin;\n+\n+  if (verbose) LOG(INFO) << \"len: \" << len << \"\\n\";\n+\n+  const uint8_t* img_bytes = new uint8_t[len];\n+  file.seekg(0, std::ios::beg);\n+  file.read((char*)img_bytes, len);\n+  const int32_t header_size =\n+      *(reinterpret_cast<const int32_t*>(img_bytes + 10));\n+  width = *(reinterpret_cast<const int32_t*>(img_bytes + 18));\n+  height = *(reinterpret_cast<const int32_t*>(img_bytes + 22));\n+  const int32_t bpp = *(reinterpret_cast<const int32_t*>(img_bytes + 28));\n+  channels = bpp / 8;\n+\n+  if (verbose)\n+    LOG(INFO) << \"width, height, channels: \" << width << \", \" << height << \", \"\n+              << channels << \"\\n\";\n+\n+  // there may be padding bytes when the width is not a multiple of 4 bytes\n+  // 8 * channels == bits per pixel\n+  const int row_size = (8 * channels * width + 31) / 32 * 4;\n+\n+  // if height is negative, data layout is top down\n+  // otherwise, it's bottom up\n+  bool top_down = (height < 0);\n+\n+  // Decode image, allocating tensor once the image size is known\n+  uint8_t* output = new uint8_t[abs(height) * width * channels];\n+  const uint8_t* bmp_pixels = &img_bytes[header_size];\n+  return decode_bmp(bmp_pixels, row_size, output, width, abs(height), channels,\n+                    top_down);\n+}\n+\n+template <class T>\n+void downsize(std::unique_ptr<tflite::Interpreter>& interpreter, int input,", "path": "tensorflow/contrib/lite/examples/label_image/label_image.cc", "position": null, "original_position": 219, "commit_id": "8b7ad1194bbcb6e3f147791381c7502edf8b0ba8", "original_commit_id": "67427966bcd5247cdcb332e8edaf213d1724f586", "user": {"login": "freedomtan", "id": 3395998, "node_id": "MDQ6VXNlcjMzOTU5OTg=", "avatar_url": "https://avatars0.githubusercontent.com/u/3395998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/freedomtan", "html_url": "https://github.com/freedomtan", "followers_url": "https://api.github.com/users/freedomtan/followers", "following_url": "https://api.github.com/users/freedomtan/following{/other_user}", "gists_url": "https://api.github.com/users/freedomtan/gists{/gist_id}", "starred_url": "https://api.github.com/users/freedomtan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/freedomtan/subscriptions", "organizations_url": "https://api.github.com/users/freedomtan/orgs", "repos_url": "https://api.github.com/users/freedomtan/repos", "events_url": "https://api.github.com/users/freedomtan/events{/privacy}", "received_events_url": "https://api.github.com/users/freedomtan/received_events", "type": "User", "site_admin": false}, "body": "done. will push patches later.", "created_at": "2017-12-05T13:41:20Z", "updated_at": "2017-12-14T07:45:55Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/15095#discussion_r154946849", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15095", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/154946849"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/15095#discussion_r154946849"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/15095"}}, "body_html": "<p>done. will push patches later.</p>", "body_text": "done. will push patches later.", "in_reply_to_id": 154725797}