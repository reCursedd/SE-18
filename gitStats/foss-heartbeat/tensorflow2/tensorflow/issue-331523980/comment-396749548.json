{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396749548", "html_url": "https://github.com/tensorflow/tensorflow/issues/19936#issuecomment-396749548", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19936", "id": 396749548, "node_id": "MDEyOklzc3VlQ29tbWVudDM5Njc0OTU0OA==", "user": {"login": "suharshs", "id": 1450614, "node_id": "MDQ6VXNlcjE0NTA2MTQ=", "avatar_url": "https://avatars1.githubusercontent.com/u/1450614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/suharshs", "html_url": "https://github.com/suharshs", "followers_url": "https://api.github.com/users/suharshs/followers", "following_url": "https://api.github.com/users/suharshs/following{/other_user}", "gists_url": "https://api.github.com/users/suharshs/gists{/gist_id}", "starred_url": "https://api.github.com/users/suharshs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/suharshs/subscriptions", "organizations_url": "https://api.github.com/users/suharshs/orgs", "repos_url": "https://api.github.com/users/suharshs/repos", "events_url": "https://api.github.com/users/suharshs/events{/privacy}", "received_events_url": "https://api.github.com/users/suharshs/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-12T22:04:30Z", "updated_at": "2018-06-12T22:04:30Z", "author_association": "MEMBER", "body_html": "<p>The create_training_graph and create_eval_graph rewrite the graph and adds variables the graph. The added variables are added in a variable scope under the hood. So when you make an explicit outer variable_scope the issue seems to be resolved, right?</p>\n<p>In practice, we try to separate training and eval graphs to avoid variable scopes and reuse issues. You can do this by either implementing an estimator or creating a separate train and eval script like we did with mobilenet_v1 here:<br>\n<a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_train.py\">https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_train.py</a><br>\n<a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py\">https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py</a></p>", "body_text": "The create_training_graph and create_eval_graph rewrite the graph and adds variables the graph. The added variables are added in a variable scope under the hood. So when you make an explicit outer variable_scope the issue seems to be resolved, right?\nIn practice, we try to separate training and eval graphs to avoid variable scopes and reuse issues. You can do this by either implementing an estimator or creating a separate train and eval script like we did with mobilenet_v1 here:\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_train.py\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py", "body": "The create_training_graph and create_eval_graph rewrite the graph and adds variables the graph. The added variables are added in a variable scope under the hood. So when you make an explicit outer variable_scope the issue seems to be resolved, right?\r\n\r\nIn practice, we try to separate training and eval graphs to avoid variable scopes and reuse issues. You can do this by either implementing an estimator or creating a separate train and eval script like we did with mobilenet_v1 here:\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_train.py\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1_eval.py"}