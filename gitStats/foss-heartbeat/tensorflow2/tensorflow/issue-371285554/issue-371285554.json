{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23056", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23056/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23056/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23056/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23056", "id": 371285554, "node_id": "MDU6SXNzdWUzNzEyODU1NTQ=", "number": 23056, "title": "Losses collection is not thread local so it can't be used inside model_fn call when using MirroredStrategy", "user": {"login": "antifriz", "id": 6382271, "node_id": "MDQ6VXNlcjYzODIyNzE=", "avatar_url": "https://avatars3.githubusercontent.com/u/6382271?v=4", "gravatar_id": "", "url": "https://api.github.com/users/antifriz", "html_url": "https://github.com/antifriz", "followers_url": "https://api.github.com/users/antifriz/followers", "following_url": "https://api.github.com/users/antifriz/following{/other_user}", "gists_url": "https://api.github.com/users/antifriz/gists{/gist_id}", "starred_url": "https://api.github.com/users/antifriz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/antifriz/subscriptions", "organizations_url": "https://api.github.com/users/antifriz/orgs", "repos_url": "https://api.github.com/users/antifriz/repos", "events_url": "https://api.github.com/users/antifriz/events{/privacy}", "received_events_url": "https://api.github.com/users/antifriz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 996845227, "node_id": "MDU6TGFiZWw5OTY4NDUyMjc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:dist-strat", "name": "comp:dist-strat", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "seemuch", "id": 2233625, "node_id": "MDQ6VXNlcjIyMzM2MjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/2233625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seemuch", "html_url": "https://github.com/seemuch", "followers_url": "https://api.github.com/users/seemuch/followers", "following_url": "https://api.github.com/users/seemuch/following{/other_user}", "gists_url": "https://api.github.com/users/seemuch/gists{/gist_id}", "starred_url": "https://api.github.com/users/seemuch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seemuch/subscriptions", "organizations_url": "https://api.github.com/users/seemuch/orgs", "repos_url": "https://api.github.com/users/seemuch/repos", "events_url": "https://api.github.com/users/seemuch/events{/privacy}", "received_events_url": "https://api.github.com/users/seemuch/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "seemuch", "id": 2233625, "node_id": "MDQ6VXNlcjIyMzM2MjU=", "avatar_url": "https://avatars0.githubusercontent.com/u/2233625?v=4", "gravatar_id": "", "url": "https://api.github.com/users/seemuch", "html_url": "https://github.com/seemuch", "followers_url": "https://api.github.com/users/seemuch/followers", "following_url": "https://api.github.com/users/seemuch/following{/other_user}", "gists_url": "https://api.github.com/users/seemuch/gists{/gist_id}", "starred_url": "https://api.github.com/users/seemuch/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/seemuch/subscriptions", "organizations_url": "https://api.github.com/users/seemuch/orgs", "repos_url": "https://api.github.com/users/seemuch/repos", "events_url": "https://api.github.com/users/seemuch/events{/privacy}", "received_events_url": "https://api.github.com/users/seemuch/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-10-17T22:06:01Z", "updated_at": "2018-11-20T07:43:28Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no</li>\n<li>TensorFlow installed from (source or binary): source</li>\n<li>TensorFlow version (use command below): 'v1.12.0-rc0-0-g1a6dea3' 1.12.0-rc0</li>\n<li>Python version: 3.6</li>\n<li>Bazel version (if compiling from source): 0.18.0</li>\n<li>GCC/Compiler version (if compiling from source): gcc-6 (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424</li>\n<li>CUDA/cuDNN version: 10.0/7.3.1.20</li>\n<li>GPU model and memory: GeForce GTX 1080 Ti (11GB)</li>\n</ul>\n<p><strong>Describe the current behavior</strong></p>\n<p>When calling <code>tf.losses.add_loss</code> inside model_fn in Estimator API, it is added to the <code>tf.GraphKeys.LOSSES</code> collection. <code>tf.losses.get_total_loss</code> is aggregating all the losses from the <code>tf.GraphKeys.LOSSES</code> collection.</p>\n<p>Unfortunately, when using <code>tf.contrib.distribute.MirroredStrategy</code> as a distribute strategy, collection is updated from all concurrent <code>model_fn</code> calls. This leads to tower losses being aggregated to total loss in other towers as well.</p>\n<p>So if we have 4 GPUs with losses L1, L2, L3, L4, Estimator will report total loss as <code>a * L1 + b * L2 + c * L3 + d* L4</code> where a,b,c,d depends on the races encountered.</p>\n<p><strong>Describe the expected behavior</strong></p>\n<p>I would expect total loss to be <code>L1 + L2 + L3 + L4</code>.</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<p>When running this code, second call to <code>model_fn</code> causes assertion that losses collection is empty to fail.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">model_fn</span>(<span class=\"pl-smi\">features</span>, <span class=\"pl-smi\">labels</span>, <span class=\"pl-smi\">mode</span>):\n    loss <span class=\"pl-k\">=</span> tf.abs(features <span class=\"pl-k\">+</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>foo<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>()) <span class=\"pl-k\">-</span> labels)\n\n    <span class=\"pl-k\">assert</span> <span class=\"pl-c1\">len</span>(tf.get_collection(tf.GraphKeys.<span class=\"pl-c1\">LOSSES</span>)) <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>\n    tf.losses.add_loss(loss)\n\n    loss <span class=\"pl-k\">=</span> tf.losses.get_total_loss()\n    train_op <span class=\"pl-k\">=</span> tf.train.GradientDescentOptimizer(<span class=\"pl-c1\">0.0</span>).minimize(loss)\n    <span class=\"pl-k\">return</span> tf.estimator.EstimatorSpec(mode, <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span>loss, <span class=\"pl-v\">train_op</span><span class=\"pl-k\">=</span>train_op)\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">input_fn</span>():\n    <span class=\"pl-k\">return</span> tf.data.Dataset.zip((\n        tf.data.Dataset.from_tensors(<span class=\"pl-c1\">0</span>.).repeat(<span class=\"pl-c1\">100</span>),\n        tf.data.Dataset.from_tensors(<span class=\"pl-c1\">0</span>.).repeat(<span class=\"pl-c1\">100</span>)\n    ))\n\n\ndistribution <span class=\"pl-k\">=</span> tf.contrib.distribute.MirroredStrategy(<span class=\"pl-v\">num_gpus</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">2</span>)\nconfig <span class=\"pl-k\">=</span> tf.estimator.RunConfig(<span class=\"pl-v\">train_distribute</span><span class=\"pl-k\">=</span>distribution)\nestimator <span class=\"pl-k\">=</span> tf.estimator.Estimator(<span class=\"pl-v\">model_fn</span><span class=\"pl-k\">=</span>model_fn, <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config)\nestimator.train(<span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span>input_fn)</pre></div>\n<p><strong>Other info / logs</strong></p>\n<p>Script output:</p>\n<pre><code>INFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:Not using Distribute Coordinator.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpq6v9w4nh\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpq6v9w4nh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': &lt;tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f27bd939240&gt;, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f27bd939f60&gt;, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:2\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:3\nINFO:tensorflow:Configured nccl all-reduce.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"&lt;ipython-input-9-57173fdb3adc&gt;\", line 7, in model_fn\n    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0\nAssertionError\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 'v1.12.0-rc0-0-g1a6dea3' 1.12.0-rc0\nPython version: 3.6\nBazel version (if compiling from source): 0.18.0\nGCC/Compiler version (if compiling from source): gcc-6 (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424\nCUDA/cuDNN version: 10.0/7.3.1.20\nGPU model and memory: GeForce GTX 1080 Ti (11GB)\n\nDescribe the current behavior\nWhen calling tf.losses.add_loss inside model_fn in Estimator API, it is added to the tf.GraphKeys.LOSSES collection. tf.losses.get_total_loss is aggregating all the losses from the tf.GraphKeys.LOSSES collection.\nUnfortunately, when using tf.contrib.distribute.MirroredStrategy as a distribute strategy, collection is updated from all concurrent model_fn calls. This leads to tower losses being aggregated to total loss in other towers as well.\nSo if we have 4 GPUs with losses L1, L2, L3, L4, Estimator will report total loss as a * L1 + b * L2 + c * L3 + d* L4 where a,b,c,d depends on the races encountered.\nDescribe the expected behavior\nI would expect total loss to be L1 + L2 + L3 + L4.\nCode to reproduce the issue\nWhen running this code, second call to model_fn causes assertion that losses collection is empty to fail.\nimport tensorflow as tf\n\n\ndef model_fn(features, labels, mode):\n    loss = tf.abs(features + tf.get_variable('foo', shape=()) - labels)\n\n    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0\n    tf.losses.add_loss(loss)\n\n    loss = tf.losses.get_total_loss()\n    train_op = tf.train.GradientDescentOptimizer(0.0).minimize(loss)\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n\n\ndef input_fn():\n    return tf.data.Dataset.zip((\n        tf.data.Dataset.from_tensors(0.).repeat(100),\n        tf.data.Dataset.from_tensors(0.).repeat(100)\n    ))\n\n\ndistribution = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\nestimator.train(input_fn=input_fn)\nOther info / logs\nScript output:\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\nINFO:tensorflow:Not using Distribute Coordinator.\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpq6v9w4nh\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpq6v9w4nh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f27bd939240>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f27bd939f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:2\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:3\nINFO:tensorflow:Configured nccl all-reduce.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-9-57173fdb3adc>\", line 7, in model_fn\n    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0\nAssertionError", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 'v1.12.0-rc0-0-g1a6dea3' 1.12.0-rc0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source): gcc-6 (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424\r\n- CUDA/cuDNN version: 10.0/7.3.1.20\r\n- GPU model and memory: GeForce GTX 1080 Ti (11GB)\r\n\r\n**Describe the current behavior**\r\n\r\nWhen calling `tf.losses.add_loss` inside model_fn in Estimator API, it is added to the `tf.GraphKeys.LOSSES` collection. `tf.losses.get_total_loss` is aggregating all the losses from the `tf.GraphKeys.LOSSES` collection.\r\n\r\nUnfortunately, when using `tf.contrib.distribute.MirroredStrategy` as a distribute strategy, collection is updated from all concurrent `model_fn` calls. This leads to tower losses being aggregated to total loss in other towers as well.\r\n\r\nSo if we have 4 GPUs with losses L1, L2, L3, L4, Estimator will report total loss as `a * L1 + b * L2 + c * L3 + d* L4` where a,b,c,d depends on the races encountered.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect total loss to be `L1 + L2 + L3 + L4`.\r\n\r\n**Code to reproduce the issue**\r\n\r\nWhen running this code, second call to `model_fn` causes assertion that losses collection is empty to fail.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef model_fn(features, labels, mode):\r\n    loss = tf.abs(features + tf.get_variable('foo', shape=()) - labels)\r\n\r\n    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0\r\n    tf.losses.add_loss(loss)\r\n\r\n    loss = tf.losses.get_total_loss()\r\n    train_op = tf.train.GradientDescentOptimizer(0.0).minimize(loss)\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n\r\ndef input_fn():\r\n    return tf.data.Dataset.zip((\r\n        tf.data.Dataset.from_tensors(0.).repeat(100),\r\n        tf.data.Dataset.from_tensors(0.).repeat(100)\r\n    ))\r\n\r\n\r\ndistribution = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\r\nconfig = tf.estimator.RunConfig(train_distribute=distribution)\r\nestimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\nestimator.train(input_fn=input_fn)\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\nScript output:\r\n\r\n```\r\nINFO:tensorflow:Initializing RunConfig with distribution strategies.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpq6v9w4nh\r\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpq6v9w4nh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f27bd939240>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f27bd939f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:2\r\nINFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:3\r\nINFO:tensorflow:Configured nccl all-reduce.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Error reported to Coordinator: \r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 795, in run\r\n    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"<ipython-input-9-57173fdb3adc>\", line 7, in model_fn\r\n    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0\r\nAssertionError\r\n```\r\n"}