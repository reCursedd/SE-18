{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14274", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14274/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14274/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14274/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14274", "id": 271377631, "node_id": "MDU6SXNzdWUyNzEzNzc2MzE=", "number": 14274, "title": "how can I print predictions  in TF-Slim's eval_image_classifier.py?", "user": {"login": "breeze5428", "id": 5536634, "node_id": "MDQ6VXNlcjU1MzY2MzQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/5536634?v=4", "gravatar_id": "", "url": "https://api.github.com/users/breeze5428", "html_url": "https://github.com/breeze5428", "followers_url": "https://api.github.com/users/breeze5428/followers", "following_url": "https://api.github.com/users/breeze5428/following{/other_user}", "gists_url": "https://api.github.com/users/breeze5428/gists{/gist_id}", "starred_url": "https://api.github.com/users/breeze5428/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/breeze5428/subscriptions", "organizations_url": "https://api.github.com/users/breeze5428/orgs", "repos_url": "https://api.github.com/users/breeze5428/repos", "events_url": "https://api.github.com/users/breeze5428/events{/privacy}", "received_events_url": "https://api.github.com/users/breeze5428/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-11-06T07:08:19Z", "updated_at": "2017-11-06T08:15:59Z", "closed_at": "2017-11-06T08:15:59Z", "author_association": "NONE", "body_html": "<p>I want to print prediction results into txt files  in TF-Slim <a href=\"https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py\">eval_image_classifier.py</a> .  I have tried many times, but failed to do it.<br>\nThank you in advance.</p>\n<p>===============================================================<br>\n`from <strong>future</strong> import absolute_import<br>\nfrom <strong>future</strong> import division<br>\nfrom <strong>future</strong> import print_function</p>\n<p>import math<br>\nimport tensorflow as tf</p>\n<p>from datasets import dataset_factory<br>\nfrom nets import nets_factory<br>\nfrom preprocessing import preprocessing_factory</p>\n<p>slim = tf.contrib.slim</p>\n<p>tf.app.flags.DEFINE_integer(<br>\n'batch_size', 100, 'The number of samples in each batch.')</p>\n<p>tf.app.flags.DEFINE_integer(<br>\n'max_num_batches', None,<br>\n'Max number of batches to evaluate by default use all.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'master', '', 'The address of the TensorFlow master to use.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'checkpoint_path', '/tmp/tfmodel/',<br>\n'The directory where the model was written to or an absolute path to a '<br>\n'checkpoint file.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'eval_dir', '/tmp/tfmodel/', 'Directory where the results are saved to.')</p>\n<p>tf.app.flags.DEFINE_integer(<br>\n'num_preprocessing_threads', 4,<br>\n'The number of threads used to create the batches.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'dataset_name', 'imagenet', 'The name of the dataset to load.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'dataset_split_name', 'test', 'The name of the train/test split.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'dataset_dir', None, 'The directory where the dataset files are stored.')</p>\n<p>tf.app.flags.DEFINE_integer(<br>\n'labels_offset', 0,<br>\n'An offset for the labels in the dataset. This flag is primarily used to '<br>\n'evaluate the VGG and ResNet architectures which do not use a background '<br>\n'class for the ImageNet dataset.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'model_name', 'inception_v3', 'The name of the architecture to evaluate.')</p>\n<p>tf.app.flags.DEFINE_string(<br>\n'preprocessing_name', None, 'The name of the preprocessing to use. If left '<br>\n'as <code>None</code>, then the model_name flag is used.')</p>\n<p>tf.app.flags.DEFINE_float(<br>\n'moving_average_decay', None,<br>\n'The decay to use for the moving average.'<br>\n'If left as None, then moving averages are not used.')</p>\n<p>tf.app.flags.DEFINE_integer(<br>\n'eval_image_size', None, 'Eval image size')</p>\n<p>FLAGS = tf.app.flags.FLAGS</p>\n<p>def main(_):<br>\nif not FLAGS.dataset_dir:<br>\nraise ValueError('You must supply the dataset directory with --dataset_dir')</p>\n<p>tf.logging.set_verbosity(tf.logging.INFO)<br>\nwith tf.Graph().as_default():<br>\ntf_global_step = slim.get_or_create_global_step()</p>\n<pre><code>######################\n# Select the dataset #\n######################\ndataset = dataset_factory.get_dataset(\n    FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n\n####################\n# Select the model #\n####################\nnetwork_fn = nets_factory.get_network_fn(\n    FLAGS.model_name,\n    num_classes=(dataset.num_classes - FLAGS.labels_offset),\n    is_training=False)\n\n##############################################################\n# Create a dataset provider that loads data from the dataset #\n##############################################################\nprovider = slim.dataset_data_provider.DatasetDataProvider(\n    dataset,\n    shuffle=False,\n    common_queue_capacity=2 * FLAGS.batch_size,\n    common_queue_min=FLAGS.batch_size)\n[image, label] = provider.get(['image', 'label'])\nlabel -= FLAGS.labels_offset\n\n#####################################\n# Select the preprocessing function #\n#####################################\npreprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\nimage_preprocessing_fn = preprocessing_factory.get_preprocessing(\n    preprocessing_name,\n    is_training=False)\n\neval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\n\nimage = image_preprocessing_fn(image, eval_image_size, eval_image_size)\n\nimages, labels = tf.train.batch(\n    [image, label],\n    batch_size=FLAGS.batch_size,\n    num_threads=FLAGS.num_preprocessing_threads,\n    capacity=5 * FLAGS.batch_size)\n\n####################\n# Define the model #\n####################\nlogits, _ = network_fn(images)\n\nif FLAGS.moving_average_decay:\n  variable_averages = tf.train.ExponentialMovingAverage(\n      FLAGS.moving_average_decay, tf_global_step)\n  variables_to_restore = variable_averages.variables_to_restore(\n      slim.get_model_variables())\n  variables_to_restore[tf_global_step.op.name] = tf_global_step\nelse:\n  variables_to_restore = slim.get_variables_to_restore()\n\npredictions = tf.argmax(logits, 1)\nlabels = tf.squeeze(labels)\n\n# Define the metrics:\nnames_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n    'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),\n    'Recall_5': slim.metrics.streaming_recall_at_k(\n        logits, labels, 5),\n})\n\n# Print the summaries to screen.\nfor name, value in names_to_values.items():\n  summary_name = 'eval/%s' % name\n  op = tf.summary.scalar(summary_name, value, collections=[])\n  op = tf.Print(op, [value], summary_name)\n  tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n\n# TODO(sguada) use num_epochs=1\nif FLAGS.max_num_batches:\n  num_batches = FLAGS.max_num_batches\nelse:\n  # This ensures that we make a single pass over all of the data.\n  num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\n\nif tf.gfile.IsDirectory(FLAGS.checkpoint_path):\n  checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\nelse:\n  checkpoint_path = FLAGS.checkpoint_path\n\ntf.logging.info('Evaluating %s' % checkpoint_path)\n\nslim.evaluation.evaluate_once(\n    master=FLAGS.master,\n    checkpoint_path=checkpoint_path,\n    logdir=FLAGS.eval_dir,\n    num_evals=num_batches,\n    eval_op=list(names_to_updates.values()),\n    variables_to_restore=variables_to_restore)\n</code></pre>\n<p>if <strong>name</strong> == '<strong>main</strong>':<br>\ntf.app.run()`</p>", "body_text": "I want to print prediction results into txt files  in TF-Slim eval_image_classifier.py .  I have tried many times, but failed to do it.\nThank you in advance.\n===============================================================\n`from future import absolute_import\nfrom future import division\nfrom future import print_function\nimport math\nimport tensorflow as tf\nfrom datasets import dataset_factory\nfrom nets import nets_factory\nfrom preprocessing import preprocessing_factory\nslim = tf.contrib.slim\ntf.app.flags.DEFINE_integer(\n'batch_size', 100, 'The number of samples in each batch.')\ntf.app.flags.DEFINE_integer(\n'max_num_batches', None,\n'Max number of batches to evaluate by default use all.')\ntf.app.flags.DEFINE_string(\n'master', '', 'The address of the TensorFlow master to use.')\ntf.app.flags.DEFINE_string(\n'checkpoint_path', '/tmp/tfmodel/',\n'The directory where the model was written to or an absolute path to a '\n'checkpoint file.')\ntf.app.flags.DEFINE_string(\n'eval_dir', '/tmp/tfmodel/', 'Directory where the results are saved to.')\ntf.app.flags.DEFINE_integer(\n'num_preprocessing_threads', 4,\n'The number of threads used to create the batches.')\ntf.app.flags.DEFINE_string(\n'dataset_name', 'imagenet', 'The name of the dataset to load.')\ntf.app.flags.DEFINE_string(\n'dataset_split_name', 'test', 'The name of the train/test split.')\ntf.app.flags.DEFINE_string(\n'dataset_dir', None, 'The directory where the dataset files are stored.')\ntf.app.flags.DEFINE_integer(\n'labels_offset', 0,\n'An offset for the labels in the dataset. This flag is primarily used to '\n'evaluate the VGG and ResNet architectures which do not use a background '\n'class for the ImageNet dataset.')\ntf.app.flags.DEFINE_string(\n'model_name', 'inception_v3', 'The name of the architecture to evaluate.')\ntf.app.flags.DEFINE_string(\n'preprocessing_name', None, 'The name of the preprocessing to use. If left '\n'as None, then the model_name flag is used.')\ntf.app.flags.DEFINE_float(\n'moving_average_decay', None,\n'The decay to use for the moving average.'\n'If left as None, then moving averages are not used.')\ntf.app.flags.DEFINE_integer(\n'eval_image_size', None, 'Eval image size')\nFLAGS = tf.app.flags.FLAGS\ndef main(_):\nif not FLAGS.dataset_dir:\nraise ValueError('You must supply the dataset directory with --dataset_dir')\ntf.logging.set_verbosity(tf.logging.INFO)\nwith tf.Graph().as_default():\ntf_global_step = slim.get_or_create_global_step()\n######################\n# Select the dataset #\n######################\ndataset = dataset_factory.get_dataset(\n    FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n\n####################\n# Select the model #\n####################\nnetwork_fn = nets_factory.get_network_fn(\n    FLAGS.model_name,\n    num_classes=(dataset.num_classes - FLAGS.labels_offset),\n    is_training=False)\n\n##############################################################\n# Create a dataset provider that loads data from the dataset #\n##############################################################\nprovider = slim.dataset_data_provider.DatasetDataProvider(\n    dataset,\n    shuffle=False,\n    common_queue_capacity=2 * FLAGS.batch_size,\n    common_queue_min=FLAGS.batch_size)\n[image, label] = provider.get(['image', 'label'])\nlabel -= FLAGS.labels_offset\n\n#####################################\n# Select the preprocessing function #\n#####################################\npreprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\nimage_preprocessing_fn = preprocessing_factory.get_preprocessing(\n    preprocessing_name,\n    is_training=False)\n\neval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\n\nimage = image_preprocessing_fn(image, eval_image_size, eval_image_size)\n\nimages, labels = tf.train.batch(\n    [image, label],\n    batch_size=FLAGS.batch_size,\n    num_threads=FLAGS.num_preprocessing_threads,\n    capacity=5 * FLAGS.batch_size)\n\n####################\n# Define the model #\n####################\nlogits, _ = network_fn(images)\n\nif FLAGS.moving_average_decay:\n  variable_averages = tf.train.ExponentialMovingAverage(\n      FLAGS.moving_average_decay, tf_global_step)\n  variables_to_restore = variable_averages.variables_to_restore(\n      slim.get_model_variables())\n  variables_to_restore[tf_global_step.op.name] = tf_global_step\nelse:\n  variables_to_restore = slim.get_variables_to_restore()\n\npredictions = tf.argmax(logits, 1)\nlabels = tf.squeeze(labels)\n\n# Define the metrics:\nnames_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\n    'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),\n    'Recall_5': slim.metrics.streaming_recall_at_k(\n        logits, labels, 5),\n})\n\n# Print the summaries to screen.\nfor name, value in names_to_values.items():\n  summary_name = 'eval/%s' % name\n  op = tf.summary.scalar(summary_name, value, collections=[])\n  op = tf.Print(op, [value], summary_name)\n  tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n\n# TODO(sguada) use num_epochs=1\nif FLAGS.max_num_batches:\n  num_batches = FLAGS.max_num_batches\nelse:\n  # This ensures that we make a single pass over all of the data.\n  num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\n\nif tf.gfile.IsDirectory(FLAGS.checkpoint_path):\n  checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\nelse:\n  checkpoint_path = FLAGS.checkpoint_path\n\ntf.logging.info('Evaluating %s' % checkpoint_path)\n\nslim.evaluation.evaluate_once(\n    master=FLAGS.master,\n    checkpoint_path=checkpoint_path,\n    logdir=FLAGS.eval_dir,\n    num_evals=num_batches,\n    eval_op=list(names_to_updates.values()),\n    variables_to_restore=variables_to_restore)\n\nif name == 'main':\ntf.app.run()`", "body": "I want to print prediction results into txt files  in TF-Slim [eval_image_classifier.py](https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py) .  I have tried many times, but failed to do it.  \r\nThank you in advance.\r\n\r\n\r\n\r\n===============================================================\r\n`from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport math\r\nimport tensorflow as tf\r\n\r\nfrom datasets import dataset_factory\r\nfrom nets import nets_factory\r\nfrom preprocessing import preprocessing_factory\r\n\r\nslim = tf.contrib.slim\r\n\r\ntf.app.flags.DEFINE_integer(\r\n    'batch_size', 100, 'The number of samples in each batch.')\r\n\r\ntf.app.flags.DEFINE_integer(\r\n    'max_num_batches', None,\r\n    'Max number of batches to evaluate by default use all.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'master', '', 'The address of the TensorFlow master to use.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'checkpoint_path', '/tmp/tfmodel/',\r\n    'The directory where the model was written to or an absolute path to a '\r\n    'checkpoint file.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'eval_dir', '/tmp/tfmodel/', 'Directory where the results are saved to.')\r\n\r\ntf.app.flags.DEFINE_integer(\r\n    'num_preprocessing_threads', 4,\r\n    'The number of threads used to create the batches.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'dataset_name', 'imagenet', 'The name of the dataset to load.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'dataset_split_name', 'test', 'The name of the train/test split.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'dataset_dir', None, 'The directory where the dataset files are stored.')\r\n\r\ntf.app.flags.DEFINE_integer(\r\n    'labels_offset', 0,\r\n    'An offset for the labels in the dataset. This flag is primarily used to '\r\n    'evaluate the VGG and ResNet architectures which do not use a background '\r\n    'class for the ImageNet dataset.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'model_name', 'inception_v3', 'The name of the architecture to evaluate.')\r\n\r\ntf.app.flags.DEFINE_string(\r\n    'preprocessing_name', None, 'The name of the preprocessing to use. If left '\r\n    'as `None`, then the model_name flag is used.')\r\n\r\ntf.app.flags.DEFINE_float(\r\n    'moving_average_decay', None,\r\n    'The decay to use for the moving average.'\r\n    'If left as None, then moving averages are not used.')\r\n\r\ntf.app.flags.DEFINE_integer(\r\n    'eval_image_size', None, 'Eval image size')\r\n\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\n\r\ndef main(_):\r\n  if not FLAGS.dataset_dir:\r\n    raise ValueError('You must supply the dataset directory with --dataset_dir')\r\n\r\n  tf.logging.set_verbosity(tf.logging.INFO)\r\n  with tf.Graph().as_default():\r\n    tf_global_step = slim.get_or_create_global_step()\r\n\r\n    ######################\r\n    # Select the dataset #\r\n    ######################\r\n    dataset = dataset_factory.get_dataset(\r\n        FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\r\n\r\n    ####################\r\n    # Select the model #\r\n    ####################\r\n    network_fn = nets_factory.get_network_fn(\r\n        FLAGS.model_name,\r\n        num_classes=(dataset.num_classes - FLAGS.labels_offset),\r\n        is_training=False)\r\n\r\n    ##############################################################\r\n    # Create a dataset provider that loads data from the dataset #\r\n    ##############################################################\r\n    provider = slim.dataset_data_provider.DatasetDataProvider(\r\n        dataset,\r\n        shuffle=False,\r\n        common_queue_capacity=2 * FLAGS.batch_size,\r\n        common_queue_min=FLAGS.batch_size)\r\n    [image, label] = provider.get(['image', 'label'])\r\n    label -= FLAGS.labels_offset\r\n\r\n    #####################################\r\n    # Select the preprocessing function #\r\n    #####################################\r\n    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name\r\n    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\r\n        preprocessing_name,\r\n        is_training=False)\r\n\r\n    eval_image_size = FLAGS.eval_image_size or network_fn.default_image_size\r\n\r\n    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)\r\n\r\n    images, labels = tf.train.batch(\r\n        [image, label],\r\n        batch_size=FLAGS.batch_size,\r\n        num_threads=FLAGS.num_preprocessing_threads,\r\n        capacity=5 * FLAGS.batch_size)\r\n\r\n    ####################\r\n    # Define the model #\r\n    ####################\r\n    logits, _ = network_fn(images)\r\n\r\n    if FLAGS.moving_average_decay:\r\n      variable_averages = tf.train.ExponentialMovingAverage(\r\n          FLAGS.moving_average_decay, tf_global_step)\r\n      variables_to_restore = variable_averages.variables_to_restore(\r\n          slim.get_model_variables())\r\n      variables_to_restore[tf_global_step.op.name] = tf_global_step\r\n    else:\r\n      variables_to_restore = slim.get_variables_to_restore()\r\n\r\n    predictions = tf.argmax(logits, 1)\r\n    labels = tf.squeeze(labels)\r\n\r\n    # Define the metrics:\r\n    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({\r\n        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),\r\n        'Recall_5': slim.metrics.streaming_recall_at_k(\r\n            logits, labels, 5),\r\n    })\r\n\r\n    # Print the summaries to screen.\r\n    for name, value in names_to_values.items():\r\n      summary_name = 'eval/%s' % name\r\n      op = tf.summary.scalar(summary_name, value, collections=[])\r\n      op = tf.Print(op, [value], summary_name)\r\n      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\r\n\r\n    # TODO(sguada) use num_epochs=1\r\n    if FLAGS.max_num_batches:\r\n      num_batches = FLAGS.max_num_batches\r\n    else:\r\n      # This ensures that we make a single pass over all of the data.\r\n      num_batches = math.ceil(dataset.num_samples / float(FLAGS.batch_size))\r\n\r\n    if tf.gfile.IsDirectory(FLAGS.checkpoint_path):\r\n      checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_path)\r\n    else:\r\n      checkpoint_path = FLAGS.checkpoint_path\r\n\r\n    tf.logging.info('Evaluating %s' % checkpoint_path)\r\n\r\n    slim.evaluation.evaluate_once(\r\n        master=FLAGS.master,\r\n        checkpoint_path=checkpoint_path,\r\n        logdir=FLAGS.eval_dir,\r\n        num_evals=num_batches,\r\n        eval_op=list(names_to_updates.values()),\r\n        variables_to_restore=variables_to_restore)\r\n\r\n\r\nif __name__ == '__main__':\r\n  tf.app.run()`"}