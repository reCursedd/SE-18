{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16323", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16323/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16323/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16323/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16323", "id": 290808502, "node_id": "MDU6SXNzdWUyOTA4MDg1MDI=", "number": 16323, "title": "Does Broadcast in TF copy first or just do ops along the axis", "user": {"login": "kbxu", "id": 6727603, "node_id": "MDQ6VXNlcjY3Mjc2MDM=", "avatar_url": "https://avatars0.githubusercontent.com/u/6727603?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kbxu", "html_url": "https://github.com/kbxu", "followers_url": "https://api.github.com/users/kbxu/followers", "following_url": "https://api.github.com/users/kbxu/following{/other_user}", "gists_url": "https://api.github.com/users/kbxu/gists{/gist_id}", "starred_url": "https://api.github.com/users/kbxu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kbxu/subscriptions", "organizations_url": "https://api.github.com/users/kbxu/orgs", "repos_url": "https://api.github.com/users/kbxu/repos", "events_url": "https://api.github.com/users/kbxu/events{/privacy}", "received_events_url": "https://api.github.com/users/kbxu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2018-01-23T11:52:14Z", "updated_at": "2018-02-09T17:40:02Z", "closed_at": "2018-02-09T17:40:02Z", "author_association": "NONE", "body_html": "<p>For example, we have<br>\ntensor a with shape (100, 100, 5) and tensor b with shape (1, 1, 5)<br>\nwhen running<br>\nc = tf.multiply(a, b)</p>\n<p>Is b first copied 100 * 100 times for the <strong>big</strong> dot multiply with a (GPU memory consuming),<br>\nor the dot multiply is done with the original b along axis 0 and 1?</p>\n<p>The tf.multiply page refers to <strong>numpy multiply</strong> that says it won't copy, just loop.<br>\n<a href=\"https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\" rel=\"nofollow\">https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html</a></p>\n<p>I guess it's copied first that I run into GPU memory problem by adjusting a bit the b.<br>\nHow's it implemented in TF? Couldn't find the source gen_math_ops</p>\n<p>Issue template update:<br>\nHave I written custom code No<br>\nOS Platform and Distribution: Windows 10 x64 Home version<br>\nTensorFlow installed from pip (anaconda with python 3.6.3)<br>\nTensorFlow version: 1.4.1<br>\nBazel version: N/A<br>\nCUDA/cuDNN version: CUDA 8.0, cuDNN 6<br>\nGPU model and memory: GTX 1050Ti, 4 GB memory (3.3 GB available)<br>\nExact command to reproduce N/A (not relevant to the question)</p>", "body_text": "For example, we have\ntensor a with shape (100, 100, 5) and tensor b with shape (1, 1, 5)\nwhen running\nc = tf.multiply(a, b)\nIs b first copied 100 * 100 times for the big dot multiply with a (GPU memory consuming),\nor the dot multiply is done with the original b along axis 0 and 1?\nThe tf.multiply page refers to numpy multiply that says it won't copy, just loop.\nhttps://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\nI guess it's copied first that I run into GPU memory problem by adjusting a bit the b.\nHow's it implemented in TF? Couldn't find the source gen_math_ops\nIssue template update:\nHave I written custom code No\nOS Platform and Distribution: Windows 10 x64 Home version\nTensorFlow installed from pip (anaconda with python 3.6.3)\nTensorFlow version: 1.4.1\nBazel version: N/A\nCUDA/cuDNN version: CUDA 8.0, cuDNN 6\nGPU model and memory: GTX 1050Ti, 4 GB memory (3.3 GB available)\nExact command to reproduce N/A (not relevant to the question)", "body": "For example, we have\r\ntensor a with shape (100, 100, 5) and tensor b with shape (1, 1, 5)\r\nwhen running\r\nc = tf.multiply(a, b)\r\n\r\nIs b first copied 100 * 100 times for the **big** dot multiply with a (GPU memory consuming),\r\nor the dot multiply is done with the original b along axis 0 and 1?\r\n\r\nThe tf.multiply page refers to **numpy multiply** that says it won't copy, just loop.\r\nhttps://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\r\n\r\nI guess it's copied first that I run into GPU memory problem by adjusting a bit the b.\r\nHow's it implemented in TF? Couldn't find the source gen_math_ops\r\n\r\nIssue template update:\r\nHave I written custom code No\r\nOS Platform and Distribution: Windows 10 x64 Home version\r\nTensorFlow installed from pip (anaconda with python 3.6.3)\r\nTensorFlow version: 1.4.1\r\nBazel version: N/A\r\nCUDA/cuDNN version: CUDA 8.0, cuDNN 6\r\nGPU model and memory: GTX 1050Ti, 4 GB memory (3.3 GB available)\r\nExact command to reproduce N/A (not relevant to the question)"}