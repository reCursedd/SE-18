{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13692", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13692/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13692/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13692/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13692", "id": 265340664, "node_id": "MDU6SXNzdWUyNjUzNDA2NjQ=", "number": 13692, "title": "TensorFlow 1.3.0 GPU for Windows doesn't work for 2 NVIDIA P4s", "user": {"login": "johnsrude", "id": 15482785, "node_id": "MDQ6VXNlcjE1NDgyNzg1", "avatar_url": "https://avatars1.githubusercontent.com/u/15482785?v=4", "gravatar_id": "", "url": "https://api.github.com/users/johnsrude", "html_url": "https://github.com/johnsrude", "followers_url": "https://api.github.com/users/johnsrude/followers", "following_url": "https://api.github.com/users/johnsrude/following{/other_user}", "gists_url": "https://api.github.com/users/johnsrude/gists{/gist_id}", "starred_url": "https://api.github.com/users/johnsrude/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/johnsrude/subscriptions", "organizations_url": "https://api.github.com/users/johnsrude/orgs", "repos_url": "https://api.github.com/users/johnsrude/repos", "events_url": "https://api.github.com/users/johnsrude/events{/privacy}", "received_events_url": "https://api.github.com/users/johnsrude/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 12, "created_at": "2017-10-13T16:05:26Z", "updated_at": "2017-10-25T16:18:44Z", "closed_at": "2017-10-14T00:27:36Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li>\n<p><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</p>\n</li>\n<li>\n<p><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 7 (factory production machine)</p>\n</li>\n<li>\n<p><strong>TensorFlow installed from (source or binary)</strong>:<br>\n<a href=\"https://pypi.python.org/pypi/tensorflow-gpu\" rel=\"nofollow\">https://pypi.python.org/pypi/tensorflow-gpu</a><br>\ntensorflow_gpu-1.3.0-cp35-cp35m-win_amd64.whl</p>\n</li>\n<li>\n<p><strong>TensorFlow version (use command below)</strong>: 1.3.0</p>\n</li>\n<li>\n<p><strong>Python version</strong>:  3.5</p>\n</li>\n<li>\n<p><strong>Bazel version (if compiling from source)</strong>:</p>\n</li>\n<li>\n<p><strong>CUDA/cuDNN version</strong>: Cuda release 8.0, V8.0.60.  cuDNN 6.</p>\n</li>\n<li>\n<p><strong>GPU model and memory</strong>:  2 NVIDIA Tesla P4s (same as specs)</p>\n</li>\n<li>\n<p><strong>Exact command to reproduce</strong>: <a href=\"https://github.com/tkuanlun350/Tensorflow-SegNet\">https://github.com/tkuanlun350/Tensorflow-SegNet</a></p>\n</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>We're currently evaluating Tensorflow as a possible replacement for Caffe but we seem to have run into a problem with running multiple P4s on a production system.</p>\n<p>Our production systems are offline so I had to install a Python wheel of the GPU version TF framework which works fine until I try to use 2 GPUs for training where I get the error message:</p>\n<p><code>2017-10-05 13:53:42.989423: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0</code></p>\n<p>P4s are installed and working correctly.  I don't understand why peer-to-peer GPU access is required for using GPUs.  We can run multiple GPUs on our Caffe implementation.</p>\n<pre><code>nvidia-smi\nTue Oct 10 10:53:57 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 385.54                 Driver Version: 385.54                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla P4            TCC  | 00000000:04:00.0 Off |                    0 |\n| N/A   31C    P8     6W /  75W |      0MiB /  7590MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla P4            TCC  | 00000000:81:00.0 Off |                    0 |\n| N/A   30C    P8     6W /  75W |      0MiB /  7590MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n</code></pre>", "body_text": "System information\n\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 (factory production machine)\n\n\nTensorFlow installed from (source or binary):\nhttps://pypi.python.org/pypi/tensorflow-gpu\ntensorflow_gpu-1.3.0-cp35-cp35m-win_amd64.whl\n\n\nTensorFlow version (use command below): 1.3.0\n\n\nPython version:  3.5\n\n\nBazel version (if compiling from source):\n\n\nCUDA/cuDNN version: Cuda release 8.0, V8.0.60.  cuDNN 6.\n\n\nGPU model and memory:  2 NVIDIA Tesla P4s (same as specs)\n\n\nExact command to reproduce: https://github.com/tkuanlun350/Tensorflow-SegNet\n\n\nDescribe the problem\nWe're currently evaluating Tensorflow as a possible replacement for Caffe but we seem to have run into a problem with running multiple P4s on a production system.\nOur production systems are offline so I had to install a Python wheel of the GPU version TF framework which works fine until I try to use 2 GPUs for training where I get the error message:\n2017-10-05 13:53:42.989423: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0\nP4s are installed and working correctly.  I don't understand why peer-to-peer GPU access is required for using GPUs.  We can run multiple GPUs on our Caffe implementation.\nnvidia-smi\nTue Oct 10 10:53:57 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 385.54                 Driver Version: 385.54                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla P4            TCC  | 00000000:04:00.0 Off |                    0 |\n| N/A   31C    P8     6W /  75W |      0MiB /  7590MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla P4            TCC  | 00000000:81:00.0 Off |                    0 |\n| N/A   30C    P8     6W /  75W |      0MiB /  7590MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 (factory production machine)\r\n- **TensorFlow installed from (source or binary)**:\r\nhttps://pypi.python.org/pypi/tensorflow-gpu\r\ntensorflow_gpu-1.3.0-cp35-cp35m-win_amd64.whl\r\n\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: Cuda release 8.0, V8.0.60.  cuDNN 6.\r\n- **GPU model and memory**:  2 NVIDIA Tesla P4s (same as specs)\r\n- **Exact command to reproduce**: https://github.com/tkuanlun350/Tensorflow-SegNet\r\n\r\n### Describe the problem\r\nWe're currently evaluating Tensorflow as a possible replacement for Caffe but we seem to have run into a problem with running multiple P4s on a production system.\r\n \r\nOur production systems are offline so I had to install a Python wheel of the GPU version TF framework which works fine until I try to use 2 GPUs for training where I get the error message:\r\n \r\n`2017-10-05 13:53:42.989423: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0`\r\n\r\nP4s are installed and working correctly.  I don't understand why peer-to-peer GPU access is required for using GPUs.  We can run multiple GPUs on our Caffe implementation.\r\n\r\n```\r\nnvidia-smi\r\nTue Oct 10 10:53:57 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 385.54                 Driver Version: 385.54                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla P4            TCC  | 00000000:04:00.0 Off |                    0 |\r\n| N/A   31C    P8     6W /  75W |      0MiB /  7590MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla P4            TCC  | 00000000:81:00.0 Off |                    0 |\r\n| N/A   30C    P8     6W /  75W |      0MiB /  7590MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n```\r\n  "}