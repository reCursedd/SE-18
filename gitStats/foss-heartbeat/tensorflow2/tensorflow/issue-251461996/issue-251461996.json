{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12421", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12421/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12421/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12421/events", "html_url": "https://github.com/tensorflow/tensorflow/pull/12421", "id": 251461996, "node_id": "MDExOlB1bGxSZXF1ZXN0MTM2NjI4MzIy", "number": 12421, "title": "Refactor word2vec_basic", "user": {"login": "lucasmoura", "id": 2703696, "node_id": "MDQ6VXNlcjI3MDM2OTY=", "avatar_url": "https://avatars2.githubusercontent.com/u/2703696?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucasmoura", "html_url": "https://github.com/lucasmoura", "followers_url": "https://api.github.com/users/lucasmoura/followers", "following_url": "https://api.github.com/users/lucasmoura/following{/other_user}", "gists_url": "https://api.github.com/users/lucasmoura/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucasmoura/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucasmoura/subscriptions", "organizations_url": "https://api.github.com/users/lucasmoura/orgs", "repos_url": "https://api.github.com/users/lucasmoura/repos", "events_url": "https://api.github.com/users/lucasmoura/events{/privacy}", "received_events_url": "https://api.github.com/users/lucasmoura/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 300136587, "node_id": "MDU6TGFiZWwzMDAxMzY1ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20yes", "name": "cla: yes", "color": "009800", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jhseu", "id": 170179, "node_id": "MDQ6VXNlcjE3MDE3OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/170179?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jhseu", "html_url": "https://github.com/jhseu", "followers_url": "https://api.github.com/users/jhseu/followers", "following_url": "https://api.github.com/users/jhseu/following{/other_user}", "gists_url": "https://api.github.com/users/jhseu/gists{/gist_id}", "starred_url": "https://api.github.com/users/jhseu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jhseu/subscriptions", "organizations_url": "https://api.github.com/users/jhseu/orgs", "repos_url": "https://api.github.com/users/jhseu/repos", "events_url": "https://api.github.com/users/jhseu/events{/privacy}", "received_events_url": "https://api.github.com/users/jhseu/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2017-08-20T02:33:18Z", "updated_at": "2017-08-28T13:41:13Z", "closed_at": "2017-08-21T23:51:40Z", "author_association": "CONTRIBUTOR", "pull_request": {"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/12421", "html_url": "https://github.com/tensorflow/tensorflow/pull/12421", "diff_url": "https://github.com/tensorflow/tensorflow/pull/12421.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/12421.patch"}, "body_html": "<p>This MR changes two functions on word2vec_basic.py</p>\n<ul>\n<li><strong>create_dataset</strong>: Update how the function search the dictionary for an index value.</li>\n<li><strong>generate_batch</strong>:  Update how the context words are obtained. The function originally does that using the following code:</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre>    targets_to_avoid <span class=\"pl-k\">=</span> [skip_window]\n    <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_skips):\n      <span class=\"pl-k\">while</span> target <span class=\"pl-k\">in</span> targets_to_avoid:\n        target <span class=\"pl-k\">=</span> random.randint(<span class=\"pl-c1\">0</span>, span <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>)\n      targets_to_avoid.append(target)\n      batch[i <span class=\"pl-k\">*</span> num_skips <span class=\"pl-k\">+</span> j] <span class=\"pl-k\">=</span> buffer[skip_window]\n      labels[i <span class=\"pl-k\">*</span> num_skips <span class=\"pl-k\">+</span> j, <span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> buffer[target]</pre></div>\n<p>Meaning that it is randomly trying to select a new word in the span and checking if the word is valid to use. If it is, it will be now used to create a batch. I believe that a simpler approach is:</p>\n<div class=\"highlight highlight-source-python\"><pre>   target <span class=\"pl-k\">=</span> skip_window  <span class=\"pl-c\"><span class=\"pl-c\">#</span> target label at the center of the buffer</span>\n    context_words <span class=\"pl-k\">=</span> [w <span class=\"pl-k\">for</span> w <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(span) <span class=\"pl-k\">if</span> w <span class=\"pl-k\">!=</span> target]\n    random.shuffle(context_words)\n    words_to_use <span class=\"pl-k\">=</span> collections.deque(context_words)\n    <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_skips):\n      batch[i <span class=\"pl-k\">*</span> num_skips <span class=\"pl-k\">+</span> j] <span class=\"pl-k\">=</span> buffer[target]\n      context_word <span class=\"pl-k\">=</span> words_to_use.pop()\n      labels[i <span class=\"pl-k\">*</span> num_skips <span class=\"pl-k\">+</span> j, <span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> buffer[context_word]</pre></div>\n<p>In this approach, an array of valid context words are created without randomly selecting each valid word. This valid context words are shuffled and added to a deque, to make word removal less costly.</p>\n<p>I believe that this modifications make both <strong>create_dataset</strong> and <strong>generate_batch</strong> a little simpler to understand, and although this is not the intention of this MR, but a little faster as well.</p>", "body_text": "This MR changes two functions on word2vec_basic.py\n\ncreate_dataset: Update how the function search the dictionary for an index value.\ngenerate_batch:  Update how the context words are obtained. The function originally does that using the following code:\n\n    targets_to_avoid = [skip_window]\n    for j in range(num_skips):\n      while target in targets_to_avoid:\n        target = random.randint(0, span - 1)\n      targets_to_avoid.append(target)\n      batch[i * num_skips + j] = buffer[skip_window]\n      labels[i * num_skips + j, 0] = buffer[target]\nMeaning that it is randomly trying to select a new word in the span and checking if the word is valid to use. If it is, it will be now used to create a batch. I believe that a simpler approach is:\n   target = skip_window  # target label at the center of the buffer\n    context_words = [w for w in range(span) if w != target]\n    random.shuffle(context_words)\n    words_to_use = collections.deque(context_words)\n    for j in range(num_skips):\n      batch[i * num_skips + j] = buffer[target]\n      context_word = words_to_use.pop()\n      labels[i * num_skips + j, 0] = buffer[context_word]\nIn this approach, an array of valid context words are created without randomly selecting each valid word. This valid context words are shuffled and added to a deque, to make word removal less costly.\nI believe that this modifications make both create_dataset and generate_batch a little simpler to understand, and although this is not the intention of this MR, but a little faster as well.", "body": "This MR changes two functions on word2vec_basic.py\r\n\r\n*  **create_dataset**: Update how the function search the dictionary for an index value.\r\n*  **generate_batch**:  Update how the context words are obtained. The function originally does that using the following code:\r\n\r\n```python\r\n    targets_to_avoid = [skip_window]\r\n    for j in range(num_skips):\r\n      while target in targets_to_avoid:\r\n        target = random.randint(0, span - 1)\r\n      targets_to_avoid.append(target)\r\n      batch[i * num_skips + j] = buffer[skip_window]\r\n      labels[i * num_skips + j, 0] = buffer[target]\r\n```\r\n\r\nMeaning that it is randomly trying to select a new word in the span and checking if the word is valid to use. If it is, it will be now used to create a batch. I believe that a simpler approach is:\r\n\r\n```python\r\n   target = skip_window  # target label at the center of the buffer\r\n    context_words = [w for w in range(span) if w != target]\r\n    random.shuffle(context_words)\r\n    words_to_use = collections.deque(context_words)\r\n    for j in range(num_skips):\r\n      batch[i * num_skips + j] = buffer[target]\r\n      context_word = words_to_use.pop()\r\n      labels[i * num_skips + j, 0] = buffer[context_word]\r\n```\r\n\r\nIn this approach, an array of valid context words are created without randomly selecting each valid word. This valid context words are shuffled and added to a deque, to make word removal less costly.\r\n\r\nI believe that this modifications make both **create_dataset** and **generate_batch** a little simpler to understand, and although this is not the intention of this MR, but a little faster as well.                                    "}