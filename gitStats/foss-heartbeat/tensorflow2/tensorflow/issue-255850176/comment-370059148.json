{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/370059148", "html_url": "https://github.com/tensorflow/tensorflow/issues/12871#issuecomment-370059148", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12871", "id": 370059148, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MDA1OTE0OA==", "user": {"login": "lucb", "id": 59227, "node_id": "MDQ6VXNlcjU5MjI3", "avatar_url": "https://avatars0.githubusercontent.com/u/59227?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lucb", "html_url": "https://github.com/lucb", "followers_url": "https://api.github.com/users/lucb/followers", "following_url": "https://api.github.com/users/lucb/following{/other_user}", "gists_url": "https://api.github.com/users/lucb/gists{/gist_id}", "starred_url": "https://api.github.com/users/lucb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lucb/subscriptions", "organizations_url": "https://api.github.com/users/lucb/orgs", "repos_url": "https://api.github.com/users/lucb/repos", "events_url": "https://api.github.com/users/lucb/events{/privacy}", "received_events_url": "https://api.github.com/users/lucb/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-02T21:34:14Z", "updated_at": "2018-03-02T21:34:14Z", "author_association": "NONE", "body_html": "<p>TF_CUDNN_USE_AUTOTUNE='0' will not work, it will use cuDNN function to retrieve the best algorithm. One solution I found was to support a new environment variable TF_CUDNN_CONVOLUTION_BWD_FILTER_ALGO_DETERMINISTIC='1' such that we only use cuDNN deterministic algorithms.</p>\n<p>I did not measure the performance of this solution but I'm getting deterministic results for gradient computation of convolutions, something that I was not getting previously</p>\n<p>The code I used to test the determinism of the backward filter of the convolution is the following:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\nnp.random.seed(<span class=\"pl-c1\">0</span>)\nnp.set_printoptions(<span class=\"pl-v\">precision</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">4</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run_convolution_test</span>(<span class=\"pl-smi\">device</span>, <span class=\"pl-smi\">N</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>):\n  tf.reset_default_graph()\n  tf.set_random_seed(<span class=\"pl-c1\">42</span>)\n  <span class=\"pl-k\">with</span> tf.device(device):\n    <span class=\"pl-c1\">input</span> <span class=\"pl-k\">=</span> tf.random_normal([<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2048</span>, <span class=\"pl-c1\">2048</span>, <span class=\"pl-c1\">1</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>input<span class=\"pl-pds\">'</span></span>)\n    kernel <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>kernel<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span> <span class=\"pl-k\">=</span> [<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>])\n    conv <span class=\"pl-k\">=</span> tf.nn.conv2d(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">input</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">input</span>,\n                        <span class=\"pl-v\">filter</span><span class=\"pl-k\">=</span>kernel, <span class=\"pl-v\">strides</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">1</span>], <span class=\"pl-v\">padding</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>SAME<span class=\"pl-pds\">'</span></span>,\n                        <span class=\"pl-v\">use_cudnn_on_gpu</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n    grad <span class=\"pl-k\">=</span> tf.gradients(conv, kernel)\n  grad_val <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n  a_val <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n  config <span class=\"pl-k\">=</span> tf.ConfigProto(<span class=\"pl-v\">intra_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>, <span class=\"pl-v\">inter_op_parallelism_threads</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>)\n  <span class=\"pl-k\">with</span> tf.Session(<span class=\"pl-v\">config</span><span class=\"pl-k\">=</span>config) <span class=\"pl-k\">as</span> sess:\n    sess.run(tf.global_variables_initializer())\n    conv_val, grad_val <span class=\"pl-k\">=</span> sess.run([tf.squeeze(conv), tf.squeeze(grad)])\n    <span class=\"pl-k\">return</span> conv_val, grad_val\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">compute_error_matrix</span>(<span class=\"pl-smi\">matrices</span>):\n    total_absolute_error <span class=\"pl-k\">=</span> np.zeros((<span class=\"pl-c1\">len</span>(matrices), <span class=\"pl-c1\">len</span>(matrices)))\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(matrices)):\n        <span class=\"pl-k\">for</span> j <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">len</span>(matrices)):\n            <span class=\"pl-k\">if</span> i <span class=\"pl-k\">!=</span> j:\n                dif<span class=\"pl-k\">=</span>matrices[i] <span class=\"pl-k\">-</span> matrices[j]\n                total_absolute_error[i][j] <span class=\"pl-k\">=</span> np.sum(np.absolute(dif))\n    <span class=\"pl-c1\">print</span>(total_absolute_error)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running on GPU<span class=\"pl-pds\">\"</span></span>)\nconv_gpu, grad_gpu <span class=\"pl-k\">=</span> <span class=\"pl-c1\">zip</span>(<span class=\"pl-k\">*</span>[run_convolution_test(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/device:GPU:0<span class=\"pl-pds\">'</span></span>, i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>)])\ncompute_error_matrix(conv_gpu)\ncompute_error_matrix(grad_gpu)\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running on CPU<span class=\"pl-pds\">\"</span></span>)\nconv_cpu, grad_cpu <span class=\"pl-k\">=</span> <span class=\"pl-c1\">zip</span>(<span class=\"pl-k\">*</span>[run_convolution_test(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/device:CPU:0<span class=\"pl-pds\">'</span></span>, i) <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">10</span>,<span class=\"pl-c1\">20</span>)])\ncompute_error_matrix(conv_cpu)\ncompute_error_matrix(grad_cpu)</pre></div>", "body_text": "TF_CUDNN_USE_AUTOTUNE='0' will not work, it will use cuDNN function to retrieve the best algorithm. One solution I found was to support a new environment variable TF_CUDNN_CONVOLUTION_BWD_FILTER_ALGO_DETERMINISTIC='1' such that we only use cuDNN deterministic algorithms.\nI did not measure the performance of this solution but I'm getting deterministic results for gradient computation of convolutions, something that I was not getting previously\nThe code I used to test the determinism of the backward filter of the convolution is the following:\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(0)\nnp.set_printoptions(precision=4)\n\ndef run_convolution_test(device, N=1):\n  tf.reset_default_graph()\n  tf.set_random_seed(42)\n  with tf.device(device):\n    input = tf.random_normal([1, 2048, 2048, 1], name='input')\n    kernel = tf.get_variable('kernel', shape = [3,3,1,1])\n    conv = tf.nn.conv2d(name='conv', input=input,\n                        filter=kernel, strides=[1,1,1,1], padding='SAME',\n                        use_cudnn_on_gpu=True)\n    grad = tf.gradients(conv, kernel)\n  grad_val = None\n  a_val = None\n  config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n  with tf.Session(config=config) as sess:\n    sess.run(tf.global_variables_initializer())\n    conv_val, grad_val = sess.run([tf.squeeze(conv), tf.squeeze(grad)])\n    return conv_val, grad_val\n\ndef compute_error_matrix(matrices):\n    total_absolute_error = np.zeros((len(matrices), len(matrices)))\n    for i in range(len(matrices)):\n        for j in range(len(matrices)):\n            if i != j:\n                dif=matrices[i] - matrices[j]\n                total_absolute_error[i][j] = np.sum(np.absolute(dif))\n    print(total_absolute_error)\n\nprint(\"Running on GPU\")\nconv_gpu, grad_gpu = zip(*[run_convolution_test('/device:GPU:0', i) for i in range(10)])\ncompute_error_matrix(conv_gpu)\ncompute_error_matrix(grad_gpu)\n\nprint(\"Running on CPU\")\nconv_cpu, grad_cpu = zip(*[run_convolution_test('/device:CPU:0', i) for i in range(10,20)])\ncompute_error_matrix(conv_cpu)\ncompute_error_matrix(grad_cpu)", "body": "TF_CUDNN_USE_AUTOTUNE='0' will not work, it will use cuDNN function to retrieve the best algorithm. One solution I found was to support a new environment variable TF_CUDNN_CONVOLUTION_BWD_FILTER_ALGO_DETERMINISTIC='1' such that we only use cuDNN deterministic algorithms.\r\n\r\nI did not measure the performance of this solution but I'm getting deterministic results for gradient computation of convolutions, something that I was not getting previously\r\n\r\nThe code I used to test the determinism of the backward filter of the convolution is the following:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnp.random.seed(0)\r\nnp.set_printoptions(precision=4)\r\n\r\ndef run_convolution_test(device, N=1):\r\n  tf.reset_default_graph()\r\n  tf.set_random_seed(42)\r\n  with tf.device(device):\r\n    input = tf.random_normal([1, 2048, 2048, 1], name='input')\r\n    kernel = tf.get_variable('kernel', shape = [3,3,1,1])\r\n    conv = tf.nn.conv2d(name='conv', input=input,\r\n                        filter=kernel, strides=[1,1,1,1], padding='SAME',\r\n                        use_cudnn_on_gpu=True)\r\n    grad = tf.gradients(conv, kernel)\r\n  grad_val = None\r\n  a_val = None\r\n  config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\r\n  with tf.Session(config=config) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    conv_val, grad_val = sess.run([tf.squeeze(conv), tf.squeeze(grad)])\r\n    return conv_val, grad_val\r\n\r\ndef compute_error_matrix(matrices):\r\n    total_absolute_error = np.zeros((len(matrices), len(matrices)))\r\n    for i in range(len(matrices)):\r\n        for j in range(len(matrices)):\r\n            if i != j:\r\n                dif=matrices[i] - matrices[j]\r\n                total_absolute_error[i][j] = np.sum(np.absolute(dif))\r\n    print(total_absolute_error)\r\n\r\nprint(\"Running on GPU\")\r\nconv_gpu, grad_gpu = zip(*[run_convolution_test('/device:GPU:0', i) for i in range(10)])\r\ncompute_error_matrix(conv_gpu)\r\ncompute_error_matrix(grad_gpu)\r\n\r\nprint(\"Running on CPU\")\r\nconv_cpu, grad_cpu = zip(*[run_convolution_test('/device:CPU:0', i) for i in range(10,20)])\r\ncompute_error_matrix(conv_cpu)\r\ncompute_error_matrix(grad_cpu)\r\n```\r\n\r\n"}