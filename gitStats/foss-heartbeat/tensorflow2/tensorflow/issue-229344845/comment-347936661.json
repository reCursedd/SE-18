{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/347936661", "html_url": "https://github.com/tensorflow/tensorflow/issues/9969#issuecomment-347936661", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9969", "id": 347936661, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NzkzNjY2MQ==", "user": {"login": "Jonathan-LeRoux", "id": 14299374, "node_id": "MDQ6VXNlcjE0Mjk5Mzc0", "avatar_url": "https://avatars1.githubusercontent.com/u/14299374?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Jonathan-LeRoux", "html_url": "https://github.com/Jonathan-LeRoux", "followers_url": "https://api.github.com/users/Jonathan-LeRoux/followers", "following_url": "https://api.github.com/users/Jonathan-LeRoux/following{/other_user}", "gists_url": "https://api.github.com/users/Jonathan-LeRoux/gists{/gist_id}", "starred_url": "https://api.github.com/users/Jonathan-LeRoux/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Jonathan-LeRoux/subscriptions", "organizations_url": "https://api.github.com/users/Jonathan-LeRoux/orgs", "repos_url": "https://api.github.com/users/Jonathan-LeRoux/repos", "events_url": "https://api.github.com/users/Jonathan-LeRoux/events{/privacy}", "received_events_url": "https://api.github.com/users/Jonathan-LeRoux/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-29T17:35:22Z", "updated_at": "2017-11-29T17:35:22Z", "author_association": "NONE", "body_html": "<p>I'm not sure I understand why this issue was marked as Closed.<br>\nWe have exactly the same problem: we're on a multi-node slurm cluster where the head node does not have a GPU. In order to run tensorboard on the head node without having to use a separate tensorflow-cpu environment (which is fine too, but that's one more thing to keep track of), we need to have the NVIDIA driver libraries on the head node.</p>\n<p>Fortunately, copying the relevant libraries from one of the compute nodes to the head node does the trick. Unfortunately, there's a bunch of them, together with a host of symbolic links.<br>\nHere's the simplest way I found to get everything in place (replace 384.90 by whatever driver version you have):</p>\n<h4>on a compute node</h4>\n<pre><code>tar cvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar --files-from /dev/null  # create an empty tar file so that we can add files to it\npushd /usr/lib/x86_64-linux-gnu/\nfor i in `ls *384.90`; do j=`echo $i | sed 's|.384.90||'`; tar rvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar ${j}*; done  # add all relevant files to the .tar\n</code></pre>\n<h4>on head node</h4>\n<pre><code>pushd /usr/lib/x86_64-linux-gnu/\nsudo tar xvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar\n</code></pre>\n<p>With this, we're now able to run tensorboard on the head node.</p>", "body_text": "I'm not sure I understand why this issue was marked as Closed.\nWe have exactly the same problem: we're on a multi-node slurm cluster where the head node does not have a GPU. In order to run tensorboard on the head node without having to use a separate tensorflow-cpu environment (which is fine too, but that's one more thing to keep track of), we need to have the NVIDIA driver libraries on the head node.\nFortunately, copying the relevant libraries from one of the compute nodes to the head node does the trick. Unfortunately, there's a bunch of them, together with a host of symbolic links.\nHere's the simplest way I found to get everything in place (replace 384.90 by whatever driver version you have):\non a compute node\ntar cvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar --files-from /dev/null  # create an empty tar file so that we can add files to it\npushd /usr/lib/x86_64-linux-gnu/\nfor i in `ls *384.90`; do j=`echo $i | sed 's|.384.90||'`; tar rvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar ${j}*; done  # add all relevant files to the .tar\n\non head node\npushd /usr/lib/x86_64-linux-gnu/\nsudo tar xvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar\n\nWith this, we're now able to run tensorboard on the head node.", "body": "I'm not sure I understand why this issue was marked as Closed. \r\nWe have exactly the same problem: we're on a multi-node slurm cluster where the head node does not have a GPU. In order to run tensorboard on the head node without having to use a separate tensorflow-cpu environment (which is fine too, but that's one more thing to keep track of), we need to have the NVIDIA driver libraries on the head node. \r\n\r\nFortunately, copying the relevant libraries from one of the compute nodes to the head node does the trick. Unfortunately, there's a bunch of them, together with a host of symbolic links. \r\nHere's the simplest way I found to get everything in place (replace 384.90 by whatever driver version you have):\r\n#### on a compute node\r\n```\r\ntar cvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar --files-from /dev/null  # create an empty tar file so that we can add files to it\r\npushd /usr/lib/x86_64-linux-gnu/\r\nfor i in `ls *384.90`; do j=`echo $i | sed 's|.384.90||'`; tar rvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar ${j}*; done  # add all relevant files to the .tar\r\n```\r\n#### on head node\r\n```\r\npushd /usr/lib/x86_64-linux-gnu/\r\nsudo tar xvf /path/to/folder/accessible/from/head/node/libs_nvidia384-90.tar\r\n```\r\nWith this, we're now able to run tensorboard on the head node. \r\n"}