{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13595", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13595/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13595/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13595/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13595", "id": 263991819, "node_id": "MDU6SXNzdWUyNjM5OTE4MTk=", "number": 13595, "title": "cifar-10-multi-gpu-train code isn't doing synchronization correctly?", "user": {"login": "heyucongtom", "id": 6735857, "node_id": "MDQ6VXNlcjY3MzU4NTc=", "avatar_url": "https://avatars0.githubusercontent.com/u/6735857?v=4", "gravatar_id": "", "url": "https://api.github.com/users/heyucongtom", "html_url": "https://github.com/heyucongtom", "followers_url": "https://api.github.com/users/heyucongtom/followers", "following_url": "https://api.github.com/users/heyucongtom/following{/other_user}", "gists_url": "https://api.github.com/users/heyucongtom/gists{/gist_id}", "starred_url": "https://api.github.com/users/heyucongtom/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/heyucongtom/subscriptions", "organizations_url": "https://api.github.com/users/heyucongtom/orgs", "repos_url": "https://api.github.com/users/heyucongtom/repos", "events_url": "https://api.github.com/users/heyucongtom/events{/privacy}", "received_events_url": "https://api.github.com/users/heyucongtom/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-10-09T18:48:53Z", "updated_at": "2017-10-09T22:32:09Z", "closed_at": "2017-10-09T22:32:08Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug or a feature request.</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: macOS Sierra 10.12.6</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>CUDA/cuDNN version</strong>:  irrelevant</li>\n<li><strong>GPU model and memory</strong>: irrelevant</li>\n<li><strong>Exact command to reproduce</strong>: irrelevant</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Recently I am trying to implement some new synchronization models, and during the research process I came across the cifar-10-multi-gpu-train code. It seems that on this line:<br>\n<a href=\"https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L196\">https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L196</a><br>\nThe synchronization point only collects gradients from each worker and do averaging. It doesn't provide a <strong>synchronization barrier</strong> as tf.train.SyncReplicaOptimizer does. In this way there may be some stale gradient exists. E.g on worker_1 it computes to local_step = 104, while on worker_2 it only computes to local_step = 91<br>\nPlease correct me if I am wrong here.</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug or a feature request.\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Sierra 10.12.6\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.3\nPython version: 3.5.2\nCUDA/cuDNN version:  irrelevant\nGPU model and memory: irrelevant\nExact command to reproduce: irrelevant\n\nDescribe the problem\nRecently I am trying to implement some new synchronization models, and during the research process I came across the cifar-10-multi-gpu-train code. It seems that on this line:\nhttps://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L196\nThe synchronization point only collects gradients from each worker and do averaging. It doesn't provide a synchronization barrier as tf.train.SyncReplicaOptimizer does. In this way there may be some stale gradient exists. E.g on worker_1 it computes to local_step = 104, while on worker_2 it only computes to local_step = 91\nPlease correct me if I am wrong here.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 3.5.2\r\n- **CUDA/cuDNN version**:  irrelevant\r\n- **GPU model and memory**: irrelevant\r\n- **Exact command to reproduce**: irrelevant\r\n\r\n### Describe the problem\r\nRecently I am trying to implement some new synchronization models, and during the research process I came across the cifar-10-multi-gpu-train code. It seems that on this line: \r\nhttps://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L196\r\nThe synchronization point only collects gradients from each worker and do averaging. It doesn't provide a **synchronization barrier** as tf.train.SyncReplicaOptimizer does. In this way there may be some stale gradient exists. E.g on worker_1 it computes to local_step = 104, while on worker_2 it only computes to local_step = 91\r\nPlease correct me if I am wrong here.\r\n"}