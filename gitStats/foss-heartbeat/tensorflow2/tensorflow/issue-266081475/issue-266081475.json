{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13779", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13779/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13779/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13779/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13779", "id": 266081475, "node_id": "MDU6SXNzdWUyNjYwODE0NzU=", "number": 13779, "title": "MonitoredSession.close() doesn't stop a thread when using SyncReplicasOptimizer hook", "user": {"login": "mjunyentb", "id": 23014354, "node_id": "MDQ6VXNlcjIzMDE0MzU0", "avatar_url": "https://avatars1.githubusercontent.com/u/23014354?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjunyentb", "html_url": "https://github.com/mjunyentb", "followers_url": "https://api.github.com/users/mjunyentb/followers", "following_url": "https://api.github.com/users/mjunyentb/following{/other_user}", "gists_url": "https://api.github.com/users/mjunyentb/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjunyentb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjunyentb/subscriptions", "organizations_url": "https://api.github.com/users/mjunyentb/orgs", "repos_url": "https://api.github.com/users/mjunyentb/repos", "events_url": "https://api.github.com/users/mjunyentb/events{/privacy}", "received_events_url": "https://api.github.com/users/mjunyentb/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "isaprykin", "id": 234070, "node_id": "MDQ6VXNlcjIzNDA3MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/234070?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isaprykin", "html_url": "https://github.com/isaprykin", "followers_url": "https://api.github.com/users/isaprykin/followers", "following_url": "https://api.github.com/users/isaprykin/following{/other_user}", "gists_url": "https://api.github.com/users/isaprykin/gists{/gist_id}", "starred_url": "https://api.github.com/users/isaprykin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isaprykin/subscriptions", "organizations_url": "https://api.github.com/users/isaprykin/orgs", "repos_url": "https://api.github.com/users/isaprykin/repos", "events_url": "https://api.github.com/users/isaprykin/events{/privacy}", "received_events_url": "https://api.github.com/users/isaprykin/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "isaprykin", "id": 234070, "node_id": "MDQ6VXNlcjIzNDA3MA==", "avatar_url": "https://avatars1.githubusercontent.com/u/234070?v=4", "gravatar_id": "", "url": "https://api.github.com/users/isaprykin", "html_url": "https://github.com/isaprykin", "followers_url": "https://api.github.com/users/isaprykin/followers", "following_url": "https://api.github.com/users/isaprykin/following{/other_user}", "gists_url": "https://api.github.com/users/isaprykin/gists{/gist_id}", "starred_url": "https://api.github.com/users/isaprykin/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/isaprykin/subscriptions", "organizations_url": "https://api.github.com/users/isaprykin/orgs", "repos_url": "https://api.github.com/users/isaprykin/repos", "events_url": "https://api.github.com/users/isaprykin/events{/privacy}", "received_events_url": "https://api.github.com/users/isaprykin/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2017-10-17T10:59:12Z", "updated_at": "2018-01-03T21:05:13Z", "closed_at": "2018-01-03T21:05:13Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>If using SyncReplicasOptimizer, the MonitoredSession is not able to stop a thread when calling session.close(). It will wait the whole \"stop_grace_period_secs\" and then close, reporting that a thread could not be stopped:  <code>INFO:tensorflow:Coordinator stopped with threads still running: Thread-5</code> (the thread number may vary).</p>\n<p>Here you can find the piece of code (reduced as much as possible) to reproduce it:</p>\n<h3>Source code</h3>\n<pre><code>import tensorflow as tf\nimport logging\nlogging.getLogger().setLevel(logging.INFO) #To see the message \"Coordinator stopped with threads still running\"\n\nopt = tf.train.RMSPropOptimizer(1.0)\nopt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=1, total_num_replicas=1)\nsync_hook = opt.make_session_run_hook(is_chief=True, num_tokens=0)\n\nglobal_step = tf.train.create_global_step() #global_step is necessary for SyncReplicasOptimizer\nvar = tf.Variable(0.0) #dummy variable and gradient\ngrad = tf.constant(1.0)\n\nopt.apply_gradients([(grad, var)], global_step = global_step)\n\nprint(\"CREATING SESSION\", flush=True)\nsess = tf.train.MonitoredSession(hooks = [sync_hook],\n                                 stop_grace_period_secs=10) #increasing this number will just make you wait more ;)\n\nprint(\"CLOSING... here's the problem!\", flush=True)\nsess.close()\n\nprint(\"DONE\", flush=True)\n</code></pre>\n<h3>Output</h3>\n<p>It hangs at sess.close() for \"stop_grace_period_secs\" (showing the message \"CLOSING...\")</p>\n<pre><code>INFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=1; total_num_replicas=1\nCREATING SESSION\nCLOSING... here's the problem!\nINFO:tensorflow:Coordinator stopped with threads still running: Thread-1\nDONE\n</code></pre>\n<p>Sometimes, I additionally get the following traceback (when calling it from ipython I always get it):</p>\n<pre><code>Traceback (most recent call last):\n  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n    self.run()\n  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 254, in _run\n    coord.request_stop(e)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 211, in request_stop\n    six.reraise(*sys.exc_info())\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.CancelledError: TakeGrad operation was cancelled\n         [[Node: sync_replicas/AccumulatorTakeGradient = AccumulatorTakeGradient[_class=[\"loc:@sync_replicas/conditional_accumulator\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](sync_replicas/conditional_accumulator, sync_replicas/AccumulatorTakeGradient/num_required)]]\n</code></pre>\n<p>After several runs of this same script I also got a segmentation fault, but only once.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.3\nPython version: 3.5.2\n\nDescribe the problem\nIf using SyncReplicasOptimizer, the MonitoredSession is not able to stop a thread when calling session.close(). It will wait the whole \"stop_grace_period_secs\" and then close, reporting that a thread could not be stopped:  INFO:tensorflow:Coordinator stopped with threads still running: Thread-5 (the thread number may vary).\nHere you can find the piece of code (reduced as much as possible) to reproduce it:\nSource code\nimport tensorflow as tf\nimport logging\nlogging.getLogger().setLevel(logging.INFO) #To see the message \"Coordinator stopped with threads still running\"\n\nopt = tf.train.RMSPropOptimizer(1.0)\nopt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=1, total_num_replicas=1)\nsync_hook = opt.make_session_run_hook(is_chief=True, num_tokens=0)\n\nglobal_step = tf.train.create_global_step() #global_step is necessary for SyncReplicasOptimizer\nvar = tf.Variable(0.0) #dummy variable and gradient\ngrad = tf.constant(1.0)\n\nopt.apply_gradients([(grad, var)], global_step = global_step)\n\nprint(\"CREATING SESSION\", flush=True)\nsess = tf.train.MonitoredSession(hooks = [sync_hook],\n                                 stop_grace_period_secs=10) #increasing this number will just make you wait more ;)\n\nprint(\"CLOSING... here's the problem!\", flush=True)\nsess.close()\n\nprint(\"DONE\", flush=True)\n\nOutput\nIt hangs at sess.close() for \"stop_grace_period_secs\" (showing the message \"CLOSING...\")\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=1; total_num_replicas=1\nCREATING SESSION\nCLOSING... here's the problem!\nINFO:tensorflow:Coordinator stopped with threads still running: Thread-1\nDONE\n\nSometimes, I additionally get the following traceback (when calling it from ipython I always get it):\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n    self.run()\n  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 254, in _run\n    coord.request_stop(e)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 211, in request_stop\n    six.reraise(*sys.exc_info())\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 693, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\n    enqueue_callable()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\n    target_list_as_strings, status, None)\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\n    next(self.gen)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.CancelledError: TakeGrad operation was cancelled\n         [[Node: sync_replicas/AccumulatorTakeGradient = AccumulatorTakeGradient[_class=[\"loc:@sync_replicas/conditional_accumulator\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](sync_replicas/conditional_accumulator, sync_replicas/AccumulatorTakeGradient/num_required)]]\n\nAfter several runs of this same script I also got a segmentation fault, but only once.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.3\r\n- **Python version**: 3.5.2\r\n\r\n### Describe the problem\r\nIf using SyncReplicasOptimizer, the MonitoredSession is not able to stop a thread when calling session.close(). It will wait the whole \"stop_grace_period_secs\" and then close, reporting that a thread could not be stopped:  `INFO:tensorflow:Coordinator stopped with threads still running: Thread-5` (the thread number may vary).\r\n\r\nHere you can find the piece of code (reduced as much as possible) to reproduce it:\r\n\r\n### Source code\r\n```\r\nimport tensorflow as tf\r\nimport logging\r\nlogging.getLogger().setLevel(logging.INFO) #To see the message \"Coordinator stopped with threads still running\"\r\n\r\nopt = tf.train.RMSPropOptimizer(1.0)\r\nopt = tf.train.SyncReplicasOptimizer(opt, replicas_to_aggregate=1, total_num_replicas=1)\r\nsync_hook = opt.make_session_run_hook(is_chief=True, num_tokens=0)\r\n\r\nglobal_step = tf.train.create_global_step() #global_step is necessary for SyncReplicasOptimizer\r\nvar = tf.Variable(0.0) #dummy variable and gradient\r\ngrad = tf.constant(1.0)\r\n\r\nopt.apply_gradients([(grad, var)], global_step = global_step)\r\n\r\nprint(\"CREATING SESSION\", flush=True)\r\nsess = tf.train.MonitoredSession(hooks = [sync_hook],\r\n                                 stop_grace_period_secs=10) #increasing this number will just make you wait more ;)\r\n\r\nprint(\"CLOSING... here's the problem!\", flush=True)\r\nsess.close()\r\n\r\nprint(\"DONE\", flush=True)\r\n```\r\n\r\n### Output\r\nIt hangs at sess.close() for \"stop_grace_period_secs\" (showing the message \"CLOSING...\") \r\n```\r\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=1; total_num_replicas=1\r\nCREATING SESSION\r\nCLOSING... here's the problem!\r\nINFO:tensorflow:Coordinator stopped with threads still running: Thread-1\r\nDONE\r\n```\r\n\r\nSometimes, I additionally get the following traceback (when calling it from ipython I always get it):\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.5/threading.py\", line 862, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 254, in _run\r\n    coord.request_stop(e)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 211, in request_stop\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.CancelledError: TakeGrad operation was cancelled\r\n         [[Node: sync_replicas/AccumulatorTakeGradient = AccumulatorTakeGradient[_class=[\"loc:@sync_replicas/conditional_accumulator\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](sync_replicas/conditional_accumulator, sync_replicas/AccumulatorTakeGradient/num_required)]]\r\n```\r\nAfter several runs of this same script I also got a segmentation fault, but only once."}