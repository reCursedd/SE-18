{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350412191", "html_url": "https://github.com/tensorflow/tensorflow/issues/14610#issuecomment-350412191", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14610", "id": 350412191, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDQxMjE5MQ==", "user": {"login": "jda91", "id": 34383622, "node_id": "MDQ6VXNlcjM0MzgzNjIy", "avatar_url": "https://avatars3.githubusercontent.com/u/34383622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jda91", "html_url": "https://github.com/jda91", "followers_url": "https://api.github.com/users/jda91/followers", "following_url": "https://api.github.com/users/jda91/following{/other_user}", "gists_url": "https://api.github.com/users/jda91/gists{/gist_id}", "starred_url": "https://api.github.com/users/jda91/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jda91/subscriptions", "organizations_url": "https://api.github.com/users/jda91/orgs", "repos_url": "https://api.github.com/users/jda91/repos", "events_url": "https://api.github.com/users/jda91/events{/privacy}", "received_events_url": "https://api.github.com/users/jda91/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-09T01:19:57Z", "updated_at": "2017-12-09T07:19:22Z", "author_association": "NONE", "body_html": "<p><strong><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=16071833\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gauravkaila\">@gauravkaila</a> hey, I tried compiling with that but I always get the same error when trying to test the running model, in fact I get the error trying to run anything in the container. I had to export the model myself by adding savedmodelbuilder code into the retrain script for inception. I pulled your image and am again running into the same error:</strong></p>\n<pre><code>root@42fd2c27af9d:/serving# bazel-bin/tensorflow_serving/example/inception_client --server=localhost:9000 --image=./Xiang_Xiang_panda.jpg\nTraceback (most recent call last):\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 56, in &lt;module&gt;\n    tf.app.run()\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 129, in run\n    _sys.exit(main(argv))\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 50, in main\n    tf.contrib.util.make_tensor_proto(data, shape=[1]))\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\n    module = self._load()\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 42, in _load\n    module = importlib.import_module(self.__name__)\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 81, in &lt;module&gt;\n    from tensorflow.contrib.eager.python import tfe as eager\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py\", line 75, in &lt;module&gt;\n    from tensorflow.contrib.eager.python.datasets import Iterator\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py\", line 23, in &lt;module&gt;\n    from tensorflow.contrib.data.python.ops import prefetching_ops\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py\", line 25, in &lt;module&gt;\n    resource_loader.get_path_to_datafile(\"../../_prefetching_ops.so\"))\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\n    ret = load_library.load_op_library(path)\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py\", line 56, in load_op_library\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.NotFoundError: /serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\n</code></pre>\n<p><strong>When I check the running log I can see that my model is running:</strong></p>\n<pre><code>\n2017-12-09 01:24:00.397485: I tensorflow_serving/model_servers/main.cc:147] Building single TensorFlow model file config:  model_name: inception model_base_path: /tmp/new5\n2017-12-09 01:24:00.397670: I tensorflow_serving/model_servers/server_core.cc:439] Adding/updating models.\n2017-12-09 01:24:00.397696: I tensorflow_serving/model_servers/server_core.cc:490]  (Re-)adding model: inception\n2017-12-09 01:24:00.498119: I tensorflow_serving/core/basic_manager.cc:705] Successfully reserved resources to load servable {name: inception version: 1}\n2017-12-09 01:24:00.498154: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: inception version: 1}\n2017-12-09 01:24:00.498169: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: inception version: 1}\n2017-12-09 01:24:00.498189: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /tmp/new5/1\n2017-12-09 01:24:00.498203: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:236] Loading SavedModel from: /tmp/new5/1\n2017-12-09 01:24:00.623487: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA\n2017-12-09 01:24:00.743901: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:155] Restoring SavedModel bundle.\n2017-12-09 01:24:00.798587: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running LegacyInitOp on SavedModel bundle.\n2017-12-09 01:24:00.805405: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: success. Took 307196 microseconds.\n2017-12-09 01:24:00.805517: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: inception version: 1}\n2017-12-09 01:24:00.810840: I tensorflow_serving/model_servers/main.cc:288] Running ModelServer at 0.0.0.0:9000 ...\n</code></pre>", "body_text": "@gauravkaila hey, I tried compiling with that but I always get the same error when trying to test the running model, in fact I get the error trying to run anything in the container. I had to export the model myself by adding savedmodelbuilder code into the retrain script for inception. I pulled your image and am again running into the same error:\nroot@42fd2c27af9d:/serving# bazel-bin/tensorflow_serving/example/inception_client --server=localhost:9000 --image=./Xiang_Xiang_panda.jpg\nTraceback (most recent call last):\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 56, in <module>\n    tf.app.run()\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 129, in run\n    _sys.exit(main(argv))\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 50, in main\n    tf.contrib.util.make_tensor_proto(data, shape=[1]))\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\n    module = self._load()\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 42, in _load\n    module = importlib.import_module(self.__name__)\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 81, in <module>\n    from tensorflow.contrib.eager.python import tfe as eager\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py\", line 75, in <module>\n    from tensorflow.contrib.eager.python.datasets import Iterator\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py\", line 23, in <module>\n    from tensorflow.contrib.data.python.ops import prefetching_ops\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py\", line 25, in <module>\n    resource_loader.get_path_to_datafile(\"../../_prefetching_ops.so\"))\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\n    ret = load_library.load_op_library(path)\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py\", line 56, in load_op_library\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.NotFoundError: /serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\n\nWhen I check the running log I can see that my model is running:\n\n2017-12-09 01:24:00.397485: I tensorflow_serving/model_servers/main.cc:147] Building single TensorFlow model file config:  model_name: inception model_base_path: /tmp/new5\n2017-12-09 01:24:00.397670: I tensorflow_serving/model_servers/server_core.cc:439] Adding/updating models.\n2017-12-09 01:24:00.397696: I tensorflow_serving/model_servers/server_core.cc:490]  (Re-)adding model: inception\n2017-12-09 01:24:00.498119: I tensorflow_serving/core/basic_manager.cc:705] Successfully reserved resources to load servable {name: inception version: 1}\n2017-12-09 01:24:00.498154: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: inception version: 1}\n2017-12-09 01:24:00.498169: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: inception version: 1}\n2017-12-09 01:24:00.498189: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /tmp/new5/1\n2017-12-09 01:24:00.498203: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:236] Loading SavedModel from: /tmp/new5/1\n2017-12-09 01:24:00.623487: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA\n2017-12-09 01:24:00.743901: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:155] Restoring SavedModel bundle.\n2017-12-09 01:24:00.798587: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running LegacyInitOp on SavedModel bundle.\n2017-12-09 01:24:00.805405: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: success. Took 307196 microseconds.\n2017-12-09 01:24:00.805517: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: inception version: 1}\n2017-12-09 01:24:00.810840: I tensorflow_serving/model_servers/main.cc:288] Running ModelServer at 0.0.0.0:9000 ...", "body": "**@gauravkaila hey, I tried compiling with that but I always get the same error when trying to test the running model, in fact I get the error trying to run anything in the container. I had to export the model myself by adding savedmodelbuilder code into the retrain script for inception. I pulled your image and am again running into the same error:**\r\n\r\n```\r\nroot@42fd2c27af9d:/serving# bazel-bin/tensorflow_serving/example/inception_client --server=localhost:9000 --image=./Xiang_Xiang_panda.jpg\r\nTraceback (most recent call last):\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 56, in <module>\r\n    tf.app.run()\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 129, in run\r\n    _sys.exit(main(argv))\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py\", line 50, in main\r\n    tf.contrib.util.make_tensor_proto(data, shape=[1]))\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 53, in __getattr__\r\n    module = self._load()\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/util/lazy_loader.py\", line 42, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/usr/lib/python2.7/importlib/__init__.py\", line 37, in import_module\r\n    __import__(name)\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 81, in <module>\r\n    from tensorflow.contrib.eager.python import tfe as eager\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py\", line 75, in <module>\r\n    from tensorflow.contrib.eager.python.datasets import Iterator\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py\", line 23, in <module>\r\n    from tensorflow.contrib.data.python.ops import prefetching_ops\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py\", line 25, in <module>\r\n    resource_loader.get_path_to_datafile(\"../../_prefetching_ops.so\"))\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py\", line 55, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py\", line 56, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\r\n  File \"/serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /serving/bazel-bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\n```\r\n\r\n\r\n**When I check the running log I can see that my model is running:**\r\n```\r\n\r\n2017-12-09 01:24:00.397485: I tensorflow_serving/model_servers/main.cc:147] Building single TensorFlow model file config:  model_name: inception model_base_path: /tmp/new5\r\n2017-12-09 01:24:00.397670: I tensorflow_serving/model_servers/server_core.cc:439] Adding/updating models.\r\n2017-12-09 01:24:00.397696: I tensorflow_serving/model_servers/server_core.cc:490]  (Re-)adding model: inception\r\n2017-12-09 01:24:00.498119: I tensorflow_serving/core/basic_manager.cc:705] Successfully reserved resources to load servable {name: inception version: 1}\r\n2017-12-09 01:24:00.498154: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: inception version: 1}\r\n2017-12-09 01:24:00.498169: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: inception version: 1}\r\n2017-12-09 01:24:00.498189: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /tmp/new5/1\r\n2017-12-09 01:24:00.498203: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:236] Loading SavedModel from: /tmp/new5/1\r\n2017-12-09 01:24:00.623487: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA\r\n2017-12-09 01:24:00.743901: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:155] Restoring SavedModel bundle.\r\n2017-12-09 01:24:00.798587: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running LegacyInitOp on SavedModel bundle.\r\n2017-12-09 01:24:00.805405: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: success. Took 307196 microseconds.\r\n2017-12-09 01:24:00.805517: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: inception version: 1}\r\n2017-12-09 01:24:00.810840: I tensorflow_serving/model_servers/main.cc:288] Running ModelServer at 0.0.0.0:9000 ...\r\n```"}