{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14093", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14093/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14093/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14093/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14093", "id": 269596673, "node_id": "MDU6SXNzdWUyNjk1OTY2NzM=", "number": 14093, "title": "Error: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE", "user": {"login": "MounirHader", "id": 15324040, "node_id": "MDQ6VXNlcjE1MzI0MDQw", "avatar_url": "https://avatars0.githubusercontent.com/u/15324040?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MounirHader", "html_url": "https://github.com/MounirHader", "followers_url": "https://api.github.com/users/MounirHader/followers", "following_url": "https://api.github.com/users/MounirHader/following{/other_user}", "gists_url": "https://api.github.com/users/MounirHader/gists{/gist_id}", "starred_url": "https://api.github.com/users/MounirHader/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MounirHader/subscriptions", "organizations_url": "https://api.github.com/users/MounirHader/orgs", "repos_url": "https://api.github.com/users/MounirHader/repos", "events_url": "https://api.github.com/users/MounirHader/events{/privacy}", "received_events_url": "https://api.github.com/users/MounirHader/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-10-30T13:20:15Z", "updated_at": "2018-10-22T01:36:46Z", "closed_at": "2017-10-30T15:01:59Z", "author_association": "NONE", "body_html": "<p>Hi, I am working on a remote machine with many GPU cards that has CUDA v8.0.61 and Cudnn 5.1.10 installed. Upgrading these is not possible because of permission rights. In my own environment I installed TensorFlow version 1.2.1, but I get the following error when launching a <code>Session()</code>:</p>\n<pre><code>import tensorflow as tf\nsess=tf.Session()\n2017-10-30 13:48:47.652605: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652665: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652680: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652694: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652708: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.930480: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1292, in __init__\n    super(Session, self).__init__(target, graph, config=config)\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 562, in __init__\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n  File \"/home/user/anaconda2/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.'\n</code></pre>\n<p>The output when calling <code>nvidia-smi</code> is</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |\n| N/A   52C    P0    61W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 0000:07:00.0     Off |                    0 |\n| N/A   40C    P0    76W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |\n| N/A   46C    P0    60W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           Off  | 0000:0B:00.0     Off |                    0 |\n| N/A   37C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   4  Tesla K80           Off  | 0000:10:00.0     Off |                    0 |\n| N/A   44C    P0    59W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   5  Tesla K80           Off  | 0000:11:00.0     Off |                    0 |\n| N/A   33C    P0    75W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   6  Tesla K80           Off  | 0000:14:00.0     Off |                    0 |\n| N/A   43C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   7  Tesla K80           Off  | 0000:15:00.0     Off |                    0 |\n| N/A   33C    P0    73W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   8  Tesla K80           Off  | 0000:87:00.0     Off |                    0 |\n| N/A   35C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   9  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |\n| N/A   31C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  10  Tesla K80           Off  | 0000:8B:00.0     Off |                    0 |\n| N/A   51C    P0   142W / 149W |   8361MiB / 11439MiB |    100%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  11  Tesla K80           Off  | 0000:8C:00.0     Off |                    0 |\n| N/A   31C    P0    86W / 149W |     86MiB / 11439MiB |     48%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  12  Tesla K80           Off  | 0000:91:00.0     Off |                    0 |\n| N/A   51C    P0   143W / 149W |   8330MiB / 11439MiB |     99%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  13  Tesla K80           Off  | 0000:92:00.0     Off |                    0 |\n| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  14  Tesla K80           Off  | 0000:95:00.0     Off |                    0 |\n| N/A   25C    P8    28W / 149W |      2MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  15  Tesla K80           Off  | 0000:96:00.0     Off |                    0 |\n| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n</code></pre>\n<p>Any ideas on the error <code>E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE</code>? Running <code>tf.Session()</code> multiple times results in the same error but will increase the number behind \"ordinal\".</p>", "body_text": "Hi, I am working on a remote machine with many GPU cards that has CUDA v8.0.61 and Cudnn 5.1.10 installed. Upgrading these is not possible because of permission rights. In my own environment I installed TensorFlow version 1.2.1, but I get the following error when launching a Session():\nimport tensorflow as tf\nsess=tf.Session()\n2017-10-30 13:48:47.652605: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652665: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652680: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652694: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.652708: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n2017-10-30 13:48:47.930480: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1292, in __init__\n    super(Session, self).__init__(target, graph, config=config)\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 562, in __init__\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\n  File \"/home/user/anaconda2/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.'\n\nThe output when calling nvidia-smi is\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |\n| N/A   52C    P0    61W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 0000:07:00.0     Off |                    0 |\n| N/A   40C    P0    76W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |\n| N/A   46C    P0    60W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           Off  | 0000:0B:00.0     Off |                    0 |\n| N/A   37C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   4  Tesla K80           Off  | 0000:10:00.0     Off |                    0 |\n| N/A   44C    P0    59W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   5  Tesla K80           Off  | 0000:11:00.0     Off |                    0 |\n| N/A   33C    P0    75W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   6  Tesla K80           Off  | 0000:14:00.0     Off |                    0 |\n| N/A   43C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   7  Tesla K80           Off  | 0000:15:00.0     Off |                    0 |\n| N/A   33C    P0    73W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   8  Tesla K80           Off  | 0000:87:00.0     Off |                    0 |\n| N/A   35C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|   9  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |\n| N/A   31C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  10  Tesla K80           Off  | 0000:8B:00.0     Off |                    0 |\n| N/A   51C    P0   142W / 149W |   8361MiB / 11439MiB |    100%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  11  Tesla K80           Off  | 0000:8C:00.0     Off |                    0 |\n| N/A   31C    P0    86W / 149W |     86MiB / 11439MiB |     48%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  12  Tesla K80           Off  | 0000:91:00.0     Off |                    0 |\n| N/A   51C    P0   143W / 149W |   8330MiB / 11439MiB |     99%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  13  Tesla K80           Off  | 0000:92:00.0     Off |                    0 |\n| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  14  Tesla K80           Off  | 0000:95:00.0     Off |                    0 |\n| N/A   25C    P8    28W / 149W |      2MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n|  15  Tesla K80           Off  | 0000:96:00.0     Off |                    0 |\n| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |\n+-------------------------------+----------------------+----------------------+\n\nAny ideas on the error E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE? Running tf.Session() multiple times results in the same error but will increase the number behind \"ordinal\".", "body": "Hi, I am working on a remote machine with many GPU cards that has CUDA v8.0.61 and Cudnn 5.1.10 installed. Upgrading these is not possible because of permission rights. In my own environment I installed TensorFlow version 1.2.1, but I get the following error when launching a `Session()`:\r\n\r\n```\r\nimport tensorflow as tf\r\nsess=tf.Session()\r\n2017-10-30 13:48:47.652605: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-10-30 13:48:47.652665: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-10-30 13:48:47.652680: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-10-30 13:48:47.652694: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-10-30 13:48:47.652708: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-10-30 13:48:47.930480: E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1292, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 562, in __init__\r\n    self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n  File \"/home/user/anaconda2/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InternalError: Failed to create session.'\r\n```\r\n\r\nThe output when calling `nvidia-smi` is\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |\r\n| N/A   52C    P0    61W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 0000:07:00.0     Off |                    0 |\r\n| N/A   40C    P0    76W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |\r\n| N/A   46C    P0    60W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           Off  | 0000:0B:00.0     Off |                    0 |\r\n| N/A   37C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla K80           Off  | 0000:10:00.0     Off |                    0 |\r\n| N/A   44C    P0    59W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla K80           Off  | 0000:11:00.0     Off |                    0 |\r\n| N/A   33C    P0    75W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  Tesla K80           Off  | 0000:14:00.0     Off |                    0 |\r\n| N/A   43C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  Tesla K80           Off  | 0000:15:00.0     Off |                    0 |\r\n| N/A   33C    P0    73W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   8  Tesla K80           Off  | 0000:87:00.0     Off |                    0 |\r\n| N/A   35C    P0    58W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|   9  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |\r\n| N/A   31C    P0    74W / 149W |     65MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|  10  Tesla K80           Off  | 0000:8B:00.0     Off |                    0 |\r\n| N/A   51C    P0   142W / 149W |   8361MiB / 11439MiB |    100%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|  11  Tesla K80           Off  | 0000:8C:00.0     Off |                    0 |\r\n| N/A   31C    P0    86W / 149W |     86MiB / 11439MiB |     48%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|  12  Tesla K80           Off  | 0000:91:00.0     Off |                    0 |\r\n| N/A   51C    P0   143W / 149W |   8330MiB / 11439MiB |     99%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|  13  Tesla K80           Off  | 0000:92:00.0     Off |                    0 |\r\n| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|  14  Tesla K80           Off  | 0000:95:00.0     Off |                    0 |\r\n| N/A   25C    P8    28W / 149W |      2MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n|  15  Tesla K80           Off  | 0000:96:00.0     Off |                    0 |\r\n| N/A   23C    P8    30W / 149W |      2MiB / 11439MiB |      0%   E. Process |\r\n+-------------------------------+----------------------+----------------------+\r\n```\r\n                                                                               \r\nAny ideas on the error `E tensorflow/core/common_runtime/direct_session.cc:138] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE`? Running `tf.Session()` multiple times results in the same error but will increase the number behind \"ordinal\".\r\n"}