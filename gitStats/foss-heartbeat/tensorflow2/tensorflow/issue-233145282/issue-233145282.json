{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10393", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10393/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10393/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10393/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10393", "id": 233145282, "node_id": "MDU6SXNzdWUyMzMxNDUyODI=", "number": 10393, "title": "I want read train or test data in next_batch by tf.cond", "user": {"login": "zhoulinyuan", "id": 7401519, "node_id": "MDQ6VXNlcjc0MDE1MTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/7401519?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhoulinyuan", "html_url": "https://github.com/zhoulinyuan", "followers_url": "https://api.github.com/users/zhoulinyuan/followers", "following_url": "https://api.github.com/users/zhoulinyuan/following{/other_user}", "gists_url": "https://api.github.com/users/zhoulinyuan/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhoulinyuan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhoulinyuan/subscriptions", "organizations_url": "https://api.github.com/users/zhoulinyuan/orgs", "repos_url": "https://api.github.com/users/zhoulinyuan/repos", "events_url": "https://api.github.com/users/zhoulinyuan/events{/privacy}", "received_events_url": "https://api.github.com/users/zhoulinyuan/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-06-02T10:44:42Z", "updated_at": "2017-06-24T19:45:48Z", "closed_at": "2017-06-02T23:24:36Z", "author_association": "NONE", "body_html": "<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nbatch_size = 4\nim_w = 32\nim_h = 32\nim_d = 3\nlabel_bytes = 1\nim_bytes = im_w*im_h*im_d\n\ndef next_path(data_dir, is_train, batch_size, shuffle):\n    # if is_train:\n    #     filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n    # else:\n    #     filenames = [os.path.join(data_dir, 'test_batch.bin')]\n\n    a = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\n    b = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\n    filenames = tf.cond(is_train, lambda: a, lambda: b)\n\n    # filenames = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\n    filenames_queue = tf.train.string_input_producer(filenames)\n    reader = tf.FixedLengthRecordReader(label_bytes+im_bytes)\n    key, value = reader.read(filenames_queue)\n    record_bytes = tf.decode_raw(value, tf.uint8)\n    label = tf.slice(record_bytes, [0], [label_bytes])\n    label = tf.cast(label, tf.int32)\n\n    im_raw = tf.slice(record_bytes, [label_bytes], [im_bytes])\n    im_raw = tf.reshape(im_raw, [im_d, im_h, im_w])\n    im = tf.transpose(im_raw, [1, 2, 0])\n    im = tf.cast(im, tf.float32)\n\n    # im = tf.image.per_image_standardization(im)\n    if shuffle:\n        images, labels = tf.train.shuffle_batch([im, label],\n                                                batch_size=batch_size,\n                                                capacity=1000,\n                                                num_threads=16,\n                                                min_after_dequeue=100)\n    else:\n        images, labels = tf.train.batch([im, label], batch_size=batch_size, capacity=1000, num_threads=16)\n\n    labels = tf.reshape(labels, [batch_size])\n\n    return images, labels\n\nis_train = tf.placeholder(tf.bool)\nimages, labels = next_path('cifar-10-batches-bin', is_train, batch_size, True)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    for step in range(1):\n        images_, _ = sess.run([images, labels], feed_dict={is_train:True})\n        plt.imshow(images_[0, :,:,:])\n        plt.show()\n\n    coord.request_stop()\n    coord.join(threads=threads)\n</code></pre>\n<pre><code>\na = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\nb = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\nfilenames = tf.cond(is_train, lambda: a, lambda: b)\n</code></pre>\n<p>this is error ,but below is ok, why and how to do<br>\n<code>filenames = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)</code></p>", "body_text": "import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nbatch_size = 4\nim_w = 32\nim_h = 32\nim_d = 3\nlabel_bytes = 1\nim_bytes = im_w*im_h*im_d\n\ndef next_path(data_dir, is_train, batch_size, shuffle):\n    # if is_train:\n    #     filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n    # else:\n    #     filenames = [os.path.join(data_dir, 'test_batch.bin')]\n\n    a = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\n    b = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\n    filenames = tf.cond(is_train, lambda: a, lambda: b)\n\n    # filenames = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\n    filenames_queue = tf.train.string_input_producer(filenames)\n    reader = tf.FixedLengthRecordReader(label_bytes+im_bytes)\n    key, value = reader.read(filenames_queue)\n    record_bytes = tf.decode_raw(value, tf.uint8)\n    label = tf.slice(record_bytes, [0], [label_bytes])\n    label = tf.cast(label, tf.int32)\n\n    im_raw = tf.slice(record_bytes, [label_bytes], [im_bytes])\n    im_raw = tf.reshape(im_raw, [im_d, im_h, im_w])\n    im = tf.transpose(im_raw, [1, 2, 0])\n    im = tf.cast(im, tf.float32)\n\n    # im = tf.image.per_image_standardization(im)\n    if shuffle:\n        images, labels = tf.train.shuffle_batch([im, label],\n                                                batch_size=batch_size,\n                                                capacity=1000,\n                                                num_threads=16,\n                                                min_after_dequeue=100)\n    else:\n        images, labels = tf.train.batch([im, label], batch_size=batch_size, capacity=1000, num_threads=16)\n\n    labels = tf.reshape(labels, [batch_size])\n\n    return images, labels\n\nis_train = tf.placeholder(tf.bool)\nimages, labels = next_path('cifar-10-batches-bin', is_train, batch_size, True)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    for step in range(1):\n        images_, _ = sess.run([images, labels], feed_dict={is_train:True})\n        plt.imshow(images_[0, :,:,:])\n        plt.show()\n\n    coord.request_stop()\n    coord.join(threads=threads)\n\n\na = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\nb = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\nfilenames = tf.cond(is_train, lambda: a, lambda: b)\n\nthis is error ,but below is ok, why and how to do\nfilenames = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)", "body": "```\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nbatch_size = 4\r\nim_w = 32\r\nim_h = 32\r\nim_d = 3\r\nlabel_bytes = 1\r\nim_bytes = im_w*im_h*im_d\r\n\r\ndef next_path(data_dir, is_train, batch_size, shuffle):\r\n    # if is_train:\r\n    #     filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)]\r\n    # else:\r\n    #     filenames = [os.path.join(data_dir, 'test_batch.bin')]\r\n\r\n    a = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\r\n    b = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\r\n    filenames = tf.cond(is_train, lambda: a, lambda: b)\r\n\r\n    # filenames = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\r\n    filenames_queue = tf.train.string_input_producer(filenames)\r\n    reader = tf.FixedLengthRecordReader(label_bytes+im_bytes)\r\n    key, value = reader.read(filenames_queue)\r\n    record_bytes = tf.decode_raw(value, tf.uint8)\r\n    label = tf.slice(record_bytes, [0], [label_bytes])\r\n    label = tf.cast(label, tf.int32)\r\n\r\n    im_raw = tf.slice(record_bytes, [label_bytes], [im_bytes])\r\n    im_raw = tf.reshape(im_raw, [im_d, im_h, im_w])\r\n    im = tf.transpose(im_raw, [1, 2, 0])\r\n    im = tf.cast(im, tf.float32)\r\n\r\n    # im = tf.image.per_image_standardization(im)\r\n    if shuffle:\r\n        images, labels = tf.train.shuffle_batch([im, label],\r\n                                                batch_size=batch_size,\r\n                                                capacity=1000,\r\n                                                num_threads=16,\r\n                                                min_after_dequeue=100)\r\n    else:\r\n        images, labels = tf.train.batch([im, label], batch_size=batch_size, capacity=1000, num_threads=16)\r\n\r\n    labels = tf.reshape(labels, [batch_size])\r\n\r\n    return images, labels\r\n\r\nis_train = tf.placeholder(tf.bool)\r\nimages, labels = next_path('cifar-10-batches-bin', is_train, batch_size, True)\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n    for step in range(1):\r\n        images_, _ = sess.run([images, labels], feed_dict={is_train:True})\r\n        plt.imshow(images_[0, :,:,:])\r\n        plt.show()\r\n\r\n    coord.request_stop()\r\n    coord.join(threads=threads)\r\n```\r\n```\r\n\r\na = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\r\nb = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\r\nfilenames = tf.cond(is_train, lambda: a, lambda: b)\r\n```\r\n    \r\nthis is error ,but below is ok, why and how to do\r\n   ` filenames = tf.cast([os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)], tf.string)\r\n`"}