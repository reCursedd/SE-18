{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282287511", "html_url": "https://github.com/tensorflow/tensorflow/issues/1736#issuecomment-282287511", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1736", "id": 282287511, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MjI4NzUxMQ==", "user": {"login": "carlthome", "id": 1595907, "node_id": "MDQ6VXNlcjE1OTU5MDc=", "avatar_url": "https://avatars3.githubusercontent.com/u/1595907?v=4", "gravatar_id": "", "url": "https://api.github.com/users/carlthome", "html_url": "https://github.com/carlthome", "followers_url": "https://api.github.com/users/carlthome/followers", "following_url": "https://api.github.com/users/carlthome/following{/other_user}", "gists_url": "https://api.github.com/users/carlthome/gists{/gist_id}", "starred_url": "https://api.github.com/users/carlthome/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/carlthome/subscriptions", "organizations_url": "https://api.github.com/users/carlthome/orgs", "repos_url": "https://api.github.com/users/carlthome/repos", "events_url": "https://api.github.com/users/carlthome/events{/privacy}", "received_events_url": "https://api.github.com/users/carlthome/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-24T13:11:01Z", "updated_at": "2017-02-24T13:12:24Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I believe one of the important points made in <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=206920\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cooijmanstim\">@cooijmanstim</a>'s paper is that you're supposed to collect mean/variances <strong>per timestep</strong> during training (to let the LSTM state stabilize properly at the start of a new sequence), and then in test time you step through them (and if a test sequence is longer, you just keep with the last mean/var for the remainder of the sequence). <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=324645\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/OlavHN\">@OlavHN</a>'s implementation doesn't do this, last I checked.</p>\n<p>I have a version that includes this in (but for ConvLSTMs, however it would be easy to copy+paste into FC-LSTMs): <a href=\"https://github.com/carlthome/tensorflow-convlstm-cell/blob/a647de6b86eff4c4bb502205d0ff9c1262869f19/ConvLSTMCell.py\">https://github.com/carlthome/tensorflow-convlstm-cell/blob/a647de6b86eff4c4bb502205d0ff9c1262869f19/ConvLSTMCell.py</a></p>", "body_text": "I believe one of the important points made in @cooijmanstim's paper is that you're supposed to collect mean/variances per timestep during training (to let the LSTM state stabilize properly at the start of a new sequence), and then in test time you step through them (and if a test sequence is longer, you just keep with the last mean/var for the remainder of the sequence). @OlavHN's implementation doesn't do this, last I checked.\nI have a version that includes this in (but for ConvLSTMs, however it would be easy to copy+paste into FC-LSTMs): https://github.com/carlthome/tensorflow-convlstm-cell/blob/a647de6b86eff4c4bb502205d0ff9c1262869f19/ConvLSTMCell.py", "body": "I believe one of the important points made in @cooijmanstim's paper is that you're supposed to collect mean/variances __per timestep__ during training (to let the LSTM state stabilize properly at the start of a new sequence), and then in test time you step through them (and if a test sequence is longer, you just keep with the last mean/var for the remainder of the sequence). @OlavHN's implementation doesn't do this, last I checked.\r\n\r\nI have a version that includes this in (but for ConvLSTMs, however it would be easy to copy+paste into FC-LSTMs): https://github.com/carlthome/tensorflow-convlstm-cell/blob/a647de6b86eff4c4bb502205d0ff9c1262869f19/ConvLSTMCell.py"}