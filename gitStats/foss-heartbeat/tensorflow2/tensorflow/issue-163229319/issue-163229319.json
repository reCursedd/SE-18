{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3128", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3128/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3128/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3128/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3128", "id": 163229319, "node_id": "MDU6SXNzdWUxNjMyMjkzMTk=", "number": 3128, "title": "conv3d_transpose -- Error in 'python': free(): invalid pointer", "user": {"login": "KendallWeihe", "id": 3602993, "node_id": "MDQ6VXNlcjM2MDI5OTM=", "avatar_url": "https://avatars3.githubusercontent.com/u/3602993?v=4", "gravatar_id": "", "url": "https://api.github.com/users/KendallWeihe", "html_url": "https://github.com/KendallWeihe", "followers_url": "https://api.github.com/users/KendallWeihe/followers", "following_url": "https://api.github.com/users/KendallWeihe/following{/other_user}", "gists_url": "https://api.github.com/users/KendallWeihe/gists{/gist_id}", "starred_url": "https://api.github.com/users/KendallWeihe/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/KendallWeihe/subscriptions", "organizations_url": "https://api.github.com/users/KendallWeihe/orgs", "repos_url": "https://api.github.com/users/KendallWeihe/repos", "events_url": "https://api.github.com/users/KendallWeihe/events{/privacy}", "received_events_url": "https://api.github.com/users/KendallWeihe/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "andydavis1", "id": 15696327, "node_id": "MDQ6VXNlcjE1Njk2MzI3", "avatar_url": "https://avatars0.githubusercontent.com/u/15696327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andydavis1", "html_url": "https://github.com/andydavis1", "followers_url": "https://api.github.com/users/andydavis1/followers", "following_url": "https://api.github.com/users/andydavis1/following{/other_user}", "gists_url": "https://api.github.com/users/andydavis1/gists{/gist_id}", "starred_url": "https://api.github.com/users/andydavis1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andydavis1/subscriptions", "organizations_url": "https://api.github.com/users/andydavis1/orgs", "repos_url": "https://api.github.com/users/andydavis1/repos", "events_url": "https://api.github.com/users/andydavis1/events{/privacy}", "received_events_url": "https://api.github.com/users/andydavis1/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andydavis1", "id": 15696327, "node_id": "MDQ6VXNlcjE1Njk2MzI3", "avatar_url": "https://avatars0.githubusercontent.com/u/15696327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andydavis1", "html_url": "https://github.com/andydavis1", "followers_url": "https://api.github.com/users/andydavis1/followers", "following_url": "https://api.github.com/users/andydavis1/following{/other_user}", "gists_url": "https://api.github.com/users/andydavis1/gists{/gist_id}", "starred_url": "https://api.github.com/users/andydavis1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andydavis1/subscriptions", "organizations_url": "https://api.github.com/users/andydavis1/orgs", "repos_url": "https://api.github.com/users/andydavis1/repos", "events_url": "https://api.github.com/users/andydavis1/events{/privacy}", "received_events_url": "https://api.github.com/users/andydavis1/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 14, "created_at": "2016-06-30T18:11:03Z", "updated_at": "2017-07-07T16:00:13Z", "closed_at": "2017-01-23T23:44:37Z", "author_association": "NONE", "body_html": "<p>I'm running into an issue with the recently added <code>conv3d_transpose</code> -- error statement in the title. The network builds, but upon first training session it outputs the above error, runs for a second, and then <code>Aborted (core dumped)</code>.  I have verified all dimensions and data.</p>\n<p>I wrote a simple convolutional-deconvolutional network to reproduce the bug. This small program actually outputs a different error than the network I am trying to build, but I believe it is pointing to the same issue.</p>\n<p>The error it is outputting is: <code>Error in 'python': double free or corruption (out):</code></p>\n<p>I have tried running the program on two different linux (Ubuntu 14) machines. I had to install Tensorflow from the nightly builds in order to include the <code>conv3d_transpose</code> source code. I want to try and run the program on my Mac, but there isn't a build out yet that includes the function.</p>\n<pre><code>#this is a small program to reproduce the bug\n    # Error in 'python': free(): invalid pointer:\n    # and\n    # Error in `python': double free or corruption (out):\n\n    #the network is designed for image segmentation\n        #input and outputs have the same dimensions\n\nimport tensorflow as tf\nimport numpy as np\nimport pdb\n\nlearning_rate = 0.001\n\nn_depth = 5\nn_input_x = 200\nn_input_y = 200\nn_classes = 2\nn_examples = 3\n\nx = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\n\n#generate random data\ninput_data = np.random.rand(n_examples, n_depth, n_input_x, n_input_y)\nlabel_data = np.random.rand(n_examples * n_depth * n_input_x * n_input_y, n_classes)\n\nweights = {\n    'l1': tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    'l2': tf.Variable(tf.random_normal([3, 2, 2, 2, 32]))\n}\n\nbiases = {\n    'l1': tf.Variable(tf.random_normal([32])),\n    'l2': tf.Variable(tf.random_normal([2]))\n}\n\n#build network\ndef conv(x, w, b):\n    #one convolutional layer followed by one deconvolutional layer\n    x = tf.reshape(x, shape=[-1, n_depth, n_input_x, n_input_y, 1])\n\n    conv1 = tf.nn.conv3d(x, weights['l1'], strides=[1,1,1,1,1], padding=\"SAME\")\n    conv1 = tf.nn.bias_add(conv1, biases['l1'])\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool3d(conv1, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding=\"SAME\")\n\n    output_shape = [n_examples, n_depth, n_input_x, n_input_y, n_classes]\n    deconv1 = tf.nn.conv3d_transpose(conv1, weights['l2'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n    deconv1 = tf.nn.bias_add(deconv1, biases['l2'])\n\n    return deconv1\n\npred = conv(x, weights, biases)\n\n#reshape for classification\ntemp_pred = tf.reshape(pred, [-1,n_classes])\ntemp_y = tf.reshape(y, [-1,n_classes])\n\n#define loss &amp; optimizer\ncost = tf.nn.softmax_cross_entropy_with_logits(temp_pred, temp_y)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ninit = tf.initialize_all_variables()\n\n#train\nwith tf.Session() as sess:\n    sess.run(init)\n    sess.run(optimizer, feed_dict={x: input_data, temp_y: label_data})\n\n</code></pre>", "body_text": "I'm running into an issue with the recently added conv3d_transpose -- error statement in the title. The network builds, but upon first training session it outputs the above error, runs for a second, and then Aborted (core dumped).  I have verified all dimensions and data.\nI wrote a simple convolutional-deconvolutional network to reproduce the bug. This small program actually outputs a different error than the network I am trying to build, but I believe it is pointing to the same issue.\nThe error it is outputting is: Error in 'python': double free or corruption (out):\nI have tried running the program on two different linux (Ubuntu 14) machines. I had to install Tensorflow from the nightly builds in order to include the conv3d_transpose source code. I want to try and run the program on my Mac, but there isn't a build out yet that includes the function.\n#this is a small program to reproduce the bug\n    # Error in 'python': free(): invalid pointer:\n    # and\n    # Error in `python': double free or corruption (out):\n\n    #the network is designed for image segmentation\n        #input and outputs have the same dimensions\n\nimport tensorflow as tf\nimport numpy as np\nimport pdb\n\nlearning_rate = 0.001\n\nn_depth = 5\nn_input_x = 200\nn_input_y = 200\nn_classes = 2\nn_examples = 3\n\nx = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\n\n#generate random data\ninput_data = np.random.rand(n_examples, n_depth, n_input_x, n_input_y)\nlabel_data = np.random.rand(n_examples * n_depth * n_input_x * n_input_y, n_classes)\n\nweights = {\n    'l1': tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    'l2': tf.Variable(tf.random_normal([3, 2, 2, 2, 32]))\n}\n\nbiases = {\n    'l1': tf.Variable(tf.random_normal([32])),\n    'l2': tf.Variable(tf.random_normal([2]))\n}\n\n#build network\ndef conv(x, w, b):\n    #one convolutional layer followed by one deconvolutional layer\n    x = tf.reshape(x, shape=[-1, n_depth, n_input_x, n_input_y, 1])\n\n    conv1 = tf.nn.conv3d(x, weights['l1'], strides=[1,1,1,1,1], padding=\"SAME\")\n    conv1 = tf.nn.bias_add(conv1, biases['l1'])\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool3d(conv1, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding=\"SAME\")\n\n    output_shape = [n_examples, n_depth, n_input_x, n_input_y, n_classes]\n    deconv1 = tf.nn.conv3d_transpose(conv1, weights['l2'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n    deconv1 = tf.nn.bias_add(deconv1, biases['l2'])\n\n    return deconv1\n\npred = conv(x, weights, biases)\n\n#reshape for classification\ntemp_pred = tf.reshape(pred, [-1,n_classes])\ntemp_y = tf.reshape(y, [-1,n_classes])\n\n#define loss & optimizer\ncost = tf.nn.softmax_cross_entropy_with_logits(temp_pred, temp_y)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ninit = tf.initialize_all_variables()\n\n#train\nwith tf.Session() as sess:\n    sess.run(init)\n    sess.run(optimizer, feed_dict={x: input_data, temp_y: label_data})", "body": "I'm running into an issue with the recently added `conv3d_transpose` -- error statement in the title. The network builds, but upon first training session it outputs the above error, runs for a second, and then `Aborted (core dumped)`.  I have verified all dimensions and data. \n\nI wrote a simple convolutional-deconvolutional network to reproduce the bug. This small program actually outputs a different error than the network I am trying to build, but I believe it is pointing to the same issue.\n\nThe error it is outputting is: `Error in 'python': double free or corruption (out):`\n\nI have tried running the program on two different linux (Ubuntu 14) machines. I had to install Tensorflow from the nightly builds in order to include the `conv3d_transpose` source code. I want to try and run the program on my Mac, but there isn't a build out yet that includes the function.\n\n```\n#this is a small program to reproduce the bug\n    # Error in 'python': free(): invalid pointer:\n    # and\n    # Error in `python': double free or corruption (out):\n\n    #the network is designed for image segmentation\n        #input and outputs have the same dimensions\n\nimport tensorflow as tf\nimport numpy as np\nimport pdb\n\nlearning_rate = 0.001\n\nn_depth = 5\nn_input_x = 200\nn_input_y = 200\nn_classes = 2\nn_examples = 3\n\nx = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y])\ny = tf.placeholder(tf.float32, [n_examples, n_depth, n_input_x, n_input_y, n_classes], name=\"ground_truth\")\n\n#generate random data\ninput_data = np.random.rand(n_examples, n_depth, n_input_x, n_input_y)\nlabel_data = np.random.rand(n_examples * n_depth * n_input_x * n_input_y, n_classes)\n\nweights = {\n    'l1': tf.Variable(tf.random_normal([5, 5, 5, 1, 32])),\n    'l2': tf.Variable(tf.random_normal([3, 2, 2, 2, 32]))\n}\n\nbiases = {\n    'l1': tf.Variable(tf.random_normal([32])),\n    'l2': tf.Variable(tf.random_normal([2]))\n}\n\n#build network\ndef conv(x, w, b):\n    #one convolutional layer followed by one deconvolutional layer\n    x = tf.reshape(x, shape=[-1, n_depth, n_input_x, n_input_y, 1])\n\n    conv1 = tf.nn.conv3d(x, weights['l1'], strides=[1,1,1,1,1], padding=\"SAME\")\n    conv1 = tf.nn.bias_add(conv1, biases['l1'])\n    conv1 = tf.nn.relu(conv1)\n    conv1 = tf.nn.max_pool3d(conv1, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding=\"SAME\")\n\n    output_shape = [n_examples, n_depth, n_input_x, n_input_y, n_classes]\n    deconv1 = tf.nn.conv3d_transpose(conv1, weights['l2'], output_shape=output_shape, strides=[1,1,2,2,1], padding=\"VALID\")\n    deconv1 = tf.nn.bias_add(deconv1, biases['l2'])\n\n    return deconv1\n\npred = conv(x, weights, biases)\n\n#reshape for classification\ntemp_pred = tf.reshape(pred, [-1,n_classes])\ntemp_y = tf.reshape(y, [-1,n_classes])\n\n#define loss & optimizer\ncost = tf.nn.softmax_cross_entropy_with_logits(temp_pred, temp_y)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\ninit = tf.initialize_all_variables()\n\n#train\nwith tf.Session() as sess:\n    sess.run(init)\n    sess.run(optimizer, feed_dict={x: input_data, temp_y: label_data})\n\n```\n"}