{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/439960905", "html_url": "https://github.com/tensorflow/tensorflow/issues/23766#issuecomment-439960905", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23766", "id": 439960905, "node_id": "MDEyOklzc3VlQ29tbWVudDQzOTk2MDkwNQ==", "user": {"login": "jdduke", "id": 479117, "node_id": "MDQ6VXNlcjQ3OTExNw==", "avatar_url": "https://avatars2.githubusercontent.com/u/479117?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jdduke", "html_url": "https://github.com/jdduke", "followers_url": "https://api.github.com/users/jdduke/followers", "following_url": "https://api.github.com/users/jdduke/following{/other_user}", "gists_url": "https://api.github.com/users/jdduke/gists{/gist_id}", "starred_url": "https://api.github.com/users/jdduke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jdduke/subscriptions", "organizations_url": "https://api.github.com/users/jdduke/orgs", "repos_url": "https://api.github.com/users/jdduke/repos", "events_url": "https://api.github.com/users/jdduke/events{/privacy}", "received_events_url": "https://api.github.com/users/jdduke/received_events", "type": "User", "site_admin": false}, "created_at": "2018-11-19T16:46:48Z", "updated_at": "2018-11-19T16:46:48Z", "author_association": "MEMBER", "body_html": "<p>We're working to add direct support for Float/Int/LongBuffer types. The problem with multi-dimensional arrays is that we can't perform a bulk copy from the output tensor to the output multi-dimensional array; we have to copy every single sub-array directly (e.g., if your output array is [1000][3], we have to perform a copy of length 3, 1000 times). <a href=\"https://developer.android.com/reference/java/nio/ByteBuffer#asFloatBuffer()\" rel=\"nofollow\">ByteBuffer#asFloatBuffer()</a> should be an extremely cheap operation, though, as it's just creating a new view of the same underlying buffer. In your case, since your buffer is [1][9216], then it should require just one copy, so I suspect the benefit from using ByteBuffer should be minimal.</p>\n<blockquote>\n<p>And also, if I run a network with multiple outputs can I just put the *Buffers in the output map to run the runForMultipleOutputs() method?</p>\n</blockquote>\n<p>Yep!</p>", "body_text": "We're working to add direct support for Float/Int/LongBuffer types. The problem with multi-dimensional arrays is that we can't perform a bulk copy from the output tensor to the output multi-dimensional array; we have to copy every single sub-array directly (e.g., if your output array is [1000][3], we have to perform a copy of length 3, 1000 times). ByteBuffer#asFloatBuffer() should be an extremely cheap operation, though, as it's just creating a new view of the same underlying buffer. In your case, since your buffer is [1][9216], then it should require just one copy, so I suspect the benefit from using ByteBuffer should be minimal.\n\nAnd also, if I run a network with multiple outputs can I just put the *Buffers in the output map to run the runForMultipleOutputs() method?\n\nYep!", "body": "We're working to add direct support for Float/Int/LongBuffer types. The problem with multi-dimensional arrays is that we can't perform a bulk copy from the output tensor to the output multi-dimensional array; we have to copy every single sub-array directly (e.g., if your output array is [1000][3], we have to perform a copy of length 3, 1000 times). [ByteBuffer#asFloatBuffer()](https://developer.android.com/reference/java/nio/ByteBuffer#asFloatBuffer()) should be an extremely cheap operation, though, as it's just creating a new view of the same underlying buffer. In your case, since your buffer is [1][9216], then it should require just one copy, so I suspect the benefit from using ByteBuffer should be minimal.\r\n\r\n> And also, if I run a network with multiple outputs can I just put the *Buffers in the output map to run the runForMultipleOutputs() method?\r\n\r\nYep!"}