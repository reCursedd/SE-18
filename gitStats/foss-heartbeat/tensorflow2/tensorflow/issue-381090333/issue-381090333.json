{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23766", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23766/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23766/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23766/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23766", "id": 381090333, "node_id": "MDU6SXNzdWUzODEwOTAzMzM=", "number": 23766, "title": "TfLite performance is way worse comapred to Tensorflow mobile", "user": {"login": "Noltibus", "id": 15614838, "node_id": "MDQ6VXNlcjE1NjE0ODM4", "avatar_url": "https://avatars3.githubusercontent.com/u/15614838?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Noltibus", "html_url": "https://github.com/Noltibus", "followers_url": "https://api.github.com/users/Noltibus/followers", "following_url": "https://api.github.com/users/Noltibus/following{/other_user}", "gists_url": "https://api.github.com/users/Noltibus/gists{/gist_id}", "starred_url": "https://api.github.com/users/Noltibus/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Noltibus/subscriptions", "organizations_url": "https://api.github.com/users/Noltibus/orgs", "repos_url": "https://api.github.com/users/Noltibus/repos", "events_url": "https://api.github.com/users/Noltibus/events{/privacy}", "received_events_url": "https://api.github.com/users/Noltibus/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "shashishekhar", "id": 1162712, "node_id": "MDQ6VXNlcjExNjI3MTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1162712?v=4", "gravatar_id": "", "url": "https://api.github.com/users/shashishekhar", "html_url": "https://github.com/shashishekhar", "followers_url": "https://api.github.com/users/shashishekhar/followers", "following_url": "https://api.github.com/users/shashishekhar/following{/other_user}", "gists_url": "https://api.github.com/users/shashishekhar/gists{/gist_id}", "starred_url": "https://api.github.com/users/shashishekhar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/shashishekhar/subscriptions", "organizations_url": "https://api.github.com/users/shashishekhar/orgs", "repos_url": "https://api.github.com/users/shashishekhar/repos", "events_url": "https://api.github.com/users/shashishekhar/events{/privacy}", "received_events_url": "https://api.github.com/users/shashishekhar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-11-15T10:14:53Z", "updated_at": "2018-11-22T06:57:18Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S8</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): On PC: current tf-nightly (14.11.2018), on phone current org.tensorflow:tensorflow-lite:0.0.0-nightly</li>\n<li>Python version: 3.6.6</li>\n<li>Bazel version (if compiling from source): -</li>\n<li>GCC/Compiler version (if compiling from source): -</li>\n<li>CUDA/cuDNN version: -</li>\n<li>GPU model and memory: CPU only</li>\n</ul>\n<p><strong>Describe the current behavior</strong><br>\nI build a model with this code:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.tools import freeze_graph\n\n\nclass AlexNet(object):\n    \"\"\"Implementation of the AlexNet.\"\"\"\n\n    def __init__(self, x, keep_prob, num_classes, skip_layer,\n                 weights_path='DEFAULT'):\n        \"\"\"Create the graph of the AlexNet model.\n        Args:\n            x: Placeholder for the input tensor.\n            keep_prob: Dropout probability.\n            num_classes: Number of classes in the dataset.\n            skip_layer: List of names of the layer, that get trained from\n                scratch\n            weights_path: Complete path to the pretrained weight file, if it\n                isn't in the same folder as this code\n        \"\"\"\n        # Parse input arguments into class variables\n        self.X = x\n        self.NUM_CLASSES = num_classes\n        self.KEEP_PROB = keep_prob\n        self.SKIP_LAYER = skip_layer\n\n        if weights_path == 'DEFAULT':\n            self.WEIGHTS_PATH = 'bvlc_alexnet.npy'\n        else:\n            self.WEIGHTS_PATH = weights_path\n\n        # Call the create function to build the computational graph of AlexNet\n        self.create()\n\n    def create(self):\n        \"\"\"Create the network graph.\"\"\"\n        # 1st Layer: Conv (w ReLu) -&gt; Lrn -&gt; Pool\n        conv1 = conv(self.X, 11, 11, 96, 4, 4, padding='VALID', name='conv1')\n        norm1 = lrn(conv1, 2, 2e-05, 0.75, name='norm1')\n        pool1 = max_pool(norm1, 3, 3, 2, 2, padding='VALID', name='pool1')\n\n        # 2nd Layer: Conv (w ReLu)  -&gt; Lrn -&gt; Pool with 2 groups\n        conv2 = conv(pool1, 5, 5, 256, 1, 1, groups=2, name='conv2')\n        norm2 = lrn(conv2, 2, 2e-05, 0.75, name='norm2')\n        pool2 = max_pool(norm2, 3, 3, 2, 2, padding='VALID', name='pool2')\n\n        # 3rd Layer: Conv (w ReLu)\n        self.conv3 = conv(pool2, 3, 3, 384, 1, 1, name='conv3')\n\n        # 4th Layer: Conv (w ReLu) splitted into two groups\n        conv4 = conv(self.conv3, 3, 3, 384, 1, 1, groups=2, name='conv4')\n\n        # 5th Layer: Conv (w ReLu) -&gt; Pool splitted into two groups\n        conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name='conv5')\n        self.pool5 = max_pool(conv5, 3, 3, 2, 2, padding='VALID', name='pool5')\n\n        # 6th Layer: Flatten -&gt; FC (w ReLu) -&gt; Dropout\n        self.flattened = tf.reshape(self.pool5, [1, 9216], name='output')\n\n    def load_initial_weights(self, session):\n        \"\"\"Load weights from file into network.\n        As the weights from http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\n        come as a dict of lists (e.g. weights['conv1'] is a list) and not as\n        dict of dicts (e.g. weights['conv1'] is a dict with keys 'weights' &amp;\n        'biases') we need a special load function\n        \"\"\"\n        # Load the weights into memory\n        weights_dict = np.load(self.WEIGHTS_PATH, encoding='bytes').item()\n\n        # Loop over all layer names stored in the weights dict\n        for op_name in weights_dict:\n\n            # Check if layer should be trained from scratch\n            if op_name not in self.SKIP_LAYER:\n\n                with tf.variable_scope(op_name, reuse=True):\n\n                    # Assign weights/biases to their corresponding tf variable\n                    for data in weights_dict[op_name]:\n\n                        # Biases\n                        if len(data.shape) == 1:\n                            var = tf.get_variable('biases', trainable=False)\n                            session.run(var.assign(data))\n\n                        # Weights\n                        else:\n                            var = tf.get_variable('weights', trainable=False)\n                            session.run(var.assign(data))\n\n\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,\n         padding='SAME', groups=1):\n    \"\"\"Create a convolution layer.\n    Adapted from: https://github.com/ethereon/caffe-tensorflow\n    \"\"\"\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n\n    # Create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k,\n                                         strides=[1, stride_y, stride_x, 1],\n                                         padding=padding)\n\n    with tf.variable_scope(name) as scope:\n        # Create tf variables for the weights and biases of the conv layer\n        weights = tf.get_variable('weights', shape=[filter_height,\n                                                    filter_width,\n                                                    input_channels/groups,\n                                                    num_filters])\n        biases = tf.get_variable('biases', shape=[num_filters])\n\n    if groups == 1:\n        conv = convolve(x, weights)\n\n    # In the cases of multiple groups, split inputs &amp; weights and\n    else:\n        # Split input and weights and convolve them separately\n        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n        weight_groups = tf.split(axis=3, num_or_size_splits=groups,\n                                 value=weights)\n        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n\n        # Concat the convolved output together again\n        conv = tf.concat(axis=3, values=output_groups)\n\n    # Add biases\n    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n\n    # Apply relu function\n    relu = tf.nn.relu(bias, name=scope.name)\n\n    return relu\n\n\ndef fc(x, num_in, num_out, name, relu=True):\n    \"\"\"Create a fully connected layer.\"\"\"\n    with tf.variable_scope(name) as scope:\n\n        # Create tf variables for the weights and biases\n        weights = tf.get_variable('weights', shape=[num_in, num_out],\n                                  trainable=True)\n        biases = tf.get_variable('biases', [num_out], trainable=True)\n\n        # Matrix multiply weights and inputs and add bias\n        act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)\n\n    if relu:\n        # Apply ReLu non linearity\n        relu = tf.nn.relu(act)\n        return relu\n    else:\n        return act\n\n\ndef max_pool(x, filter_height, filter_width, stride_y, stride_x, name,\n             padding='SAME'):\n    \"\"\"Create a max pooling layer.\"\"\"\n    return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],\n                          strides=[1, stride_y, stride_x, 1],\n                          padding=padding, name=name)\n\n\ndef lrn(x, radius, alpha, beta, name, bias=1.0):\n    \"\"\"Create a local response normalization layer.\"\"\"\n    return tf.nn.local_response_normalization(x, depth_radius=radius,\n                                              alpha=alpha, beta=beta,\n                                              bias=bias, name=name)\n\n\ndef dropout(x, keep_prob):\n    \"\"\"Create a dropout layer.\"\"\"\n    return tf.nn.dropout(x, keep_prob)\n\n\n\n\ng = tf.Graph()\nwith g.as_default():\n    # Initialize all variables\n    x = tf.placeholder(tf.float32, [1, 227, 227, 3])\n    y = tf.placeholder(tf.float32, [1, 1000])\n    keep_prob = tf.placeholder(tf.float32)\n    alex_net = AlexNet(x, keep_prob, 1000, [\"fc6\", \"fc7\", \"fc8\"])\n</code></pre>\n<p>Then I froze the model. In the first try I converted it to TFlite directly, in a second try I set the <code>converter.post_training_quantize = True</code> option in the conversion process to quantize my model and in a second try I optimized my model for inference before converting and quantizing.<br>\nThe code for the tflite conversion is the following:</p>\n<pre><code>import tensorflow as tf\n\ngraph_def_file = \"alex_frozen_optimized.pb\"\ninput_arrays = [\"Placeholder\"]\noutput_arrays = [\"output\"]\n\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\n    graph_def_file, input_arrays, output_arrays, input_shapes={\"Placeholder\" : [1, 227, 227, 3]})\nconverter.post_training_quantize = True\ntflite_model = converter.convert()\nopen(\"save_path/alex_frozen_optimized_quantized.tflite\", \"wb\").write(tflite_model)\n</code></pre>\n<p>The code for optimizing for inference was the following terminal call: <code>python -m tensorflow.python.tools.optimize_for_inference --input alex_frozen.pb --output alex_frozen_optimized.pb --input_names=Placeholder --output_names=output</code></p>\n<p>All my models, including the plain, unconverted model is uploaded here for testing: <a href=\"https://www.dropbox.com/s/gyu9cfkn3yn07oc/models.zip?dl=0\" rel=\"nofollow\">models.zip</a></p>\n<p><strong>Describe the expected behavior</strong><br>\nI deployed those models to my phone. I get runtime of around 290 ms for the unconverted model, while having runtimes of about 420 ms for the quantized tflite, the optimized and quantized tflite and the plain tflite model. That can't be right, can it?</p>\n<p><strong>Code to reproduce the issue</strong><br>\nThe code for running inference on the phone for the tflite models is the following:</p>\n<pre><code>import android.content.res.AssetFileDescriptor;\nimport android.content.res.AssetManager;\nimport android.graphics.Bitmap;\nimport android.os.Trace;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.nio.ByteOrder;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\nimport one.realnote.app.PpmItem;\nimport one.realnote.app.Util;\nimport org.tensorflow.lite.Interpreter;\nimport org.tensorflow.lite.Interpreter.Options;\n\npublic class AlexFeatureExtractionLite {\n\n  private static final String TAG = \"TFLiteAPIAlex\";\n\n  // Only return this many results.\n  private boolean isModelQuantized;\n  // Float model\n  // Number of threads in the java app\n  private static final int NUM_THREADS = 4;\n  // Config values.\n  private int inputSize;\n  // Pre-allocated buffers.\n  private float[][] outputVector;\n  private int[] intValues;\n\n  private static PpmItem ppm_tfRun = PpmItem.createDebugItem(\"TFA\", \"runAlex\", String.class);\n\n  private ByteBuffer imgData;\n  private Interpreter tfLite;\n\n  /**\n   * Memory-map the model file in Assets.\n   */\n  private static MappedByteBuffer loadModelFile(AssetManager assets)\n      throws IOException {\n    AssetFileDescriptor fileDescriptor = assets.openFd(\"tf/alex_frozen_optimized_quantized.tflite\");\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\n    FileChannel fileChannel = inputStream.getChannel();\n    long startOffset = fileDescriptor.getStartOffset();\n    long declaredLength = fileDescriptor.getDeclaredLength();\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\n  }\n\n  /**\n   * Initializes a native TensorFlow session for classifying images.\n   *\n   * @param assetManager The asset manager to be used to load assets.\n   * @param inputSize The size of image input\n   * @param isQuantized Boolean representing model is quantized or not\n   */\n  public static AlexFeatureExtractionLite create(final AssetManager assetManager,\n      final int inputSize, final boolean isQuantized) {\n    final AlexFeatureExtractionLite d = new AlexFeatureExtractionLite();\n\n    d.inputSize = inputSize;\n    Interpreter.Options options = new Options();\n    options.setUseNNAPI(false);\n    options.setAllowFp16PrecisionForFp32(false);\n    options.setNumThreads(4);\n    try {\n      d.tfLite = new Interpreter(loadModelFile(assetManager), options);\n    } catch (Exception e) {\n      Util.logError(e);\n      throw new RuntimeException(e);\n    }\n\n    d.isModelQuantized = isQuantized;\n    // Pre-allocate buffers.\n    int numBytesPerChannel;\n    if (isQuantized) {\n      numBytesPerChannel = 1; // Quantized\n    } else {\n      numBytesPerChannel = 4; // Floating point\n    }\n    d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\n    d.imgData.order(ByteOrder.nativeOrder());\n    d.intValues = new int[d.inputSize * d.inputSize];\n    d.outputVector = new float[1][9216];\n\n    //d.tfLite.setNumThreads(NUM_THREADS);\n    return d;\n  }\n\n  private AlexFeatureExtractionLite() {\n  }\n\n\n  public float[] calcFeatureVector(final Bitmap bitmap) {\n    // Log this method so that it can be analyzed with systrace.\n    Trace.beginSection(\"recognizeImage\");\n\n    Trace.beginSection(\"preprocessBitmap\");\n    // Preprocess the image data from 0-255 int to normalized float based\n    // on the provided parameters.\n    bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\n\n    imgData.rewind();\n    for (int i = 0; i &lt; inputSize; ++i) {\n      for (int j = 0; j &lt; inputSize; ++j) {\n        int pixelValue = intValues[i * inputSize + j];\n        if (isModelQuantized) {\n          // Quantized model\n          imgData.put((byte) ((pixelValue &gt;&gt; 16) &amp; 0xFF));\n          imgData.put((byte) ((pixelValue &gt;&gt; 8) &amp; 0xFF));\n          imgData.put((byte) (pixelValue &amp; 0xFF));\n        } else { // Float model\n          imgData.putFloat((((pixelValue &gt;&gt; 16) &amp; 0xFF) - 104f));\n          imgData.putFloat((((pixelValue &gt;&gt; 8) &amp; 0xFF) - 117f));\n          imgData.putFloat(((pixelValue &amp; 0xFF) - 124f));\n        }\n      }\n    }\n    Trace.endSection(); // preprocessBitmap\n\n    // Copy the input data into TensorFlow.\n    Trace.beginSection(\"feed\");\n    outputVector = new float[1][9216];\n\n    Trace.endSection();\n\n    // Run the inference call.\n    Trace.beginSection(\"run\");\n    ppm_tfRun.start();\n    tfLite.run(imgData, outputVector);\n    ppm_tfRun.stop();\n    Trace.endSection();\n\n    Trace.endSection(); // \"recognizeImage\"\n    return outputVector[0];\n  }\n}\n</code></pre>\n<p>The code to run inference for the unconverted model is:</p>\n<pre><code>import android.content.res.AssetManager;\nimport android.graphics.Bitmap;\nimport android.os.Trace;\nimport one.realnote.app.PpmItem;\nimport org.tensorflow.Graph;\nimport org.tensorflow.Operation;\nimport org.tensorflow.contrib.android.TensorFlowInferenceInterface;\n\npublic class AlexFeatureExtraction {\n\n    private static final String TAG = \"AlexFeatureExtraction\";\n\n    // Config values.\n    private String inputName;\n    private int inputSize;\n\n    // Pre-allocated buffers.\n    private float[] outputVector;\n\n    private int[] intValues;\n    private float[] floatValues;\n\n    private TensorFlowInferenceInterface inferenceInterface;\n\n    public static AlexFeatureExtraction create(\n        final AssetManager assetManager) {\n\n        final AlexFeatureExtraction d = new AlexFeatureExtraction();\n\n\n        final String modelFilename = \"file:///android_asset/tf/alex.pb\";\n        final int inputSize = 227;\n\n        d.inferenceInterface = new TensorFlowInferenceInterface(assetManager, modelFilename);\n\n        final Graph g = d.inferenceInterface.graph();\n\n        d.inputName = \"Placeholder\"; // ssd: \"image_tensor\";\n\n        // The inputName node has a shape of [N, H, W, C], where\n        // N is the batch size\n        // H = W are the height and width\n        // C is the number of channels (3 for our purposes - RGB)\n        final Operation inputOp = g.operation(d.inputName);\n        if (inputOp == null) {\n            throw new RuntimeException(\"Failed to find input Node '\" + d.inputName + \"'\");\n        }\n        d.inputSize = inputSize;\n        // The outputScoresName node has a shape of [N, NumLocations], where N\n        // is the batch size.\n\n        // ssd: final Operation outputOp1 = g.operation(\"detection_scores\");\n        final Operation outputOp1 = g.operation(\"output\");\n        if (outputOp1 == null) {\n            throw new RuntimeException(\"Failed to find output Node 'detection_scores'\");\n        }\n\n        // Pre-allocate buffers.\n        d.outputVector = new float[9216];\n\n        d.intValues = new int[d.inputSize * d.inputSize];\n        d.floatValues = new float[d.inputSize * d.inputSize * 3];\n\n        return d;\n    }\n\n\n    private AlexFeatureExtraction() {\n    }\n\n\n    private static PpmItem ppm_tfFeed = PpmItem.createDebugItem(\"TFA\", \"feed\", String.class);\n    private static PpmItem ppm_tfRun = PpmItem.createDebugItem(\"TFA\", \"runAlex\", String.class);\n\n\n    public float[] calcFeatureVector(final Bitmap bitmap) {\n        // Log this method so that it can be analyzed with systrace.\n        Trace.beginSection(\"recognizeImage\");\n\n        Trace.beginSection(\"preprocessBitmap\");\n        // Preprocess the image data from 0-255 int to normalized float based\n        // on the provided parameters.\n        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\n\n        for (int i = 0; i &lt; intValues.length; ++i) {\n            floatValues[i * 3 + 2] = (float) (intValues[i] &amp; 0xFF) - 124f;\n            floatValues[i * 3 + 1] = (float) ((intValues[i] &gt;&gt; 8) &amp; 0xFF) - 117f;\n            floatValues[i * 3 + 0] = (float) ((intValues[i] &gt;&gt; 16) &amp; 0xFF) -104f;\n        }\n\n        Trace.endSection(); // preprocessBitmap\n\n        // Copy the input data into TensorFlow.\n        Trace.beginSection(\"feed\");\n        ppm_tfFeed.start();\n        inferenceInterface.feed(inputName, floatValues, 1, inputSize, inputSize, 3);\n        ppm_tfFeed.stop();\n        Trace.endSection();\n\n        // Run the inference call.\n        Trace.beginSection(\"run\");\n        ppm_tfRun.start();\n        inferenceInterface.run(new String[]{\"output\"}, false);\n        ppm_tfRun.stop();\n        Trace.endSection();\n\n        // Copy the output Tensor back into the output array.\n        Trace.beginSection(\"fetch\");\n\n\n        inferenceInterface.fetch(\"output\", outputVector);\n\n        Trace.endSection();\n\n        Trace.endSection(); // \"recognizeImage\"\n\n        return outputVector;\n    }\n\n    public void close() {\n        inferenceInterface.close();\n    }\n}\n</code></pre>\n<p><strong>Other info / logs</strong><br>\nOutput behavior is as expected for all models. Activating the useNNAPI option doesn't really do anything performance wise aswell as setting the number of threads.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S8\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): On PC: current tf-nightly (14.11.2018), on phone current org.tensorflow:tensorflow-lite:0.0.0-nightly\nPython version: 3.6.6\nBazel version (if compiling from source): -\nGCC/Compiler version (if compiling from source): -\nCUDA/cuDNN version: -\nGPU model and memory: CPU only\n\nDescribe the current behavior\nI build a model with this code:\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.tools import freeze_graph\n\n\nclass AlexNet(object):\n    \"\"\"Implementation of the AlexNet.\"\"\"\n\n    def __init__(self, x, keep_prob, num_classes, skip_layer,\n                 weights_path='DEFAULT'):\n        \"\"\"Create the graph of the AlexNet model.\n        Args:\n            x: Placeholder for the input tensor.\n            keep_prob: Dropout probability.\n            num_classes: Number of classes in the dataset.\n            skip_layer: List of names of the layer, that get trained from\n                scratch\n            weights_path: Complete path to the pretrained weight file, if it\n                isn't in the same folder as this code\n        \"\"\"\n        # Parse input arguments into class variables\n        self.X = x\n        self.NUM_CLASSES = num_classes\n        self.KEEP_PROB = keep_prob\n        self.SKIP_LAYER = skip_layer\n\n        if weights_path == 'DEFAULT':\n            self.WEIGHTS_PATH = 'bvlc_alexnet.npy'\n        else:\n            self.WEIGHTS_PATH = weights_path\n\n        # Call the create function to build the computational graph of AlexNet\n        self.create()\n\n    def create(self):\n        \"\"\"Create the network graph.\"\"\"\n        # 1st Layer: Conv (w ReLu) -> Lrn -> Pool\n        conv1 = conv(self.X, 11, 11, 96, 4, 4, padding='VALID', name='conv1')\n        norm1 = lrn(conv1, 2, 2e-05, 0.75, name='norm1')\n        pool1 = max_pool(norm1, 3, 3, 2, 2, padding='VALID', name='pool1')\n\n        # 2nd Layer: Conv (w ReLu)  -> Lrn -> Pool with 2 groups\n        conv2 = conv(pool1, 5, 5, 256, 1, 1, groups=2, name='conv2')\n        norm2 = lrn(conv2, 2, 2e-05, 0.75, name='norm2')\n        pool2 = max_pool(norm2, 3, 3, 2, 2, padding='VALID', name='pool2')\n\n        # 3rd Layer: Conv (w ReLu)\n        self.conv3 = conv(pool2, 3, 3, 384, 1, 1, name='conv3')\n\n        # 4th Layer: Conv (w ReLu) splitted into two groups\n        conv4 = conv(self.conv3, 3, 3, 384, 1, 1, groups=2, name='conv4')\n\n        # 5th Layer: Conv (w ReLu) -> Pool splitted into two groups\n        conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name='conv5')\n        self.pool5 = max_pool(conv5, 3, 3, 2, 2, padding='VALID', name='pool5')\n\n        # 6th Layer: Flatten -> FC (w ReLu) -> Dropout\n        self.flattened = tf.reshape(self.pool5, [1, 9216], name='output')\n\n    def load_initial_weights(self, session):\n        \"\"\"Load weights from file into network.\n        As the weights from http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\n        come as a dict of lists (e.g. weights['conv1'] is a list) and not as\n        dict of dicts (e.g. weights['conv1'] is a dict with keys 'weights' &\n        'biases') we need a special load function\n        \"\"\"\n        # Load the weights into memory\n        weights_dict = np.load(self.WEIGHTS_PATH, encoding='bytes').item()\n\n        # Loop over all layer names stored in the weights dict\n        for op_name in weights_dict:\n\n            # Check if layer should be trained from scratch\n            if op_name not in self.SKIP_LAYER:\n\n                with tf.variable_scope(op_name, reuse=True):\n\n                    # Assign weights/biases to their corresponding tf variable\n                    for data in weights_dict[op_name]:\n\n                        # Biases\n                        if len(data.shape) == 1:\n                            var = tf.get_variable('biases', trainable=False)\n                            session.run(var.assign(data))\n\n                        # Weights\n                        else:\n                            var = tf.get_variable('weights', trainable=False)\n                            session.run(var.assign(data))\n\n\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,\n         padding='SAME', groups=1):\n    \"\"\"Create a convolution layer.\n    Adapted from: https://github.com/ethereon/caffe-tensorflow\n    \"\"\"\n    # Get number of input channels\n    input_channels = int(x.get_shape()[-1])\n\n    # Create lambda function for the convolution\n    convolve = lambda i, k: tf.nn.conv2d(i, k,\n                                         strides=[1, stride_y, stride_x, 1],\n                                         padding=padding)\n\n    with tf.variable_scope(name) as scope:\n        # Create tf variables for the weights and biases of the conv layer\n        weights = tf.get_variable('weights', shape=[filter_height,\n                                                    filter_width,\n                                                    input_channels/groups,\n                                                    num_filters])\n        biases = tf.get_variable('biases', shape=[num_filters])\n\n    if groups == 1:\n        conv = convolve(x, weights)\n\n    # In the cases of multiple groups, split inputs & weights and\n    else:\n        # Split input and weights and convolve them separately\n        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n        weight_groups = tf.split(axis=3, num_or_size_splits=groups,\n                                 value=weights)\n        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n\n        # Concat the convolved output together again\n        conv = tf.concat(axis=3, values=output_groups)\n\n    # Add biases\n    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n\n    # Apply relu function\n    relu = tf.nn.relu(bias, name=scope.name)\n\n    return relu\n\n\ndef fc(x, num_in, num_out, name, relu=True):\n    \"\"\"Create a fully connected layer.\"\"\"\n    with tf.variable_scope(name) as scope:\n\n        # Create tf variables for the weights and biases\n        weights = tf.get_variable('weights', shape=[num_in, num_out],\n                                  trainable=True)\n        biases = tf.get_variable('biases', [num_out], trainable=True)\n\n        # Matrix multiply weights and inputs and add bias\n        act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)\n\n    if relu:\n        # Apply ReLu non linearity\n        relu = tf.nn.relu(act)\n        return relu\n    else:\n        return act\n\n\ndef max_pool(x, filter_height, filter_width, stride_y, stride_x, name,\n             padding='SAME'):\n    \"\"\"Create a max pooling layer.\"\"\"\n    return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],\n                          strides=[1, stride_y, stride_x, 1],\n                          padding=padding, name=name)\n\n\ndef lrn(x, radius, alpha, beta, name, bias=1.0):\n    \"\"\"Create a local response normalization layer.\"\"\"\n    return tf.nn.local_response_normalization(x, depth_radius=radius,\n                                              alpha=alpha, beta=beta,\n                                              bias=bias, name=name)\n\n\ndef dropout(x, keep_prob):\n    \"\"\"Create a dropout layer.\"\"\"\n    return tf.nn.dropout(x, keep_prob)\n\n\n\n\ng = tf.Graph()\nwith g.as_default():\n    # Initialize all variables\n    x = tf.placeholder(tf.float32, [1, 227, 227, 3])\n    y = tf.placeholder(tf.float32, [1, 1000])\n    keep_prob = tf.placeholder(tf.float32)\n    alex_net = AlexNet(x, keep_prob, 1000, [\"fc6\", \"fc7\", \"fc8\"])\n\nThen I froze the model. In the first try I converted it to TFlite directly, in a second try I set the converter.post_training_quantize = True option in the conversion process to quantize my model and in a second try I optimized my model for inference before converting and quantizing.\nThe code for the tflite conversion is the following:\nimport tensorflow as tf\n\ngraph_def_file = \"alex_frozen_optimized.pb\"\ninput_arrays = [\"Placeholder\"]\noutput_arrays = [\"output\"]\n\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\n    graph_def_file, input_arrays, output_arrays, input_shapes={\"Placeholder\" : [1, 227, 227, 3]})\nconverter.post_training_quantize = True\ntflite_model = converter.convert()\nopen(\"save_path/alex_frozen_optimized_quantized.tflite\", \"wb\").write(tflite_model)\n\nThe code for optimizing for inference was the following terminal call: python -m tensorflow.python.tools.optimize_for_inference --input alex_frozen.pb --output alex_frozen_optimized.pb --input_names=Placeholder --output_names=output\nAll my models, including the plain, unconverted model is uploaded here for testing: models.zip\nDescribe the expected behavior\nI deployed those models to my phone. I get runtime of around 290 ms for the unconverted model, while having runtimes of about 420 ms for the quantized tflite, the optimized and quantized tflite and the plain tflite model. That can't be right, can it?\nCode to reproduce the issue\nThe code for running inference on the phone for the tflite models is the following:\nimport android.content.res.AssetFileDescriptor;\nimport android.content.res.AssetManager;\nimport android.graphics.Bitmap;\nimport android.os.Trace;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.nio.ByteOrder;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\nimport one.realnote.app.PpmItem;\nimport one.realnote.app.Util;\nimport org.tensorflow.lite.Interpreter;\nimport org.tensorflow.lite.Interpreter.Options;\n\npublic class AlexFeatureExtractionLite {\n\n  private static final String TAG = \"TFLiteAPIAlex\";\n\n  // Only return this many results.\n  private boolean isModelQuantized;\n  // Float model\n  // Number of threads in the java app\n  private static final int NUM_THREADS = 4;\n  // Config values.\n  private int inputSize;\n  // Pre-allocated buffers.\n  private float[][] outputVector;\n  private int[] intValues;\n\n  private static PpmItem ppm_tfRun = PpmItem.createDebugItem(\"TFA\", \"runAlex\", String.class);\n\n  private ByteBuffer imgData;\n  private Interpreter tfLite;\n\n  /**\n   * Memory-map the model file in Assets.\n   */\n  private static MappedByteBuffer loadModelFile(AssetManager assets)\n      throws IOException {\n    AssetFileDescriptor fileDescriptor = assets.openFd(\"tf/alex_frozen_optimized_quantized.tflite\");\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\n    FileChannel fileChannel = inputStream.getChannel();\n    long startOffset = fileDescriptor.getStartOffset();\n    long declaredLength = fileDescriptor.getDeclaredLength();\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\n  }\n\n  /**\n   * Initializes a native TensorFlow session for classifying images.\n   *\n   * @param assetManager The asset manager to be used to load assets.\n   * @param inputSize The size of image input\n   * @param isQuantized Boolean representing model is quantized or not\n   */\n  public static AlexFeatureExtractionLite create(final AssetManager assetManager,\n      final int inputSize, final boolean isQuantized) {\n    final AlexFeatureExtractionLite d = new AlexFeatureExtractionLite();\n\n    d.inputSize = inputSize;\n    Interpreter.Options options = new Options();\n    options.setUseNNAPI(false);\n    options.setAllowFp16PrecisionForFp32(false);\n    options.setNumThreads(4);\n    try {\n      d.tfLite = new Interpreter(loadModelFile(assetManager), options);\n    } catch (Exception e) {\n      Util.logError(e);\n      throw new RuntimeException(e);\n    }\n\n    d.isModelQuantized = isQuantized;\n    // Pre-allocate buffers.\n    int numBytesPerChannel;\n    if (isQuantized) {\n      numBytesPerChannel = 1; // Quantized\n    } else {\n      numBytesPerChannel = 4; // Floating point\n    }\n    d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\n    d.imgData.order(ByteOrder.nativeOrder());\n    d.intValues = new int[d.inputSize * d.inputSize];\n    d.outputVector = new float[1][9216];\n\n    //d.tfLite.setNumThreads(NUM_THREADS);\n    return d;\n  }\n\n  private AlexFeatureExtractionLite() {\n  }\n\n\n  public float[] calcFeatureVector(final Bitmap bitmap) {\n    // Log this method so that it can be analyzed with systrace.\n    Trace.beginSection(\"recognizeImage\");\n\n    Trace.beginSection(\"preprocessBitmap\");\n    // Preprocess the image data from 0-255 int to normalized float based\n    // on the provided parameters.\n    bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\n\n    imgData.rewind();\n    for (int i = 0; i < inputSize; ++i) {\n      for (int j = 0; j < inputSize; ++j) {\n        int pixelValue = intValues[i * inputSize + j];\n        if (isModelQuantized) {\n          // Quantized model\n          imgData.put((byte) ((pixelValue >> 16) & 0xFF));\n          imgData.put((byte) ((pixelValue >> 8) & 0xFF));\n          imgData.put((byte) (pixelValue & 0xFF));\n        } else { // Float model\n          imgData.putFloat((((pixelValue >> 16) & 0xFF) - 104f));\n          imgData.putFloat((((pixelValue >> 8) & 0xFF) - 117f));\n          imgData.putFloat(((pixelValue & 0xFF) - 124f));\n        }\n      }\n    }\n    Trace.endSection(); // preprocessBitmap\n\n    // Copy the input data into TensorFlow.\n    Trace.beginSection(\"feed\");\n    outputVector = new float[1][9216];\n\n    Trace.endSection();\n\n    // Run the inference call.\n    Trace.beginSection(\"run\");\n    ppm_tfRun.start();\n    tfLite.run(imgData, outputVector);\n    ppm_tfRun.stop();\n    Trace.endSection();\n\n    Trace.endSection(); // \"recognizeImage\"\n    return outputVector[0];\n  }\n}\n\nThe code to run inference for the unconverted model is:\nimport android.content.res.AssetManager;\nimport android.graphics.Bitmap;\nimport android.os.Trace;\nimport one.realnote.app.PpmItem;\nimport org.tensorflow.Graph;\nimport org.tensorflow.Operation;\nimport org.tensorflow.contrib.android.TensorFlowInferenceInterface;\n\npublic class AlexFeatureExtraction {\n\n    private static final String TAG = \"AlexFeatureExtraction\";\n\n    // Config values.\n    private String inputName;\n    private int inputSize;\n\n    // Pre-allocated buffers.\n    private float[] outputVector;\n\n    private int[] intValues;\n    private float[] floatValues;\n\n    private TensorFlowInferenceInterface inferenceInterface;\n\n    public static AlexFeatureExtraction create(\n        final AssetManager assetManager) {\n\n        final AlexFeatureExtraction d = new AlexFeatureExtraction();\n\n\n        final String modelFilename = \"file:///android_asset/tf/alex.pb\";\n        final int inputSize = 227;\n\n        d.inferenceInterface = new TensorFlowInferenceInterface(assetManager, modelFilename);\n\n        final Graph g = d.inferenceInterface.graph();\n\n        d.inputName = \"Placeholder\"; // ssd: \"image_tensor\";\n\n        // The inputName node has a shape of [N, H, W, C], where\n        // N is the batch size\n        // H = W are the height and width\n        // C is the number of channels (3 for our purposes - RGB)\n        final Operation inputOp = g.operation(d.inputName);\n        if (inputOp == null) {\n            throw new RuntimeException(\"Failed to find input Node '\" + d.inputName + \"'\");\n        }\n        d.inputSize = inputSize;\n        // The outputScoresName node has a shape of [N, NumLocations], where N\n        // is the batch size.\n\n        // ssd: final Operation outputOp1 = g.operation(\"detection_scores\");\n        final Operation outputOp1 = g.operation(\"output\");\n        if (outputOp1 == null) {\n            throw new RuntimeException(\"Failed to find output Node 'detection_scores'\");\n        }\n\n        // Pre-allocate buffers.\n        d.outputVector = new float[9216];\n\n        d.intValues = new int[d.inputSize * d.inputSize];\n        d.floatValues = new float[d.inputSize * d.inputSize * 3];\n\n        return d;\n    }\n\n\n    private AlexFeatureExtraction() {\n    }\n\n\n    private static PpmItem ppm_tfFeed = PpmItem.createDebugItem(\"TFA\", \"feed\", String.class);\n    private static PpmItem ppm_tfRun = PpmItem.createDebugItem(\"TFA\", \"runAlex\", String.class);\n\n\n    public float[] calcFeatureVector(final Bitmap bitmap) {\n        // Log this method so that it can be analyzed with systrace.\n        Trace.beginSection(\"recognizeImage\");\n\n        Trace.beginSection(\"preprocessBitmap\");\n        // Preprocess the image data from 0-255 int to normalized float based\n        // on the provided parameters.\n        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\n\n        for (int i = 0; i < intValues.length; ++i) {\n            floatValues[i * 3 + 2] = (float) (intValues[i] & 0xFF) - 124f;\n            floatValues[i * 3 + 1] = (float) ((intValues[i] >> 8) & 0xFF) - 117f;\n            floatValues[i * 3 + 0] = (float) ((intValues[i] >> 16) & 0xFF) -104f;\n        }\n\n        Trace.endSection(); // preprocessBitmap\n\n        // Copy the input data into TensorFlow.\n        Trace.beginSection(\"feed\");\n        ppm_tfFeed.start();\n        inferenceInterface.feed(inputName, floatValues, 1, inputSize, inputSize, 3);\n        ppm_tfFeed.stop();\n        Trace.endSection();\n\n        // Run the inference call.\n        Trace.beginSection(\"run\");\n        ppm_tfRun.start();\n        inferenceInterface.run(new String[]{\"output\"}, false);\n        ppm_tfRun.stop();\n        Trace.endSection();\n\n        // Copy the output Tensor back into the output array.\n        Trace.beginSection(\"fetch\");\n\n\n        inferenceInterface.fetch(\"output\", outputVector);\n\n        Trace.endSection();\n\n        Trace.endSection(); // \"recognizeImage\"\n\n        return outputVector;\n    }\n\n    public void close() {\n        inferenceInterface.close();\n    }\n}\n\nOther info / logs\nOutput behavior is as expected for all models. Activating the useNNAPI option doesn't really do anything performance wise aswell as setting the number of threads.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S8\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): On PC: current tf-nightly (14.11.2018), on phone current org.tensorflow:tensorflow-lite:0.0.0-nightly\r\n- Python version: 3.6.6\r\n- Bazel version (if compiling from source): - \r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: - \r\n- GPU model and memory: CPU only\r\n\r\n**Describe the current behavior**\r\nI build a model with this code:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.tools import freeze_graph\r\n\r\n\r\nclass AlexNet(object):\r\n    \"\"\"Implementation of the AlexNet.\"\"\"\r\n\r\n    def __init__(self, x, keep_prob, num_classes, skip_layer,\r\n                 weights_path='DEFAULT'):\r\n        \"\"\"Create the graph of the AlexNet model.\r\n        Args:\r\n            x: Placeholder for the input tensor.\r\n            keep_prob: Dropout probability.\r\n            num_classes: Number of classes in the dataset.\r\n            skip_layer: List of names of the layer, that get trained from\r\n                scratch\r\n            weights_path: Complete path to the pretrained weight file, if it\r\n                isn't in the same folder as this code\r\n        \"\"\"\r\n        # Parse input arguments into class variables\r\n        self.X = x\r\n        self.NUM_CLASSES = num_classes\r\n        self.KEEP_PROB = keep_prob\r\n        self.SKIP_LAYER = skip_layer\r\n\r\n        if weights_path == 'DEFAULT':\r\n            self.WEIGHTS_PATH = 'bvlc_alexnet.npy'\r\n        else:\r\n            self.WEIGHTS_PATH = weights_path\r\n\r\n        # Call the create function to build the computational graph of AlexNet\r\n        self.create()\r\n\r\n    def create(self):\r\n        \"\"\"Create the network graph.\"\"\"\r\n        # 1st Layer: Conv (w ReLu) -> Lrn -> Pool\r\n        conv1 = conv(self.X, 11, 11, 96, 4, 4, padding='VALID', name='conv1')\r\n        norm1 = lrn(conv1, 2, 2e-05, 0.75, name='norm1')\r\n        pool1 = max_pool(norm1, 3, 3, 2, 2, padding='VALID', name='pool1')\r\n\r\n        # 2nd Layer: Conv (w ReLu)  -> Lrn -> Pool with 2 groups\r\n        conv2 = conv(pool1, 5, 5, 256, 1, 1, groups=2, name='conv2')\r\n        norm2 = lrn(conv2, 2, 2e-05, 0.75, name='norm2')\r\n        pool2 = max_pool(norm2, 3, 3, 2, 2, padding='VALID', name='pool2')\r\n\r\n        # 3rd Layer: Conv (w ReLu)\r\n        self.conv3 = conv(pool2, 3, 3, 384, 1, 1, name='conv3')\r\n\r\n        # 4th Layer: Conv (w ReLu) splitted into two groups\r\n        conv4 = conv(self.conv3, 3, 3, 384, 1, 1, groups=2, name='conv4')\r\n\r\n        # 5th Layer: Conv (w ReLu) -> Pool splitted into two groups\r\n        conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name='conv5')\r\n        self.pool5 = max_pool(conv5, 3, 3, 2, 2, padding='VALID', name='pool5')\r\n\r\n        # 6th Layer: Flatten -> FC (w ReLu) -> Dropout\r\n        self.flattened = tf.reshape(self.pool5, [1, 9216], name='output')\r\n\r\n    def load_initial_weights(self, session):\r\n        \"\"\"Load weights from file into network.\r\n        As the weights from http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/\r\n        come as a dict of lists (e.g. weights['conv1'] is a list) and not as\r\n        dict of dicts (e.g. weights['conv1'] is a dict with keys 'weights' &\r\n        'biases') we need a special load function\r\n        \"\"\"\r\n        # Load the weights into memory\r\n        weights_dict = np.load(self.WEIGHTS_PATH, encoding='bytes').item()\r\n\r\n        # Loop over all layer names stored in the weights dict\r\n        for op_name in weights_dict:\r\n\r\n            # Check if layer should be trained from scratch\r\n            if op_name not in self.SKIP_LAYER:\r\n\r\n                with tf.variable_scope(op_name, reuse=True):\r\n\r\n                    # Assign weights/biases to their corresponding tf variable\r\n                    for data in weights_dict[op_name]:\r\n\r\n                        # Biases\r\n                        if len(data.shape) == 1:\r\n                            var = tf.get_variable('biases', trainable=False)\r\n                            session.run(var.assign(data))\r\n\r\n                        # Weights\r\n                        else:\r\n                            var = tf.get_variable('weights', trainable=False)\r\n                            session.run(var.assign(data))\r\n\r\n\r\ndef conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,\r\n         padding='SAME', groups=1):\r\n    \"\"\"Create a convolution layer.\r\n    Adapted from: https://github.com/ethereon/caffe-tensorflow\r\n    \"\"\"\r\n    # Get number of input channels\r\n    input_channels = int(x.get_shape()[-1])\r\n\r\n    # Create lambda function for the convolution\r\n    convolve = lambda i, k: tf.nn.conv2d(i, k,\r\n                                         strides=[1, stride_y, stride_x, 1],\r\n                                         padding=padding)\r\n\r\n    with tf.variable_scope(name) as scope:\r\n        # Create tf variables for the weights and biases of the conv layer\r\n        weights = tf.get_variable('weights', shape=[filter_height,\r\n                                                    filter_width,\r\n                                                    input_channels/groups,\r\n                                                    num_filters])\r\n        biases = tf.get_variable('biases', shape=[num_filters])\r\n\r\n    if groups == 1:\r\n        conv = convolve(x, weights)\r\n\r\n    # In the cases of multiple groups, split inputs & weights and\r\n    else:\r\n        # Split input and weights and convolve them separately\r\n        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\r\n        weight_groups = tf.split(axis=3, num_or_size_splits=groups,\r\n                                 value=weights)\r\n        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\r\n\r\n        # Concat the convolved output together again\r\n        conv = tf.concat(axis=3, values=output_groups)\r\n\r\n    # Add biases\r\n    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\r\n\r\n    # Apply relu function\r\n    relu = tf.nn.relu(bias, name=scope.name)\r\n\r\n    return relu\r\n\r\n\r\ndef fc(x, num_in, num_out, name, relu=True):\r\n    \"\"\"Create a fully connected layer.\"\"\"\r\n    with tf.variable_scope(name) as scope:\r\n\r\n        # Create tf variables for the weights and biases\r\n        weights = tf.get_variable('weights', shape=[num_in, num_out],\r\n                                  trainable=True)\r\n        biases = tf.get_variable('biases', [num_out], trainable=True)\r\n\r\n        # Matrix multiply weights and inputs and add bias\r\n        act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)\r\n\r\n    if relu:\r\n        # Apply ReLu non linearity\r\n        relu = tf.nn.relu(act)\r\n        return relu\r\n    else:\r\n        return act\r\n\r\n\r\ndef max_pool(x, filter_height, filter_width, stride_y, stride_x, name,\r\n             padding='SAME'):\r\n    \"\"\"Create a max pooling layer.\"\"\"\r\n    return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],\r\n                          strides=[1, stride_y, stride_x, 1],\r\n                          padding=padding, name=name)\r\n\r\n\r\ndef lrn(x, radius, alpha, beta, name, bias=1.0):\r\n    \"\"\"Create a local response normalization layer.\"\"\"\r\n    return tf.nn.local_response_normalization(x, depth_radius=radius,\r\n                                              alpha=alpha, beta=beta,\r\n                                              bias=bias, name=name)\r\n\r\n\r\ndef dropout(x, keep_prob):\r\n    \"\"\"Create a dropout layer.\"\"\"\r\n    return tf.nn.dropout(x, keep_prob)\r\n\r\n\r\n\r\n\r\ng = tf.Graph()\r\nwith g.as_default():\r\n    # Initialize all variables\r\n    x = tf.placeholder(tf.float32, [1, 227, 227, 3])\r\n    y = tf.placeholder(tf.float32, [1, 1000])\r\n    keep_prob = tf.placeholder(tf.float32)\r\n    alex_net = AlexNet(x, keep_prob, 1000, [\"fc6\", \"fc7\", \"fc8\"])\r\n```\r\n\r\nThen I froze the model. In the first try I converted it to TFlite directly, in a second try I set the `converter.post_training_quantize = True` option in the conversion process to quantize my model and in a second try I optimized my model for inference before converting and quantizing.\r\nThe code for the tflite conversion is the following:\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"alex_frozen_optimized.pb\"\r\ninput_arrays = [\"Placeholder\"]\r\noutput_arrays = [\"output\"]\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\r\n    graph_def_file, input_arrays, output_arrays, input_shapes={\"Placeholder\" : [1, 227, 227, 3]})\r\nconverter.post_training_quantize = True\r\ntflite_model = converter.convert()\r\nopen(\"save_path/alex_frozen_optimized_quantized.tflite\", \"wb\").write(tflite_model)\r\n```\r\nThe code for optimizing for inference was the following terminal call: `python -m tensorflow.python.tools.optimize_for_inference --input alex_frozen.pb --output alex_frozen_optimized.pb --input_names=Placeholder --output_names=output`\r\n\r\nAll my models, including the plain, unconverted model is uploaded here for testing: [models.zip](https://www.dropbox.com/s/gyu9cfkn3yn07oc/models.zip?dl=0)\r\n\r\n**Describe the expected behavior**\r\nI deployed those models to my phone. I get runtime of around 290 ms for the unconverted model, while having runtimes of about 420 ms for the quantized tflite, the optimized and quantized tflite and the plain tflite model. That can't be right, can it?\r\n\r\n**Code to reproduce the issue**\r\nThe code for running inference on the phone for the tflite models is the following:\r\n```\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.content.res.AssetManager;\r\nimport android.graphics.Bitmap;\r\nimport android.os.Trace;\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.ByteOrder;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport one.realnote.app.PpmItem;\r\nimport one.realnote.app.Util;\r\nimport org.tensorflow.lite.Interpreter;\r\nimport org.tensorflow.lite.Interpreter.Options;\r\n\r\npublic class AlexFeatureExtractionLite {\r\n\r\n  private static final String TAG = \"TFLiteAPIAlex\";\r\n\r\n  // Only return this many results.\r\n  private boolean isModelQuantized;\r\n  // Float model\r\n  // Number of threads in the java app\r\n  private static final int NUM_THREADS = 4;\r\n  // Config values.\r\n  private int inputSize;\r\n  // Pre-allocated buffers.\r\n  private float[][] outputVector;\r\n  private int[] intValues;\r\n\r\n  private static PpmItem ppm_tfRun = PpmItem.createDebugItem(\"TFA\", \"runAlex\", String.class);\r\n\r\n  private ByteBuffer imgData;\r\n  private Interpreter tfLite;\r\n\r\n  /**\r\n   * Memory-map the model file in Assets.\r\n   */\r\n  private static MappedByteBuffer loadModelFile(AssetManager assets)\r\n      throws IOException {\r\n    AssetFileDescriptor fileDescriptor = assets.openFd(\"tf/alex_frozen_optimized_quantized.tflite\");\r\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n    FileChannel fileChannel = inputStream.getChannel();\r\n    long startOffset = fileDescriptor.getStartOffset();\r\n    long declaredLength = fileDescriptor.getDeclaredLength();\r\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n  }\r\n\r\n  /**\r\n   * Initializes a native TensorFlow session for classifying images.\r\n   *\r\n   * @param assetManager The asset manager to be used to load assets.\r\n   * @param inputSize The size of image input\r\n   * @param isQuantized Boolean representing model is quantized or not\r\n   */\r\n  public static AlexFeatureExtractionLite create(final AssetManager assetManager,\r\n      final int inputSize, final boolean isQuantized) {\r\n    final AlexFeatureExtractionLite d = new AlexFeatureExtractionLite();\r\n\r\n    d.inputSize = inputSize;\r\n    Interpreter.Options options = new Options();\r\n    options.setUseNNAPI(false);\r\n    options.setAllowFp16PrecisionForFp32(false);\r\n    options.setNumThreads(4);\r\n    try {\r\n      d.tfLite = new Interpreter(loadModelFile(assetManager), options);\r\n    } catch (Exception e) {\r\n      Util.logError(e);\r\n      throw new RuntimeException(e);\r\n    }\r\n\r\n    d.isModelQuantized = isQuantized;\r\n    // Pre-allocate buffers.\r\n    int numBytesPerChannel;\r\n    if (isQuantized) {\r\n      numBytesPerChannel = 1; // Quantized\r\n    } else {\r\n      numBytesPerChannel = 4; // Floating point\r\n    }\r\n    d.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\r\n    d.imgData.order(ByteOrder.nativeOrder());\r\n    d.intValues = new int[d.inputSize * d.inputSize];\r\n    d.outputVector = new float[1][9216];\r\n\r\n    //d.tfLite.setNumThreads(NUM_THREADS);\r\n    return d;\r\n  }\r\n\r\n  private AlexFeatureExtractionLite() {\r\n  }\r\n\r\n\r\n  public float[] calcFeatureVector(final Bitmap bitmap) {\r\n    // Log this method so that it can be analyzed with systrace.\r\n    Trace.beginSection(\"recognizeImage\");\r\n\r\n    Trace.beginSection(\"preprocessBitmap\");\r\n    // Preprocess the image data from 0-255 int to normalized float based\r\n    // on the provided parameters.\r\n    bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n\r\n    imgData.rewind();\r\n    for (int i = 0; i < inputSize; ++i) {\r\n      for (int j = 0; j < inputSize; ++j) {\r\n        int pixelValue = intValues[i * inputSize + j];\r\n        if (isModelQuantized) {\r\n          // Quantized model\r\n          imgData.put((byte) ((pixelValue >> 16) & 0xFF));\r\n          imgData.put((byte) ((pixelValue >> 8) & 0xFF));\r\n          imgData.put((byte) (pixelValue & 0xFF));\r\n        } else { // Float model\r\n          imgData.putFloat((((pixelValue >> 16) & 0xFF) - 104f));\r\n          imgData.putFloat((((pixelValue >> 8) & 0xFF) - 117f));\r\n          imgData.putFloat(((pixelValue & 0xFF) - 124f));\r\n        }\r\n      }\r\n    }\r\n    Trace.endSection(); // preprocessBitmap\r\n\r\n    // Copy the input data into TensorFlow.\r\n    Trace.beginSection(\"feed\");\r\n    outputVector = new float[1][9216];\r\n\r\n    Trace.endSection();\r\n\r\n    // Run the inference call.\r\n    Trace.beginSection(\"run\");\r\n    ppm_tfRun.start();\r\n    tfLite.run(imgData, outputVector);\r\n    ppm_tfRun.stop();\r\n    Trace.endSection();\r\n\r\n    Trace.endSection(); // \"recognizeImage\"\r\n    return outputVector[0];\r\n  }\r\n}\r\n```\r\n\r\nThe code to run inference for the unconverted model is:\r\n```\r\nimport android.content.res.AssetManager;\r\nimport android.graphics.Bitmap;\r\nimport android.os.Trace;\r\nimport one.realnote.app.PpmItem;\r\nimport org.tensorflow.Graph;\r\nimport org.tensorflow.Operation;\r\nimport org.tensorflow.contrib.android.TensorFlowInferenceInterface;\r\n\r\npublic class AlexFeatureExtraction {\r\n\r\n    private static final String TAG = \"AlexFeatureExtraction\";\r\n\r\n    // Config values.\r\n    private String inputName;\r\n    private int inputSize;\r\n\r\n    // Pre-allocated buffers.\r\n    private float[] outputVector;\r\n\r\n    private int[] intValues;\r\n    private float[] floatValues;\r\n\r\n    private TensorFlowInferenceInterface inferenceInterface;\r\n\r\n    public static AlexFeatureExtraction create(\r\n        final AssetManager assetManager) {\r\n\r\n        final AlexFeatureExtraction d = new AlexFeatureExtraction();\r\n\r\n\r\n        final String modelFilename = \"file:///android_asset/tf/alex.pb\";\r\n        final int inputSize = 227;\r\n\r\n        d.inferenceInterface = new TensorFlowInferenceInterface(assetManager, modelFilename);\r\n\r\n        final Graph g = d.inferenceInterface.graph();\r\n\r\n        d.inputName = \"Placeholder\"; // ssd: \"image_tensor\";\r\n\r\n        // The inputName node has a shape of [N, H, W, C], where\r\n        // N is the batch size\r\n        // H = W are the height and width\r\n        // C is the number of channels (3 for our purposes - RGB)\r\n        final Operation inputOp = g.operation(d.inputName);\r\n        if (inputOp == null) {\r\n            throw new RuntimeException(\"Failed to find input Node '\" + d.inputName + \"'\");\r\n        }\r\n        d.inputSize = inputSize;\r\n        // The outputScoresName node has a shape of [N, NumLocations], where N\r\n        // is the batch size.\r\n\r\n        // ssd: final Operation outputOp1 = g.operation(\"detection_scores\");\r\n        final Operation outputOp1 = g.operation(\"output\");\r\n        if (outputOp1 == null) {\r\n            throw new RuntimeException(\"Failed to find output Node 'detection_scores'\");\r\n        }\r\n\r\n        // Pre-allocate buffers.\r\n        d.outputVector = new float[9216];\r\n\r\n        d.intValues = new int[d.inputSize * d.inputSize];\r\n        d.floatValues = new float[d.inputSize * d.inputSize * 3];\r\n\r\n        return d;\r\n    }\r\n\r\n\r\n    private AlexFeatureExtraction() {\r\n    }\r\n\r\n\r\n    private static PpmItem ppm_tfFeed = PpmItem.createDebugItem(\"TFA\", \"feed\", String.class);\r\n    private static PpmItem ppm_tfRun = PpmItem.createDebugItem(\"TFA\", \"runAlex\", String.class);\r\n\r\n\r\n    public float[] calcFeatureVector(final Bitmap bitmap) {\r\n        // Log this method so that it can be analyzed with systrace.\r\n        Trace.beginSection(\"recognizeImage\");\r\n\r\n        Trace.beginSection(\"preprocessBitmap\");\r\n        // Preprocess the image data from 0-255 int to normalized float based\r\n        // on the provided parameters.\r\n        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());\r\n\r\n        for (int i = 0; i < intValues.length; ++i) {\r\n            floatValues[i * 3 + 2] = (float) (intValues[i] & 0xFF) - 124f;\r\n            floatValues[i * 3 + 1] = (float) ((intValues[i] >> 8) & 0xFF) - 117f;\r\n            floatValues[i * 3 + 0] = (float) ((intValues[i] >> 16) & 0xFF) -104f;\r\n        }\r\n\r\n        Trace.endSection(); // preprocessBitmap\r\n\r\n        // Copy the input data into TensorFlow.\r\n        Trace.beginSection(\"feed\");\r\n        ppm_tfFeed.start();\r\n        inferenceInterface.feed(inputName, floatValues, 1, inputSize, inputSize, 3);\r\n        ppm_tfFeed.stop();\r\n        Trace.endSection();\r\n\r\n        // Run the inference call.\r\n        Trace.beginSection(\"run\");\r\n        ppm_tfRun.start();\r\n        inferenceInterface.run(new String[]{\"output\"}, false);\r\n        ppm_tfRun.stop();\r\n        Trace.endSection();\r\n\r\n        // Copy the output Tensor back into the output array.\r\n        Trace.beginSection(\"fetch\");\r\n\r\n\r\n        inferenceInterface.fetch(\"output\", outputVector);\r\n\r\n        Trace.endSection();\r\n\r\n        Trace.endSection(); // \"recognizeImage\"\r\n\r\n        return outputVector;\r\n    }\r\n\r\n    public void close() {\r\n        inferenceInterface.close();\r\n    }\r\n}\r\n```\r\n\r\n**Other info / logs**\r\nOutput behavior is as expected for all models. Activating the useNNAPI option doesn't really do anything performance wise aswell as setting the number of threads.\r\n"}