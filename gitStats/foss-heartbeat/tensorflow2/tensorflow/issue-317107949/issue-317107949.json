{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18822", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18822/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18822/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18822/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18822", "id": 317107949, "node_id": "MDU6SXNzdWUzMTcxMDc5NDk=", "number": 18822, "title": "does tensorflow take all resource from GPU, making other CUDA code slow ?", "user": {"login": "ChiFang", "id": 16358320, "node_id": "MDQ6VXNlcjE2MzU4MzIw", "avatar_url": "https://avatars3.githubusercontent.com/u/16358320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ChiFang", "html_url": "https://github.com/ChiFang", "followers_url": "https://api.github.com/users/ChiFang/followers", "following_url": "https://api.github.com/users/ChiFang/following{/other_user}", "gists_url": "https://api.github.com/users/ChiFang/gists{/gist_id}", "starred_url": "https://api.github.com/users/ChiFang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ChiFang/subscriptions", "organizations_url": "https://api.github.com/users/ChiFang/orgs", "repos_url": "https://api.github.com/users/ChiFang/repos", "events_url": "https://api.github.com/users/ChiFang/events{/privacy}", "received_events_url": "https://api.github.com/users/ChiFang/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jart", "id": 49262, "node_id": "MDQ6VXNlcjQ5MjYy", "avatar_url": "https://avatars1.githubusercontent.com/u/49262?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jart", "html_url": "https://github.com/jart", "followers_url": "https://api.github.com/users/jart/followers", "following_url": "https://api.github.com/users/jart/following{/other_user}", "gists_url": "https://api.github.com/users/jart/gists{/gist_id}", "starred_url": "https://api.github.com/users/jart/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jart/subscriptions", "organizations_url": "https://api.github.com/users/jart/orgs", "repos_url": "https://api.github.com/users/jart/repos", "events_url": "https://api.github.com/users/jart/events{/privacy}", "received_events_url": "https://api.github.com/users/jart/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-04-24T07:47:03Z", "updated_at": "2018-04-30T02:46:00Z", "closed_at": "2018-04-26T16:03:20Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nI have a custom CUDA code but not register into Tensorflow OP</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nbinary: by \"pip3 install --upgrade tensorflow-gpu\"</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\ntensorflow-gpu (1.7.0)</li>\n<li><strong>Python version</strong>:<br>\nPython 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:<br>\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA 9.0 cuDNN 7</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have a cuda lib build from C++ for post-processing after predict result by tensorflow model.<br>\nI use following way to make python able to use cuda code from C++<br>\n<code>lib = ctypes.cdll.LoadLibrary(my.so)</code></p>\n<p>If I test the cuda code alone without tensorflow. it work fine.<br>\nBut when tensorflow is used in my project, my cuda code become 10 times slower....</p>\n<p>My  time log is in cuda .so lib, so it's no way that the gap come from python to .so  wrap.</p>\n<p>I have try to set the fraction of GPU memory to be allocated in tensorflow by:<br>\n<code># Assume that you have 12GB of GPU memory and want to allocate ~4GB:</code><br>\n<code>gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)</code><br>\n<code>sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))</code></p>\n<p>but useless....<br>\nso I wonder does tensorflow take all resource from GPU, making other CUDA code slow ?<br>\nthe only solution is make my cuda code as a tensorflow OP by register?</p>\n<p>Any suggestion? Thanks~~~</p>\n<p>----------------------Update----------------------<br>\nI have tested following way to set gpu_options, but still useless....<br>\n<code>config = tf.ConfigProto()</code><br>\n<code>config.gpu_options.allow_growth = True</code><br>\n<code>sess = tf.Session(config=config)</code></p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nI have a custom CUDA code but not register into Tensorflow OP\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Ubuntu 16.04\nTensorFlow installed from (source or binary):\nbinary: by \"pip3 install --upgrade tensorflow-gpu\"\nTensorFlow version (use command below):\ntensorflow-gpu (1.7.0)\nPython version:\nPython 3.5.2\nBazel version (if compiling from source): 0.11.0\nGCC/Compiler version (if compiling from source):\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\nCUDA/cuDNN version: CUDA 9.0 cuDNN 7\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nI have a cuda lib build from C++ for post-processing after predict result by tensorflow model.\nI use following way to make python able to use cuda code from C++\nlib = ctypes.cdll.LoadLibrary(my.so)\nIf I test the cuda code alone without tensorflow. it work fine.\nBut when tensorflow is used in my project, my cuda code become 10 times slower....\nMy  time log is in cuda .so lib, so it's no way that the gap come from python to .so  wrap.\nI have try to set the fraction of GPU memory to be allocated in tensorflow by:\n# Assume that you have 12GB of GPU memory and want to allocate ~4GB:\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\nbut useless....\nso I wonder does tensorflow take all resource from GPU, making other CUDA code slow ?\nthe only solution is make my cuda code as a tensorflow OP by register?\nAny suggestion? Thanks~~~\n----------------------Update----------------------\nI have tested following way to set gpu_options, but still useless....\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI have a custom CUDA code but not register into Tensorflow OP\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary: by \"pip3 install --upgrade tensorflow-gpu\"\r\n- **TensorFlow version (use command below)**:\r\ntensorflow-gpu (1.7.0)\r\n- **Python version**: \r\nPython 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: CUDA 9.0 cuDNN 7\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI have a cuda lib build from C++ for post-processing after predict result by tensorflow model.\r\nI use following way to make python able to use cuda code from C++\r\n`lib = ctypes.cdll.LoadLibrary(my.so)`\r\n\r\nIf I test the cuda code alone without tensorflow. it work fine.\r\nBut when tensorflow is used in my project, my cuda code become 10 times slower....\r\n\r\nMy  time log is in cuda .so lib, so it's no way that the gap come from python to .so  wrap.\r\n\r\nI have try to set the fraction of GPU memory to be allocated in tensorflow by:\r\n`# Assume that you have 12GB of GPU memory and want to allocate ~4GB:`\r\n`gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)`\r\n`sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))`\r\n\r\nbut useless....\r\nso I wonder does tensorflow take all resource from GPU, making other CUDA code slow ?\r\nthe only solution is make my cuda code as a tensorflow OP by register?\r\n\r\nAny suggestion? Thanks~~~\r\n\r\n----------------------Update----------------------\r\nI have tested following way to set gpu_options, but still useless....\r\n`config = tf.ConfigProto()`\r\n`config.gpu_options.allow_growth = True`\r\n`sess = tf.Session(config=config)`"}