{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/209412116", "pull_request_review_id": 145431496, "id": 209412116, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwOTQxMjExNg==", "diff_hunk": "@@ -3963,6 +4093,161 @@ Status MklLayoutRewritePass::MergeConv2DWithBiasAdd(std::unique_ptr<Graph>* g,\n   return Status::OK();\n }\n \n+Status MklLayoutRewritePass::MergePadWithConv2D(std::unique_ptr<Graph>* g,\n+                                                    Node* m, Node* n) {\n+  CHECK_EQ(((m->type_string() == csinfo_.pad &&\n+             n->type_string() == csinfo_.conv2d)) ||\n+               ((n->type_string() == csinfo_.pad &&\n+                 m->type_string() == csinfo_.conv2d)),\n+           true);\n+      \n+  // Conv2D is successor node, and Pad predecessor node.\n+  Node* pred = m->type_string() == csinfo_.pad ? m : n;\n+  Node* succ = m->type_string() == csinfo_.pad ? n : m;\n+\n+  // 1. Get all attributes from input nodes.\n+  DataType T_pred, T_succ;\n+  string padding;\n+  std::vector<int32> strides;\n+  std::vector<int32> dilations;\n+  string data_format_pred, data_format_succ;\n+  bool use_cudnn_on_gnu;\n+  TF_CHECK_OK(GetNodeAttr(pred->def(), \"T\", &T_pred));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"T\", &T_succ));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"padding\", &padding));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"strides\", &strides));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"dilations\", &dilations));\n+  // data format for pad is not available and not necessary, thus\n+  // we dont need to match data format\n+  // TF_CHECK_OK(GetNodeAttr(pred->def(), \"data_format\", &data_format_pred));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"data_format\", &data_format_succ));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"use_cudnn_on_gpu\", &use_cudnn_on_gnu));\n+  // We check to ensure that data formats of both succ and pred are same.\n+  // We expect them to be same, so we can enforce this as assert.\n+  // But assert can be too strict, so we enforce this as a check.\n+  // If the check fails, then we do not merge two nodes.\n+  // We also do same check for devices.\n+  // if (data_format_pred != data_format_succ || T_pred != T_succ ||\n+  if (T_pred != T_succ ||\n+      pred->assigned_device_name() != succ->assigned_device_name() ||\n+      pred->def().device() != succ->def().device()) {\n+    return Status(error::Code::INVALID_ARGUMENT,\n+                  \"data_format or T attribute or devices of Conv2D and \"\n+                  \"Pad do not match. Will skip node merge optimization\");\n+  }\n+\n+  const int succ_num = succ->num_inputs();\n+  gtl::InlinedVector<Node*, 4> succ_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> succ_in(succ_num);\n+  FillInputs(succ, &succ_control_edges, &succ_in);\n+\n+  const int pred_num = pred->num_inputs();\n+  gtl::InlinedVector<Node*, 4> pred_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> pred_in(pred_num);\n+  FillInputs(pred, &pred_control_edges, &pred_in);\n+\n+  // We need to ensure that Pad only feeds to Conv2D (some other operator is\n+  // not expecting output of Pad). If this is not the case, then we cannot\n+  // merge Conv2D with Pad.\n+  const int kFirstOutputSlot = 0;\n+  for (const Edge* e : pred->out_edges()) {\n+    if (e->src_output() == kFirstOutputSlot && e->dst() != succ) {\n+      return Status(error::Code::INVALID_ARGUMENT,\n+                    \"Pad does not feed to Conv2D, or \"\n+                    \"it feeds Conv2D but has multiple outputs. \"\n+                    \"Will skip node merge optimization\");\n+    }\n+  }\n+\n+  // 2. Get inputs from both the nodes. ( ? ? Explanation of the following)\n+  // Find the 2 inputs from the Pad and the Filter input from the Conv2D.\n+  // Get operand 0, 1 of conv2D.", "path": "tensorflow/core/graph/mkl_layout_pass.cc", "position": null, "original_position": 275, "commit_id": "48809b87793882266f01b7b40bc9e4a6e0f18f57", "original_commit_id": "dd63093a599081accfe2a2d2ca8c029d413a15d7", "user": {"login": "ashraf-bhuiyan", "id": 8062406, "node_id": "MDQ6VXNlcjgwNjI0MDY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8062406?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ashraf-bhuiyan", "html_url": "https://github.com/ashraf-bhuiyan", "followers_url": "https://api.github.com/users/ashraf-bhuiyan/followers", "following_url": "https://api.github.com/users/ashraf-bhuiyan/following{/other_user}", "gists_url": "https://api.github.com/users/ashraf-bhuiyan/gists{/gist_id}", "starred_url": "https://api.github.com/users/ashraf-bhuiyan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ashraf-bhuiyan/subscriptions", "organizations_url": "https://api.github.com/users/ashraf-bhuiyan/orgs", "repos_url": "https://api.github.com/users/ashraf-bhuiyan/repos", "events_url": "https://api.github.com/users/ashraf-bhuiyan/events{/privacy}", "received_events_url": "https://api.github.com/users/ashraf-bhuiyan/received_events", "type": "User", "site_admin": false}, "body": "Yes, not needed. Removed it.", "created_at": "2018-08-11T01:11:10Z", "updated_at": "2018-11-23T19:46:17Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21318#discussion_r209412116", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21318", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/209412116"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21318#discussion_r209412116"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21318"}}, "body_html": "<p>Yes, not needed. Removed it.</p>", "body_text": "Yes, not needed. Removed it.", "in_reply_to_id": 208053789}