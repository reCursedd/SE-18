{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/209714799", "pull_request_review_id": 145770414, "id": 209714799, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwOTcxNDc5OQ==", "diff_hunk": "@@ -3963,6 +4093,161 @@ Status MklLayoutRewritePass::MergeConv2DWithBiasAdd(std::unique_ptr<Graph>* g,\n   return Status::OK();\n }\n \n+Status MklLayoutRewritePass::MergePadWithConv2D(std::unique_ptr<Graph>* g,\n+                                                    Node* m, Node* n) {\n+  CHECK_EQ(((m->type_string() == csinfo_.pad &&\n+             n->type_string() == csinfo_.conv2d)) ||\n+               ((n->type_string() == csinfo_.pad &&\n+                 m->type_string() == csinfo_.conv2d)),\n+           true);\n+      \n+  // Conv2D is successor node, and Pad predecessor node.\n+  Node* pred = m->type_string() == csinfo_.pad ? m : n;\n+  Node* succ = m->type_string() == csinfo_.pad ? n : m;\n+\n+  // 1. Get all attributes from input nodes.\n+  DataType T_pred, T_succ;\n+  string padding;\n+  std::vector<int32> strides;\n+  std::vector<int32> dilations;\n+  string data_format_pred, data_format_succ;\n+  bool use_cudnn_on_gnu;\n+  TF_CHECK_OK(GetNodeAttr(pred->def(), \"T\", &T_pred));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"T\", &T_succ));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"padding\", &padding));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"strides\", &strides));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"dilations\", &dilations));\n+  // data format for pad is not available and not necessary, thus\n+  // we dont need to match data format\n+  // TF_CHECK_OK(GetNodeAttr(pred->def(), \"data_format\", &data_format_pred));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"data_format\", &data_format_succ));\n+  TF_CHECK_OK(GetNodeAttr(succ->def(), \"use_cudnn_on_gpu\", &use_cudnn_on_gnu));\n+  // We check to ensure that data formats of both succ and pred are same.\n+  // We expect them to be same, so we can enforce this as assert.\n+  // But assert can be too strict, so we enforce this as a check.\n+  // If the check fails, then we do not merge two nodes.\n+  // We also do same check for devices.\n+  // if (data_format_pred != data_format_succ || T_pred != T_succ ||\n+  if (T_pred != T_succ ||\n+      pred->assigned_device_name() != succ->assigned_device_name() ||\n+      pred->def().device() != succ->def().device()) {\n+    return Status(error::Code::INVALID_ARGUMENT,\n+                  \"data_format or T attribute or devices of Conv2D and \"\n+                  \"Pad do not match. Will skip node merge optimization\");\n+  }\n+\n+  const int succ_num = succ->num_inputs();\n+  gtl::InlinedVector<Node*, 4> succ_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> succ_in(succ_num);\n+  FillInputs(succ, &succ_control_edges, &succ_in);\n+\n+  const int pred_num = pred->num_inputs();\n+  gtl::InlinedVector<Node*, 4> pred_control_edges;\n+  gtl::InlinedVector<std::pair<Node*, int>, 4> pred_in(pred_num);\n+  FillInputs(pred, &pred_control_edges, &pred_in);\n+\n+  // We need to ensure that Pad only feeds to Conv2D (some other operator is\n+  // not expecting output of Pad). If this is not the case, then we cannot\n+  // merge Conv2D with Pad.\n+  const int kFirstOutputSlot = 0;\n+  for (const Edge* e : pred->out_edges()) {\n+    if (e->src_output() == kFirstOutputSlot && e->dst() != succ) {\n+      return Status(error::Code::INVALID_ARGUMENT,\n+                    \"Pad does not feed to Conv2D, or \"\n+                    \"it feeds Conv2D but has multiple outputs. \"\n+                    \"Will skip node merge optimization\");\n+    }\n+  }\n+\n+  // 2. Get inputs from both the nodes. ( ? ? Explanation of the following)\n+  // Find the 2 inputs from the Pad and the Filter input from the Conv2D.\n+  // Get operand 0, 1 of conv2D.\n+  CHECK_EQ(pred->in_edges().size(), 2);  // Pad must have 2 inputs.\n+  // Get operand 1 of add_bias???\n+  // Conv2D must have 2 inputs: pad output and Filter\n+  CHECK_EQ(succ->in_edges().size(), 2);\n+\n+  // We will use the node name of Conv2D as the name of new node\n+  // Build new node. We use same name as original node, but change the op\n+  // name.\n+  NodeBuilder nb(succ->name(), csinfo_.pad_with_conv2d);\n+  nb.Input(pred_in[0].first, pred_in[0].second);  // In1 (input data)  of Pad\n+  // pred_in[1] will be 2nd Tensorflow tensor for Conv2D.\n+  nb.Input(succ_in[1].first, succ_in[1].second);  // In2 (filter) of conv2d\n+  // In1 of Conv2D is same as output of Pad.\n+  // Thus, only need to add In2 of Conv2D\n+  nb.Input(pred_in[1].first, pred_in[1].second);  // In2 (paddings) of Pad\n+\n+  // Copy attributes from Pad and conv2D to PadWithConv2D.\n+  CopyAttrsFromPadAndConv2D(const_cast<const Node*>(succ), const_cast<const Node*>(pred),\n+                            &nb);\n+\n+  // Copy the device assigned to old node to new node.\n+  nb.Device(succ->def().device());\n+\n+  // Create node.\n+  Node* new_node;\n+  TF_CHECK_OK(nb.Finalize(&**g, &new_node));\n+  CHECK_NOTNULL(new_node);\n+\n+  // Incoming data edges from 'pred' node and 'succ' node to new 'new_node'\n+  // node are already copied in BuildNode. \n+  // We handle control edges now.\n+  for (const Edge* e : pred->in_edges()) {\n+    if (e->IsControlEdge()) {\n+      // Allow duplicate while adding control edge as it would fail (return\n+      // NULL) if we try to add duplicate edge.\n+      CHECK_NOTNULL((*g)->AddControlEdge(e->src(), new_node, true));\n+    }\n+  }\n+  for (const Edge* e : succ->in_edges()) {\n+    if (e->IsControlEdge()) {\n+      // Allow duplicate while adding control edge as it would fail (return\n+      // NULL) if we try to add duplicate edge.\n+      CHECK_NOTNULL((*g)->AddControlEdge(e->src(), new_node, true));\n+    }\n+  }", "path": "tensorflow/core/graph/mkl_layout_pass.cc", "position": 316, "original_position": 320, "commit_id": "48809b87793882266f01b7b40bc9e4a6e0f18f57", "original_commit_id": "dd63093a599081accfe2a2d2ca8c029d413a15d7", "user": {"login": "penpornk", "id": 38085909, "node_id": "MDQ6VXNlcjM4MDg1OTA5", "avatar_url": "https://avatars3.githubusercontent.com/u/38085909?v=4", "gravatar_id": "", "url": "https://api.github.com/users/penpornk", "html_url": "https://github.com/penpornk", "followers_url": "https://api.github.com/users/penpornk/followers", "following_url": "https://api.github.com/users/penpornk/following{/other_user}", "gists_url": "https://api.github.com/users/penpornk/gists{/gist_id}", "starred_url": "https://api.github.com/users/penpornk/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/penpornk/subscriptions", "organizations_url": "https://api.github.com/users/penpornk/orgs", "repos_url": "https://api.github.com/users/penpornk/repos", "events_url": "https://api.github.com/users/penpornk/events{/privacy}", "received_events_url": "https://api.github.com/users/penpornk/received_events", "type": "User", "site_admin": false}, "body": "I understand that the-allow-redundant-edge flag is set to true because the new merged node has the same name as Conv2D's, and that if any node happen to point to both Pad and Conv2D we won't have a problem adding the edge twice. \r\n\r\nAny (not-truly) redundant edges that happen because the new node and the old Conv2D node have the same name will be eliminated when the old Conv2D node is removed. But there doesn't seem to be a logic to eliminate/handle redundant edges from one node pointing to both Pad and Conv2D yet. Even if it is rare, it could still happen, and it might introduce an unwanted behavior in addition to just inefficiency. So, let's fix this now. (We should fix this for other ops that have a similar issue as well -- in a different PR).\r\n\r\nI can think of two ways to do this:\r\n1. In the loop adding the edges from `succ`, check if a control edge (that started from the same node) is already added. Only add a new edge if it isn't already in there; or\r\n2. Check for redundancies and eliminate them after removing `succ` and `pred`.\r\n\r\nWe should check for redundancy in outgoing control edges, i.e., when `Pad` and `Conv2D` point to the same node, as well.", "created_at": "2018-08-13T18:37:46Z", "updated_at": "2018-11-23T19:46:17Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/21318#discussion_r209714799", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21318", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/209714799"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/21318#discussion_r209714799"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/21318"}}, "body_html": "<p>I understand that the-allow-redundant-edge flag is set to true because the new merged node has the same name as Conv2D's, and that if any node happen to point to both Pad and Conv2D we won't have a problem adding the edge twice.</p>\n<p>Any (not-truly) redundant edges that happen because the new node and the old Conv2D node have the same name will be eliminated when the old Conv2D node is removed. But there doesn't seem to be a logic to eliminate/handle redundant edges from one node pointing to both Pad and Conv2D yet. Even if it is rare, it could still happen, and it might introduce an unwanted behavior in addition to just inefficiency. So, let's fix this now. (We should fix this for other ops that have a similar issue as well -- in a different PR).</p>\n<p>I can think of two ways to do this:</p>\n<ol>\n<li>In the loop adding the edges from <code>succ</code>, check if a control edge (that started from the same node) is already added. Only add a new edge if it isn't already in there; or</li>\n<li>Check for redundancies and eliminate them after removing <code>succ</code> and <code>pred</code>.</li>\n</ol>\n<p>We should check for redundancy in outgoing control edges, i.e., when <code>Pad</code> and <code>Conv2D</code> point to the same node, as well.</p>", "body_text": "I understand that the-allow-redundant-edge flag is set to true because the new merged node has the same name as Conv2D's, and that if any node happen to point to both Pad and Conv2D we won't have a problem adding the edge twice.\nAny (not-truly) redundant edges that happen because the new node and the old Conv2D node have the same name will be eliminated when the old Conv2D node is removed. But there doesn't seem to be a logic to eliminate/handle redundant edges from one node pointing to both Pad and Conv2D yet. Even if it is rare, it could still happen, and it might introduce an unwanted behavior in addition to just inefficiency. So, let's fix this now. (We should fix this for other ops that have a similar issue as well -- in a different PR).\nI can think of two ways to do this:\n\nIn the loop adding the edges from succ, check if a control edge (that started from the same node) is already added. Only add a new edge if it isn't already in there; or\nCheck for redundancies and eliminate them after removing succ and pred.\n\nWe should check for redundancy in outgoing control edges, i.e., when Pad and Conv2D point to the same node, as well.", "in_reply_to_id": 208335112}