{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11265", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11265/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11265/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11265/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11265", "id": 240334541, "node_id": "MDU6SXNzdWUyNDAzMzQ1NDE=", "number": 11265, "title": "faster-rcnn incompatible shapes randomly during training custom dataset", "user": {"login": "ckalas", "id": 8230386, "node_id": "MDQ6VXNlcjgyMzAzODY=", "avatar_url": "https://avatars2.githubusercontent.com/u/8230386?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ckalas", "html_url": "https://github.com/ckalas", "followers_url": "https://api.github.com/users/ckalas/followers", "following_url": "https://api.github.com/users/ckalas/following{/other_user}", "gists_url": "https://api.github.com/users/ckalas/gists{/gist_id}", "starred_url": "https://api.github.com/users/ckalas/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ckalas/subscriptions", "organizations_url": "https://api.github.com/users/ckalas/orgs", "repos_url": "https://api.github.com/users/ckalas/repos", "events_url": "https://api.github.com/users/ckalas/events{/privacy}", "received_events_url": "https://api.github.com/users/ckalas/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 6, "created_at": "2017-07-04T07:27:08Z", "updated_at": "2018-08-21T09:48:35Z", "closed_at": "2017-07-06T16:53:13Z", "author_association": "NONE", "body_html": "<p>I'm trying to train faster-rcnn with resnet101 on a custom dataset, which I have formatted appropriately for tf. When I run training, it can run anywhere from 30-1000 steps before it gives me an error like this:</p>\n<pre><code>File \"train.py\", line 195, in main\n   worker_job_name, is_chief, FLAGS.train_dir)\n File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 192, in train\n   clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\n File \"/home/chris/tensorflow/models/slim/deployment/model_deploy.py\", line 193, in create_clones\n   outputs = model_fn(*args, **kwargs)\n File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 133, in _create_losses\n   losses_dict = detection_model.loss(prediction_dict)\n File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1173, in loss\n   groundtruth_classes_with_background_list))\n File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1329, in _loss_box_classifier\n   batch_reg_targets, weights=batch_reg_weights) / normalizer\n File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 71, in __call__\n   return self._compute_loss(prediction_tensor, target_tensor, **params)\n File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 158, in _compute_loss\n   diff = prediction_tensor - target_tensor\n File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 846, in binary_op_wrapper\n   return func(x, y, name=name)\n File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2582, in _sub\n   result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n   op_def=op_def)\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,61,4] vs. [1,64,4]\n    [[Node: gradients/Loss/BoxClassifierLoss/Loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape, gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape_1)]]\n    [[Node: gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1/_3949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_22091_gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n</code></pre>\n<p>The dimension mismatch is from what I can tell from from looking in losses.py the number of anchors, but I really don't know how to try debug this. FWIW, the training on ssd runs without issue so far.</p>\n<p>A bit of info about the dataset, the images all contain multiple (likely crowded) of the same object.</p>", "body_text": "I'm trying to train faster-rcnn with resnet101 on a custom dataset, which I have formatted appropriately for tf. When I run training, it can run anywhere from 30-1000 steps before it gives me an error like this:\nFile \"train.py\", line 195, in main\n   worker_job_name, is_chief, FLAGS.train_dir)\n File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 192, in train\n   clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\n File \"/home/chris/tensorflow/models/slim/deployment/model_deploy.py\", line 193, in create_clones\n   outputs = model_fn(*args, **kwargs)\n File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 133, in _create_losses\n   losses_dict = detection_model.loss(prediction_dict)\n File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1173, in loss\n   groundtruth_classes_with_background_list))\n File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1329, in _loss_box_classifier\n   batch_reg_targets, weights=batch_reg_weights) / normalizer\n File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 71, in __call__\n   return self._compute_loss(prediction_tensor, target_tensor, **params)\n File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 158, in _compute_loss\n   diff = prediction_tensor - target_tensor\n File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 846, in binary_op_wrapper\n   return func(x, y, name=name)\n File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2582, in _sub\n   result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n   op_def=op_def)\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,61,4] vs. [1,64,4]\n    [[Node: gradients/Loss/BoxClassifierLoss/Loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape, gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape_1)]]\n    [[Node: gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1/_3949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_22091_gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nThe dimension mismatch is from what I can tell from from looking in losses.py the number of anchors, but I really don't know how to try debug this. FWIW, the training on ssd runs without issue so far.\nA bit of info about the dataset, the images all contain multiple (likely crowded) of the same object.", "body": "I'm trying to train faster-rcnn with resnet101 on a custom dataset, which I have formatted appropriately for tf. When I run training, it can run anywhere from 30-1000 steps before it gives me an error like this:\r\n\r\n ```\r\nFile \"train.py\", line 195, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 192, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"/home/chris/tensorflow/models/slim/deployment/model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"/home/chris/tensorflow/models/object_detection/trainer.py\", line 133, in _create_losses\r\n    losses_dict = detection_model.loss(prediction_dict)\r\n  File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1173, in loss\r\n    groundtruth_classes_with_background_list))\r\n  File \"/home/chris/tensorflow/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1329, in _loss_box_classifier\r\n    batch_reg_targets, weights=batch_reg_weights) / normalizer\r\n  File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 71, in __call__\r\n    return self._compute_loss(prediction_tensor, target_tensor, **params)\r\n  File \"/home/chris/tensorflow/models/object_detection/core/losses.py\", line 158, in _compute_loss\r\n    diff = prediction_tensor - target_tensor\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 846, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2582, in _sub\r\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n\r\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,61,4] vs. [1,64,4]\r\n\t [[Node: gradients/Loss/BoxClassifierLoss/Loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape, gradients/Loss/BoxClassifierLoss/Loss/sub_grad/Shape_1)]]\r\n\t [[Node: gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1/_3949 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_22091_gradients/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/batchnorm/mul_grad/tuple/control_dependency_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\n\r\n\r\nThe dimension mismatch is from what I can tell from from looking in losses.py the number of anchors, but I really don't know how to try debug this. FWIW, the training on ssd runs without issue so far.\r\n\r\nA bit of info about the dataset, the images all contain multiple (likely crowded) of the same object."}