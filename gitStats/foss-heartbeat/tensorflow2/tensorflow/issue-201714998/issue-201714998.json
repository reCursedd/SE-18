{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6943", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6943/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6943/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6943/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6943", "id": 201714998, "node_id": "MDU6SXNzdWUyMDE3MTQ5OTg=", "number": 6943, "title": "Adding new vocab words to seq2seq machine translation model during training?", "user": {"login": "jrthom18", "id": 9363452, "node_id": "MDQ6VXNlcjkzNjM0NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/9363452?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrthom18", "html_url": "https://github.com/jrthom18", "followers_url": "https://api.github.com/users/jrthom18/followers", "following_url": "https://api.github.com/users/jrthom18/following{/other_user}", "gists_url": "https://api.github.com/users/jrthom18/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrthom18/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrthom18/subscriptions", "organizations_url": "https://api.github.com/users/jrthom18/orgs", "repos_url": "https://api.github.com/users/jrthom18/repos", "events_url": "https://api.github.com/users/jrthom18/events{/privacy}", "received_events_url": "https://api.github.com/users/jrthom18/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-01-18T22:48:42Z", "updated_at": "2017-01-18T23:38:31Z", "closed_at": "2017-01-18T23:38:31Z", "author_association": "NONE", "body_html": "<p>I am using the seq2seq tutorial to play with machine translation. Say I have trained the model for some time and determine that I want to supplement the original vocab with new words to enhance the quality of the model. Is there a way to pause training, add words to the vocabulary, and then resume training from the most recent checkpoint? I attempted to do so but when I began training again I got this error:</p>\n<p>Traceback (most recent call last):<br>\nFile \"execute.py\", line 405, in <br>\ntrain()<br>\nFile \"execute.py\", line 127, in train<br>\nmodel = create_model(sess, False)<br>\nFile \"execute.py\", line 108, in create_model<br>\nmodel.saver.restore(session, ckpt.model_checkpoint_path)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-    packages/tensorflow/python/training/saver.py\", line 1388, in restore<br>\n{self.saver_def.filename_tensor_name: save_path})<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run<br>\nrun_metadata_ptr)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run<br>\nfeed_dict_string, options, run_metadata)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run<br>\ntarget_list, options, run_metadata)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign   requires shapes of both tensors to match. lhs shape= [384633] rhs shape=   [384617]<br>\n[[Node: save/Assign_82 = Assign[T=DT_FLOAT, _class=[\"loc:@proj_b\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](proj_b, save/RestoreV2_82)]]</p>\n<p>Caused by op u'save/Assign_82', defined at:<br>\nFile \"execute.py\", line 405, in <br>\ntrain()<br>\nFile \"execute.py\", line 127, in train<br>\nmodel = create_model(sess, False)<br>\nFile \"execute.py\", line 99, in create_model<br>\nmodel = seq2seq_model.Seq2SeqModel( gConfig['enc_vocab_size'],  gConfig['dec_vocab_size'], _buckets, gConfig['layer_size'], gConfig['num_layers'], gConfig['max_gradient_norm'], gConfig['batch_size'], gConfig['learning_rate'], gConfig['learning_rate_decay_factor'], forward_only=forward_only)<br>\nFile \"/home/jrthom18/data/3x256_bs32/easy_seq2seq/seq2seq_model.py\", line 166, in <strong>init</strong><br>\nself.saver = tf.train.Saver(tf.global_variables(), keep_checkpoint_every_n_hours=2.0)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1000, in <strong>init</strong><br>\nself.build()<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1030, in build<br>\nrestore_sequentially=self._restore_sequentially)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 624, in build<br>\nrestore_sequentially, reshape)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 373, in _AddRestoreOps<br>\nassign_ops.append(saveable.restore(tensors, shapes))<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 130, in restore<br>\nself.op.get_shape().is_fully_defined())<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign<br>\nuse_locking=use_locking, name=name)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op<br>\nop_def=op_def)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<p>InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [384633] rhs shape= [384617]<br>\n[[Node: save/Assign_82 = Assign[T=DT_FLOAT, _class=[\"loc:@proj_b\"],   use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](proj_b, save/RestoreV2_82)]]</p>\n<p>Obviously the new vocab is larger and so the tensor sizes do not match. Is there some way around this?</p>", "body_text": "I am using the seq2seq tutorial to play with machine translation. Say I have trained the model for some time and determine that I want to supplement the original vocab with new words to enhance the quality of the model. Is there a way to pause training, add words to the vocabulary, and then resume training from the most recent checkpoint? I attempted to do so but when I began training again I got this error:\nTraceback (most recent call last):\nFile \"execute.py\", line 405, in \ntrain()\nFile \"execute.py\", line 127, in train\nmodel = create_model(sess, False)\nFile \"execute.py\", line 108, in create_model\nmodel.saver.restore(session, ckpt.model_checkpoint_path)\nFile \"/home/jrthom18/.local/lib/python2.7/site-    packages/tensorflow/python/training/saver.py\", line 1388, in restore\n{self.saver_def.filename_tensor_name: save_path})\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\nrun_metadata_ptr)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\nfeed_dict_string, options, run_metadata)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\ntarget_list, options, run_metadata)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign   requires shapes of both tensors to match. lhs shape= [384633] rhs shape=   [384617]\n[[Node: save/Assign_82 = Assign[T=DT_FLOAT, _class=[\"loc:@proj_b\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](proj_b, save/RestoreV2_82)]]\nCaused by op u'save/Assign_82', defined at:\nFile \"execute.py\", line 405, in \ntrain()\nFile \"execute.py\", line 127, in train\nmodel = create_model(sess, False)\nFile \"execute.py\", line 99, in create_model\nmodel = seq2seq_model.Seq2SeqModel( gConfig['enc_vocab_size'],  gConfig['dec_vocab_size'], _buckets, gConfig['layer_size'], gConfig['num_layers'], gConfig['max_gradient_norm'], gConfig['batch_size'], gConfig['learning_rate'], gConfig['learning_rate_decay_factor'], forward_only=forward_only)\nFile \"/home/jrthom18/data/3x256_bs32/easy_seq2seq/seq2seq_model.py\", line 166, in init\nself.saver = tf.train.Saver(tf.global_variables(), keep_checkpoint_every_n_hours=2.0)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1000, in init\nself.build()\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\nrestore_sequentially=self._restore_sequentially)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 624, in build\nrestore_sequentially, reshape)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 373, in _AddRestoreOps\nassign_ops.append(saveable.restore(tensors, shapes))\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 130, in restore\nself.op.get_shape().is_fully_defined())\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\nuse_locking=use_locking, name=name)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\nop_def=op_def)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in init\nself._traceback = _extract_stack()\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [384633] rhs shape= [384617]\n[[Node: save/Assign_82 = Assign[T=DT_FLOAT, _class=[\"loc:@proj_b\"],   use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](proj_b, save/RestoreV2_82)]]\nObviously the new vocab is larger and so the tensor sizes do not match. Is there some way around this?", "body": "I am using the seq2seq tutorial to play with machine translation. Say I have trained the model for some time and determine that I want to supplement the original vocab with new words to enhance the quality of the model. Is there a way to pause training, add words to the vocabulary, and then resume training from the most recent checkpoint? I attempted to do so but when I began training again I got this error:\r\n\r\nTraceback (most recent call last):\r\nFile \"execute.py\", line 405, in <module>\r\ntrain()\r\nFile \"execute.py\", line 127, in train\r\nmodel = create_model(sess, False)\r\nFile \"execute.py\", line 108, in create_model\r\nmodel.saver.restore(session, ckpt.model_checkpoint_path)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-    packages/tensorflow/python/training/saver.py\", line 1388, in restore\r\n{self.saver_def.filename_tensor_name: save_path})\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\nrun_metadata_ptr)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\nfeed_dict_string, options, run_metadata)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\ntarget_list, options, run_metadata)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\nraise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign   requires shapes of both tensors to match. lhs shape= [384633] rhs shape=   [384617]\r\n [[Node: save/Assign_82 = Assign[T=DT_FLOAT, _class=[\"loc:@proj_b\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](proj_b, save/RestoreV2_82)]]\r\n\r\nCaused by op u'save/Assign_82', defined at:\r\nFile \"execute.py\", line 405, in <module>\r\ntrain()\r\nFile \"execute.py\", line 127, in train\r\nmodel = create_model(sess, False)\r\nFile \"execute.py\", line 99, in create_model\r\nmodel = seq2seq_model.Seq2SeqModel( gConfig['enc_vocab_size'],  gConfig['dec_vocab_size'], _buckets, gConfig['layer_size'], gConfig['num_layers'], gConfig['max_gradient_norm'], gConfig['batch_size'], gConfig['learning_rate'], gConfig['learning_rate_decay_factor'], forward_only=forward_only)\r\nFile \"/home/jrthom18/data/3x256_bs32/easy_seq2seq/seq2seq_model.py\", line 166, in __init__\r\nself.saver = tf.train.Saver(tf.global_variables(), keep_checkpoint_every_n_hours=2.0)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\r\nself.build()\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1030, in build\r\nrestore_sequentially=self._restore_sequentially)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 624, in build\r\nrestore_sequentially, reshape)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 373, in _AddRestoreOps\r\nassign_ops.append(saveable.restore(tensors, shapes))\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 130, in restore\r\nself.op.get_shape().is_fully_defined())\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\r\nuse_locking=use_locking, name=name)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\nop_def=op_def)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\noriginal_op=self._default_original_op, op_def=op_def)\r\nFile \"/home/jrthom18/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\nself._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [384633] rhs shape= [384617]\r\n [[Node: save/Assign_82 = Assign[T=DT_FLOAT, _class=[\"loc:@proj_b\"],   use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](proj_b, save/RestoreV2_82)]]\r\n\r\nObviously the new vocab is larger and so the tensor sizes do not match. Is there some way around this?"}