{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/422381886", "html_url": "https://github.com/tensorflow/tensorflow/issues/18394#issuecomment-422381886", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18394", "id": 422381886, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMjM4MTg4Ng==", "user": {"login": "Carl-Jensen-Bose", "id": 40073256, "node_id": "MDQ6VXNlcjQwMDczMjU2", "avatar_url": "https://avatars3.githubusercontent.com/u/40073256?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Carl-Jensen-Bose", "html_url": "https://github.com/Carl-Jensen-Bose", "followers_url": "https://api.github.com/users/Carl-Jensen-Bose/followers", "following_url": "https://api.github.com/users/Carl-Jensen-Bose/following{/other_user}", "gists_url": "https://api.github.com/users/Carl-Jensen-Bose/gists{/gist_id}", "starred_url": "https://api.github.com/users/Carl-Jensen-Bose/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Carl-Jensen-Bose/subscriptions", "organizations_url": "https://api.github.com/users/Carl-Jensen-Bose/orgs", "repos_url": "https://api.github.com/users/Carl-Jensen-Bose/repos", "events_url": "https://api.github.com/users/Carl-Jensen-Bose/events{/privacy}", "received_events_url": "https://api.github.com/users/Carl-Jensen-Bose/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-18T12:56:10Z", "updated_at": "2018-09-18T14:20:25Z", "author_association": "NONE", "body_html": "<p>I've had a problem with the the <code>stop_if_no_decrease</code> hook and I think I've found the problem in the code I changed below.</p>\n<p>The problem is that the python <code>dict.items()</code> method doesn't return entries in the order they went in. The indeterminate ordering means that the hook can trigger when it comes across any eval checkpoints that are more than max_steps apart without having come across a better eval inbetween.</p>\n<p>To fix it, I keep the best eval as well as the most current and check how far apart they are.</p>\n<div class=\"highlight highlight-source-diff\"><pre><span class=\"pl-c1\">diff --git a/tensorflow/contrib/estimator/python/estimator/early_stopping.py b/tensorflow/contrib/estimator/python/estimator/early_stopping.py</span>\nindex af4855e..194422b 100644\n<span class=\"pl-md\">--- a/tensorflow/contrib/estimator/python/estimator/early_stopping.py</span>\n<span class=\"pl-mi1\">+++ b/tensorflow/contrib/estimator/python/estimator/early_stopping.py</span>\n<span class=\"pl-mdr\">@@ -362,6 +362,8 @@</span> def _stop_if_no_metric_improvement_hook(\n\n     best_val = None\n     best_val_step = None\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>    current_val = None</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>    current_step = None</span>\n     for step, metrics in eval_results.items():\n       if step &lt; min_steps:\n         continue\n<span class=\"pl-mdr\">@@ -369,13 +371,16 @@</span> def _stop_if_no_metric_improvement_hook(\n       if best_val is None or is_lhs_better(val, best_val):\n         best_val = val\n         best_val_step = step\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>      if current_val is None or operator.gt(step, current_step):</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>        current_val = val</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>        current_val_step = step</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>    if current_val is not None:</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>      if current_step - best_val_step &gt;= max_steps_without_improvement:</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>        tf_logging.info(</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>            'No %s in metric \"%s\" for %s steps, which is greater than or equal '</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>            'to max steps (%s) configured for early stopping.',</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>            increase_or_decrease, metric_name, current_step - best_val_step,</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>            max_steps_without_improvement)</span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span>        return True</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>      if step - best_val_step &gt;= max_steps_without_improvement:</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>        tf_logging.info(</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>            'No %s in metric \"%s\" for %s steps, which is greater than or equal '</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>            'to max steps (%s) configured for early stopping.',</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>            increase_or_decrease, metric_name, step - best_val_step,</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>            max_steps_without_improvement)</span>\n<span class=\"pl-md\"><span class=\"pl-md\">-</span>        return True</span>\n     return False\n</pre></div>", "body_text": "I've had a problem with the the stop_if_no_decrease hook and I think I've found the problem in the code I changed below.\nThe problem is that the python dict.items() method doesn't return entries in the order they went in. The indeterminate ordering means that the hook can trigger when it comes across any eval checkpoints that are more than max_steps apart without having come across a better eval inbetween.\nTo fix it, I keep the best eval as well as the most current and check how far apart they are.\ndiff --git a/tensorflow/contrib/estimator/python/estimator/early_stopping.py b/tensorflow/contrib/estimator/python/estimator/early_stopping.py\nindex af4855e..194422b 100644\n--- a/tensorflow/contrib/estimator/python/estimator/early_stopping.py\n+++ b/tensorflow/contrib/estimator/python/estimator/early_stopping.py\n@@ -362,6 +362,8 @@ def _stop_if_no_metric_improvement_hook(\n\n     best_val = None\n     best_val_step = None\n+    current_val = None\n+    current_step = None\n     for step, metrics in eval_results.items():\n       if step < min_steps:\n         continue\n@@ -369,13 +371,16 @@ def _stop_if_no_metric_improvement_hook(\n       if best_val is None or is_lhs_better(val, best_val):\n         best_val = val\n         best_val_step = step\n+      if current_val is None or operator.gt(step, current_step):\n+        current_val = val\n+        current_val_step = step\n+    if current_val is not None:\n+      if current_step - best_val_step >= max_steps_without_improvement:\n+        tf_logging.info(\n+            'No %s in metric \"%s\" for %s steps, which is greater than or equal '\n+            'to max steps (%s) configured for early stopping.',\n+            increase_or_decrease, metric_name, current_step - best_val_step,\n+            max_steps_without_improvement)\n+        return True\n-      if step - best_val_step >= max_steps_without_improvement:\n-        tf_logging.info(\n-            'No %s in metric \"%s\" for %s steps, which is greater than or equal '\n-            'to max steps (%s) configured for early stopping.',\n-            increase_or_decrease, metric_name, step - best_val_step,\n-            max_steps_without_improvement)\n-        return True\n     return False", "body": "I've had a problem with the the `stop_if_no_decrease` hook and I think I've found the problem in the code I changed below. \r\n\r\nThe problem is that the python `dict.items()` method doesn't return entries in the order they went in. The indeterminate ordering means that the hook can trigger when it comes across any eval checkpoints that are more than max_steps apart without having come across a better eval inbetween. \r\n\r\nTo fix it, I keep the best eval as well as the most current and check how far apart they are.\r\n\r\n```diff\r\ndiff --git a/tensorflow/contrib/estimator/python/estimator/early_stopping.py b/tensorflow/contrib/estimator/python/estimator/early_stopping.py\r\nindex af4855e..194422b 100644\r\n--- a/tensorflow/contrib/estimator/python/estimator/early_stopping.py\r\n+++ b/tensorflow/contrib/estimator/python/estimator/early_stopping.py\r\n@@ -362,6 +362,8 @@ def _stop_if_no_metric_improvement_hook(\r\n\r\n     best_val = None\r\n     best_val_step = None\r\n+    current_val = None\r\n+    current_step = None\r\n     for step, metrics in eval_results.items():\r\n       if step < min_steps:\r\n         continue\r\n@@ -369,13 +371,16 @@ def _stop_if_no_metric_improvement_hook(\r\n       if best_val is None or is_lhs_better(val, best_val):\r\n         best_val = val\r\n         best_val_step = step\r\n+      if current_val is None or operator.gt(step, current_step):\r\n+        current_val = val\r\n+        current_val_step = step\r\n+    if current_val is not None:\r\n+      if current_step - best_val_step >= max_steps_without_improvement:\r\n+        tf_logging.info(\r\n+            'No %s in metric \"%s\" for %s steps, which is greater than or equal '\r\n+            'to max steps (%s) configured for early stopping.',\r\n+            increase_or_decrease, metric_name, current_step - best_val_step,\r\n+            max_steps_without_improvement)\r\n+        return True\r\n-      if step - best_val_step >= max_steps_without_improvement:\r\n-        tf_logging.info(\r\n-            'No %s in metric \"%s\" for %s steps, which is greater than or equal '\r\n-            'to max steps (%s) configured for early stopping.',\r\n-            increase_or_decrease, metric_name, step - best_val_step,\r\n-            max_steps_without_improvement)\r\n-        return True\r\n     return False\r\n\r\n```"}