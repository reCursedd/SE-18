{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/173261625", "html_url": "https://github.com/tensorflow/tensorflow/pull/662#issuecomment-173261625", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/662", "id": 173261625, "node_id": "MDEyOklzc3VlQ29tbWVudDE3MzI2MTYyNQ==", "user": {"login": "ppwwyyxx", "id": 1381301, "node_id": "MDQ6VXNlcjEzODEzMDE=", "avatar_url": "https://avatars3.githubusercontent.com/u/1381301?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ppwwyyxx", "html_url": "https://github.com/ppwwyyxx", "followers_url": "https://api.github.com/users/ppwwyyxx/followers", "following_url": "https://api.github.com/users/ppwwyyxx/following{/other_user}", "gists_url": "https://api.github.com/users/ppwwyyxx/gists{/gist_id}", "starred_url": "https://api.github.com/users/ppwwyyxx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ppwwyyxx/subscriptions", "organizations_url": "https://api.github.com/users/ppwwyyxx/orgs", "repos_url": "https://api.github.com/users/ppwwyyxx/repos", "events_url": "https://api.github.com/users/ppwwyyxx/events{/privacy}", "received_events_url": "https://api.github.com/users/ppwwyyxx/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-20T16:28:02Z", "updated_at": "2016-01-20T16:29:00Z", "author_association": "CONTRIBUTOR", "body_html": "<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> sys\n<span class=\"pl-k\">import</span> cv2\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">get_output</span>(<span class=\"pl-smi\">img</span>):\n    img <span class=\"pl-k\">=</span> tf.train.slice_input_producer([img], <span class=\"pl-v\">shuffle</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">capacity</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>)\n    img <span class=\"pl-k\">=</span> tf.train.batch(img, <span class=\"pl-c1\">128</span>)\n\n    img <span class=\"pl-k\">=</span> tf.reshape(img, [<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">28</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">28</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">3</span>])\n    W <span class=\"pl-k\">=</span> tf.get_variable(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>W<span class=\"pl-pds\">'</span></span>, [<span class=\"pl-c1\">28</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">28</span> <span class=\"pl-k\">*</span> <span class=\"pl-c1\">3</span>, <span class=\"pl-c1\">10</span>],\n                        <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span>tf.truncated_normal_initializer(<span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>))\n    out <span class=\"pl-k\">=</span> tf.matmul(img, W)\n    <span class=\"pl-k\">return</span> tf.sigmoid(out)\n\nG <span class=\"pl-k\">=</span> tf.Graph()\n<span class=\"pl-k\">with</span> G.as_default():\n    <span class=\"pl-c1\">FAKE</span> <span class=\"pl-k\">=</span> np.random.rand(<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">3</span>)\n    img <span class=\"pl-k\">=</span> tf.constant(<span class=\"pl-c1\">FAKE</span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">3</span>])\n    img <span class=\"pl-k\">=</span> tf.train.batch([img], <span class=\"pl-c1\">128</span>)\n    output <span class=\"pl-k\">=</span> get_output(img)\n\n    sess <span class=\"pl-k\">=</span> tf.Session()\n    sess.run(tf.initialize_all_variables())\n\n    coord <span class=\"pl-k\">=</span> tf.train.Coordinator()\n    tf.train.start_queue_runners(\n        <span class=\"pl-v\">sess</span><span class=\"pl-k\">=</span>sess, <span class=\"pl-v\">coord</span><span class=\"pl-k\">=</span>coord, <span class=\"pl-v\">daemon</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">start</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n    start <span class=\"pl-k\">=</span> time.time()\n    <span class=\"pl-k\">for</span> k <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>):\n        sess.run(output)\n        <span class=\"pl-c1\">print</span> k\n    <span class=\"pl-c1\">print</span> time.time() <span class=\"pl-k\">-</span> start, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> seconds<span class=\"pl-pds\">\"</span></span>\n    coord.request_stop()</pre></div>\n<p>I made a script for testing. On my laptop without GPU, I see the following numbers:</p>\n<ul>\n<li>Run with 0.6.0 release: 16s.</li>\n<li>With my patch: 0.25s</li>\n<li>Without <code>slice + batch</code> (delete the first two lines in <code>get_output</code>): 0.14s</li>\n</ul>\n<p>And it surprises me that a <code>slice + batch</code> can slow down the run time so much. Last time I tested (with real data and models) the difference wasn't that much.<br>\nI'm also interested in why that happens. Maybe there are ways to optimize this script that I didn't notice.</p>\n<p>Also, I noticed that if I passed a constant variable of shape 128x28x28x3 to <code>get_output</code> instead, there is no performance issue anymore.</p>", "body_text": "import tensorflow as tf\nimport numpy as np\nimport time\nimport sys\nimport cv2\n\ndef get_output(img):\n    img = tf.train.slice_input_producer([img], shuffle=False, capacity=32)\n    img = tf.train.batch(img, 128)\n\n    img = tf.reshape(img, [-1, 28 * 28 * 3])\n    W = tf.get_variable('W', [28 * 28 * 3, 10],\n                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n    out = tf.matmul(img, W)\n    return tf.sigmoid(out)\n\nG = tf.Graph()\nwith G.as_default():\n    FAKE = np.random.rand(28, 28, 3)\n    img = tf.constant(FAKE, dtype=tf.float32, shape=[28, 28, 3])\n    img = tf.train.batch([img], 128)\n    output = get_output(img)\n\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n\n    coord = tf.train.Coordinator()\n    tf.train.start_queue_runners(\n        sess=sess, coord=coord, daemon=True, start=True)\n\n    start = time.time()\n    for k in range(5):\n        sess.run(output)\n        print k\n    print time.time() - start, \" seconds\"\n    coord.request_stop()\nI made a script for testing. On my laptop without GPU, I see the following numbers:\n\nRun with 0.6.0 release: 16s.\nWith my patch: 0.25s\nWithout slice + batch (delete the first two lines in get_output): 0.14s\n\nAnd it surprises me that a slice + batch can slow down the run time so much. Last time I tested (with real data and models) the difference wasn't that much.\nI'm also interested in why that happens. Maybe there are ways to optimize this script that I didn't notice.\nAlso, I noticed that if I passed a constant variable of shape 128x28x28x3 to get_output instead, there is no performance issue anymore.", "body": "``` python\nimport tensorflow as tf\nimport numpy as np\nimport time\nimport sys\nimport cv2\n\ndef get_output(img):\n    img = tf.train.slice_input_producer([img], shuffle=False, capacity=32)\n    img = tf.train.batch(img, 128)\n\n    img = tf.reshape(img, [-1, 28 * 28 * 3])\n    W = tf.get_variable('W', [28 * 28 * 3, 10],\n                        initializer=tf.truncated_normal_initializer(stddev=0.1))\n    out = tf.matmul(img, W)\n    return tf.sigmoid(out)\n\nG = tf.Graph()\nwith G.as_default():\n    FAKE = np.random.rand(28, 28, 3)\n    img = tf.constant(FAKE, dtype=tf.float32, shape=[28, 28, 3])\n    img = tf.train.batch([img], 128)\n    output = get_output(img)\n\n    sess = tf.Session()\n    sess.run(tf.initialize_all_variables())\n\n    coord = tf.train.Coordinator()\n    tf.train.start_queue_runners(\n        sess=sess, coord=coord, daemon=True, start=True)\n\n    start = time.time()\n    for k in range(5):\n        sess.run(output)\n        print k\n    print time.time() - start, \" seconds\"\n    coord.request_stop()\n```\n\nI made a script for testing. On my laptop without GPU, I see the following numbers:\n- Run with 0.6.0 release: 16s.\n- With my patch: 0.25s\n- Without `slice + batch` (delete the first two lines in `get_output`): 0.14s\n\nAnd it surprises me that a `slice + batch` can slow down the run time so much. Last time I tested (with real data and models) the difference wasn't that much.\nI'm also interested in why that happens. Maybe there are ways to optimize this script that I didn't notice.\n\nAlso, I noticed that if I passed a constant variable of shape 128x28x28x3 to `get_output` instead, there is no performance issue anymore.\n"}