{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409624387", "html_url": "https://github.com/tensorflow/tensorflow/issues/21274#issuecomment-409624387", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21274", "id": 409624387, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTYyNDM4Nw==", "user": {"login": "yashk2810", "id": 14262417, "node_id": "MDQ6VXNlcjE0MjYyNDE3", "avatar_url": "https://avatars1.githubusercontent.com/u/14262417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yashk2810", "html_url": "https://github.com/yashk2810", "followers_url": "https://api.github.com/users/yashk2810/followers", "following_url": "https://api.github.com/users/yashk2810/following{/other_user}", "gists_url": "https://api.github.com/users/yashk2810/gists{/gist_id}", "starred_url": "https://api.github.com/users/yashk2810/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yashk2810/subscriptions", "organizations_url": "https://api.github.com/users/yashk2810/orgs", "repos_url": "https://api.github.com/users/yashk2810/repos", "events_url": "https://api.github.com/users/yashk2810/events{/privacy}", "received_events_url": "https://api.github.com/users/yashk2810/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-01T15:56:14Z", "updated_at": "2018-08-01T16:29:35Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=912111\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/olix20\">@olix20</a>  The docsting also specifies that if you use tf.data dataset, then the batch_size parameter won't be taken into consideration.</p>\n<p><code>batch_size: Integer or </code>None<code>. Number of samples per gradient update. If unspecified, </code>batch_size<code>will default to 32. Do not specify the</code>batch_size<code>if your data is in the form of symbolic tensors, datasets, or dataset iterators (since they generate batches).</code></p>\n<p>If you are creating a tf.data dataset for training, a tf.data dataset for testing and validation makes the most sense(it is only 1-2 lines of code), as everything is consistent and makes it easier to understand the flow. If you are using validation steps then it will be calculated according to the formula you mentioned above.</p>", "body_text": "@olix20  The docsting also specifies that if you use tf.data dataset, then the batch_size parameter won't be taken into consideration.\nbatch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_sizewill default to 32. Do not specify thebatch_sizeif your data is in the form of symbolic tensors, datasets, or dataset iterators (since they generate batches).\nIf you are creating a tf.data dataset for training, a tf.data dataset for testing and validation makes the most sense(it is only 1-2 lines of code), as everything is consistent and makes it easier to understand the flow. If you are using validation steps then it will be calculated according to the formula you mentioned above.", "body": "@olix20  The docsting also specifies that if you use tf.data dataset, then the batch_size parameter won't be taken into consideration. \r\n\r\n`batch_size: Integer or `None`.\r\n            Number of samples per gradient update.\r\n            If unspecified, `batch_size` will default to 32.\r\n            Do not specify the `batch_size` if your data is in the\r\n            form of symbolic tensors, datasets, or dataset iterators\r\n            (since they generate batches).\r\n`\r\n\r\nIf you are creating a tf.data dataset for training, a tf.data dataset for testing and validation makes the most sense(it is only 1-2 lines of code), as everything is consistent and makes it easier to understand the flow. If you are using validation steps then it will be calculated according to the formula you mentioned above. "}