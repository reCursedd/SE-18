{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21274", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21274/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21274/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21274/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21274", "id": 346172635, "node_id": "MDU6SXNzdWUzNDYxNzI2MzU=", "number": 21274, "title": "Using a tuple of Numpy arrays as validation_data fails when fitting a tf.keras model with a tf.data.Dataset", "user": {"login": "olix20", "id": 912111, "node_id": "MDQ6VXNlcjkxMjExMQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/912111?v=4", "gravatar_id": "", "url": "https://api.github.com/users/olix20", "html_url": "https://github.com/olix20", "followers_url": "https://api.github.com/users/olix20/followers", "following_url": "https://api.github.com/users/olix20/following{/other_user}", "gists_url": "https://api.github.com/users/olix20/gists{/gist_id}", "starred_url": "https://api.github.com/users/olix20/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/olix20/subscriptions", "organizations_url": "https://api.github.com/users/olix20/orgs", "repos_url": "https://api.github.com/users/olix20/repos", "events_url": "https://api.github.com/users/olix20/events{/privacy}", "received_events_url": "https://api.github.com/users/olix20/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-07-31T12:49:15Z", "updated_at": "2018-08-01T16:29:35Z", "closed_at": "2018-08-01T16:19:44Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Ubuntu 16.04</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: NA</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0</li>\n<li><strong>Python version</strong>: 3.6.6</li>\n<li><strong>CUDA/cuDNN version</strong>:9.2</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>model.fit(train_dataset,\n          steps_per_epoch=100,\n          validation_data=(val_samples, valid_targets),\n          epochs=10)\n</code></pre>\n<h3>Describe the problem</h3>\n<p>Usecase: train a tf.keras.Model using the <code>fit</code> method. I for training data I have a <code>tf.data.Dataset</code> but for  <code>validation_data</code> I'd like to have a prefetched tuple <code>(x_val, y_val)</code> of Numpy arrays. At the end of the epoch it fails with the error <code>TypeError: float() argument must be a string or a number, not 'NoneType'. </code></p>\n<p>It seems it's trying to calculate <code>validation_steps</code> but it fails. Passing <code>validation_steps</code> will avoid the exception but it's unnecessary and i'm not sure what the <code>fit</code> model does with it.</p>\n<h3>Source code / logs</h3>\n<pre><code>\n#### train Dataset\n\nwith tf.device('/cpu:0'):\n    dataset = tf.data.Dataset.from_tensor_slices(\n    (train_df.file.values, train_targets))\n    dataset = dataset.apply(\n        tf.contrib.data.shuffle_and_repeat(len(train_df)))\n    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n    map_func=proces_audio, batch_size=batch_size,\n        num_parallel_calls=64))\n\n#### model definition\nx_logml = tf.keras.Input(shape=(timesteps,input_dim))\nx = get_conv_layers(x_logml)  # returns a stack of conv/batch_norm/max_pool layers\nx = tf.keras.layers.Dense(128, activation = 'relu')(x) \nx = tf.keras.layers.Dense(len(classes), activation = 'softmax')(x)\nmodel = tf.keras.Model(inputs = x_logml, outputs = x)\nmodel.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n              loss=['categorical_crossentropy'],\n              metrics=['accuracy'])\n\nmodel.fit(dataset,\n          steps_per_epoch=100,\n          validation_data=(val_samples,valid_targets),\n#               validation_steps=10,  #including this line will avoid the exception, but not sure what's the point\n         epochs=10)\n</code></pre>\n<p>as a smoke test, I used <code>val_samples</code> and <code>valid_targets</code> as training data (<code>x</code> and <code>y</code>) and it runs fine. So the problem seems to be when using a <code>tf.data.Dataset</code> and <code>(x_val, y_val)</code>. Using a <code>tf.data.Dataset</code> as <code>validation_data</code> (with <code>validation_steps</code>) also works fine.</p>\n<p>error log at the end of epoch:</p>\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-22-b8d33816aaa6&gt; in &lt;module&gt;()\n      9               validation_data=(val_samples,valid_targets),#val_dataset,\n     10 #               validation_steps=len(valid_df)//16,\n---&gt; 11              epochs=100)\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1346           initial_epoch=initial_epoch,\n   1347           steps_per_epoch=steps_per_epoch,\n-&gt; 1348           validation_steps=validation_steps)\n   1349 \n   1350   def evaluate(self,\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n    218             batch_size=batch_size,\n    219             steps=validation_steps,\n--&gt; 220             verbose=0)\n    221         if not isinstance(val_outs, list):\n    222           val_outs = [val_outs]\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in test_loop(model, inputs, targets, sample_weights, batch_size, verbose, steps)\n    459         outs[i] /= steps\n    460   else:\n--&gt; 461     batches = make_batches(num_samples, batch_size)\n    462     index_array = np.arange(num_samples)\n    463     for batch_index, (batch_start, batch_end) in enumerate(batches):\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py in make_batches(size, batch_size)\n    465       A list of tuples of array indices.\n    466   \"\"\"\n--&gt; 467   num_batches = int(np.ceil(size / float(batch_size)))\n    468   return [(i * batch_size, min(size, (i + 1) * batch_size))\n    469           for i in range(0, num_batches)]\n\nTypeError: float() argument must be a string or a number, not 'NoneType'\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\nTensorFlow installed from (source or binary): pip\nTensorFlow version (use command below): 1.9.0\nPython version: 3.6.6\nCUDA/cuDNN version:9.2\nGPU model and memory: NA\nExact command to reproduce:\n\nmodel.fit(train_dataset,\n          steps_per_epoch=100,\n          validation_data=(val_samples, valid_targets),\n          epochs=10)\n\nDescribe the problem\nUsecase: train a tf.keras.Model using the fit method. I for training data I have a tf.data.Dataset but for  validation_data I'd like to have a prefetched tuple (x_val, y_val) of Numpy arrays. At the end of the epoch it fails with the error TypeError: float() argument must be a string or a number, not 'NoneType'. \nIt seems it's trying to calculate validation_steps but it fails. Passing validation_steps will avoid the exception but it's unnecessary and i'm not sure what the fit model does with it.\nSource code / logs\n\n#### train Dataset\n\nwith tf.device('/cpu:0'):\n    dataset = tf.data.Dataset.from_tensor_slices(\n    (train_df.file.values, train_targets))\n    dataset = dataset.apply(\n        tf.contrib.data.shuffle_and_repeat(len(train_df)))\n    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n    map_func=proces_audio, batch_size=batch_size,\n        num_parallel_calls=64))\n\n#### model definition\nx_logml = tf.keras.Input(shape=(timesteps,input_dim))\nx = get_conv_layers(x_logml)  # returns a stack of conv/batch_norm/max_pool layers\nx = tf.keras.layers.Dense(128, activation = 'relu')(x) \nx = tf.keras.layers.Dense(len(classes), activation = 'softmax')(x)\nmodel = tf.keras.Model(inputs = x_logml, outputs = x)\nmodel.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n              loss=['categorical_crossentropy'],\n              metrics=['accuracy'])\n\nmodel.fit(dataset,\n          steps_per_epoch=100,\n          validation_data=(val_samples,valid_targets),\n#               validation_steps=10,  #including this line will avoid the exception, but not sure what's the point\n         epochs=10)\n\nas a smoke test, I used val_samples and valid_targets as training data (x and y) and it runs fine. So the problem seems to be when using a tf.data.Dataset and (x_val, y_val). Using a tf.data.Dataset as validation_data (with validation_steps) also works fine.\nerror log at the end of epoch:\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-22-b8d33816aaa6> in <module>()\n      9               validation_data=(val_samples,valid_targets),#val_dataset,\n     10 #               validation_steps=len(valid_df)//16,\n---> 11              epochs=100)\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n   1346           initial_epoch=initial_epoch,\n   1347           steps_per_epoch=steps_per_epoch,\n-> 1348           validation_steps=validation_steps)\n   1349 \n   1350   def evaluate(self,\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n    218             batch_size=batch_size,\n    219             steps=validation_steps,\n--> 220             verbose=0)\n    221         if not isinstance(val_outs, list):\n    222           val_outs = [val_outs]\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in test_loop(model, inputs, targets, sample_weights, batch_size, verbose, steps)\n    459         outs[i] /= steps\n    460   else:\n--> 461     batches = make_batches(num_samples, batch_size)\n    462     index_array = np.arange(num_samples)\n    463     for batch_index, (batch_start, batch_end) in enumerate(batches):\n\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py in make_batches(size, batch_size)\n    465       A list of tuples of array indices.\n    466   \"\"\"\n--> 467   num_batches = int(np.ceil(size / float(batch_size)))\n    468   return [(i * batch_size, min(size, (i + 1) * batch_size))\n    469           for i in range(0, num_batches)]\n\nTypeError: float() argument must be a string or a number, not 'NoneType'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.6.6\r\n- **CUDA/cuDNN version**:9.2\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n```\r\nmodel.fit(train_dataset,\r\n          steps_per_epoch=100,\r\n          validation_data=(val_samples, valid_targets),\r\n          epochs=10)\r\n```\r\n### Describe the problem\r\nUsecase: train a tf.keras.Model using the `fit` method. I for training data I have a `tf.data.Dataset` but for  `validation_data` I'd like to have a prefetched tuple `(x_val, y_val)` of Numpy arrays. At the end of the epoch it fails with the error `TypeError: float() argument must be a string or a number, not 'NoneType'. `\r\n\r\nIt seems it's trying to calculate `validation_steps` but it fails. Passing `validation_steps` will avoid the exception but it's unnecessary and i'm not sure what the `fit` model does with it.\r\n\r\n### Source code / logs\r\n\r\n```\r\n\r\n#### train Dataset\r\n\r\nwith tf.device('/cpu:0'):\r\n    dataset = tf.data.Dataset.from_tensor_slices(\r\n    (train_df.file.values, train_targets))\r\n    dataset = dataset.apply(\r\n        tf.contrib.data.shuffle_and_repeat(len(train_df)))\r\n    dataset = dataset.apply(tf.contrib.data.map_and_batch(\r\n    map_func=proces_audio, batch_size=batch_size,\r\n        num_parallel_calls=64))\r\n\r\n#### model definition\r\nx_logml = tf.keras.Input(shape=(timesteps,input_dim))\r\nx = get_conv_layers(x_logml)  # returns a stack of conv/batch_norm/max_pool layers\r\nx = tf.keras.layers.Dense(128, activation = 'relu')(x) \r\nx = tf.keras.layers.Dense(len(classes), activation = 'softmax')(x)\r\nmodel = tf.keras.Model(inputs = x_logml, outputs = x)\r\nmodel.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \r\n              loss=['categorical_crossentropy'],\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(dataset,\r\n          steps_per_epoch=100,\r\n          validation_data=(val_samples,valid_targets),\r\n#               validation_steps=10,  #including this line will avoid the exception, but not sure what's the point\r\n         epochs=10)\r\n```\r\n\r\nas a smoke test, I used `val_samples` and `valid_targets` as training data (`x` and `y`) and it runs fine. So the problem seems to be when using a `tf.data.Dataset` and `(x_val, y_val)`. Using a `tf.data.Dataset` as `validation_data` (with `validation_steps`) also works fine.\r\n\r\n\r\n\r\nerror log at the end of epoch:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-22-b8d33816aaa6> in <module>()\r\n      9               validation_data=(val_samples,valid_targets),#val_dataset,\r\n     10 #               validation_steps=len(valid_df)//16,\r\n---> 11              epochs=100)\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n   1346           initial_epoch=initial_epoch,\r\n   1347           steps_per_epoch=steps_per_epoch,\r\n-> 1348           validation_steps=validation_steps)\r\n   1349 \r\n   1350   def evaluate(self,\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in fit_loop(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\r\n    218             batch_size=batch_size,\r\n    219             steps=validation_steps,\r\n--> 220             verbose=0)\r\n    221         if not isinstance(val_outs, list):\r\n    222           val_outs = [val_outs]\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py in test_loop(model, inputs, targets, sample_weights, batch_size, verbose, steps)\r\n    459         outs[i] /= steps\r\n    460   else:\r\n--> 461     batches = make_batches(num_samples, batch_size)\r\n    462     index_array = np.arange(num_samples)\r\n    463     for batch_index, (batch_start, batch_end) in enumerate(batches):\r\n\r\n~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py in make_batches(size, batch_size)\r\n    465       A list of tuples of array indices.\r\n    466   \"\"\"\r\n--> 467   num_batches = int(np.ceil(size / float(batch_size)))\r\n    468   return [(i * batch_size, min(size, (i + 1) * batch_size))\r\n    469           for i in range(0, num_batches)]\r\n\r\nTypeError: float() argument must be a string or a number, not 'NoneType'\r\n```"}