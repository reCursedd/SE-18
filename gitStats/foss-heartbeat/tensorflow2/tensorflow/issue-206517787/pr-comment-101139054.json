{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/101139054", "pull_request_review_id": 21859780, "id": 101139054, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDEwMTEzOTA1NA==", "diff_hunk": "@@ -324,13 +324,43 @@ def sort_key(input_index, a):\n     num_summed_elements = _total_size(t0_shape[-len(axes_to_sum):])\n     new_shape = t0_shape[:len(preserved_axes)] + (num_broadcast_elements_t0,\n                                                   num_summed_elements)\n+    # Make new_shape valid, if invalid to be used in reshape\n+    none_dims = [i for i, d in enumerate(new_shape)", "path": "tensorflow/python/ops/special_math_ops.py", "position": null, "original_position": 5, "commit_id": "1d849832d6c5b63ff5136a4ca72e13f2e5c4a236", "original_commit_id": "6274c6e011b0e943dfc761f692df28bf926f6c4e", "user": {"login": "mstreeter", "id": 2622806, "node_id": "MDQ6VXNlcjI2MjI4MDY=", "avatar_url": "https://avatars1.githubusercontent.com/u/2622806?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mstreeter", "html_url": "https://github.com/mstreeter", "followers_url": "https://api.github.com/users/mstreeter/followers", "following_url": "https://api.github.com/users/mstreeter/following{/other_user}", "gists_url": "https://api.github.com/users/mstreeter/gists{/gist_id}", "starred_url": "https://api.github.com/users/mstreeter/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mstreeter/subscriptions", "organizations_url": "https://api.github.com/users/mstreeter/orgs", "repos_url": "https://api.github.com/users/mstreeter/repos", "events_url": "https://api.github.com/users/mstreeter/events{/privacy}", "received_events_url": "https://api.github.com/users/mstreeter/received_events", "type": "User", "site_admin": false}, "body": "Rather than defining new_shape in terms of get_shape() values (on line 325) and then fixing it here if necessary, could we just define new_shape in terms of array_ops.shape initially?  In other words, something like:\r\n\r\nt0_shape = array_ops.shape(t0)\r\nt1_shape = array_ops.shape(t1)\r\nnum_summed_elements = math_ops.reduce_prod(t0_shape[len(preserved_axes):-len(axes_to_sum)])\r\nnum_broadcast_elements_t1 = math.ops.reduce_prod(t0_shape[-len(axes_to_sum):])\r\nnew_shape = t1_shape[:len(preserved_axes)] + (num_summed_elements, num_broadcast_elements_t1)\r\n\r\nYou could do the same for lines 344-348, and then remove the _total_size() method.  It seems like this would also let you remove the logic for fixing uncompacted_shape below.", "created_at": "2017-02-14T20:47:02Z", "updated_at": "2017-02-17T01:56:08Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/7387#discussion_r101139054", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7387", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/101139054"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/7387#discussion_r101139054"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/7387"}}, "body_html": "<p>Rather than defining new_shape in terms of get_shape() values (on line 325) and then fixing it here if necessary, could we just define new_shape in terms of array_ops.shape initially?  In other words, something like:</p>\n<p>t0_shape = array_ops.shape(t0)<br>\nt1_shape = array_ops.shape(t1)<br>\nnum_summed_elements = math_ops.reduce_prod(t0_shape[len(preserved_axes):-len(axes_to_sum)])<br>\nnum_broadcast_elements_t1 = math.ops.reduce_prod(t0_shape[-len(axes_to_sum):])<br>\nnew_shape = t1_shape[:len(preserved_axes)] + (num_summed_elements, num_broadcast_elements_t1)</p>\n<p>You could do the same for lines 344-348, and then remove the _total_size() method.  It seems like this would also let you remove the logic for fixing uncompacted_shape below.</p>", "body_text": "Rather than defining new_shape in terms of get_shape() values (on line 325) and then fixing it here if necessary, could we just define new_shape in terms of array_ops.shape initially?  In other words, something like:\nt0_shape = array_ops.shape(t0)\nt1_shape = array_ops.shape(t1)\nnum_summed_elements = math_ops.reduce_prod(t0_shape[len(preserved_axes):-len(axes_to_sum)])\nnum_broadcast_elements_t1 = math.ops.reduce_prod(t0_shape[-len(axes_to_sum):])\nnew_shape = t1_shape[:len(preserved_axes)] + (num_summed_elements, num_broadcast_elements_t1)\nYou could do the same for lines 344-348, and then remove the _total_size() method.  It seems like this would also let you remove the logic for fixing uncompacted_shape below.", "in_reply_to_id": 100726342}