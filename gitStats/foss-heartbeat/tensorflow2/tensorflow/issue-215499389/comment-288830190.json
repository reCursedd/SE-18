{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/288830190", "html_url": "https://github.com/tensorflow/tensorflow/issues/8560#issuecomment-288830190", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8560", "id": 288830190, "node_id": "MDEyOklzc3VlQ29tbWVudDI4ODgzMDE5MA==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-23T19:12:22Z", "updated_at": "2017-03-23T19:12:22Z", "author_association": "MEMBER", "body_html": "<p>Note that there is another plausible design solution to this problem.  If your CPU has enough RAM for this purpose, a large area could be carved out, pre-locked for DMA, then a BFCAllocator or similar could be provisioned on top of that.  The PoolAllocator is a simple solution that works well enough when there's a small, fixed number of Tensor sizes on the GPU.  I don't have time to work on the more complex solution right now, and it's probably of little value for most users.</p>", "body_text": "Note that there is another plausible design solution to this problem.  If your CPU has enough RAM for this purpose, a large area could be carved out, pre-locked for DMA, then a BFCAllocator or similar could be provisioned on top of that.  The PoolAllocator is a simple solution that works well enough when there's a small, fixed number of Tensor sizes on the GPU.  I don't have time to work on the more complex solution right now, and it's probably of little value for most users.", "body": "Note that there is another plausible design solution to this problem.  If your CPU has enough RAM for this purpose, a large area could be carved out, pre-locked for DMA, then a BFCAllocator or similar could be provisioned on top of that.  The PoolAllocator is a simple solution that works well enough when there's a small, fixed number of Tensor sizes on the GPU.  I don't have time to work on the more complex solution right now, and it's probably of little value for most users.  "}