{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/320177518", "html_url": "https://github.com/tensorflow/tensorflow/issues/12002#issuecomment-320177518", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12002", "id": 320177518, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMDE3NzUxOA==", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-04T07:24:22Z", "updated_at": "2017-08-04T07:31:27Z", "author_association": "NONE", "body_html": "<p>Could you please put some of the consistent results you have please ? Because I don't have the same results at all ... Here are the results when I replace <code>tf.log(tf.nn.softmax(logits) + 1e-10)</code> by <code>tf.nn.log_softmax(logits)</code> on 3 different runs :</p>\n<h4>run 1</h4>\n<p>mathematical :  9671.87484341<br>\nsparse_softmax_cross_entropy :  1208.98436916</p>\n<h4>run 2</h4>\n<p>mathematical :  30372.4364977<br>\nsparse_softmax_cross_entropy :  3796.55453706</p>\n<h4>run 3</h4>\n<p>mathematical :  9671.87484341<br>\nsparse_softmax_cross_entropy :  1208.98436916</p>\n<p>Any Idea why ? A numerical stability issue ?</p>", "body_text": "Could you please put some of the consistent results you have please ? Because I don't have the same results at all ... Here are the results when I replace tf.log(tf.nn.softmax(logits) + 1e-10) by tf.nn.log_softmax(logits) on 3 different runs :\nrun 1\nmathematical :  9671.87484341\nsparse_softmax_cross_entropy :  1208.98436916\nrun 2\nmathematical :  30372.4364977\nsparse_softmax_cross_entropy :  3796.55453706\nrun 3\nmathematical :  9671.87484341\nsparse_softmax_cross_entropy :  1208.98436916\nAny Idea why ? A numerical stability issue ?", "body": "Could you please put some of the consistent results you have please ? Because I don't have the same results at all ... Here are the results when I replace `tf.log(tf.nn.softmax(logits) + 1e-10)` by `tf.nn.log_softmax(logits)` on 3 different runs :  \r\n#### run 1\r\nmathematical :  9671.87484341\r\nsparse_softmax_cross_entropy :  1208.98436916\r\n\r\n#### run 2\r\nmathematical :  30372.4364977\r\nsparse_softmax_cross_entropy :  3796.55453706\r\n\r\n#### run 3\r\nmathematical :  9671.87484341\r\nsparse_softmax_cross_entropy :  1208.98436916 \r\n\r\nAny Idea why ? A numerical stability issue ?"}