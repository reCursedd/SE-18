{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14402", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14402/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14402/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14402/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/14402", "id": 272515179, "node_id": "MDU6SXNzdWUyNzI1MTUxNzk=", "number": 14402, "title": "Encountered a training error when using slim with multi-GPU connect by PIX type", "user": {"login": "BobLiu20", "id": 6102702, "node_id": "MDQ6VXNlcjYxMDI3MDI=", "avatar_url": "https://avatars1.githubusercontent.com/u/6102702?v=4", "gravatar_id": "", "url": "https://api.github.com/users/BobLiu20", "html_url": "https://github.com/BobLiu20", "followers_url": "https://api.github.com/users/BobLiu20/followers", "following_url": "https://api.github.com/users/BobLiu20/following{/other_user}", "gists_url": "https://api.github.com/users/BobLiu20/gists{/gist_id}", "starred_url": "https://api.github.com/users/BobLiu20/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/BobLiu20/subscriptions", "organizations_url": "https://api.github.com/users/BobLiu20/orgs", "repos_url": "https://api.github.com/users/BobLiu20/repos", "events_url": "https://api.github.com/users/BobLiu20/events{/privacy}", "received_events_url": "https://api.github.com/users/BobLiu20/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2017-11-09T10:35:58Z", "updated_at": "2018-09-18T18:53:44Z", "closed_at": "2017-12-21T01:37:44Z", "author_association": "NONE", "body_html": "<p>Hi all, I encountered a training error when I training model in multi GPU.<br>\nThe key condition is using slim to write model and training in multi GPU(GTX TITAN X) which connect by PIX type.</p>\n<p>How to reproduce:</p>\n<ul>\n<li>\n<ol>\n<li>checkout office code in <a href=\"https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10\">here</a></li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li>copy code in below(slim model code) and replace it to cifar10.py file. (Because only slim code can reproduce this issue)</li>\n</ol>\n</li>\n<li>\n<ol start=\"3\">\n<li>start to training: <code>CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2</code></li>\n</ol>\n</li>\n<li>\n<ol start=\"4\">\n<li>an incorrect loss will appear. (Also GPU usage is incorrect)</li>\n</ol>\n</li>\n</ul>\n<p>Note 1: Check GPU info in below. this issue only happend when I using GPU 0,1 or GPU 2,3 or GPU 4,5 or GPU 6,7(connect by PIX). In this case, everything is ok If I using other combinations<br>\nNote 2: I can't reproduce this issue in GTX 1080 ti</p>\n<p>Thank you so much!</p>\n<p>The training error log in below:</p>\n<pre><code>linux@172.25.52.02:~/models/tutorials/image/cifar10: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n2017-11-09 18:13:02.264529: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are\navailable on your machine and could speed up CPU computations.\n2017-11-09 18:13:06.359127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:05:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\n2017-11-09 18:13:06.784690: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f00120 exists before initializing the StreamExecutor\n. We haven't verified StreamExecutor works with that.\n2017-11-09 18:13:06.786072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\n2017-11-09 18:13:06.786507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1\n2017-11-09 18:13:06.786527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y\n2017-11-09 18:13:06.786592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y\n2017-11-09 18:13:06.786623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n2017-11-09 18:13:06.786635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\n2017-11-09 18:13:06.830077: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0\n2017-11-09 18:13:06.830125: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0\n2017-11-09 18:13:09.804877: step 0, loss = 2.30 (119.9 examples/sec; 1.067 sec/batch)\n2017-11-09 18:13:17.096214: step 10, loss = 2.30 (421.3 examples/sec; 0.304 sec/batch)\n2017-11-09 18:13:23.708459: step 20, loss = 2.30 (390.0 examples/sec; 0.328 sec/batch)\n2017-11-09 18:13:31.362454: step 30, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)\n2017-11-09 18:13:38.225150: step 40, loss = 2.30 (363.3 examples/sec; 0.352 sec/batch)\n2017-11-09 18:13:44.695175: step 50, loss = 2.30 (389.8 examples/sec; 0.328 sec/batch)\n2017-11-09 18:13:51.994245: step 60, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)\n2017-11-09 18:13:58.623306: step 70, loss = 2.30 (421.2 examples/sec; 0.304 sec/batch)\n2017-11-09 18:14:05.480061: step 80, loss = 2.30 (390.6 examples/sec; 0.328 sec/batch)\n2017-11-09 18:14:11.952376: step 90, loss = 2.30 (389.2 examples/sec; 0.329 sec/batch)\n2017-11-09 18:14:18.375831: step 100, loss = 293778.34 (362.7 examples/sec; 0.353 sec/batch)\nTraceback (most recent call last):\n  File \"cifar10_multi_gpu_train.py\", line 283, in &lt;module&gt;\n    tf.app.run()\n  File \"/home/zhangjiguo/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"cifar10_multi_gpu_train.py\", line 278, in main\n    train()\n  File \"cifar10_multi_gpu_train.py\", line 251, in train\n    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\nAssertionError: Model diverged with loss = NaN\n</code></pre>\n<p>My GPU list with command <code>nvidia-smi -L</code></p>\n<pre><code>GPU 0: GeForce GTX TITAN X (UUID: GPU-2c9601fc-369e-fce7-d139-8c7144700def)\nGPU 1: GeForce GTX TITAN X (UUID: GPU-eb4d8327-7058-39fe-e510-3437fe258745)\nGPU 2: GeForce GTX TITAN X (UUID: GPU-62fbacf7-0120-5c6b-ceea-ad026fddc537)\nGPU 3: GeForce GTX TITAN X (UUID: GPU-15be755d-9982-f4f4-4455-1d648d836b6e)\nGPU 4: GeForce GTX TITAN X (UUID: GPU-e48fae89-debd-9769-3851-61ba44acd6e1)\nGPU 5: GeForce GTX TITAN X (UUID: GPU-f796ad02-e104-04b5-d6c1-ff72d872654f)\nGPU 6: GeForce GTX TITAN X (UUID: GPU-7e27fd1e-ba3b-2dd3-6d03-960b8c76a0be)\nGPU 7: GeForce GTX TITAN X (UUID: GPU-8de522e7-f375-ab05-28ff-5ddfd9e325b0)\n</code></pre>\n<p>and GPU connection info with command <code>nvidia-smi topo -m</code></p>\n<pre><code>       \tGPU0   \tGPU1   \tGPU2   \tGPU3   \tGPU4   \tGPU5   \tGPU6   \tGPU7   \tmlx4_0 \tCPU Affinity\nGPU0   \t X     \tPIX    \tPHB    \tPHB    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU1   \tPIX    \t X     \tPHB    \tPHB    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU2   \tPHB    \tPHB    \t X     \tPIX    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU3   \tPHB    \tPHB    \tPIX    \t X     \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU4   \tSOC    \tSOC    \tSOC    \tSOC    \t X     \tPIX    \tPHB    \tPHB    \tPHB    \t14-27,42-55\nGPU5   \tSOC    \tSOC    \tSOC    \tSOC    \tPIX    \t X     \tPHB    \tPHB    \tPHB    \t14-27,42-55\nGPU6   \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \t X     \tPIX    \tPHB    \t14-27,42-55\nGPU7   \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \tPIX    \t X     \tPHB    \t14-27,42-55\nmlx4_0 \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \tPHB    \tPHB    \t X\n\nLegend:\n\n  X   = Self\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing a single PCIe switch\n  NV#  = Connection traversing a bonded set of # NVLinks\n</code></pre>\n<p>slim model code: (Please replace these code to cifar10.py)</p>\n<pre><code>def inference(images):\n\t# reimplement by slim\n    slim = tf.contrib.slim\n    conv1 = slim.conv2d(images, 64, [5, 5], scope='conv1',\n                       weights_regularizer=slim.l2_regularizer(0.0),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n                       activation_fn=tf.nn.relu)\n    pool1 = slim.max_pool2d(conv1, [3, 3], 2, padding='SAME', scope='poll1')\n    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n    conv2 = slim.conv2d(norm1, 64, [5, 5], scope='conv2',\n                       weights_regularizer=slim.l2_regularizer(0.0),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=5e-2),\n                       biases_initializer=tf.constant_initializer(0.1),\n                       activation_fn=tf.nn.relu)\n    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n    pool2 = slim.max_pool2d(norm2, [3, 3], 2, padding='SAME', scope='poll2')\n    flatten2 = slim.flatten(pool2)\n    local3 = slim.fully_connected(flatten2, 384, scope='local3',\n                       weights_regularizer=slim.l2_regularizer(0.004),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),\n                       biases_initializer=tf.constant_initializer(0.1),\n                       activation_fn=tf.nn.relu)\n    local4 = slim.fully_connected(local3, 192, scope='local4',\n                       weights_regularizer=slim.l2_regularizer(0.004),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),\n                       biases_initializer=tf.constant_initializer(0.1),\n                       activation_fn=tf.nn.relu)\n    softmax_linear = slim.fully_connected(local4, NUM_CLASSES, scope='softmax_linear',\n                       weights_regularizer=slim.l2_regularizer(0.0),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=1/192.0),\n                       biases_initializer=tf.constant_initializer(0.0),\n                       activation_fn=None)\n    return softmax_linear\n</code></pre>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: no</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:CentOS Linux release 7.2.1511</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:source</li>\n<li><strong>TensorFlow version (use command below)</strong>:Tensorflow 1.2.0/ 1.0.1</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 1.4.5</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:4.8.5</li>\n<li><strong>CUDA/cuDNN version</strong>:CUDA 8.0 and cuDNN 5.0</li>\n<li><strong>GPU model and memory</strong>:TITAN X with 12GB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>", "body_text": "Hi all, I encountered a training error when I training model in multi GPU.\nThe key condition is using slim to write model and training in multi GPU(GTX TITAN X) which connect by PIX type.\nHow to reproduce:\n\n\n\ncheckout office code in here\n\n\n\n\ncopy code in below(slim model code) and replace it to cifar10.py file. (Because only slim code can reproduce this issue)\n\n\n\n\nstart to training: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2\n\n\n\n\nan incorrect loss will appear. (Also GPU usage is incorrect)\n\n\n\nNote 1: Check GPU info in below. this issue only happend when I using GPU 0,1 or GPU 2,3 or GPU 4,5 or GPU 6,7(connect by PIX). In this case, everything is ok If I using other combinations\nNote 2: I can't reproduce this issue in GTX 1080 ti\nThank you so much!\nThe training error log in below:\nlinux@172.25.52.02:~/models/tutorials/image/cifar10: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n2017-11-09 18:13:02.264529: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are\navailable on your machine and could speed up CPU computations.\n2017-11-09 18:13:06.359127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:05:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\n2017-11-09 18:13:06.784690: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f00120 exists before initializing the StreamExecutor\n. We haven't verified StreamExecutor works with that.\n2017-11-09 18:13:06.786072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\n2017-11-09 18:13:06.786507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1\n2017-11-09 18:13:06.786527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y\n2017-11-09 18:13:06.786592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y\n2017-11-09 18:13:06.786623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\n2017-11-09 18:13:06.786635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\n2017-11-09 18:13:06.830077: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0\n2017-11-09 18:13:06.830125: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0\n2017-11-09 18:13:09.804877: step 0, loss = 2.30 (119.9 examples/sec; 1.067 sec/batch)\n2017-11-09 18:13:17.096214: step 10, loss = 2.30 (421.3 examples/sec; 0.304 sec/batch)\n2017-11-09 18:13:23.708459: step 20, loss = 2.30 (390.0 examples/sec; 0.328 sec/batch)\n2017-11-09 18:13:31.362454: step 30, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)\n2017-11-09 18:13:38.225150: step 40, loss = 2.30 (363.3 examples/sec; 0.352 sec/batch)\n2017-11-09 18:13:44.695175: step 50, loss = 2.30 (389.8 examples/sec; 0.328 sec/batch)\n2017-11-09 18:13:51.994245: step 60, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)\n2017-11-09 18:13:58.623306: step 70, loss = 2.30 (421.2 examples/sec; 0.304 sec/batch)\n2017-11-09 18:14:05.480061: step 80, loss = 2.30 (390.6 examples/sec; 0.328 sec/batch)\n2017-11-09 18:14:11.952376: step 90, loss = 2.30 (389.2 examples/sec; 0.329 sec/batch)\n2017-11-09 18:14:18.375831: step 100, loss = 293778.34 (362.7 examples/sec; 0.353 sec/batch)\nTraceback (most recent call last):\n  File \"cifar10_multi_gpu_train.py\", line 283, in <module>\n    tf.app.run()\n  File \"/home/zhangjiguo/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"cifar10_multi_gpu_train.py\", line 278, in main\n    train()\n  File \"cifar10_multi_gpu_train.py\", line 251, in train\n    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\nAssertionError: Model diverged with loss = NaN\n\nMy GPU list with command nvidia-smi -L\nGPU 0: GeForce GTX TITAN X (UUID: GPU-2c9601fc-369e-fce7-d139-8c7144700def)\nGPU 1: GeForce GTX TITAN X (UUID: GPU-eb4d8327-7058-39fe-e510-3437fe258745)\nGPU 2: GeForce GTX TITAN X (UUID: GPU-62fbacf7-0120-5c6b-ceea-ad026fddc537)\nGPU 3: GeForce GTX TITAN X (UUID: GPU-15be755d-9982-f4f4-4455-1d648d836b6e)\nGPU 4: GeForce GTX TITAN X (UUID: GPU-e48fae89-debd-9769-3851-61ba44acd6e1)\nGPU 5: GeForce GTX TITAN X (UUID: GPU-f796ad02-e104-04b5-d6c1-ff72d872654f)\nGPU 6: GeForce GTX TITAN X (UUID: GPU-7e27fd1e-ba3b-2dd3-6d03-960b8c76a0be)\nGPU 7: GeForce GTX TITAN X (UUID: GPU-8de522e7-f375-ab05-28ff-5ddfd9e325b0)\n\nand GPU connection info with command nvidia-smi topo -m\n       \tGPU0   \tGPU1   \tGPU2   \tGPU3   \tGPU4   \tGPU5   \tGPU6   \tGPU7   \tmlx4_0 \tCPU Affinity\nGPU0   \t X     \tPIX    \tPHB    \tPHB    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU1   \tPIX    \t X     \tPHB    \tPHB    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU2   \tPHB    \tPHB    \t X     \tPIX    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU3   \tPHB    \tPHB    \tPIX    \t X     \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\nGPU4   \tSOC    \tSOC    \tSOC    \tSOC    \t X     \tPIX    \tPHB    \tPHB    \tPHB    \t14-27,42-55\nGPU5   \tSOC    \tSOC    \tSOC    \tSOC    \tPIX    \t X     \tPHB    \tPHB    \tPHB    \t14-27,42-55\nGPU6   \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \t X     \tPIX    \tPHB    \t14-27,42-55\nGPU7   \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \tPIX    \t X     \tPHB    \t14-27,42-55\nmlx4_0 \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \tPHB    \tPHB    \t X\n\nLegend:\n\n  X   = Self\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing a single PCIe switch\n  NV#  = Connection traversing a bonded set of # NVLinks\n\nslim model code: (Please replace these code to cifar10.py)\ndef inference(images):\n\t# reimplement by slim\n    slim = tf.contrib.slim\n    conv1 = slim.conv2d(images, 64, [5, 5], scope='conv1',\n                       weights_regularizer=slim.l2_regularizer(0.0),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n                       activation_fn=tf.nn.relu)\n    pool1 = slim.max_pool2d(conv1, [3, 3], 2, padding='SAME', scope='poll1')\n    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n    conv2 = slim.conv2d(norm1, 64, [5, 5], scope='conv2',\n                       weights_regularizer=slim.l2_regularizer(0.0),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=5e-2),\n                       biases_initializer=tf.constant_initializer(0.1),\n                       activation_fn=tf.nn.relu)\n    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n    pool2 = slim.max_pool2d(norm2, [3, 3], 2, padding='SAME', scope='poll2')\n    flatten2 = slim.flatten(pool2)\n    local3 = slim.fully_connected(flatten2, 384, scope='local3',\n                       weights_regularizer=slim.l2_regularizer(0.004),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),\n                       biases_initializer=tf.constant_initializer(0.1),\n                       activation_fn=tf.nn.relu)\n    local4 = slim.fully_connected(local3, 192, scope='local4',\n                       weights_regularizer=slim.l2_regularizer(0.004),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),\n                       biases_initializer=tf.constant_initializer(0.1),\n                       activation_fn=tf.nn.relu)\n    softmax_linear = slim.fully_connected(local4, NUM_CLASSES, scope='softmax_linear',\n                       weights_regularizer=slim.l2_regularizer(0.0),\n                       weights_initializer=tf.truncated_normal_initializer(stddev=1/192.0),\n                       biases_initializer=tf.constant_initializer(0.0),\n                       activation_fn=None)\n    return softmax_linear\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): no\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS Linux release 7.2.1511\nTensorFlow installed from (source or binary):source\nTensorFlow version (use command below):Tensorflow 1.2.0/ 1.0.1\nPython version: 2.7\nBazel version (if compiling from source): 1.4.5\nGCC/Compiler version (if compiling from source):4.8.5\nCUDA/cuDNN version:CUDA 8.0 and cuDNN 5.0\nGPU model and memory:TITAN X with 12GB\nExact command to reproduce:", "body": "Hi all, I encountered a training error when I training model in multi GPU.    \r\nThe key condition is using slim to write model and training in multi GPU(GTX TITAN X) which connect by PIX type.\r\n\r\nHow to reproduce:\r\n * 1. checkout office code in [here](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10)\r\n * 2. copy code in below(slim model code) and replace it to cifar10.py file. (Because only slim code can reproduce this issue)\r\n * 3. start to training: ```CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2```\r\n * 4. an incorrect loss will appear. (Also GPU usage is incorrect)\r\n\r\nNote 1: Check GPU info in below. this issue only happend when I using GPU 0,1 or GPU 2,3 or GPU 4,5 or GPU 6,7(connect by PIX). In this case, everything is ok If I using other combinations   \r\nNote 2: I can't reproduce this issue in GTX 1080 ti   \r\n\r\nThank you so much!\r\n\r\nThe training error log in below:\r\n\r\n```\r\nlinux@172.25.52.02:~/models/tutorials/image/cifar10: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2\r\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\r\n2017-11-09 18:13:02.264529: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are\r\navailable on your machine and could speed up CPU computations.\r\n2017-11-09 18:13:06.359127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\r\nname: GeForce GTX TITAN X\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\r\npciBusID 0000:05:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.81GiB\r\n2017-11-09 18:13:06.784690: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f00120 exists before initializing the StreamExecutor\r\n. We haven't verified StreamExecutor works with that.\r\n2017-11-09 18:13:06.786072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:\r\nname: GeForce GTX TITAN X\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\r\npciBusID 0000:04:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.81GiB\r\n2017-11-09 18:13:06.786507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1\r\n2017-11-09 18:13:06.786527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y\r\n2017-11-09 18:13:06.786592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y\r\n2017-11-09 18:13:06.786623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\r\n2017-11-09 18:13:06.786635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\r\n2017-11-09 18:13:06.830077: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0\r\n2017-11-09 18:13:06.830125: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0\r\n2017-11-09 18:13:09.804877: step 0, loss = 2.30 (119.9 examples/sec; 1.067 sec/batch)\r\n2017-11-09 18:13:17.096214: step 10, loss = 2.30 (421.3 examples/sec; 0.304 sec/batch)\r\n2017-11-09 18:13:23.708459: step 20, loss = 2.30 (390.0 examples/sec; 0.328 sec/batch)\r\n2017-11-09 18:13:31.362454: step 30, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)\r\n2017-11-09 18:13:38.225150: step 40, loss = 2.30 (363.3 examples/sec; 0.352 sec/batch)\r\n2017-11-09 18:13:44.695175: step 50, loss = 2.30 (389.8 examples/sec; 0.328 sec/batch)\r\n2017-11-09 18:13:51.994245: step 60, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)\r\n2017-11-09 18:13:58.623306: step 70, loss = 2.30 (421.2 examples/sec; 0.304 sec/batch)\r\n2017-11-09 18:14:05.480061: step 80, loss = 2.30 (390.6 examples/sec; 0.328 sec/batch)\r\n2017-11-09 18:14:11.952376: step 90, loss = 2.30 (389.2 examples/sec; 0.329 sec/batch)\r\n2017-11-09 18:14:18.375831: step 100, loss = 293778.34 (362.7 examples/sec; 0.353 sec/batch)\r\nTraceback (most recent call last):\r\n  File \"cifar10_multi_gpu_train.py\", line 283, in <module>\r\n    tf.app.run()\r\n  File \"/home/zhangjiguo/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"cifar10_multi_gpu_train.py\", line 278, in main\r\n    train()\r\n  File \"cifar10_multi_gpu_train.py\", line 251, in train\r\n    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\r\nAssertionError: Model diverged with loss = NaN\r\n```\r\n\r\nMy GPU list with command `nvidia-smi -L`    \r\n\r\n```\r\nGPU 0: GeForce GTX TITAN X (UUID: GPU-2c9601fc-369e-fce7-d139-8c7144700def)\r\nGPU 1: GeForce GTX TITAN X (UUID: GPU-eb4d8327-7058-39fe-e510-3437fe258745)\r\nGPU 2: GeForce GTX TITAN X (UUID: GPU-62fbacf7-0120-5c6b-ceea-ad026fddc537)\r\nGPU 3: GeForce GTX TITAN X (UUID: GPU-15be755d-9982-f4f4-4455-1d648d836b6e)\r\nGPU 4: GeForce GTX TITAN X (UUID: GPU-e48fae89-debd-9769-3851-61ba44acd6e1)\r\nGPU 5: GeForce GTX TITAN X (UUID: GPU-f796ad02-e104-04b5-d6c1-ff72d872654f)\r\nGPU 6: GeForce GTX TITAN X (UUID: GPU-7e27fd1e-ba3b-2dd3-6d03-960b8c76a0be)\r\nGPU 7: GeForce GTX TITAN X (UUID: GPU-8de522e7-f375-ab05-28ff-5ddfd9e325b0)\r\n```\r\n\r\nand GPU connection info with command `nvidia-smi topo -m`\r\n\r\n```\r\n       \tGPU0   \tGPU1   \tGPU2   \tGPU3   \tGPU4   \tGPU5   \tGPU6   \tGPU7   \tmlx4_0 \tCPU Affinity\r\nGPU0   \t X     \tPIX    \tPHB    \tPHB    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\r\nGPU1   \tPIX    \t X     \tPHB    \tPHB    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\r\nGPU2   \tPHB    \tPHB    \t X     \tPIX    \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\r\nGPU3   \tPHB    \tPHB    \tPIX    \t X     \tSOC    \tSOC    \tSOC    \tSOC    \tSOC    \t0-13,28-41\r\nGPU4   \tSOC    \tSOC    \tSOC    \tSOC    \t X     \tPIX    \tPHB    \tPHB    \tPHB    \t14-27,42-55\r\nGPU5   \tSOC    \tSOC    \tSOC    \tSOC    \tPIX    \t X     \tPHB    \tPHB    \tPHB    \t14-27,42-55\r\nGPU6   \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \t X     \tPIX    \tPHB    \t14-27,42-55\r\nGPU7   \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \tPIX    \t X     \tPHB    \t14-27,42-55\r\nmlx4_0 \tSOC    \tSOC    \tSOC    \tSOC    \tPHB    \tPHB    \tPHB    \tPHB    \t X\r\n\r\nLegend:\r\n\r\n  X   = Self\r\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\r\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\r\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\r\n  PIX  = Connection traversing a single PCIe switch\r\n  NV#  = Connection traversing a bonded set of # NVLinks\r\n```\r\n\r\nslim model code: (Please replace these code to cifar10.py)\r\n\r\n```\r\ndef inference(images):\r\n\t# reimplement by slim\r\n    slim = tf.contrib.slim\r\n    conv1 = slim.conv2d(images, 64, [5, 5], scope='conv1',\r\n                       weights_regularizer=slim.l2_regularizer(0.0),\r\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\r\n                       activation_fn=tf.nn.relu)\r\n    pool1 = slim.max_pool2d(conv1, [3, 3], 2, padding='SAME', scope='poll1')\r\n    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\r\n    conv2 = slim.conv2d(norm1, 64, [5, 5], scope='conv2',\r\n                       weights_regularizer=slim.l2_regularizer(0.0),\r\n                       weights_initializer=tf.truncated_normal_initializer(stddev=5e-2),\r\n                       biases_initializer=tf.constant_initializer(0.1),\r\n                       activation_fn=tf.nn.relu)\r\n    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\r\n    pool2 = slim.max_pool2d(norm2, [3, 3], 2, padding='SAME', scope='poll2')\r\n    flatten2 = slim.flatten(pool2)\r\n    local3 = slim.fully_connected(flatten2, 384, scope='local3',\r\n                       weights_regularizer=slim.l2_regularizer(0.004),\r\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),\r\n                       biases_initializer=tf.constant_initializer(0.1),\r\n                       activation_fn=tf.nn.relu)\r\n    local4 = slim.fully_connected(local3, 192, scope='local4',\r\n                       weights_regularizer=slim.l2_regularizer(0.004),\r\n                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),\r\n                       biases_initializer=tf.constant_initializer(0.1),\r\n                       activation_fn=tf.nn.relu)\r\n    softmax_linear = slim.fully_connected(local4, NUM_CLASSES, scope='softmax_linear',\r\n                       weights_regularizer=slim.l2_regularizer(0.0),\r\n                       weights_initializer=tf.truncated_normal_initializer(stddev=1/192.0),\r\n                       biases_initializer=tf.constant_initializer(0.0),\r\n                       activation_fn=None)\r\n    return softmax_linear\r\n```\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS Linux release 7.2.1511\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:Tensorflow 1.2.0/ 1.0.1\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 1.4.5\r\n- **GCC/Compiler version (if compiling from source)**:4.8.5\r\n- **CUDA/cuDNN version**:CUDA 8.0 and cuDNN 5.0\r\n- **GPU model and memory**:TITAN X with 12GB\r\n- **Exact command to reproduce**:\r\n"}