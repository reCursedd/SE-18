{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/379711342", "html_url": "https://github.com/tensorflow/tensorflow/issues/18271#issuecomment-379711342", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18271", "id": 379711342, "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTcxMTM0Mg==", "user": {"login": "Luonic", "id": 13236173, "node_id": "MDQ6VXNlcjEzMjM2MTcz", "avatar_url": "https://avatars1.githubusercontent.com/u/13236173?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Luonic", "html_url": "https://github.com/Luonic", "followers_url": "https://api.github.com/users/Luonic/followers", "following_url": "https://api.github.com/users/Luonic/following{/other_user}", "gists_url": "https://api.github.com/users/Luonic/gists{/gist_id}", "starred_url": "https://api.github.com/users/Luonic/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Luonic/subscriptions", "organizations_url": "https://api.github.com/users/Luonic/orgs", "repos_url": "https://api.github.com/users/Luonic/repos", "events_url": "https://api.github.com/users/Luonic/events{/privacy}", "received_events_url": "https://api.github.com/users/Luonic/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-09T10:47:19Z", "updated_at": "2018-04-09T10:47:19Z", "author_association": "NONE", "body_html": "<p>Also it would be very nice to be able to split utf-8 encoded string into multibyte characters instead of separate raw bytes to be able to implement character-level NLP completely with TF's OPs. Current solution is dirty hack: py_func that decodes string to utf-8, insert some separator (for example: \"|\") after each character and then this string tensor is separated by tf.string_split(input_tensor, delimiter=\"|\")<br>\nIt could be better)</p>", "body_text": "Also it would be very nice to be able to split utf-8 encoded string into multibyte characters instead of separate raw bytes to be able to implement character-level NLP completely with TF's OPs. Current solution is dirty hack: py_func that decodes string to utf-8, insert some separator (for example: \"|\") after each character and then this string tensor is separated by tf.string_split(input_tensor, delimiter=\"|\")\nIt could be better)", "body": "Also it would be very nice to be able to split utf-8 encoded string into multibyte characters instead of separate raw bytes to be able to implement character-level NLP completely with TF's OPs. Current solution is dirty hack: py_func that decodes string to utf-8, insert some separator (for example: \"|\") after each character and then this string tensor is separated by tf.string_split(input_tensor, delimiter=\"|\")\r\nIt could be better)"}