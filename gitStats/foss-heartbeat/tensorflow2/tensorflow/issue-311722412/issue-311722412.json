{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18271", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18271/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18271/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18271/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18271", "id": 311722412, "node_id": "MDU6SXNzdWUzMTE3MjI0MTI=", "number": 18271, "title": "[Feature Request] Python - like behavior of tf.string_split. Consider whole multi-byte delimiter.", "user": {"login": "nxphi47", "id": 19323568, "node_id": "MDQ6VXNlcjE5MzIzNTY4", "avatar_url": "https://avatars3.githubusercontent.com/u/19323568?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nxphi47", "html_url": "https://github.com/nxphi47", "followers_url": "https://api.github.com/users/nxphi47/followers", "following_url": "https://api.github.com/users/nxphi47/following{/other_user}", "gists_url": "https://api.github.com/users/nxphi47/gists{/gist_id}", "starred_url": "https://api.github.com/users/nxphi47/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nxphi47/subscriptions", "organizations_url": "https://api.github.com/users/nxphi47/orgs", "repos_url": "https://api.github.com/users/nxphi47/repos", "events_url": "https://api.github.com/users/nxphi47/events{/privacy}", "received_events_url": "https://api.github.com/users/nxphi47/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-04-05T18:35:09Z", "updated_at": "2018-06-04T17:17:11Z", "closed_at": "2018-06-04T17:17:11Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: MacOS, Ubuntu</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.7</li>\n<li><strong>Python version</strong>: 3.6,3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:No</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p><code>tf.string_split</code> is documented as <code>If delimiter contains multiple bytes, it is treated as a set of delimiters with each considered a potential split point.</code> Hence, each character in a multi-byte string delimiter will become a separate delimiter, which is very non-intuitive and difficult to implement.</p>\n<p>so for example, I want to split by to the token <code>&lt;eos&gt;</code></p>\n<pre><code>tf.string_split([\"hello world &lt;eos&gt; tensorflow\"], delimiter=\"&lt;eos&gt;\").values\n# equal:     ['h', 'll', ' w', 'rld ', ' t', 'n', 'rfl', 'w']  \n# should be ['hello world ', ' tensorflow]  \n</code></pre>\n<p>Can tf.string_split be reimplemented so that it consider the whole delimiter string, whether single or multiple character, to be its true delimiter instead making every single character in it delimiter?</p>\n<p>Thank you</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, Ubuntu\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.7\nPython version: 3.6,3.5\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:No\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\ntf.string_split is documented as If delimiter contains multiple bytes, it is treated as a set of delimiters with each considered a potential split point. Hence, each character in a multi-byte string delimiter will become a separate delimiter, which is very non-intuitive and difficult to implement.\nso for example, I want to split by to the token <eos>\ntf.string_split([\"hello world <eos> tensorflow\"], delimiter=\"<eos>\").values\n# equal:     ['h', 'll', ' w', 'rld ', ' t', 'n', 'rfl', 'w']  \n# should be ['hello world ', ' tensorflow]  \n\nCan tf.string_split be reimplemented so that it consider the whole delimiter string, whether single or multiple character, to be its true delimiter instead making every single character in it delimiter?\nThank you", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS, Ubuntu\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.7\r\n- **Python version**: 3.6,3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:No\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\n`tf.string_split` is documented as `If delimiter contains multiple bytes, it is treated as a set of delimiters with each considered a potential split point.` Hence, each character in a multi-byte string delimiter will become a separate delimiter, which is very non-intuitive and difficult to implement.\r\n\r\nso for example, I want to split by to the token `<eos>`\r\n```\r\ntf.string_split([\"hello world <eos> tensorflow\"], delimiter=\"<eos>\").values\r\n# equal:     ['h', 'll', ' w', 'rld ', ' t', 'n', 'rfl', 'w']  \r\n# should be ['hello world ', ' tensorflow]  \r\n```\r\n\r\nCan tf.string_split be reimplemented so that it consider the whole delimiter string, whether single or multiple character, to be its true delimiter instead making every single character in it delimiter?\r\n\r\nThank you\r\n\r\n"}