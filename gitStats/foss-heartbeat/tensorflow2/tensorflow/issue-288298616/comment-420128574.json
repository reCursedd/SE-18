{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/420128574", "html_url": "https://github.com/tensorflow/tensorflow/issues/16093#issuecomment-420128574", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16093", "id": 420128574, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMDEyODU3NA==", "user": {"login": "xiaoyunwu", "id": 5473617, "node_id": "MDQ6VXNlcjU0NzM2MTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/5473617?v=4", "gravatar_id": "", "url": "https://api.github.com/users/xiaoyunwu", "html_url": "https://github.com/xiaoyunwu", "followers_url": "https://api.github.com/users/xiaoyunwu/followers", "following_url": "https://api.github.com/users/xiaoyunwu/following{/other_user}", "gists_url": "https://api.github.com/users/xiaoyunwu/gists{/gist_id}", "starred_url": "https://api.github.com/users/xiaoyunwu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/xiaoyunwu/subscriptions", "organizations_url": "https://api.github.com/users/xiaoyunwu/orgs", "repos_url": "https://api.github.com/users/xiaoyunwu/repos", "events_url": "https://api.github.com/users/xiaoyunwu/events{/privacy}", "received_events_url": "https://api.github.com/users/xiaoyunwu/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-11T02:48:30Z", "updated_at": "2018-09-11T02:48:30Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">Asim,\nany update on using multi gpu with eager mode?\nThanks.\n\nXiaoyun</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sat, Jul 14, 2018 at 12:39 AM Asim Shankar ***@***.***&gt; wrote:\n That tutorial you referred to is nice - it does demonstrate the general\n idea that the exact same code (tf.keras.Model object) used with eager\n execution can be used to create an Estimator for distributed (multi-GPU\n or multi-node) training.\n\n We are working on making that process much smoother, where say the\n DistributionStrategy to use can be provided directly to the tf.keras.Model\n object. Till that happens, the notebook you referred to is one possibility.\n Sound reasonable?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"288298616\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/16093\" href=\"https://github.com/tensorflow/tensorflow/issues/16093#issuecomment-404886240\">#16093 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AFOFURD9fHXJiA5f5Ijcbvjgz2vijUgvks5uGM1PgaJpZM4RdFUg\">https://github.com/notifications/unsubscribe-auth/AFOFURD9fHXJiA5f5Ijcbvjgz2vijUgvks5uGM1PgaJpZM4RdFUg</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Asim,\nany update on using multi gpu with eager mode?\nThanks.\n\nXiaoyun\n\u2026\nOn Sat, Jul 14, 2018 at 12:39 AM Asim Shankar ***@***.***> wrote:\n That tutorial you referred to is nice - it does demonstrate the general\n idea that the exact same code (tf.keras.Model object) used with eager\n execution can be used to create an Estimator for distributed (multi-GPU\n or multi-node) training.\n\n We are working on making that process much smoother, where say the\n DistributionStrategy to use can be provided directly to the tf.keras.Model\n object. Till that happens, the notebook you referred to is one possibility.\n Sound reasonable?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#16093 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AFOFURD9fHXJiA5f5Ijcbvjgz2vijUgvks5uGM1PgaJpZM4RdFUg>\n .", "body": "Asim,\nany update on using multi gpu with eager mode?\nThanks.\n\nXiaoyun\n\nOn Sat, Jul 14, 2018 at 12:39 AM Asim Shankar <notifications@github.com>\nwrote:\n\n> That tutorial you referred to is nice - it does demonstrate the general\n> idea that the exact same code (tf.keras.Model object) used with eager\n> execution can be used to create an Estimator for distributed (multi-GPU\n> or multi-node) training.\n>\n> We are working on making that process much smoother, where say the\n> DistributionStrategy to use can be provided directly to the tf.keras.Model\n> object. Till that happens, the notebook you referred to is one possibility.\n> Sound reasonable?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/16093#issuecomment-404886240>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFOFURD9fHXJiA5f5Ijcbvjgz2vijUgvks5uGM1PgaJpZM4RdFUg>\n> .\n>\n"}