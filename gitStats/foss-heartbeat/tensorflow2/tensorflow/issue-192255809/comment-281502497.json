{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/281502497", "html_url": "https://github.com/tensorflow/tensorflow/issues/5934#issuecomment-281502497", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5934", "id": 281502497, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTUwMjQ5Nw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-21T22:26:59Z", "updated_at": "2017-02-21T22:26:59Z", "author_association": "MEMBER", "body_html": "<p>I tested this on a p2.8xLarge with TF 1.0 (hash:c7fca9e) as follows:</p>\n<p><code>python benchmark_alexnet.py</code><br>\nand<br>\n<code>CUDA_VISIBLE_DEVICES=0 python benchmark_alexnet.py</code></p>\n<p>It worked fine for both cases.  Unless I am reading the code incorrectly (which happens), this <a href=\"https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py\">benchmark</a> is not multi-GPU so the result is testing single GPU performance for AlexNet.  My results just because I have them:</p>\n<p>K80<br>\n2017-02-21 22:05:39.664444: Forward across 100 steps, 0.064 +/- 0.006 sec / batch<br>\n2017-02-21 22:06:01.289066: Forward-backward across 100 steps, 0.186 +/- 0.019 sec / batch</p>\n<p>Local GTX 1080 (also my display GPU)<br>\n2017-02-21 14:24:55.096074: Forward across 100 steps, 0.023 +/- 0.003 sec / batch<br>\n2017-02-21 14:25:03.292397: Forward-backward across 100 steps, 0.070 +/- 0.007 sec / batch</p>\n<p>p.s. I did have to install future as well <code>sudo pip install future</code></p>", "body_text": "I tested this on a p2.8xLarge with TF 1.0 (hash:c7fca9e) as follows:\npython benchmark_alexnet.py\nand\nCUDA_VISIBLE_DEVICES=0 python benchmark_alexnet.py\nIt worked fine for both cases.  Unless I am reading the code incorrectly (which happens), this benchmark is not multi-GPU so the result is testing single GPU performance for AlexNet.  My results just because I have them:\nK80\n2017-02-21 22:05:39.664444: Forward across 100 steps, 0.064 +/- 0.006 sec / batch\n2017-02-21 22:06:01.289066: Forward-backward across 100 steps, 0.186 +/- 0.019 sec / batch\nLocal GTX 1080 (also my display GPU)\n2017-02-21 14:24:55.096074: Forward across 100 steps, 0.023 +/- 0.003 sec / batch\n2017-02-21 14:25:03.292397: Forward-backward across 100 steps, 0.070 +/- 0.007 sec / batch\np.s. I did have to install future as well sudo pip install future", "body": "I tested this on a p2.8xLarge with TF 1.0 (hash:c7fca9e) as follows:\r\n\r\n`python benchmark_alexnet.py`\r\nand\r\n`CUDA_VISIBLE_DEVICES=0 python benchmark_alexnet.py`\r\n\r\nIt worked fine for both cases.  Unless I am reading the code incorrectly (which happens), this [benchmark](https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py) is not multi-GPU so the result is testing single GPU performance for AlexNet.  My results just because I have them:\r\n\r\nK80\r\n2017-02-21 22:05:39.664444: Forward across 100 steps, 0.064 +/- 0.006 sec / batch\r\n2017-02-21 22:06:01.289066: Forward-backward across 100 steps, 0.186 +/- 0.019 sec / batch\r\n\r\nLocal GTX 1080 (also my display GPU)\r\n2017-02-21 14:24:55.096074: Forward across 100 steps, 0.023 +/- 0.003 sec / batch\r\n2017-02-21 14:25:03.292397: Forward-backward across 100 steps, 0.070 +/- 0.007 sec / batch\r\n\r\np.s. I did have to install future as well `sudo pip install future`\r\n\r\n"}