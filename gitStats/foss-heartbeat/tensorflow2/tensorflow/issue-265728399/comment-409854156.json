{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409854156", "html_url": "https://github.com/tensorflow/tensorflow/issues/13744#issuecomment-409854156", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13744", "id": 409854156, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTg1NDE1Ng==", "user": {"login": "secsilm", "id": 8894643, "node_id": "MDQ6VXNlcjg4OTQ2NDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/8894643?v=4", "gravatar_id": "", "url": "https://api.github.com/users/secsilm", "html_url": "https://github.com/secsilm", "followers_url": "https://api.github.com/users/secsilm/followers", "following_url": "https://api.github.com/users/secsilm/following{/other_user}", "gists_url": "https://api.github.com/users/secsilm/gists{/gist_id}", "starred_url": "https://api.github.com/users/secsilm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/secsilm/subscriptions", "organizations_url": "https://api.github.com/users/secsilm/orgs", "repos_url": "https://api.github.com/users/secsilm/repos", "events_url": "https://api.github.com/users/secsilm/events{/privacy}", "received_events_url": "https://api.github.com/users/secsilm/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-02T08:48:40Z", "updated_at": "2018-08-02T08:48:40Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Without <code>tf.set_random_seed</code>, running multiple training in the same <code>model_dir</code> cause a fake accuracy improvement. But with <code>tf.set_random_seed</code>, it's fine. Why is this related with <code>tf.set_random_seed</code>?</p>\n<p>Here is the question I asked on SO: <a href=\"https://stackoverflow.com/questions/51629819/weird-accuracy-improvement-by-multiple-small-epochs-training\" rel=\"nofollow\">python - Weird accuracy improvement by multiple small epochs training - Stack Overflow</a></p>\n<p>Thanks.</p>", "body_text": "Without tf.set_random_seed, running multiple training in the same model_dir cause a fake accuracy improvement. But with tf.set_random_seed, it's fine. Why is this related with tf.set_random_seed?\nHere is the question I asked on SO: python - Weird accuracy improvement by multiple small epochs training - Stack Overflow\nThanks.", "body": "Without `tf.set_random_seed`, running multiple training in the same `model_dir` cause a fake accuracy improvement. But with `tf.set_random_seed`, it's fine. Why is this related with `tf.set_random_seed`?\r\n\r\nHere is the question I asked on SO: [python - Weird accuracy improvement by multiple small epochs training - Stack Overflow](https://stackoverflow.com/questions/51629819/weird-accuracy-improvement-by-multiple-small-epochs-training)\r\n\r\nThanks."}