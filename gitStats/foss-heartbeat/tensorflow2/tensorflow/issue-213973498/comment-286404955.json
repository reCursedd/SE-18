{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/286404955", "html_url": "https://github.com/tensorflow/tensorflow/issues/8382#issuecomment-286404955", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8382", "id": 286404955, "node_id": "MDEyOklzc3VlQ29tbWVudDI4NjQwNDk1NQ==", "user": {"login": "drpngx", "id": 20959853, "node_id": "MDQ6VXNlcjIwOTU5ODUz", "avatar_url": "https://avatars1.githubusercontent.com/u/20959853?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drpngx", "html_url": "https://github.com/drpngx", "followers_url": "https://api.github.com/users/drpngx/followers", "following_url": "https://api.github.com/users/drpngx/following{/other_user}", "gists_url": "https://api.github.com/users/drpngx/gists{/gist_id}", "starred_url": "https://api.github.com/users/drpngx/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drpngx/subscriptions", "organizations_url": "https://api.github.com/users/drpngx/orgs", "repos_url": "https://api.github.com/users/drpngx/repos", "events_url": "https://api.github.com/users/drpngx/events{/privacy}", "received_events_url": "https://api.github.com/users/drpngx/received_events", "type": "User", "site_admin": false}, "created_at": "2017-03-14T12:21:57Z", "updated_at": "2017-03-14T12:21:57Z", "author_association": "MEMBER", "body_html": "<p>As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=17184992\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/MicaelCarvalho\">@MicaelCarvalho</a> this is best answered on StackOverflow where we monitor all questions with the tag <code>tensorflow</code>. All optimizers have the <code>compute_gradients</code> method. You will get the variables and gradients back, then you can modify them at your leisure, before calling <code>apply_gradients</code>.</p>", "body_text": "As @MicaelCarvalho this is best answered on StackOverflow where we monitor all questions with the tag tensorflow. All optimizers have the compute_gradients method. You will get the variables and gradients back, then you can modify them at your leisure, before calling apply_gradients.", "body": "As @MicaelCarvalho this is best answered on StackOverflow where we monitor all questions with the tag `tensorflow`. All optimizers have the `compute_gradients` method. You will get the variables and gradients back, then you can modify them at your leisure, before calling `apply_gradients`."}