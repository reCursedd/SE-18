{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20140", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20140/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20140/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20140/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20140", "id": 333963701, "node_id": "MDU6SXNzdWUzMzM5NjM3MDE=", "number": 20140, "title": "Find a bug in tensorflow", "user": {"login": "zyj183247166", "id": 7501074, "node_id": "MDQ6VXNlcjc1MDEwNzQ=", "avatar_url": "https://avatars2.githubusercontent.com/u/7501074?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zyj183247166", "html_url": "https://github.com/zyj183247166", "followers_url": "https://api.github.com/users/zyj183247166/followers", "following_url": "https://api.github.com/users/zyj183247166/following{/other_user}", "gists_url": "https://api.github.com/users/zyj183247166/gists{/gist_id}", "starred_url": "https://api.github.com/users/zyj183247166/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zyj183247166/subscriptions", "organizations_url": "https://api.github.com/users/zyj183247166/orgs", "repos_url": "https://api.github.com/users/zyj183247166/repos", "events_url": "https://api.github.com/users/zyj183247166/events{/privacy}", "received_events_url": "https://api.github.com/users/zyj183247166/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "open", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2018-06-20T07:55:39Z", "updated_at": "2018-06-29T01:55:25Z", "closed_at": null, "author_association": "NONE", "body_html": "<p>write the code below, and save it to  a ,ckpt as a model</p>\n<pre><code>import tensorflow as tf`\nv1 = tf.Variable(tf.constant(1.0, shape=[1]), name = \"v1\")\nv2 = tf.Variable(tf.constant(2.0, shape=[1]), name = \"v2\")\nv3 = tf.Variable(tf.constant(3.0, shape=[1]), name = \"v3\")\nresult=v1+v2\nresult2= result + v3\n\ninit_op = tf.global_variables_initializer()\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    sess.run(init_op)\n    writer = tf.summary.FileWriter('./graphs/const_add', sess.graph)\n    saver.save(sess, \"Saved_model/model.ckpt\")`\n</code></pre>\n<p>then in another .py\uff0c we restore the model from the model.ckpt file</p>\n<pre><code>import tensorflow as tf\nsaver = tf.train.import_meta_graph(\"Saved_model/model.ckpt.meta\")\nwith tf.Session() as sess:\n    saver.restore(sess, \"Saved_model/model.ckpt\")\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))\n    #sess.run(tf.assign(v1,[10])) #\u76f4\u63a5\u8fd9\u6837\u4f7f\u7528v1\uff0c\u4f1a\u63d0\u793av1\u6ca1\u6709\u5b9a\u4e49\n    \n    #with tf.variable_scope(\"\",reuse=tf.AUTO_REUSE):\n    with tf.variable_scope(\"\",reuse=False):\n        v1=tf.get_variable(name=\"v1\",shape=[1])\n        print(v1.name)\n    sess.run(tf.assign(v1,[10]))\n    \"\"\"\u2463\u8f93\u51fa\u6240\u6709\u53ef\u8bad\u7ec3\u7684\u53d8\u91cf\u540d\u79f0\uff0c\u4e5f\u5c31\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\"\"\"\n    trainable_variables=tf.trainable_variables()\n    variable_list_name = [c.name for c in tf.trainable_variables()]\n    variable_list = sess.run(variable_list_name)\n    for k,v in zip(variable_list_name,variable_list):\n        print(\"variable name:\",k)\n        print(\"shape:\",v.shape)\n            #print(v) \n    \"\"\"\u2463\u8f93\u51fa\u6240\u6709\u53ef\u8bad\u7ec3\u7684\u53d8\u91cf\u540d\u79f0\uff0c\u4e5f\u5c31\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\"\"\"\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"v1:0\")))\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add_1:0\")))\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"v1_1:0\")))\n</code></pre>\n<p>the results will be as below:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/7501074/41644510-d1957e98-74a0-11e8-9327-7e2cd5ccd438.png\"><img src=\"https://user-images.githubusercontent.com/7501074/41644510-d1957e98-74a0-11e8-9327-7e2cd5ccd438.png\" alt=\"image\" style=\"max-width:100%;\"></a><br>\nwe will find that:<br>\nif we restore some variables from the already existed model file \"\"Saved_model/model.ckpt.meta\")\",<br>\nsuch as v1,v2,v3 in this example.<br>\nit will influence the process of calling get_variable. Because of these two causes as below:</p>\n<ol>\n<li>the variables restored from the model file such as v1,v2 and v3 will not exist in the scope of get_variable, it means you can only use</li>\n</ol>\n<pre><code>with tf.variable_scope(\"\",reuse=False):\n        v1=tf.get_variable(name=\"v1\",shape=[1])\n</code></pre>\n<p>and create a new variable.  you can not  reuse the restored variable v1 from the model file unless you define a v1 , before you restore from the model file. like below</p>\n<pre><code>v1=tf.get_variable(name=\"v1\",shape=[1])\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    saver.restore(sess, \"Saved_model/model.ckpt\")\n    print (sess.run(result))\n</code></pre>\n<p>that is , you can not reuse the restored variable v1 which is from restoring the model file unless you define it befor you restore.<br>\n2.  although tensorflow doesnot allow reusing the restored variable v1 which is from restoring the model file if you don't define v1 before you restore the model file.<br>\nBut if you call get_varialbe after you restore the model file, it will create a variable whose name is \"v1_1\" but not as name='v1' which you specify.<br>\nin my opinion, it should be corrected because it is so confusing.  how to correct it?<br>\ni think get_variable should also reuse the variables which is loaded by restoring some model file.<br>\nthe last sentence is what i finally want to say.<br>\nMy english is to bad, you can run the code i offer and will find what i want to convey.<br>\nThanks.</p>", "body_text": "write the code below, and save it to  a ,ckpt as a model\nimport tensorflow as tf`\nv1 = tf.Variable(tf.constant(1.0, shape=[1]), name = \"v1\")\nv2 = tf.Variable(tf.constant(2.0, shape=[1]), name = \"v2\")\nv3 = tf.Variable(tf.constant(3.0, shape=[1]), name = \"v3\")\nresult=v1+v2\nresult2= result + v3\n\ninit_op = tf.global_variables_initializer()\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    sess.run(init_op)\n    writer = tf.summary.FileWriter('./graphs/const_add', sess.graph)\n    saver.save(sess, \"Saved_model/model.ckpt\")`\n\nthen in another .py\uff0c we restore the model from the model.ckpt file\nimport tensorflow as tf\nsaver = tf.train.import_meta_graph(\"Saved_model/model.ckpt.meta\")\nwith tf.Session() as sess:\n    saver.restore(sess, \"Saved_model/model.ckpt\")\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))\n    #sess.run(tf.assign(v1,[10])) #\u76f4\u63a5\u8fd9\u6837\u4f7f\u7528v1\uff0c\u4f1a\u63d0\u793av1\u6ca1\u6709\u5b9a\u4e49\n    \n    #with tf.variable_scope(\"\",reuse=tf.AUTO_REUSE):\n    with tf.variable_scope(\"\",reuse=False):\n        v1=tf.get_variable(name=\"v1\",shape=[1])\n        print(v1.name)\n    sess.run(tf.assign(v1,[10]))\n    \"\"\"\u2463\u8f93\u51fa\u6240\u6709\u53ef\u8bad\u7ec3\u7684\u53d8\u91cf\u540d\u79f0\uff0c\u4e5f\u5c31\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\"\"\"\n    trainable_variables=tf.trainable_variables()\n    variable_list_name = [c.name for c in tf.trainable_variables()]\n    variable_list = sess.run(variable_list_name)\n    for k,v in zip(variable_list_name,variable_list):\n        print(\"variable name:\",k)\n        print(\"shape:\",v.shape)\n            #print(v) \n    \"\"\"\u2463\u8f93\u51fa\u6240\u6709\u53ef\u8bad\u7ec3\u7684\u53d8\u91cf\u540d\u79f0\uff0c\u4e5f\u5c31\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\"\"\"\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"v1:0\")))\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add_1:0\")))\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"v1_1:0\")))\n\nthe results will be as below:\n\nwe will find that:\nif we restore some variables from the already existed model file \"\"Saved_model/model.ckpt.meta\")\",\nsuch as v1,v2,v3 in this example.\nit will influence the process of calling get_variable. Because of these two causes as below:\n\nthe variables restored from the model file such as v1,v2 and v3 will not exist in the scope of get_variable, it means you can only use\n\nwith tf.variable_scope(\"\",reuse=False):\n        v1=tf.get_variable(name=\"v1\",shape=[1])\n\nand create a new variable.  you can not  reuse the restored variable v1 from the model file unless you define a v1 , before you restore from the model file. like below\nv1=tf.get_variable(name=\"v1\",shape=[1])\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    saver.restore(sess, \"Saved_model/model.ckpt\")\n    print (sess.run(result))\n\nthat is , you can not reuse the restored variable v1 which is from restoring the model file unless you define it befor you restore.\n2.  although tensorflow doesnot allow reusing the restored variable v1 which is from restoring the model file if you don't define v1 before you restore the model file.\nBut if you call get_varialbe after you restore the model file, it will create a variable whose name is \"v1_1\" but not as name='v1' which you specify.\nin my opinion, it should be corrected because it is so confusing.  how to correct it?\ni think get_variable should also reuse the variables which is loaded by restoring some model file.\nthe last sentence is what i finally want to say.\nMy english is to bad, you can run the code i offer and will find what i want to convey.\nThanks.", "body": "write the code below, and save it to  a ,ckpt as a model\r\n```\r\nimport tensorflow as tf`\r\nv1 = tf.Variable(tf.constant(1.0, shape=[1]), name = \"v1\")\r\nv2 = tf.Variable(tf.constant(2.0, shape=[1]), name = \"v2\")\r\nv3 = tf.Variable(tf.constant(3.0, shape=[1]), name = \"v3\")\r\nresult=v1+v2\r\nresult2= result + v3\r\n\r\ninit_op = tf.global_variables_initializer()\r\nsaver = tf.train.Saver()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init_op)\r\n    writer = tf.summary.FileWriter('./graphs/const_add', sess.graph)\r\n    saver.save(sess, \"Saved_model/model.ckpt\")`\r\n```\r\nthen in another .py\uff0c we restore the model from the model.ckpt file\r\n```\r\nimport tensorflow as tf\r\nsaver = tf.train.import_meta_graph(\"Saved_model/model.ckpt.meta\")\r\nwith tf.Session() as sess:\r\n    saver.restore(sess, \"Saved_model/model.ckpt\")\r\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))\r\n    #sess.run(tf.assign(v1,[10])) #\u76f4\u63a5\u8fd9\u6837\u4f7f\u7528v1\uff0c\u4f1a\u63d0\u793av1\u6ca1\u6709\u5b9a\u4e49\r\n    \r\n    #with tf.variable_scope(\"\",reuse=tf.AUTO_REUSE):\r\n    with tf.variable_scope(\"\",reuse=False):\r\n        v1=tf.get_variable(name=\"v1\",shape=[1])\r\n        print(v1.name)\r\n    sess.run(tf.assign(v1,[10]))\r\n    \"\"\"\u2463\u8f93\u51fa\u6240\u6709\u53ef\u8bad\u7ec3\u7684\u53d8\u91cf\u540d\u79f0\uff0c\u4e5f\u5c31\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\"\"\"\r\n    trainable_variables=tf.trainable_variables()\r\n    variable_list_name = [c.name for c in tf.trainable_variables()]\r\n    variable_list = sess.run(variable_list_name)\r\n    for k,v in zip(variable_list_name,variable_list):\r\n        print(\"variable name:\",k)\r\n        print(\"shape:\",v.shape)\r\n            #print(v) \r\n    \"\"\"\u2463\u8f93\u51fa\u6240\u6709\u53ef\u8bad\u7ec3\u7684\u53d8\u91cf\u540d\u79f0\uff0c\u4e5f\u5c31\u662f\u795e\u7ecf\u7f51\u7edc\u7684\u53c2\u6570\"\"\"\r\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"v1:0\")))\r\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))\r\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"add_1:0\")))\r\n    print (sess.run(tf.get_default_graph().get_tensor_by_name(\"v1_1:0\")))\r\n```\r\nthe results will be as below:\r\n![image](https://user-images.githubusercontent.com/7501074/41644510-d1957e98-74a0-11e8-9327-7e2cd5ccd438.png)\r\nwe will find that:\r\nif we restore some variables from the already existed model file \"\"Saved_model/model.ckpt.meta\")\",\r\nsuch as v1,v2,v3 in this example.\r\nit will influence the process of calling get_variable. Because of these two causes as below:\r\n1. the variables restored from the model file such as v1,v2 and v3 will not exist in the scope of get_variable, it means you can only use\r\n```\r\nwith tf.variable_scope(\"\",reuse=False):\r\n        v1=tf.get_variable(name=\"v1\",shape=[1])\r\n```\r\nand create a new variable.  you can not  reuse the restored variable v1 from the model file unless you define a v1 , before you restore from the model file. like below\r\n```\r\nv1=tf.get_variable(name=\"v1\",shape=[1])\r\nsaver = tf.train.Saver()\r\nwith tf.Session() as sess:\r\n    saver.restore(sess, \"Saved_model/model.ckpt\")\r\n    print (sess.run(result))\r\n```\r\nthat is , you can not reuse the restored variable v1 which is from restoring the model file unless you define it befor you restore.\r\n2.  although tensorflow doesnot allow reusing the restored variable v1 which is from restoring the model file if you don't define v1 before you restore the model file.\r\nBut if you call get_varialbe after you restore the model file, it will create a variable whose name is \"v1_1\" but not as name='v1' which you specify.\r\n    in my opinion, it should be corrected because it is so confusing.  how to correct it?\r\ni think get_variable should also reuse the variables which is loaded by restoring some model file.\r\nthe last sentence is what i finally want to say. \r\nMy english is to bad, you can run the code i offer and will find what i want to convey. \r\nThanks.\r\n\r\n"}