{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/473", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/473/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/473/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/473/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/473", "id": 121606683, "node_id": "MDU6SXNzdWUxMjE2MDY2ODM=", "number": 473, "title": "Occupies GPU even if it is not compatible", "user": {"login": "noisychannel", "id": 807183, "node_id": "MDQ6VXNlcjgwNzE4Mw==", "avatar_url": "https://avatars3.githubusercontent.com/u/807183?v=4", "gravatar_id": "", "url": "https://api.github.com/users/noisychannel", "html_url": "https://github.com/noisychannel", "followers_url": "https://api.github.com/users/noisychannel/followers", "following_url": "https://api.github.com/users/noisychannel/following{/other_user}", "gists_url": "https://api.github.com/users/noisychannel/gists{/gist_id}", "starred_url": "https://api.github.com/users/noisychannel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/noisychannel/subscriptions", "organizations_url": "https://api.github.com/users/noisychannel/orgs", "repos_url": "https://api.github.com/users/noisychannel/repos", "events_url": "https://api.github.com/users/noisychannel/events{/privacy}", "received_events_url": "https://api.github.com/users/noisychannel/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284463744, "node_id": "MDU6TGFiZWwyODQ0NjM3NDQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cuda", "name": "cuda", "color": "f7c6c7", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2015-12-11T00:08:48Z", "updated_at": "2017-02-09T22:02:25Z", "closed_at": "2016-06-06T18:52:22Z", "author_association": "NONE", "body_html": "<p>As the title states, even if a GPU is not CUDA compatible, Tensorflow will occupy the GPU and then proceed to ignore it.</p>\n<p>Here's a use case :</p>\n<p>CUDA_VISIBLE_DEVICES=3 python convolutional.py<br>\n....<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:669] Ignoring gpu device (device: 0, name: Tesla K10.G2.8GB, pci bus id: 0000:45:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.<br>\n....<br>\nFrom nvidia-dmi<br>\n|   3  Tesla K10.G2.8GB    Off  | 0000:45:00.0     Off |                    0 |<br>\n| N/A   34C    P0    43W / 117W |     50MiB /  3583MiB |      <strong>0%</strong>    E. Thread |<br>\n.....<br>\n|    3     26078    C   python                                          37MiB |<br>\n+-----------------------------------------------------------------------------+</p>", "body_text": "As the title states, even if a GPU is not CUDA compatible, Tensorflow will occupy the GPU and then proceed to ignore it.\nHere's a use case :\nCUDA_VISIBLE_DEVICES=3 python convolutional.py\n....\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:669] Ignoring gpu device (device: 0, name: Tesla K10.G2.8GB, pci bus id: 0000:45:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\n....\nFrom nvidia-dmi\n|   3  Tesla K10.G2.8GB    Off  | 0000:45:00.0     Off |                    0 |\n| N/A   34C    P0    43W / 117W |     50MiB /  3583MiB |      0%    E. Thread |\n.....\n|    3     26078    C   python                                          37MiB |\n+-----------------------------------------------------------------------------+", "body": "As the title states, even if a GPU is not CUDA compatible, Tensorflow will occupy the GPU and then proceed to ignore it.\n\nHere's a use case : \n\nCUDA_VISIBLE_DEVICES=3 python convolutional.py\n....\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:669] Ignoring gpu device (device: 0, name: Tesla K10.G2.8GB, pci bus id: 0000:45:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5. \n....\nFrom nvidia-dmi\n|   3  Tesla K10.G2.8GB    Off  | 0000:45:00.0     Off |                    0 |\n| N/A   34C    P0    43W / 117W |     50MiB /  3583MiB |      **0%**    E. Thread |\n.....\n|    3     26078    C   python                                          37MiB |\n+-----------------------------------------------------------------------------+\n"}