{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/425228580", "html_url": "https://github.com/tensorflow/tensorflow/issues/22526#issuecomment-425228580", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22526", "id": 425228580, "node_id": "MDEyOklzc3VlQ29tbWVudDQyNTIyODU4MA==", "user": {"login": "wt-huang", "id": 42785337, "node_id": "MDQ6VXNlcjQyNzg1MzM3", "avatar_url": "https://avatars0.githubusercontent.com/u/42785337?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wt-huang", "html_url": "https://github.com/wt-huang", "followers_url": "https://api.github.com/users/wt-huang/followers", "following_url": "https://api.github.com/users/wt-huang/following{/other_user}", "gists_url": "https://api.github.com/users/wt-huang/gists{/gist_id}", "starred_url": "https://api.github.com/users/wt-huang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wt-huang/subscriptions", "organizations_url": "https://api.github.com/users/wt-huang/orgs", "repos_url": "https://api.github.com/users/wt-huang/repos", "events_url": "https://api.github.com/users/wt-huang/events{/privacy}", "received_events_url": "https://api.github.com/users/wt-huang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-27T20:17:47Z", "updated_at": "2018-09-27T20:18:15Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7981826\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/7oud\">@7oud</a> You can have multiple sessions to conduct trainings in parallel. Each session will need to have its own set of variables in its own thread. Alternatively, you can have multiple processes with its own session and graph. To change the gpu memory, you can try something like this instead:</p>\n<pre><code>config = tf.contrib.learn.RunConfig(session_config = config))\n</code></pre>\n<p>Note that graph can grow very fast and the session may be running out memory very soon.</p>", "body_text": "@7oud You can have multiple sessions to conduct trainings in parallel. Each session will need to have its own set of variables in its own thread. Alternatively, you can have multiple processes with its own session and graph. To change the gpu memory, you can try something like this instead:\nconfig = tf.contrib.learn.RunConfig(session_config = config))\n\nNote that graph can grow very fast and the session may be running out memory very soon.", "body": "@7oud You can have multiple sessions to conduct trainings in parallel. Each session will need to have its own set of variables in its own thread. Alternatively, you can have multiple processes with its own session and graph. To change the gpu memory, you can try something like this instead:\r\n```\r\nconfig = tf.contrib.learn.RunConfig(session_config = config))\r\n```\r\nNote that graph can grow very fast and the session may be running out memory very soon."}