{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1568", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1568/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1568/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1568/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/1568", "id": 142335645, "node_id": "MDU6SXNzdWUxNDIzMzU2NDU=", "number": 1568, "title": "ResourceExhaustedError in translate example (with GPU)", "user": {"login": "ybbaigo", "id": 525266, "node_id": "MDQ6VXNlcjUyNTI2Ng==", "avatar_url": "https://avatars1.githubusercontent.com/u/525266?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ybbaigo", "html_url": "https://github.com/ybbaigo", "followers_url": "https://api.github.com/users/ybbaigo/followers", "following_url": "https://api.github.com/users/ybbaigo/following{/other_user}", "gists_url": "https://api.github.com/users/ybbaigo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ybbaigo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ybbaigo/subscriptions", "organizations_url": "https://api.github.com/users/ybbaigo/orgs", "repos_url": "https://api.github.com/users/ybbaigo/repos", "events_url": "https://api.github.com/users/ybbaigo/events{/privacy}", "received_events_url": "https://api.github.com/users/ybbaigo/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2016-03-21T12:40:00Z", "updated_at": "2017-06-20T00:31:55Z", "closed_at": "2016-07-25T20:23:42Z", "author_association": "CONTRIBUTOR", "body_html": "<p>GitHub issues are for bugs / installation problems / feature requests.<br>\nFor general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>Environment info</h3>\n<p>Operating System: Ubuntu 15.10</p>\n<p>If installed from binary pip package, provide:</p>\n<p>Which pip package you installed.</p>\n<blockquote>\n<p>sudo pip install --upgrade <a href=\"https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl</a></p>\n</blockquote>\n<p>The output from python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)\".</p>\n<blockquote>\n<p>I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally<br>\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally<br>\n0.7.1</p>\n</blockquote>\n<p>If installed from sources, provide the commit hash:</p>\n<h3>Steps to reproduce</h3>\n<p>Just run translate.py with 10M pairs training data.</p>\n<h3>What have you tried?</h3>\n<p>smaller batch size 32</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment).</p>\n<p>I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 3.63GiB<br>\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 32.00MiB.  See logs for memory state<br>\nW tensorflow/core/kernels/matmul_op.cc:158] Resource exhausted: OOM when allocating tensor with shape[2048,4096]<br>\nW tensorflow/core/common_runtime/executor.cc:1102] 0xe723bd30 Compute status: Resource exhausted: OOM when allocating tensor with shape[2048,4096]<br>\n[[Node: gradients_2/model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/concat, gradients_2/model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/add_grad/Reshape)]]<br>\nTraceback (most recent call last):<br>\nFile \"translate.py\", line 289, in <br>\ntf.app.run()<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run<br>\nsys.exit(main(sys.argv))<br>\nFile \"translate.py\", line 286, in main<br>\ntrain()<br>\nFile \"translate.py\", line 187, in train<br>\ntarget_weights, bucket_id, False)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 224, in step<br>\noutputs = session.run(output_feed, input_feed)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 315, in run<br>\nreturn self._run(None, fetches, feed_dict)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 511, in _run<br>\nfeed_dict_string)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _do_run<br>\ntarget_list)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 586, in _do_call<br>\ne.code)<br>\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[2048,4096]<br>\n[[Node: gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/concat, gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/add_grad/Reshape)]]<br>\n[[Node: clip_by_global_norm_2/clip_by_global_norm_2/_9/_3023 = _Recv<a href=\"\">client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_179468_clip_by_global_norm_2/clip_by_global_norm_2/_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"</a>]]<br>\nCaused by op u'gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1', defined at:<br>\nFile \"translate.py\", line 289, in <br>\ntf.app.run()<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run<br>\nsys.exit(main(sys.argv))<br>\nFile \"translate.py\", line 286, in main<br>\ntrain()<br>\nFile \"translate.py\", line 155, in train<br>\nmodel = create_model(sess, False)<br>\nFile \"translate.py\", line 132, in create_model<br>\nforward_only=forward_only)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 161, in <strong>init</strong><br>\ngradients = tf.gradients(self.losses[b], params)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 483, in gradients<br>\nin_grads = _AsList(grad_fn(wrapped_op, *out_grads))<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 431, in _MatMulGrad<br>\nmath_ops.matmul(op.inputs[0], grad, transpose_a=True))<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 951, in matmul<br>\nname=name)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 686, in _mat_mul<br>\ntranspose_b=transpose_b, name=name)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op<br>\nop_def=op_def)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op<br>\noriginal_op=self._default_original_op, op_def=op_def)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in <strong>init</strong><br>\nself._traceback = _extract_stack()</p>\n<p>...which was originally created as op u'model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul', defined at:<br>\nFile \"translate.py\", line 289, in <br>\ntf.app.run()<br>\n[elided 3 identical lines from previous traceback]<br>\nFile \"translate.py\", line 132, in create_model<br>\nforward_only=forward_only)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 152, in <strong>init</strong><br>\nsoftmax_loss_function=softmax_loss_function)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 926, in model_with_buckets<br>\ndecoder_inputs[:bucket[1]])<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 151, in <br>\nlambda x, y: seq2seq_f(x, y, False),<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 115, in seq2seq_f<br>\nfeed_previous=do_decode)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 691, in embedding_attention_seq2seq<br>\ninitial_state_attention=initial_state_attention)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 621, in embedding_attention_decoder<br>\ninitial_state_attention=initial_state_attention)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 530, in attention_decoder<br>\ncell_output, state = cell(x, state)<br>\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 663, in <strong>call</strong><br>\ncur_inp, new_state = cell(cur_inp, cur_state)</p>", "body_text": "GitHub issues are for bugs / installation problems / feature requests.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nEnvironment info\nOperating System: Ubuntu 15.10\nIf installed from binary pip package, provide:\nWhich pip package you installed.\n\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n\nThe output from python -c \"import tensorflow; print(tensorflow.version)\".\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n0.7.1\n\nIf installed from sources, provide the commit hash:\nSteps to reproduce\nJust run translate.py with 10M pairs training data.\nWhat have you tried?\nsmaller batch size 32\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment).\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 3.63GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 32.00MiB.  See logs for memory state\nW tensorflow/core/kernels/matmul_op.cc:158] Resource exhausted: OOM when allocating tensor with shape[2048,4096]\nW tensorflow/core/common_runtime/executor.cc:1102] 0xe723bd30 Compute status: Resource exhausted: OOM when allocating tensor with shape[2048,4096]\n[[Node: gradients_2/model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/concat, gradients_2/model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/add_grad/Reshape)]]\nTraceback (most recent call last):\nFile \"translate.py\", line 289, in \ntf.app.run()\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\nsys.exit(main(sys.argv))\nFile \"translate.py\", line 286, in main\ntrain()\nFile \"translate.py\", line 187, in train\ntarget_weights, bucket_id, False)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 224, in step\noutputs = session.run(output_feed, input_feed)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 315, in run\nreturn self._run(None, fetches, feed_dict)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 511, in _run\nfeed_dict_string)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _do_run\ntarget_list)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 586, in _do_call\ne.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[2048,4096]\n[[Node: gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/concat, gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/add_grad/Reshape)]]\n[[Node: clip_by_global_norm_2/clip_by_global_norm_2/_9/_3023 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_179468_clip_by_global_norm_2/clip_by_global_norm_2/_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]]\nCaused by op u'gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1', defined at:\nFile \"translate.py\", line 289, in \ntf.app.run()\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\nsys.exit(main(sys.argv))\nFile \"translate.py\", line 286, in main\ntrain()\nFile \"translate.py\", line 155, in train\nmodel = create_model(sess, False)\nFile \"translate.py\", line 132, in create_model\nforward_only=forward_only)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 161, in init\ngradients = tf.gradients(self.losses[b], params)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 483, in gradients\nin_grads = _AsList(grad_fn(wrapped_op, *out_grads))\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 431, in _MatMulGrad\nmath_ops.matmul(op.inputs[0], grad, transpose_a=True))\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 951, in matmul\nname=name)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 686, in _mat_mul\ntranspose_b=transpose_b, name=name)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\nop_def=op_def)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\noriginal_op=self._default_original_op, op_def=op_def)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in init\nself._traceback = _extract_stack()\n...which was originally created as op u'model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul', defined at:\nFile \"translate.py\", line 289, in \ntf.app.run()\n[elided 3 identical lines from previous traceback]\nFile \"translate.py\", line 132, in create_model\nforward_only=forward_only)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 152, in init\nsoftmax_loss_function=softmax_loss_function)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 926, in model_with_buckets\ndecoder_inputs[:bucket[1]])\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 151, in \nlambda x, y: seq2seq_f(x, y, False),\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 115, in seq2seq_f\nfeed_previous=do_decode)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 691, in embedding_attention_seq2seq\ninitial_state_attention=initial_state_attention)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 621, in embedding_attention_decoder\ninitial_state_attention=initial_state_attention)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 530, in attention_decoder\ncell_output, state = cell(x, state)\nFile \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 663, in call\ncur_inp, new_state = cell(cur_inp, cur_state)", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Ubuntu 15.10\n\nIf installed from binary pip package, provide:\n\nWhich pip package you installed.\n\n> sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n\nThe output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n> I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n> 0.7.1\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\nJust run translate.py with 10M pairs training data.\n### What have you tried?\n\nsmaller batch size 32\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 3.63GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 32.00MiB.  See logs for memory state\nW tensorflow/core/kernels/matmul_op.cc:158] Resource exhausted: OOM when allocating tensor with shape[2048,4096]\nW tensorflow/core/common_runtime/executor.cc:1102] 0xe723bd30 Compute status: Resource exhausted: OOM when allocating tensor with shape[2048,4096]\n     [[Node: gradients_2/model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/concat, gradients_2/model_with_buckets/embedding_attention_seq2seq_2/RNN/MultiRNNCell/Cell0/BasicLSTMCell/add_grad/Reshape)]]\nTraceback (most recent call last):\n  File \"translate.py\", line 289, in <module>\n    tf.app.run()\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"translate.py\", line 286, in main\n    train()\n  File \"translate.py\", line 187, in train\n    target_weights, bucket_id, False)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 224, in step\n    outputs = session.run(output_feed, input_feed)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 315, in run\n    return self._run(None, fetches, feed_dict)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 511, in _run\n    feed_dict_string)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _do_run\n    target_list)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 586, in _do_call\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[2048,4096]\n     [[Node: gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/concat, gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/add_grad/Reshape)]]\n     [[Node: clip_by_global_norm_2/clip_by_global_norm_2/_9/_3023 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_179468_clip_by_global_norm_2/clip_by_global_norm_2/_9\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'gradients_2/model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul_grad/MatMul_1', defined at:\n  File \"translate.py\", line 289, in <module>\n    tf.app.run()\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"translate.py\", line 286, in main\n    train()\n  File \"translate.py\", line 155, in train\n    model = create_model(sess, False)\n  File \"translate.py\", line 132, in create_model\n    forward_only=forward_only)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 161, in __init__\n    gradients = tf.gradients(self.losses[b], params)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 483, in gradients\n    in_grads = _AsList(grad_fn(wrapped_op, *out_grads))\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 431, in _MatMulGrad\n    math_ops.matmul(op.inputs[0], grad, transpose_a=True))\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 951, in matmul\n    name=name)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 686, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2040, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1087, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'model_with_buckets/embedding_attention_seq2seq_2/embedding_attention_decoder/attention_decoder/MultiRNNCell_3/Cell0/BasicLSTMCell/Linear/MatMul', defined at:\n  File \"translate.py\", line 289, in <module>\n    tf.app.run()\n[elided 3 identical lines from previous traceback]\n  File \"translate.py\", line 132, in create_model\n    forward_only=forward_only)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 152, in **init**\n    softmax_loss_function=softmax_loss_function)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 926, in model_with_buckets\n    decoder_inputs[:bucket[1]])\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 151, in <lambda>\n    lambda x, y: seq2seq_f(x, y, False),\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 115, in seq2seq_f\n    feed_previous=do_decode)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 691, in embedding_attention_seq2seq\n    initial_state_attention=initial_state_attention)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 621, in embedding_attention_decoder\n    initial_state_attention=initial_state_attention)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py\", line 530, in attention_decoder\n    cell_output, state = cell(x, state)\n  File \"/home/yy/virtualenv/env1/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py\", line 663, in **call**\n    cur_inp, new_state = cell(cur_inp, cur_state)\n"}