{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15638", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15638/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15638/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15638/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/15638", "id": 284513865, "node_id": "MDU6SXNzdWUyODQ1MTM4NjU=", "number": 15638, "title": "PS:0 runs nothing but seizes the network in the distributed training", "user": {"login": "niewuya", "id": 17894544, "node_id": "MDQ6VXNlcjE3ODk0NTQ0", "avatar_url": "https://avatars0.githubusercontent.com/u/17894544?v=4", "gravatar_id": "", "url": "https://api.github.com/users/niewuya", "html_url": "https://github.com/niewuya", "followers_url": "https://api.github.com/users/niewuya/followers", "following_url": "https://api.github.com/users/niewuya/following{/other_user}", "gists_url": "https://api.github.com/users/niewuya/gists{/gist_id}", "starred_url": "https://api.github.com/users/niewuya/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/niewuya/subscriptions", "organizations_url": "https://api.github.com/users/niewuya/orgs", "repos_url": "https://api.github.com/users/niewuya/repos", "events_url": "https://api.github.com/users/niewuya/events{/privacy}", "received_events_url": "https://api.github.com/users/niewuya/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2017-12-26T08:08:35Z", "updated_at": "2018-04-10T14:27:48Z", "closed_at": "2018-04-10T14:27:48Z", "author_association": "NONE", "body_html": "<p>It's strange but I think is a bug in tensorflow. When I use multi machine as PS, I specify the operations in PS:* but not PS:0. And I not use the PS:0, but the variable transfer between the PS:* and PS:0. By the way, I  use the lenet5 about 1.6M parameters, but when iterating one time, the data between PS:* and PS:0 is 4.7M in the network using tcpdump to calculate it. I don't know why. The following is my main code in worker machine and PS server just run server.join().<br>\n<a href=\"https://github.com/niewuya/tensorflow-distributed-training/blob/master/code.py\">https://github.com/niewuya/tensorflow-distributed-training/blob/master/code.py</a><br>\nI will appreciate your reply.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\nslim <span class=\"pl-k\">=</span> tf.contrib.slim\n\nparameter_servers <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>172.16.101.248:2225<span class=\"pl-pds\">\"</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>172.16.101.249:2225<span class=\"pl-pds\">\"</span></span>,<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>172.16.101.105:2225<span class=\"pl-pds\">\"</span></span>]\nworkers <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>172.20.110.94:2225<span class=\"pl-pds\">\"</span></span>]\ncluster <span class=\"pl-k\">=</span> tf.train.ClusterSpec({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>: parameter_servers, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: workers})\nserver <span class=\"pl-k\">=</span> tf.train.Server(\n    cluster,\n    <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>,\n    <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">dataset_input_fn</span>():\n    buffer_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1024</span>\n    batch <span class=\"pl-k\">=</span> <span class=\"pl-c1\">128</span>\n    num_epochs <span class=\"pl-k\">=</span> <span class=\"pl-c1\">50</span>\n    filenames <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>../datasets/mnist/train.tfrecord<span class=\"pl-pds\">'</span></span>]\n    dataset <span class=\"pl-k\">=</span> tf.data.TFRecordDataset(filenames)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">parser</span>(<span class=\"pl-smi\">record</span>):\n        keys_to_features <span class=\"pl-k\">=</span> {\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image/encoded<span class=\"pl-pds\">\"</span></span>: tf.FixedLenFeature((), tf.string, <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>),\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image/class/label<span class=\"pl-pds\">\"</span></span>: tf.FixedLenFeature((), tf.int64,\n                                                    <span class=\"pl-v\">default_value</span><span class=\"pl-k\">=</span>tf.zeros([], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int64)),\n        }\n        parsed <span class=\"pl-k\">=</span> tf.parse_single_example(record, keys_to_features)\n\n        image <span class=\"pl-k\">=</span> tf.image.decode_jpeg(parsed[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image/encoded<span class=\"pl-pds\">\"</span></span>])\n        image <span class=\"pl-k\">=</span> tf.image.convert_image_dtype(image, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n        image <span class=\"pl-k\">=</span> tf.reshape(image, [<span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">28</span>, <span class=\"pl-c1\">1</span>])\n        label <span class=\"pl-k\">=</span> tf.cast(parsed[<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image/class/label<span class=\"pl-pds\">\"</span></span>], tf.int32)\n        label <span class=\"pl-k\">=</span> slim.one_hot_encoding(label, <span class=\"pl-c1\">10</span>)\n        <span class=\"pl-k\">return</span> image, label\n\n    dataset <span class=\"pl-k\">=</span> dataset.repeat()\n    dataset <span class=\"pl-k\">=</span> dataset.map(parser, <span class=\"pl-v\">num_parallel_calls</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">8</span>)\n    dataset <span class=\"pl-k\">=</span> dataset.prefetch(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span>batch)\n    dataset <span class=\"pl-k\">=</span> dataset.prefetch(<span class=\"pl-v\">buffer_size</span><span class=\"pl-k\">=</span>buffer_size)\n    dataset <span class=\"pl-k\">=</span> dataset.shuffle(buffer_size)\n    dataset <span class=\"pl-k\">=</span> dataset.batch(batch)\n    iterator <span class=\"pl-k\">=</span> dataset.make_one_shot_iterator()\n    images, labels <span class=\"pl-k\">=</span> iterator.get_next()\n    <span class=\"pl-k\">return</span> images, labels\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">lenet</span>(<span class=\"pl-smi\">images</span>,<span class=\"pl-smi\">labels</span>,<span class=\"pl-smi\">flag</span>):\n    num_classes <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10</span>\n    dropout_keep_prob <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0.5</span>\n    scope <span class=\"pl-k\">=</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>lenet<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-v\">reuse</span><span class=\"pl-k\">=</span>flag)\n    <span class=\"pl-k\">with</span> scope, slim.arg_scope([slim.conv2d, slim.fully_connected],\n                               <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span>tf.nn.relu,\n                               <span class=\"pl-v\">weights_initializer</span><span class=\"pl-k\">=</span>tf.truncated_normal_initializer(<span class=\"pl-v\">stddev</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>),\n                               <span class=\"pl-v\">weights_regularizer</span><span class=\"pl-k\">=</span>slim.l2_regularizer(<span class=\"pl-c1\">0.0</span>)):\n        net <span class=\"pl-k\">=</span> slim.conv2d(images, <span class=\"pl-c1\">20</span>, [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>], <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1_1<span class=\"pl-pds\">'</span></span>)\n        net <span class=\"pl-k\">=</span> slim.max_pool2d(net, [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>], <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pool1_1<span class=\"pl-pds\">'</span></span>)\n        net <span class=\"pl-k\">=</span> slim.conv2d(net, <span class=\"pl-c1\">50</span>, [<span class=\"pl-c1\">5</span>, <span class=\"pl-c1\">5</span>], <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>conv1_2<span class=\"pl-pds\">'</span></span>)\n        net <span class=\"pl-k\">=</span> slim.max_pool2d(net, [<span class=\"pl-c1\">2</span>, <span class=\"pl-c1\">2</span>], <span class=\"pl-c1\">2</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>pool1_2<span class=\"pl-pds\">'</span></span>)\n        net <span class=\"pl-k\">=</span> slim.flatten(net)\n        net <span class=\"pl-k\">=</span> slim.fully_connected(net, <span class=\"pl-c1\">500</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc1_3<span class=\"pl-pds\">'</span></span>)\n        net <span class=\"pl-k\">=</span> slim.dropout(net, dropout_keep_prob, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>dropout1_3<span class=\"pl-pds\">'</span></span>)\n        logits <span class=\"pl-k\">=</span> slim.fully_connected(net, num_classes, <span class=\"pl-v\">activation_fn</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>fc1_4<span class=\"pl-pds\">'</span></span>)\n        loss <span class=\"pl-k\">=</span> tf.losses.softmax_cross_entropy(\n            <span class=\"pl-v\">logits</span><span class=\"pl-k\">=</span>logits, <span class=\"pl-v\">onehot_labels</span><span class=\"pl-k\">=</span>labels)\n        loss <span class=\"pl-k\">=</span> tf.reduce_mean(loss)\n        optimizer <span class=\"pl-k\">=</span> tf.train.AdagradOptimizer(<span class=\"pl-c1\">0.01</span>)\n        correct_prediction <span class=\"pl-k\">=</span> tf.equal(tf.argmax(logits, <span class=\"pl-c1\">1</span>), tf.argmax(labels, <span class=\"pl-c1\">1</span>))\n        accuracy <span class=\"pl-k\">=</span> tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        grads <span class=\"pl-k\">=</span> optimizer.compute_gradients(loss)\n    <span class=\"pl-k\">return</span> grads, accuracy, optimizer\n\n<span class=\"pl-k\">with</span> tf.Graph().as_default():\n    <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/CPU:0<span class=\"pl-pds\">'</span></span>):\n        all_grads <span class=\"pl-k\">=</span> []\n        <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/job:ps/task:2<span class=\"pl-pds\">'</span></span>):\n            images, labels <span class=\"pl-k\">=</span> dataset_input_fn()\n            grads, accuracy_ps, optimizer <span class=\"pl-k\">=</span>lenet(images,labels,<span class=\"pl-c1\">False</span>)\n\n        all_grads.clear()\n        all_grads.append(grads)\n        train_op_all<span class=\"pl-k\">=</span>[]\n        <span class=\"pl-k\">for</span> i, grad_and_vars <span class=\"pl-k\">in</span> <span class=\"pl-c1\">enumerate</span>(<span class=\"pl-c1\">zip</span>(<span class=\"pl-k\">*</span>all_grads)):\n            grads <span class=\"pl-k\">=</span> []\n            <span class=\"pl-k\">for</span> g, _ <span class=\"pl-k\">in</span> grad_and_vars:\n                g <span class=\"pl-k\">=</span> tf.expand_dims(g, <span class=\"pl-c1\">0</span>)\n                grads.append(g)\n            grad <span class=\"pl-k\">=</span> tf.concat(<span class=\"pl-v\">axis</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>, <span class=\"pl-v\">values</span><span class=\"pl-k\">=</span>grads)\n            grad <span class=\"pl-k\">=</span> tf.reduce_mean(grad, <span class=\"pl-c1\">0</span>)\n            v <span class=\"pl-k\">=</span> grad_and_vars[<span class=\"pl-c1\">0</span>][<span class=\"pl-c1\">1</span>]\n            train_op_all.append(optimizer.apply_gradients([(grad, v)]))\n        train_op<span class=\"pl-k\">=</span>tf.group(<span class=\"pl-k\">*</span>train_op_all)\n\n    <span class=\"pl-k\">with</span> tf.train.MonitoredTrainingSession(<span class=\"pl-v\">master</span><span class=\"pl-k\">=</span>server.target,\n                                               <span class=\"pl-v\">is_chief</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>\n                                           )<span class=\"pl-k\">as</span> mon_sess:\n        frequency<span class=\"pl-k\">=</span><span class=\"pl-c1\">10</span>\n        <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n            _ ,accuracy<span class=\"pl-k\">=</span> mon_sess.run([train_op,accuracy_ps])\n            <span class=\"pl-k\">if</span> i <span class=\"pl-k\">%</span> frequency <span class=\"pl-k\">==</span><span class=\"pl-c1\">0</span> :\n                <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>accuracy is :<span class=\"pl-c1\">%f</span><span class=\"pl-pds\">\"</span></span><span class=\"pl-k\">%</span>accuracy)</pre></div>", "body_text": "It's strange but I think is a bug in tensorflow. When I use multi machine as PS, I specify the operations in PS:* but not PS:0. And I not use the PS:0, but the variable transfer between the PS:* and PS:0. By the way, I  use the lenet5 about 1.6M parameters, but when iterating one time, the data between PS:* and PS:0 is 4.7M in the network using tcpdump to calculate it. I don't know why. The following is my main code in worker machine and PS server just run server.join().\nhttps://github.com/niewuya/tensorflow-distributed-training/blob/master/code.py\nI will appreciate your reply.\nimport tensorflow as tf\nslim = tf.contrib.slim\n\nparameter_servers = [\"172.16.101.248:2225\",\"172.16.101.249:2225\",\"172.16.101.105:2225\"]\nworkers = [\"172.20.110.94:2225\"]\ncluster = tf.train.ClusterSpec({\"ps\": parameter_servers, \"worker\": workers})\nserver = tf.train.Server(\n    cluster,\n    job_name=\"worker\",\n    task_index=0)\n\ndef dataset_input_fn():\n    buffer_size = 1024\n    batch = 128\n    num_epochs = 50\n    filenames = ['../datasets/mnist/train.tfrecord']\n    dataset = tf.data.TFRecordDataset(filenames)\n\n    def parser(record):\n        keys_to_features = {\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n            \"image/class/label\": tf.FixedLenFeature((), tf.int64,\n                                                    default_value=tf.zeros([], dtype=tf.int64)),\n        }\n        parsed = tf.parse_single_example(record, keys_to_features)\n\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"])\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n        image = tf.reshape(image, [28, 28, 1])\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\n        label = slim.one_hot_encoding(label, 10)\n        return image, label\n\n    dataset = dataset.repeat()\n    dataset = dataset.map(parser, num_parallel_calls=8)\n    dataset = dataset.prefetch(buffer_size=batch)\n    dataset = dataset.prefetch(buffer_size=buffer_size)\n    dataset = dataset.shuffle(buffer_size)\n    dataset = dataset.batch(batch)\n    iterator = dataset.make_one_shot_iterator()\n    images, labels = iterator.get_next()\n    return images, labels\n\ndef lenet(images,labels,flag):\n    num_classes = 10\n    dropout_keep_prob = 0.5\n    scope = tf.variable_scope(\"lenet\", reuse=flag)\n    with scope, slim.arg_scope([slim.conv2d, slim.fully_connected],\n                               activation_fn=tf.nn.relu,\n                               weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n                               weights_regularizer=slim.l2_regularizer(0.0)):\n        net = slim.conv2d(images, 20, [5, 5], scope='conv1_1')\n        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_1')\n        net = slim.conv2d(net, 50, [5, 5], scope='conv1_2')\n        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_2')\n        net = slim.flatten(net)\n        net = slim.fully_connected(net, 500, scope='fc1_3')\n        net = slim.dropout(net, dropout_keep_prob, scope='dropout1_3')\n        logits = slim.fully_connected(net, num_classes, activation_fn=None, scope='fc1_4')\n        loss = tf.losses.softmax_cross_entropy(\n            logits=logits, onehot_labels=labels)\n        loss = tf.reduce_mean(loss)\n        optimizer = tf.train.AdagradOptimizer(0.01)\n        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n        grads = optimizer.compute_gradients(loss)\n    return grads, accuracy, optimizer\n\nwith tf.Graph().as_default():\n    with tf.device('/CPU:0'):\n        all_grads = []\n        with tf.device('/job:ps/task:2'):\n            images, labels = dataset_input_fn()\n            grads, accuracy_ps, optimizer =lenet(images,labels,False)\n\n        all_grads.clear()\n        all_grads.append(grads)\n        train_op_all=[]\n        for i, grad_and_vars in enumerate(zip(*all_grads)):\n            grads = []\n            for g, _ in grad_and_vars:\n                g = tf.expand_dims(g, 0)\n                grads.append(g)\n            grad = tf.concat(axis=0, values=grads)\n            grad = tf.reduce_mean(grad, 0)\n            v = grad_and_vars[0][1]\n            train_op_all.append(optimizer.apply_gradients([(grad, v)]))\n        train_op=tf.group(*train_op_all)\n\n    with tf.train.MonitoredTrainingSession(master=server.target,\n                                               is_chief=True\n                                           )as mon_sess:\n        frequency=10\n        for i in range(1000):\n            _ ,accuracy= mon_sess.run([train_op,accuracy_ps])\n            if i % frequency ==0 :\n                print(\"accuracy is :%f\"%accuracy)", "body": "   It's strange but I think is a bug in tensorflow. When I use multi machine as PS, I specify the operations in PS:* but not PS:0. And I not use the PS:0, but the variable transfer between the PS:* and PS:0. By the way, I  use the lenet5 about 1.6M parameters, but when iterating one time, the data between PS:* and PS:0 is 4.7M in the network using tcpdump to calculate it. I don't know why. The following is my main code in worker machine and PS server just run server.join().\r\nhttps://github.com/niewuya/tensorflow-distributed-training/blob/master/code.py\r\nI will appreciate your reply.\r\n\r\n```python\r\nimport tensorflow as tf\r\nslim = tf.contrib.slim\r\n\r\nparameter_servers = [\"172.16.101.248:2225\",\"172.16.101.249:2225\",\"172.16.101.105:2225\"]\r\nworkers = [\"172.20.110.94:2225\"]\r\ncluster = tf.train.ClusterSpec({\"ps\": parameter_servers, \"worker\": workers})\r\nserver = tf.train.Server(\r\n    cluster,\r\n    job_name=\"worker\",\r\n    task_index=0)\r\n\r\ndef dataset_input_fn():\r\n    buffer_size = 1024\r\n    batch = 128\r\n    num_epochs = 50\r\n    filenames = ['../datasets/mnist/train.tfrecord']\r\n    dataset = tf.data.TFRecordDataset(filenames)\r\n\r\n    def parser(record):\r\n        keys_to_features = {\r\n            \"image/encoded\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\r\n            \"image/class/label\": tf.FixedLenFeature((), tf.int64,\r\n                                                    default_value=tf.zeros([], dtype=tf.int64)),\r\n        }\r\n        parsed = tf.parse_single_example(record, keys_to_features)\r\n\r\n        image = tf.image.decode_jpeg(parsed[\"image/encoded\"])\r\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n        image = tf.reshape(image, [28, 28, 1])\r\n        label = tf.cast(parsed[\"image/class/label\"], tf.int32)\r\n        label = slim.one_hot_encoding(label, 10)\r\n        return image, label\r\n\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.map(parser, num_parallel_calls=8)\r\n    dataset = dataset.prefetch(buffer_size=batch)\r\n    dataset = dataset.prefetch(buffer_size=buffer_size)\r\n    dataset = dataset.shuffle(buffer_size)\r\n    dataset = dataset.batch(batch)\r\n    iterator = dataset.make_one_shot_iterator()\r\n    images, labels = iterator.get_next()\r\n    return images, labels\r\n\r\ndef lenet(images,labels,flag):\r\n    num_classes = 10\r\n    dropout_keep_prob = 0.5\r\n    scope = tf.variable_scope(\"lenet\", reuse=flag)\r\n    with scope, slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                               activation_fn=tf.nn.relu,\r\n                               weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\r\n                               weights_regularizer=slim.l2_regularizer(0.0)):\r\n        net = slim.conv2d(images, 20, [5, 5], scope='conv1_1')\r\n        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_1')\r\n        net = slim.conv2d(net, 50, [5, 5], scope='conv1_2')\r\n        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_2')\r\n        net = slim.flatten(net)\r\n        net = slim.fully_connected(net, 500, scope='fc1_3')\r\n        net = slim.dropout(net, dropout_keep_prob, scope='dropout1_3')\r\n        logits = slim.fully_connected(net, num_classes, activation_fn=None, scope='fc1_4')\r\n        loss = tf.losses.softmax_cross_entropy(\r\n            logits=logits, onehot_labels=labels)\r\n        loss = tf.reduce_mean(loss)\r\n        optimizer = tf.train.AdagradOptimizer(0.01)\r\n        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\r\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n        grads = optimizer.compute_gradients(loss)\r\n    return grads, accuracy, optimizer\r\n\r\nwith tf.Graph().as_default():\r\n    with tf.device('/CPU:0'):\r\n        all_grads = []\r\n        with tf.device('/job:ps/task:2'):\r\n            images, labels = dataset_input_fn()\r\n            grads, accuracy_ps, optimizer =lenet(images,labels,False)\r\n\r\n        all_grads.clear()\r\n        all_grads.append(grads)\r\n        train_op_all=[]\r\n        for i, grad_and_vars in enumerate(zip(*all_grads)):\r\n            grads = []\r\n            for g, _ in grad_and_vars:\r\n                g = tf.expand_dims(g, 0)\r\n                grads.append(g)\r\n            grad = tf.concat(axis=0, values=grads)\r\n            grad = tf.reduce_mean(grad, 0)\r\n            v = grad_and_vars[0][1]\r\n            train_op_all.append(optimizer.apply_gradients([(grad, v)]))\r\n        train_op=tf.group(*train_op_all)\r\n\r\n    with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                               is_chief=True\r\n                                           )as mon_sess:\r\n        frequency=10\r\n        for i in range(1000):\r\n            _ ,accuracy= mon_sess.run([train_op,accuracy_ps])\r\n            if i % frequency ==0 :\r\n                print(\"accuracy is :%f\"%accuracy)\r\n```"}