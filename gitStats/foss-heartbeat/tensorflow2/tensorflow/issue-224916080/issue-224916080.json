{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9502", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9502/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9502/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9502/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9502", "id": 224916080, "node_id": "MDU6SXNzdWUyMjQ5MTYwODA=", "number": 9502, "title": "Internally inconsistent results on GPU, not on CPU", "user": {"login": "rkeisler", "id": 4852957, "node_id": "MDQ6VXNlcjQ4NTI5NTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/4852957?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rkeisler", "html_url": "https://github.com/rkeisler", "followers_url": "https://api.github.com/users/rkeisler/followers", "following_url": "https://api.github.com/users/rkeisler/following{/other_user}", "gists_url": "https://api.github.com/users/rkeisler/gists{/gist_id}", "starred_url": "https://api.github.com/users/rkeisler/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rkeisler/subscriptions", "organizations_url": "https://api.github.com/users/rkeisler/orgs", "repos_url": "https://api.github.com/users/rkeisler/repos", "events_url": "https://api.github.com/users/rkeisler/events{/privacy}", "received_events_url": "https://api.github.com/users/rkeisler/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}, {"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "protoget", "id": 5117188, "node_id": "MDQ6VXNlcjUxMTcxODg=", "avatar_url": "https://avatars1.githubusercontent.com/u/5117188?v=4", "gravatar_id": "", "url": "https://api.github.com/users/protoget", "html_url": "https://github.com/protoget", "followers_url": "https://api.github.com/users/protoget/followers", "following_url": "https://api.github.com/users/protoget/following{/other_user}", "gists_url": "https://api.github.com/users/protoget/gists{/gist_id}", "starred_url": "https://api.github.com/users/protoget/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/protoget/subscriptions", "organizations_url": "https://api.github.com/users/protoget/orgs", "repos_url": "https://api.github.com/users/protoget/repos", "events_url": "https://api.github.com/users/protoget/events{/privacy}", "received_events_url": "https://api.github.com/users/protoget/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2017-04-27T21:18:46Z", "updated_at": "2017-05-05T16:49:45Z", "closed_at": "2017-05-05T16:49:45Z", "author_association": "NONE", "body_html": "<h3>System Information</h3>\n<pre><code>Ubuntu 16.04 LTS\nCUDA 8.0\ncuDNN v5.1\nNVIDIA Tesla K80 (11439MiB)\ntensorflow 1.0.1 (bug also present in 1.1.0) [pip]\nkeras 2.0.3 [python setup.py install]\n</code></pre>\n<h3>Problem</h3>\n<p>I can define a convnet that returns reasonable results with CPU, but returns a mixture of expected and nonsense results with GPU. The problem with the GPU processing is made clear by passing a set of \"all ones\" images to the net; the output should be identical for all 16 images, yet the outputs for the last one or two images differ drastically from the rest.</p>\n<p>I see this problem when using the GPU, but not with CPU.  No exceptions are raised, and there are no warnings beyond the usual <code>TensorFlow library wasn't compiled to use ___ instructions, but these are available on your machine and could speed up CPU computations.</code>.</p>\n<p>I see this problem using <code>tensorflow</code> as my <code>keras</code> backend, but not when using <code>theano</code> as my backend.  That statement is true whether I set <code>image_data_format</code> to <code>channels_last</code> or <code>channels_first</code>, for either backend.</p>\n<p>I've found three changes to the model architecture defined below that make the problem go away: (1) change the number of filters, as described in more detail below, (2) remove the <code>UpSampling2D</code> layer, or (3) remove the  <code>AveragePooling2D</code> layer.  Given (3), this issue may be related to <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"215557799\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/8566\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/8566/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/8566\">#8566</a> .</p>\n<h3>Code</h3>\n<p>Consider the following convnet.</p>\n<pre><code>import tensorflow as tf\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\nfrom keras.models import Model\nimport numpy as np\n\ndef my_model(filters=65):\n    np.random.seed(0)\n    inputs = Input((None, None, 3))\n    conv1 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(inputs)\n    conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)\n    conv2 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(conv1)\n    conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv2)\n    conv3 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv2)\n    conv3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv3)\n    conv4 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv3)\n    conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv4)\n    conv5 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv4)\n    conv5_up = UpSampling2D(size=(8, 8))(conv5)\n    conv5_up = AveragePooling2D(pool_size=(8, 8), strides=(1,1), padding='same')(conv5_up)\n    return Model(inputs=inputs, outputs=conv5_up)\n</code></pre>\n<p>We can test the self-consistency of this net by feeding it 16 \"all ones\" images.  The output features should be identical for each input image, since the input images are simply all ones.</p>\n<pre><code>def test(filters=65, device='gpu'):\n    # Make a batch of 16 \"images\", ALL ONES.\n    img = np.ones((16, 512, 512, 3), dtype='float32')\n    with tf.device('/%s:0'%device):\n        model = my_model(filters)\n        features = model.predict(img)\n    # Compare features of 1st and 16th image.\n    # Since the input was all ones, they should agree.\n    inconsistent = np.any(features[0] != features[15])\n    if inconsistent:\n        print \"Inconsistent!\"\n</code></pre>\n<p>The model architecture is parameterized by a single parameter, <code>filters</code>, the number of filters in each layer.  Interestingly, I see that the model inconsistency cares about powers of 2 in <code>filters</code>:</p>\n<p>\u2022\u00a0consistency for <code>filters=1 through 64</code>,<br>\n\u2022\u00a0inconsistency for <code>filters=65 through 127</code>,<br>\n\u2022\u00a0consistency for <code>filters=128</code>,<br>\n\u2022\u00a0inconsistency for <code>filters=129 through 150</code>.</p>\n<p>The smallest model that shows the problem is at <code>filters=65</code>.  Below I show a single feature output for the 1st and 16th input images.  They should agree, but they don't.</p>\n<p>Features for 1st image (which is identical for images 1-15):<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4852957/25504294/33eb3ad6-2b52-11e7-9b1d-636bd576ed23.png\"><img src=\"https://cloud.githubusercontent.com/assets/4852957/25504294/33eb3ad6-2b52-11e7-9b1d-636bd576ed23.png\" alt=\"features_1st_image\" style=\"max-width:100%;\"></a></p>\n<p>Features for 16th image:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://cloud.githubusercontent.com/assets/4852957/25504297/3969ab6e-2b52-11e7-87e7-67bed7a8c7b3.png\"><img src=\"https://cloud.githubusercontent.com/assets/4852957/25504297/3969ab6e-2b52-11e7-87e7-67bed7a8c7b3.png\" alt=\"features_16th_image\" style=\"max-width:100%;\"></a></p>\n<p>As can be seen, the feature map for the 16th image differs dramatically from images 1-15, even though the inputs are identical (all ones).</p>\n<p>If I repeat this test with a <code>filters=129</code> instead of <code>filters=65</code>, the bug appears earlier in the batch; the features for images 1-14 are identical, while the features for images 15 and 16 differ from the rest, and from each other.</p>", "body_text": "System Information\nUbuntu 16.04 LTS\nCUDA 8.0\ncuDNN v5.1\nNVIDIA Tesla K80 (11439MiB)\ntensorflow 1.0.1 (bug also present in 1.1.0) [pip]\nkeras 2.0.3 [python setup.py install]\n\nProblem\nI can define a convnet that returns reasonable results with CPU, but returns a mixture of expected and nonsense results with GPU. The problem with the GPU processing is made clear by passing a set of \"all ones\" images to the net; the output should be identical for all 16 images, yet the outputs for the last one or two images differ drastically from the rest.\nI see this problem when using the GPU, but not with CPU.  No exceptions are raised, and there are no warnings beyond the usual TensorFlow library wasn't compiled to use ___ instructions, but these are available on your machine and could speed up CPU computations..\nI see this problem using tensorflow as my keras backend, but not when using theano as my backend.  That statement is true whether I set image_data_format to channels_last or channels_first, for either backend.\nI've found three changes to the model architecture defined below that make the problem go away: (1) change the number of filters, as described in more detail below, (2) remove the UpSampling2D layer, or (3) remove the  AveragePooling2D layer.  Given (3), this issue may be related to #8566 .\nCode\nConsider the following convnet.\nimport tensorflow as tf\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\nfrom keras.models import Model\nimport numpy as np\n\ndef my_model(filters=65):\n    np.random.seed(0)\n    inputs = Input((None, None, 3))\n    conv1 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(inputs)\n    conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)\n    conv2 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(conv1)\n    conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv2)\n    conv3 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv2)\n    conv3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv3)\n    conv4 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv3)\n    conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv4)\n    conv5 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv4)\n    conv5_up = UpSampling2D(size=(8, 8))(conv5)\n    conv5_up = AveragePooling2D(pool_size=(8, 8), strides=(1,1), padding='same')(conv5_up)\n    return Model(inputs=inputs, outputs=conv5_up)\n\nWe can test the self-consistency of this net by feeding it 16 \"all ones\" images.  The output features should be identical for each input image, since the input images are simply all ones.\ndef test(filters=65, device='gpu'):\n    # Make a batch of 16 \"images\", ALL ONES.\n    img = np.ones((16, 512, 512, 3), dtype='float32')\n    with tf.device('/%s:0'%device):\n        model = my_model(filters)\n        features = model.predict(img)\n    # Compare features of 1st and 16th image.\n    # Since the input was all ones, they should agree.\n    inconsistent = np.any(features[0] != features[15])\n    if inconsistent:\n        print \"Inconsistent!\"\n\nThe model architecture is parameterized by a single parameter, filters, the number of filters in each layer.  Interestingly, I see that the model inconsistency cares about powers of 2 in filters:\n\u2022\u00a0consistency for filters=1 through 64,\n\u2022\u00a0inconsistency for filters=65 through 127,\n\u2022\u00a0consistency for filters=128,\n\u2022\u00a0inconsistency for filters=129 through 150.\nThe smallest model that shows the problem is at filters=65.  Below I show a single feature output for the 1st and 16th input images.  They should agree, but they don't.\nFeatures for 1st image (which is identical for images 1-15):\n\nFeatures for 16th image:\n\nAs can be seen, the feature map for the 16th image differs dramatically from images 1-15, even though the inputs are identical (all ones).\nIf I repeat this test with a filters=129 instead of filters=65, the bug appears earlier in the batch; the features for images 1-14 are identical, while the features for images 15 and 16 differ from the rest, and from each other.", "body": "### System Information\r\n```\r\nUbuntu 16.04 LTS\r\nCUDA 8.0\r\ncuDNN v5.1\r\nNVIDIA Tesla K80 (11439MiB)\r\ntensorflow 1.0.1 (bug also present in 1.1.0) [pip]\r\nkeras 2.0.3 [python setup.py install]\r\n```\r\n\r\n### Problem\r\nI can define a convnet that returns reasonable results with CPU, but returns a mixture of expected and nonsense results with GPU. The problem with the GPU processing is made clear by passing a set of \"all ones\" images to the net; the output should be identical for all 16 images, yet the outputs for the last one or two images differ drastically from the rest.\r\n\r\nI see this problem when using the GPU, but not with CPU.  No exceptions are raised, and there are no warnings beyond the usual `TensorFlow library wasn't compiled to use ___ instructions, but these are available on your machine and could speed up CPU computations.`.\r\n\r\nI see this problem using `tensorflow` as my `keras` backend, but not when using `theano` as my backend.  That statement is true whether I set `image_data_format` to `channels_last` or `channels_first`, for either backend.\r\n\r\nI've found three changes to the model architecture defined below that make the problem go away: (1) change the number of filters, as described in more detail below, (2) remove the `UpSampling2D` layer, or (3) remove the  `AveragePooling2D` layer.  Given (3), this issue may be related to https://github.com/tensorflow/tensorflow/issues/8566 .\r\n\r\n### Code\r\nConsider the following convnet.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D\r\nfrom keras.models import Model\r\nimport numpy as np\r\n\r\ndef my_model(filters=65):\r\n    np.random.seed(0)\r\n    inputs = Input((None, None, 3))\r\n    conv1 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(inputs)\r\n    conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)\r\n    conv2 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(conv1)\r\n    conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv2)\r\n    conv3 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv2)\r\n    conv3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv3)\r\n    conv4 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv3)\r\n    conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv4)\r\n    conv5 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv4)\r\n    conv5_up = UpSampling2D(size=(8, 8))(conv5)\r\n    conv5_up = AveragePooling2D(pool_size=(8, 8), strides=(1,1), padding='same')(conv5_up)\r\n    return Model(inputs=inputs, outputs=conv5_up)\r\n```\r\n\r\nWe can test the self-consistency of this net by feeding it 16 \"all ones\" images.  The output features should be identical for each input image, since the input images are simply all ones.\r\n\r\n```\r\ndef test(filters=65, device='gpu'):\r\n    # Make a batch of 16 \"images\", ALL ONES.\r\n    img = np.ones((16, 512, 512, 3), dtype='float32')\r\n    with tf.device('/%s:0'%device):\r\n        model = my_model(filters)\r\n        features = model.predict(img)\r\n    # Compare features of 1st and 16th image.\r\n    # Since the input was all ones, they should agree.\r\n    inconsistent = np.any(features[0] != features[15])\r\n    if inconsistent:\r\n        print \"Inconsistent!\"\r\n```\r\n\r\nThe model architecture is parameterized by a single parameter, `filters`, the number of filters in each layer.  Interestingly, I see that the model inconsistency cares about powers of 2 in `filters`:\r\n\r\n\u2022\u00a0consistency for `filters=1 through 64`,\r\n\u2022\u00a0inconsistency for `filters=65 through 127`,\r\n\u2022\u00a0consistency for `filters=128`, \r\n\u2022\u00a0inconsistency for `filters=129 through 150`.\r\n\r\nThe smallest model that shows the problem is at `filters=65`.  Below I show a single feature output for the 1st and 16th input images.  They should agree, but they don't.\r\n\r\nFeatures for 1st image (which is identical for images 1-15):\r\n![features_1st_image](https://cloud.githubusercontent.com/assets/4852957/25504294/33eb3ad6-2b52-11e7-9b1d-636bd576ed23.png)\r\n\r\nFeatures for 16th image:\r\n![features_16th_image](https://cloud.githubusercontent.com/assets/4852957/25504297/3969ab6e-2b52-11e7-87e7-67bed7a8c7b3.png)\r\n\r\nAs can be seen, the feature map for the 16th image differs dramatically from images 1-15, even though the inputs are identical (all ones).\r\n\r\nIf I repeat this test with a `filters=129` instead of `filters=65`, the bug appears earlier in the batch; the features for images 1-14 are identical, while the features for images 15 and 16 differ from the rest, and from each other.\r\n\r\n\r\n"}