{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7922", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7922/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7922/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7922/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7922", "id": 210501606, "node_id": "MDU6SXNzdWUyMTA1MDE2MDY=", "number": 7922, "title": "Unable to specify loss function in tf.contrib.learn.DNNLinearCombinedRegressor", "user": {"login": "nateypants", "id": 10746370, "node_id": "MDQ6VXNlcjEwNzQ2Mzcw", "avatar_url": "https://avatars0.githubusercontent.com/u/10746370?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nateypants", "html_url": "https://github.com/nateypants", "followers_url": "https://api.github.com/users/nateypants/followers", "following_url": "https://api.github.com/users/nateypants/following{/other_user}", "gists_url": "https://api.github.com/users/nateypants/gists{/gist_id}", "starred_url": "https://api.github.com/users/nateypants/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nateypants/subscriptions", "organizations_url": "https://api.github.com/users/nateypants/orgs", "repos_url": "https://api.github.com/users/nateypants/repos", "events_url": "https://api.github.com/users/nateypants/events{/privacy}", "received_events_url": "https://api.github.com/users/nateypants/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-02-27T14:37:24Z", "updated_at": "2017-03-01T13:34:57Z", "closed_at": "2017-03-01T02:08:39Z", "author_association": "NONE", "body_html": "<p>NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.</p>\n<p>For general support from the community, see <a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">StackOverflow</a>.<br>\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed<br>\nout of scope for GitHub Issues and point people to StackOverflow.</p>\n<p>For bugs or installation issues, please provide the following information.<br>\nThe more information you provide, the more easily we will be able to offer<br>\nhelp and advice.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>Have been unable to find how to specify loss function for both linear and deep components of the DNNLinearCombinedRegressor initializer. Looked in many places including tf.train (initialize optimizer with specific loss function?) and in learn.estimators. Also could not find a solution on stackoverflow or anywhere else through google searches.</p>\n<h3>Environment info</h3>\n<p>Operating System: mac OS 10.12.3</p>\n<p>Installed version of CUDA and cuDNN: None.<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed:</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>. Version 1.0.0</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Have not been able to specify loss function.</p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>Tried to create custom estimator using tf.contrib.losses to specify desired loss but unable to combine both deep and wide this way. Would prefer to use the pre-defined linearCombinedRegressor with a loss function specified for <em>each</em> of the linear and deep optimizers. How?</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>", "body_text": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\nFor general support from the community, see StackOverflow.\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nHave been unable to find how to specify loss function for both linear and deep components of the DNNLinearCombinedRegressor initializer. Looked in many places including tf.train (initialize optimizer with specific loss function?) and in learn.estimators. Also could not find a solution on stackoverflow or anywhere else through google searches.\nEnvironment info\nOperating System: mac OS 10.12.3\nInstalled version of CUDA and cuDNN: None.\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed:\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\". Version 1.0.0\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nHave not been able to specify loss function.\nWhat other attempted solutions have you tried?\nTried to create custom estimator using tf.contrib.losses to specify desired loss but unable to combine both deep and wide this way. Would prefer to use the pre-defined linearCombinedRegressor with a loss function specified for each of the linear and deep optimizers. How?\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nHave been unable to find how to specify loss function for both linear and deep components of the DNNLinearCombinedRegressor initializer. Looked in many places including tf.train (initialize optimizer with specific loss function?) and in learn.estimators. Also could not find a solution on stackoverflow or anywhere else through google searches.\r\n\r\n### Environment info\r\nOperating System: mac OS 10.12.3\r\n\r\nInstalled version of CUDA and cuDNN: None.\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: \r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. Version 1.0.0\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nHave not been able to specify loss function. \r\n\r\n\r\n### What other attempted solutions have you tried?\r\nTried to create custom estimator using tf.contrib.losses to specify desired loss but unable to combine both deep and wide this way. Would prefer to use the pre-defined linearCombinedRegressor with a loss function specified for _each_ of the linear and deep optimizers. How?\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n"}