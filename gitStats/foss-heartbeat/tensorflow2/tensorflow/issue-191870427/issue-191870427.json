{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5884", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5884/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5884/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5884/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5884", "id": 191870427, "node_id": "MDU6SXNzdWUxOTE4NzA0Mjc=", "number": 5884, "title": "Tensor slice is too large to serialize", "user": {"login": "ericyue", "id": 918889, "node_id": "MDQ6VXNlcjkxODg4OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/918889?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ericyue", "html_url": "https://github.com/ericyue", "followers_url": "https://api.github.com/users/ericyue/followers", "following_url": "https://api.github.com/users/ericyue/following{/other_user}", "gists_url": "https://api.github.com/users/ericyue/gists{/gist_id}", "starred_url": "https://api.github.com/users/ericyue/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ericyue/subscriptions", "organizations_url": "https://api.github.com/users/ericyue/orgs", "repos_url": "https://api.github.com/users/ericyue/repos", "events_url": "https://api.github.com/users/ericyue/events{/privacy}", "received_events_url": "https://api.github.com/users/ericyue/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2016-11-27T16:31:41Z", "updated_at": "2016-11-29T23:23:55Z", "closed_at": "2016-11-29T09:57:59Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I have read the realted isssue  <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"175920473\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/4291\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/4291/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/4291\">#4291</a> , but it's not solved.</p>\n<h3>Environment info</h3>\n<p>centos with cpu support and tensorflow latest version</p>\n<p>no cuda or cudnn</p>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>I am build a 4 layer network (128<em>64</em>64*32), input_unit feature size 20000000\uff08sparse feature size\uff09,  when train the model ,it errors that \"Tensor slice is too large to serialize\".</p>\n<p>my training code is like this <a href=\"https://github.com/tobegit3hub/deep_recommend_system/blob/master/a8a_classifier.py\">https://github.com/tobegit3hub/deep_recommend_system/blob/master/a8a_classifier.py</a></p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>nothing , it's seems that a protobuf limitation , but I want to know how to solve this with changes in my training code</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>\"Tensor slice is too large to serialize\"</p>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI have read the realted isssue  #4291 , but it's not solved.\nEnvironment info\ncentos with cpu support and tensorflow latest version\nno cuda or cudnn\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nI am build a 4 layer network (1286464*32), input_unit feature size 20000000\uff08sparse feature size\uff09,  when train the model ,it errors that \"Tensor slice is too large to serialize\".\nmy training code is like this https://github.com/tobegit3hub/deep_recommend_system/blob/master/a8a_classifier.py\nWhat other attempted solutions have you tried?\nnothing , it's seems that a protobuf limitation , but I want to know how to solve this with changes in my training code\nLogs or other output that would be helpful\n\"Tensor slice is too large to serialize\"", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI have read the realted isssue  https://github.com/tensorflow/tensorflow/issues/4291 , but it's not solved.\r\n\r\n### Environment info\r\ncentos with cpu support and tensorflow latest version\r\n\r\nno cuda or cudnn\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nI am build a 4 layer network (128*64*64*32), input_unit feature size 20000000\uff08sparse feature size\uff09,  when train the model ,it errors that \"Tensor slice is too large to serialize\".\r\n\r\n\r\nmy training code is like this https://github.com/tobegit3hub/deep_recommend_system/blob/master/a8a_classifier.py\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nnothing , it's seems that a protobuf limitation , but I want to know how to solve this with changes in my training code \r\n\r\n### Logs or other output that would be helpful\r\n\"Tensor slice is too large to serialize\"\r\n\r\n\r\n"}