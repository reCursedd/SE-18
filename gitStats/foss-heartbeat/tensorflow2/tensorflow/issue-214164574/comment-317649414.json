{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/317649414", "html_url": "https://github.com/tensorflow/tensorflow/issues/8404#issuecomment-317649414", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8404", "id": 317649414, "node_id": "MDEyOklzc3VlQ29tbWVudDMxNzY0OTQxNA==", "user": {"login": "Lakedaemon", "id": 103175, "node_id": "MDQ6VXNlcjEwMzE3NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/103175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lakedaemon", "html_url": "https://github.com/Lakedaemon", "followers_url": "https://api.github.com/users/Lakedaemon/followers", "following_url": "https://api.github.com/users/Lakedaemon/following{/other_user}", "gists_url": "https://api.github.com/users/Lakedaemon/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lakedaemon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lakedaemon/subscriptions", "organizations_url": "https://api.github.com/users/Lakedaemon/orgs", "repos_url": "https://api.github.com/users/Lakedaemon/repos", "events_url": "https://api.github.com/users/Lakedaemon/events{/privacy}", "received_events_url": "https://api.github.com/users/Lakedaemon/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-25T07:06:28Z", "updated_at": "2017-07-25T07:06:28Z", "author_association": "NONE", "body_html": "<p>If you are using keras, don't rename node to identity to strip switches from learning to inference.<br>\nIn keras, you train your model, you save weigths and when you want to export your frozen model to tenserflow, you :</p>\n<ol>\n<li>launch a new python script FROM SCRATCH that</li>\n</ol>\n<p><code>K.set_learning_phase(0) inputShape = (32, 32, 1) model = self.buildModel(inputShape, self.nbClasses)# I'm building the model from scratch here model.load_weights('weights-improvement-12-0.96.hdf5') saver = tf.train.Saver() saver.save(K.get_session(), self.exportPath + self.modelName, global_step=self.step) self.frozenOptimizedQuantizied()# I optimize things here </code></p>\n<ol start=\"2\">\n<li>load your weigths (with learning phase set to false) -&gt; the useless switches will be stripped</li>\n<li>then you save your model to tenserflow</li>\n<li>after that, you apply a python method to freeze your graph</li>\n<li>afterwards, you use the transfrom tools (you need bazel) to optimize your model for android</li>\n<li>then it works really great<br>\nI have a 5MB model that classify 3000 japanese characters on android blazingly fast :<br>\nThe guys who developped NN and tensorflow are geniuses. This is one of the best tools ever...</li>\n</ol>", "body_text": "If you are using keras, don't rename node to identity to strip switches from learning to inference.\nIn keras, you train your model, you save weigths and when you want to export your frozen model to tenserflow, you :\n\nlaunch a new python script FROM SCRATCH that\n\nK.set_learning_phase(0) inputShape = (32, 32, 1) model = self.buildModel(inputShape, self.nbClasses)# I'm building the model from scratch here model.load_weights('weights-improvement-12-0.96.hdf5') saver = tf.train.Saver() saver.save(K.get_session(), self.exportPath + self.modelName, global_step=self.step) self.frozenOptimizedQuantizied()# I optimize things here \n\nload your weigths (with learning phase set to false) -> the useless switches will be stripped\nthen you save your model to tenserflow\nafter that, you apply a python method to freeze your graph\nafterwards, you use the transfrom tools (you need bazel) to optimize your model for android\nthen it works really great\nI have a 5MB model that classify 3000 japanese characters on android blazingly fast :\nThe guys who developped NN and tensorflow are geniuses. This is one of the best tools ever...", "body": "If you are using keras, don't rename node to identity to strip switches from learning to inference.\r\nIn keras, you train your model, you save weigths and when you want to export your frozen model to tenserflow, you : \r\n1) launch a new python script FROM SCRATCH that\r\n\r\n `K.set_learning_phase(0)\r\n      inputShape = (32, 32, 1)\r\n      model = self.buildModel(inputShape, self.nbClasses)# I'm building the model from scratch here\r\n      model.load_weights('weights-improvement-12-0.96.hdf5')\r\n      saver = tf.train.Saver()\r\n      saver.save(K.get_session(), self.exportPath + self.modelName, global_step=self.step)\r\n      self.frozenOptimizedQuantizied()# I optimize things here\r\n`\r\n\r\n2) load your weigths (with learning phase set to false) -> the useless switches will be stripped\r\n3) then you save your model to tenserflow\r\n4) after that, you apply a python method to freeze your graph\r\n5) afterwards, you use the transfrom tools (you need bazel) to optimize your model for android\r\n6) then it works really great\r\nI have a 5MB model that classify 3000 japanese characters on android blazingly fast : \r\nThe guys who developped NN and tensorflow are geniuses. This is one of the best tools ever...\r\n\r\n\r\n"}