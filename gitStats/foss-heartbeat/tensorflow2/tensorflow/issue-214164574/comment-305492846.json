{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/305492846", "html_url": "https://github.com/tensorflow/tensorflow/issues/8404#issuecomment-305492846", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8404", "id": 305492846, "node_id": "MDEyOklzc3VlQ29tbWVudDMwNTQ5Mjg0Ng==", "user": {"login": "Lakedaemon", "id": 103175, "node_id": "MDQ6VXNlcjEwMzE3NQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/103175?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Lakedaemon", "html_url": "https://github.com/Lakedaemon", "followers_url": "https://api.github.com/users/Lakedaemon/followers", "following_url": "https://api.github.com/users/Lakedaemon/following{/other_user}", "gists_url": "https://api.github.com/users/Lakedaemon/gists{/gist_id}", "starred_url": "https://api.github.com/users/Lakedaemon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Lakedaemon/subscriptions", "organizations_url": "https://api.github.com/users/Lakedaemon/orgs", "repos_url": "https://api.github.com/users/Lakedaemon/repos", "events_url": "https://api.github.com/users/Lakedaemon/events{/privacy}", "received_events_url": "https://api.github.com/users/Lakedaemon/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-01T13:28:00Z", "updated_at": "2017-06-01T13:28:00Z", "author_association": "NONE", "body_html": "<p>I have tried a few commands :</p>\n<ol>\n<li>bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" tensorflow/contrib/android:libtensorflow_inference.so --config=android_arm</li>\n</ol>\n<p>-&gt; I get a 37 MB libtensorflow_inference.</p>\n<p>When compiling in an android apk, I get<br>\n:app:transformNativeLibsWithStripDebugSymbolForDebug/home/lakedaemon/Android/Sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-strip:/home/lakedaemon/IdeaProjects/Handwriter/app/build/intermediates/transforms/mergeJniLibs/debug/folders/2000/1f/main/lib/armeabi-v7a/libtensorflow_inference.so: File format not recognized</p>\n<p>So, the file format might be wrong</p>\n<p>When trying my app on an arm device, I get<br>\ndlopen(\"/data/app-lib/org.lakedaemon.handwriter-5/libtensorflow_inference.so\") failed: dlopen failed: \"/data/app-lib/org.lakedaemon.handwriter-5/libtensorflow_inference.so\" not 32-bit: 2<br>\nand then a java.lang.RuntimeException: Native TF methods not found; check that the correct native libraries are present in the APK</p>\n<ol start=\"2\">\n<li>bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --config=android_arm</li>\n</ol>\n<p>-&gt; I get a 91.2 MB libtensorflow_inference. Which means that the \"-DSELECTIVE_REGISTRATION\" looks like it is working.</p>\n<p>But I get the same errors on android...</p>\n<p>investigating further</p>", "body_text": "I have tried a few commands :\n\nbazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" tensorflow/contrib/android:libtensorflow_inference.so --config=android_arm\n\n-> I get a 37 MB libtensorflow_inference.\nWhen compiling in an android apk, I get\n:app:transformNativeLibsWithStripDebugSymbolForDebug/home/lakedaemon/Android/Sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-strip:/home/lakedaemon/IdeaProjects/Handwriter/app/build/intermediates/transforms/mergeJniLibs/debug/folders/2000/1f/main/lib/armeabi-v7a/libtensorflow_inference.so: File format not recognized\nSo, the file format might be wrong\nWhen trying my app on an arm device, I get\ndlopen(\"/data/app-lib/org.lakedaemon.handwriter-5/libtensorflow_inference.so\") failed: dlopen failed: \"/data/app-lib/org.lakedaemon.handwriter-5/libtensorflow_inference.so\" not 32-bit: 2\nand then a java.lang.RuntimeException: Native TF methods not found; check that the correct native libraries are present in the APK\n\nbazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --config=android_arm\n\n-> I get a 91.2 MB libtensorflow_inference. Which means that the \"-DSELECTIVE_REGISTRATION\" looks like it is working.\nBut I get the same errors on android...\ninvestigating further", "body": "I have tried a few commands : \r\n1) bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" tensorflow/contrib/android:libtensorflow_inference.so --config=android_arm\r\n\r\n-> I get a 37 MB libtensorflow_inference. \r\n\r\nWhen compiling in an android apk, I get \r\n:app:transformNativeLibsWithStripDebugSymbolForDebug/home/lakedaemon/Android/Sdk/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-strip:/home/lakedaemon/IdeaProjects/Handwriter/app/build/intermediates/transforms/mergeJniLibs/debug/folders/2000/1f/main/lib/armeabi-v7a/libtensorflow_inference.so: File format not recognized\r\n\r\nSo, the file format might be wrong\r\n\r\nWhen trying my app on an arm device, I get \r\ndlopen(\"/data/app-lib/org.lakedaemon.handwriter-5/libtensorflow_inference.so\") failed: dlopen failed: \"/data/app-lib/org.lakedaemon.handwriter-5/libtensorflow_inference.so\" not 32-bit: 2\r\nand then a java.lang.RuntimeException: Native TF methods not found; check that the correct native libraries are present in the APK\r\n\r\n2) bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --config=android_arm\r\n\r\n-> I get a 91.2 MB libtensorflow_inference. Which means that the \"-DSELECTIVE_REGISTRATION\" looks like it is working.\r\n\r\nBut I get the same errors on android...\r\n\r\ninvestigating further"}