{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/392876389", "html_url": "https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-392876389", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18880", "id": 392876389, "node_id": "MDEyOklzc3VlQ29tbWVudDM5Mjg3NjM4OQ==", "user": {"login": "ajbouh", "id": 7325, "node_id": "MDQ6VXNlcjczMjU=", "avatar_url": "https://avatars2.githubusercontent.com/u/7325?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ajbouh", "html_url": "https://github.com/ajbouh", "followers_url": "https://api.github.com/users/ajbouh/followers", "following_url": "https://api.github.com/users/ajbouh/following{/other_user}", "gists_url": "https://api.github.com/users/ajbouh/gists{/gist_id}", "starred_url": "https://api.github.com/users/ajbouh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ajbouh/subscriptions", "organizations_url": "https://api.github.com/users/ajbouh/orgs", "repos_url": "https://api.github.com/users/ajbouh/repos", "events_url": "https://api.github.com/users/ajbouh/events{/privacy}", "received_events_url": "https://api.github.com/users/ajbouh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-29T17:59:46Z", "updated_at": "2018-05-29T17:59:46Z", "author_association": "NONE", "body_html": "<div class=\"email-fragment\">I think a good solution to this family of problems should not make\nassumptions about layers or primitives \"above\" the abstractions that are\npart of the TF distributed abstractions.\n\nI also think that we are probably too early in the development and\ndeployment of these systems to be able to recognize and implement a good\npolicy for handling all the kinds of failures that may exist. Better would\nbe to implement the primitives we need to detect and handle failure and\nallow everyone to experiment with policies on their own.\n\nGiven the cost and scale of the training sessions people are running, it\nshould be easy to see why a robust and reliable training system is\ndesirable.\n\nIf others are in agreement about this approach, I suggest an even narrower\nset of questions:\n- what TF ops are missing that would allow in-graph detection of a worker\nfailure?\n- what ops are missing that would allow in-graph re-init of a\nrecovered/replaced worker?\n- what ops (or combinations of ops) exist today might be incompatible with\nin-graph recovery?\n\nIf the above were addressed, perhaps we could get away with a simple outer\nwhile loop that repeatedly calls session.run until the termination\ncondition has been reached?</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Tue, May 29, 2018, 09:36 Brennan Saeta ***@***.***&gt; wrote:\n Hmm, this is a very nuanced topic that deserves careful thought. I guess I\n see 2 approaches to failure handling: either (1) we adopt the \"crash-only\"\n philosophy, or (2) we attempt some sort of \"online\" recovery to handle\n partial (e.g. single node) failures. Unfortunately, they don't mix terribly\n well.\n\n Advantages of the first is that it dramatically simplifies the semantics\n as well as the system implementation. Because fewer code paths are required\n (and they are exercised constantly), software projects with this fault\n tolerance model can sometimes be more robust.\n\n That said, in some domains this approach cannot meet certain system goals,\n and thus partial failures must be tolerated and handled correctly. (e.g. A\n distributed database.) Unfortunately, these systems are very complicated\n and are generally designed around handling failures. These systems have\n uptime measured over months / years and are distributed across hundreds,\n thousands, or more servers. By contrast, TensorFlow is instead focused on\n training jobs that last hours to days (weeks at most), and typically don't\n scale beyond hundreds of servers. Because of these differing requirements,\n TensorFlow has historically taken the crash-only approach. (Note:\n TensorFlow has actually been moving in the opposite direction; new\n distribution strategies centered around all-reduce and other HPC-style\n primitives are known to be higher performance (e.g. than parameter-server\n style configurations) but are easier to ensure they are working reliably in\n crash-only systems. Parameter-server style configurations running in an\n async approach are pretty resilient to workers going down.)\n\n If we are to deviate from this, one way to think about it would be to\n answer the following questions:\n\n    1. What are the overall system goals? What application are we trying\n    to meet that we can't meet today?\n    2. What is the end-to-end design? Are certain layers crash-only? If\n    so, how does that mix with online recovery of other layers?\n    3. What is the expected implementation cost of the approach? Does it\n    prevent easy implementation of other features on our roadmap?\n    4. Does the value of the applications outweigh the above costs?\n\n Dropping down a level (if the above response is focused on the larger\n discussion, this is on a more detailed technical level), the cost of\n creating a new session is typically pretty cheap (assuming the graph is not\n gigantic). State can be stored in containers outside of specific sessions,\n so [some] more complicated partial-failure recovery can be implemented\n (e.g. in Python) on top of the core TF primitives today.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"317821563\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/18880\" href=\"https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-392842564\">#18880 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AAAcne2F8tsnGDm3ptBdVVzFD-JvwpAXks5t3XkSgaJpZM4TkRsG\">https://github.com/notifications/unsubscribe-auth/AAAcne2F8tsnGDm3ptBdVVzFD-JvwpAXks5t3XkSgaJpZM4TkRsG</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "I think a good solution to this family of problems should not make\nassumptions about layers or primitives \"above\" the abstractions that are\npart of the TF distributed abstractions.\n\nI also think that we are probably too early in the development and\ndeployment of these systems to be able to recognize and implement a good\npolicy for handling all the kinds of failures that may exist. Better would\nbe to implement the primitives we need to detect and handle failure and\nallow everyone to experiment with policies on their own.\n\nGiven the cost and scale of the training sessions people are running, it\nshould be easy to see why a robust and reliable training system is\ndesirable.\n\nIf others are in agreement about this approach, I suggest an even narrower\nset of questions:\n- what TF ops are missing that would allow in-graph detection of a worker\nfailure?\n- what ops are missing that would allow in-graph re-init of a\nrecovered/replaced worker?\n- what ops (or combinations of ops) exist today might be incompatible with\nin-graph recovery?\n\nIf the above were addressed, perhaps we could get away with a simple outer\nwhile loop that repeatedly calls session.run until the termination\ncondition has been reached?\n\u2026\nOn Tue, May 29, 2018, 09:36 Brennan Saeta ***@***.***> wrote:\n Hmm, this is a very nuanced topic that deserves careful thought. I guess I\n see 2 approaches to failure handling: either (1) we adopt the \"crash-only\"\n philosophy, or (2) we attempt some sort of \"online\" recovery to handle\n partial (e.g. single node) failures. Unfortunately, they don't mix terribly\n well.\n\n Advantages of the first is that it dramatically simplifies the semantics\n as well as the system implementation. Because fewer code paths are required\n (and they are exercised constantly), software projects with this fault\n tolerance model can sometimes be more robust.\n\n That said, in some domains this approach cannot meet certain system goals,\n and thus partial failures must be tolerated and handled correctly. (e.g. A\n distributed database.) Unfortunately, these systems are very complicated\n and are generally designed around handling failures. These systems have\n uptime measured over months / years and are distributed across hundreds,\n thousands, or more servers. By contrast, TensorFlow is instead focused on\n training jobs that last hours to days (weeks at most), and typically don't\n scale beyond hundreds of servers. Because of these differing requirements,\n TensorFlow has historically taken the crash-only approach. (Note:\n TensorFlow has actually been moving in the opposite direction; new\n distribution strategies centered around all-reduce and other HPC-style\n primitives are known to be higher performance (e.g. than parameter-server\n style configurations) but are easier to ensure they are working reliably in\n crash-only systems. Parameter-server style configurations running in an\n async approach are pretty resilient to workers going down.)\n\n If we are to deviate from this, one way to think about it would be to\n answer the following questions:\n\n    1. What are the overall system goals? What application are we trying\n    to meet that we can't meet today?\n    2. What is the end-to-end design? Are certain layers crash-only? If\n    so, how does that mix with online recovery of other layers?\n    3. What is the expected implementation cost of the approach? Does it\n    prevent easy implementation of other features on our roadmap?\n    4. Does the value of the applications outweigh the above costs?\n\n Dropping down a level (if the above response is focused on the larger\n discussion, this is on a more detailed technical level), the cost of\n creating a new session is typically pretty cheap (assuming the graph is not\n gigantic). State can be stored in containers outside of specific sessions,\n so [some] more complicated partial-failure recovery can be implemented\n (e.g. in Python) on top of the core TF primitives today.\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#18880 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AAAcne2F8tsnGDm3ptBdVVzFD-JvwpAXks5t3XkSgaJpZM4TkRsG>\n .", "body": "I think a good solution to this family of problems should not make\nassumptions about layers or primitives \"above\" the abstractions that are\npart of the TF distributed abstractions.\n\nI also think that we are probably too early in the development and\ndeployment of these systems to be able to recognize and implement a good\npolicy for handling all the kinds of failures that may exist. Better would\nbe to implement the primitives we need to detect and handle failure and\nallow everyone to experiment with policies on their own.\n\nGiven the cost and scale of the training sessions people are running, it\nshould be easy to see why a robust and reliable training system is\ndesirable.\n\nIf others are in agreement about this approach, I suggest an even narrower\nset of questions:\n- what TF ops are missing that would allow in-graph detection of a worker\nfailure?\n- what ops are missing that would allow in-graph re-init of a\nrecovered/replaced worker?\n- what ops (or combinations of ops) exist today might be incompatible with\nin-graph recovery?\n\nIf the above were addressed, perhaps we could get away with a simple outer\nwhile loop that repeatedly calls session.run until the termination\ncondition has been reached?\n\n\nOn Tue, May 29, 2018, 09:36 Brennan Saeta <notifications@github.com> wrote:\n\n> Hmm, this is a very nuanced topic that deserves careful thought. I guess I\n> see 2 approaches to failure handling: either (1) we adopt the \"crash-only\"\n> philosophy, or (2) we attempt some sort of \"online\" recovery to handle\n> partial (e.g. single node) failures. Unfortunately, they don't mix terribly\n> well.\n>\n> Advantages of the first is that it dramatically simplifies the semantics\n> as well as the system implementation. Because fewer code paths are required\n> (and they are exercised constantly), software projects with this fault\n> tolerance model can sometimes be more robust.\n>\n> That said, in some domains this approach cannot meet certain system goals,\n> and thus partial failures must be tolerated and handled correctly. (e.g. A\n> distributed database.) Unfortunately, these systems are very complicated\n> and are generally designed around handling failures. These systems have\n> uptime measured over months / years and are distributed across hundreds,\n> thousands, or more servers. By contrast, TensorFlow is instead focused on\n> training jobs that last hours to days (weeks at most), and typically don't\n> scale beyond hundreds of servers. Because of these differing requirements,\n> TensorFlow has historically taken the crash-only approach. (Note:\n> TensorFlow has actually been moving in the opposite direction; new\n> distribution strategies centered around all-reduce and other HPC-style\n> primitives are known to be higher performance (e.g. than parameter-server\n> style configurations) but are easier to ensure they are working reliably in\n> crash-only systems. Parameter-server style configurations running in an\n> async approach are pretty resilient to workers going down.)\n>\n> If we are to deviate from this, one way to think about it would be to\n> answer the following questions:\n>\n>    1. What are the overall system goals? What application are we trying\n>    to meet that we can't meet today?\n>    2. What is the end-to-end design? Are certain layers crash-only? If\n>    so, how does that mix with online recovery of other layers?\n>    3. What is the expected implementation cost of the approach? Does it\n>    prevent easy implementation of other features on our roadmap?\n>    4. Does the value of the applications outweigh the above costs?\n>\n> Dropping down a level (if the above response is focused on the larger\n> discussion, this is on a more detailed technical level), the cost of\n> creating a new session is typically pretty cheap (assuming the graph is not\n> gigantic). State can be stored in containers outside of specific sessions,\n> so [some] more complicated partial-failure recovery can be implemented\n> (e.g. in Python) on top of the core TF primitives today.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-392842564>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcne2F8tsnGDm3ptBdVVzFD-JvwpAXks5t3XkSgaJpZM4TkRsG>\n> .\n>\n"}