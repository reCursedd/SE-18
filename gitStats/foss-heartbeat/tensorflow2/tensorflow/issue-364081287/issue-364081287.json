{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22541", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22541/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22541/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22541/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22541", "id": 364081287, "node_id": "MDU6SXNzdWUzNjQwODEyODc=", "number": 22541, "title": "Java process crashes during model loading", "user": {"login": "sam701", "id": 7078566, "node_id": "MDQ6VXNlcjcwNzg1NjY=", "avatar_url": "https://avatars2.githubusercontent.com/u/7078566?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sam701", "html_url": "https://github.com/sam701", "followers_url": "https://api.github.com/users/sam701/followers", "following_url": "https://api.github.com/users/sam701/following{/other_user}", "gists_url": "https://api.github.com/users/sam701/gists{/gist_id}", "starred_url": "https://api.github.com/users/sam701/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sam701/subscriptions", "organizations_url": "https://api.github.com/users/sam701/orgs", "repos_url": "https://api.github.com/users/sam701/repos", "events_url": "https://api.github.com/users/sam701/events{/privacy}", "received_events_url": "https://api.github.com/users/sam701/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-09-26T15:12:08Z", "updated_at": "2018-11-12T18:52:21Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: AWS c5.xlarge, Amazon Linux</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: java binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: java org.tensorflow:tensorflow:1.11.0-rc2</li>\n<li><strong>Python version</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I run the following program on <code>c5.xlarge</code> (CPU only, no GPU) with 8GB RAM and 12GB swap memory.</p>\n<div class=\"highlight highlight-source-java\"><pre><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en\">TryOut</span> {\n    <span class=\"pl-k\">public</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">void</span> <span class=\"pl-en\">main</span>(<span class=\"pl-k\">String</span>[] <span class=\"pl-v\">args</span>) {\n        <span class=\"pl-k\">SavedModelBundle</span>[] loadedModels <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">SavedModelBundle</span>[<span class=\"pl-c1\">15</span>];\n        <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i <span class=\"pl-k\">=</span> <span class=\"pl-c1\">0</span>; i <span class=\"pl-k\">&lt;</span> <span class=\"pl-c1\">15</span>; i<span class=\"pl-k\">++</span>) {\n            <span class=\"pl-smi\">System</span><span class=\"pl-k\">.</span>out<span class=\"pl-k\">.</span>println(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>loading model <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> i);\n            loadedModels[i] <span class=\"pl-k\">=</span> <span class=\"pl-smi\">SavedModelBundle</span><span class=\"pl-k\">.</span>load(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>models/0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>serve<span class=\"pl-pds\">\"</span></span>);\n        }\n    }\n}</pre></div>\n<p><code>models/0</code> contains the model <a href=\"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz\" rel=\"nofollow\">faster_rcnn_resnet101_coco</a> from the <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">model zoo</a>.<br>\nHere is the directory structure:</p>\n<div class=\"highlight highlight-source-shell\"><pre>models/0/\n\u2514\u2500\u2500 saved_model.pb</pre></div>\n<p>I run the program as <code>java -jar mem-test.jar</code>.</p>\n<h4>Problem</h4>\n<p>Process crashes during model loading when the free memory becomes low (see <code>output.txt</code>).<br>\nThe process does not try to utilize available swap memory.</p>\n<p>This behavior is reproducible with other models from the model zoo.</p>\n<p>On the other hand, <code>tensorflow-serving</code> can download multiple models into memory, utilizes swap and runs inferences without crashing as long as there is swap memory available.</p>\n<h3>Source code / logs</h3>\n<p>See also the attached files:</p>\n<ul>\n<li><a href=\"https://github.com/tensorflow/tensorflow/files/2420367/output.txt\">output.txt</a></li>\n<li><a href=\"https://github.com/tensorflow/tensorflow/files/2420368/hs_err_pid31150.log\">hs_err_pid31150.log</a></li>\n</ul>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): AWS c5.xlarge, Amazon Linux\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): java binary\nTensorFlow version (use command below): java org.tensorflow:tensorflow:1.11.0-rc2\nPython version:\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nI run the following program on c5.xlarge (CPU only, no GPU) with 8GB RAM and 12GB swap memory.\npublic class TryOut {\n    public static void main(String[] args) {\n        SavedModelBundle[] loadedModels = new SavedModelBundle[15];\n        for (int i = 0; i < 15; i++) {\n            System.out.println(\"loading model \" + i);\n            loadedModels[i] = SavedModelBundle.load(\"models/0\", \"serve\");\n        }\n    }\n}\nmodels/0 contains the model faster_rcnn_resnet101_coco from the model zoo.\nHere is the directory structure:\nmodels/0/\n\u2514\u2500\u2500 saved_model.pb\nI run the program as java -jar mem-test.jar.\nProblem\nProcess crashes during model loading when the free memory becomes low (see output.txt).\nThe process does not try to utilize available swap memory.\nThis behavior is reproducible with other models from the model zoo.\nOn the other hand, tensorflow-serving can download multiple models into memory, utilizes swap and runs inferences without crashing as long as there is swap memory available.\nSource code / logs\nSee also the attached files:\n\noutput.txt\nhs_err_pid31150.log", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: AWS c5.xlarge, Amazon Linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: java binary\r\n- **TensorFlow version (use command below)**: java org.tensorflow:tensorflow:1.11.0-rc2\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nI run the following program on `c5.xlarge` (CPU only, no GPU) with 8GB RAM and 12GB swap memory.\r\n```java\r\npublic class TryOut {\r\n    public static void main(String[] args) {\r\n        SavedModelBundle[] loadedModels = new SavedModelBundle[15];\r\n        for (int i = 0; i < 15; i++) {\r\n            System.out.println(\"loading model \" + i);\r\n            loadedModels[i] = SavedModelBundle.load(\"models/0\", \"serve\");\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n`models/0` contains the model [faster_rcnn_resnet101_coco](http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz) from the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).\r\nHere is the directory structure:\r\n```sh\r\nmodels/0/\r\n\u2514\u2500\u2500 saved_model.pb\r\n```\r\n\r\nI run the program as `java -jar mem-test.jar`.\r\n\r\n\r\n#### Problem\r\nProcess crashes during model loading when the free memory becomes low (see `output.txt`).\r\nThe process does not try to utilize available swap memory.\r\n\r\nThis behavior is reproducible with other models from the model zoo.\r\n\r\nOn the other hand, `tensorflow-serving` can download multiple models into memory, utilizes swap and runs inferences without crashing as long as there is swap memory available.\r\n\r\n### Source code / logs\r\n\r\nSee also the attached files:\r\n* [output.txt](https://github.com/tensorflow/tensorflow/files/2420367/output.txt)\r\n* [hs_err_pid31150.log](https://github.com/tensorflow/tensorflow/files/2420368/hs_err_pid31150.log)\r\n\r\n"}