{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20922", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20922/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20922/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20922/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20922", "id": 342295673, "node_id": "MDU6SXNzdWUzNDIyOTU2NzM=", "number": 20922, "title": "Decoding 16bit PNG bug", "user": {"login": "apisarek", "id": 14896299, "node_id": "MDQ6VXNlcjE0ODk2Mjk5", "avatar_url": "https://avatars1.githubusercontent.com/u/14896299?v=4", "gravatar_id": "", "url": "https://api.github.com/users/apisarek", "html_url": "https://github.com/apisarek", "followers_url": "https://api.github.com/users/apisarek/followers", "following_url": "https://api.github.com/users/apisarek/following{/other_user}", "gists_url": "https://api.github.com/users/apisarek/gists{/gist_id}", "starred_url": "https://api.github.com/users/apisarek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/apisarek/subscriptions", "organizations_url": "https://api.github.com/users/apisarek/orgs", "repos_url": "https://api.github.com/users/apisarek/repos", "events_url": "https://api.github.com/users/apisarek/events{/privacy}", "received_events_url": "https://api.github.com/users/apisarek/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "sguada", "id": 1766524, "node_id": "MDQ6VXNlcjE3NjY1MjQ=", "avatar_url": "https://avatars3.githubusercontent.com/u/1766524?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sguada", "html_url": "https://github.com/sguada", "followers_url": "https://api.github.com/users/sguada/followers", "following_url": "https://api.github.com/users/sguada/following{/other_user}", "gists_url": "https://api.github.com/users/sguada/gists{/gist_id}", "starred_url": "https://api.github.com/users/sguada/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sguada/subscriptions", "organizations_url": "https://api.github.com/users/sguada/orgs", "repos_url": "https://api.github.com/users/sguada/repos", "events_url": "https://api.github.com/users/sguada/events{/privacy}", "received_events_url": "https://api.github.com/users/sguada/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-07-18T11:52:48Z", "updated_at": "2018-11-11T18:40:30Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nI have written a test that (IMHO) should not fail, but it fails.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nLinux Mint 18</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\n<code>pip install tensorflow==1.8</code> in a clean environment</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.8</li>\n<li><strong>Python version</strong>:<br>\n3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nPlease run</li>\n</ul>\n<pre><code># Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for slim.data.tfexample_decoder.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom tensorflow.contrib.slim.python.slim.data import tfexample_decoder\nfrom tensorflow.core.example import example_pb2\nfrom tensorflow.core.example import feature_pb2\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import lookup_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import parsing_ops\nfrom tensorflow.python.platform import test\n\n\nclass TFExampleDecoderTest(test.TestCase):\n\n    def _EncodedFloatFeature(self, ndarray):\n        return feature_pb2.Feature(float_list=feature_pb2.FloatList(\n            value=ndarray.flatten().tolist()))\n\n    def _EncodedInt64Feature(self, ndarray):\n        return feature_pb2.Feature(int64_list=feature_pb2.Int64List(\n            value=ndarray.flatten().tolist()))\n\n    def _EncodedBytesFeature(self, tf_encoded):\n        with self.test_session():\n            encoded = tf_encoded.eval()\n\n        def BytesList(value):\n            return feature_pb2.BytesList(value=[value])\n\n        return feature_pb2.Feature(bytes_list=BytesList(encoded))\n\n    def _BytesFeature(self, ndarray):\n        values = ndarray.flatten().tolist()\n        for i in range(len(values)):\n            values[i] = values[i].encode('utf-8')\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=values))\n\n    def _StringFeature(self, value):\n        value = value.encode('utf-8')\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=[value]))\n\n    def _Encoder(self, image, image_format):\n        assert image_format in ['jpeg', 'JPEG', 'png', 'PNG', 'raw', 'RAW']\n        if image_format in ['jpeg', 'JPEG']:\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\n            return image_ops.encode_jpeg(tf_image)\n        if image_format in ['png', 'PNG']:\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\n            return image_ops.encode_png(tf_image)\n        if image_format in ['raw', 'RAW']:\n            return constant_op.constant(image.tostring(), dtype=dtypes.string)\n\n    def GenerateImage(self, image_format, image_shape):\n        \"\"\"Generates an image and an example containing the encoded image.\n\n        Args:\n          image_format: the encoding format of the image.\n          image_shape: the shape of the image to generate.\n\n        Returns:\n          image: the generated image.\n          example: a TF-example with a feature key 'image/encoded' set to the\n            serialized image and a feature key 'image/format' set to the image\n            encoding format ['jpeg', 'JPEG', 'png', 'PNG', 'raw'].\n        \"\"\"\n        num_pixels = image_shape[0] * image_shape[1] * image_shape[2]\n        image = np.linspace(\n            0, num_pixels - 1, num=num_pixels).reshape(image_shape).astype(np.uint8)\n        tf_encoded = self._Encoder(image, image_format)\n        example = example_pb2.Example(features=feature_pb2.Features(feature={\n            'image/encoded': self._EncodedBytesFeature(tf_encoded),\n            'image/format': self._StringFeature(image_format)\n        }))\n\n        return image, example.SerializeToString()\n\n    def DecodeExample(self, serialized_example, item_handler, image_format):\n        \"\"\"Decodes the given serialized example with the specified item handler.\n\n        Args:\n          serialized_example: a serialized TF example string.\n          item_handler: the item handler used to decode the image.\n          image_format: the image format being decoded.\n\n        Returns:\n          the decoded image found in the serialized Example.\n        \"\"\"\n        serialized_example = array_ops.reshape(serialized_example, shape=[])\n        decoder = tfexample_decoder.TFExampleDecoder(\n            keys_to_features={\n                'image/encoded':\n                    parsing_ops.FixedLenFeature(\n                        (), dtypes.string, default_value=''),\n                'image/format':\n                    parsing_ops.FixedLenFeature(\n                        (), dtypes.string, default_value=image_format),\n            },\n            items_to_handlers={'image': item_handler})\n        [tf_image] = decoder.decode(serialized_example, ['image'])\n        return tf_image\n\n    def RunDecodeExample(self, serialized_example, item_handler, image_format):\n        tf_image = self.DecodeExample(serialized_example, item_handler,\n                                      image_format)\n\n        with self.test_session():\n            decoded_image = tf_image.eval()\n\n            # We need to recast them here to avoid some issues with uint8.\n            return decoded_image.astype(np.float32)\n\n    def testDecodeExampleWithPngEncodingAt16Bit(self):\n        image_shape = (2, 3, 3)\n        unused_image, serialized_example = self.GenerateImage(\n            image_format='png', image_shape=image_shape)\n        unused_decoded_image = self.RunDecodeExample(\n            serialized_example,\n            tfexample_decoder.Image(dtype=dtypes.uint16),\n            image_format='png')\n        self.assertAllClose(unused_image, unused_decoded_image)\n\n\nif __name__ == '__main__':\n    test.main()\n</code></pre>\n<p>It is a modified <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/tfexample_decoder_test.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/tfexample_decoder_test.py</a></p>\n<h3>Describe the problem</h3>\n<p>I would like to decode and encode a single channel 16bit (uint16) PNG and it is not possible. I have modified the tests also to create a np.uint16 image, then trying to decode it, but it does not work.</p>\n<pre><code>  def testDecodeExampleWithPngEncodingAt16Bit(self):\n    image_shape = (2, 3, 3)\n    unused_image, serialized_example = self.GenerateImage(\n        image_format='png', image_shape=image_shape, dtype=np.uint16)\n    unused_decoded_image = self.RunDecodeExample(\n          serialized_example,\n          tfexample_decoder.Image(dtype=dtypes.uint16),\n          image_format='png')\n    self.assertAllClose(unused_image, unused_decoded_image)\n</code></pre>\n<p>(modifying the <code>GenerateImage</code> method accordingly).</p>\n<p>I understand that it should be possible since decode_png function allows uint16 as an output type: <a href=\"https://www.tensorflow.org/api_docs/python/tf/image/decode_png\" rel=\"nofollow\">https://www.tensorflow.org/api_docs/python/tf/image/decode_png</a></p>\n<p>The test fails because the program raises</p>\n<pre><code>ValueError: Outputs of true_fn and false_fn must have the same type: uint16, uint8\n</code></pre>\n<p>I understand that it is due to the fact that <code>tf.cond</code> needs the same output types from branches.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nI have written a test that (IMHO) should not fail, but it fails.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nLinux Mint 18\nTensorFlow installed from (source or binary):\npip install tensorflow==1.8 in a clean environment\nTensorFlow version (use command below):\n1.8\nPython version:\n3.6\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\nPlease run\n\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for slim.data.tfexample_decoder.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\nfrom tensorflow.contrib.slim.python.slim.data import tfexample_decoder\nfrom tensorflow.core.example import example_pb2\nfrom tensorflow.core.example import feature_pb2\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import image_ops\nfrom tensorflow.python.ops import lookup_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import parsing_ops\nfrom tensorflow.python.platform import test\n\n\nclass TFExampleDecoderTest(test.TestCase):\n\n    def _EncodedFloatFeature(self, ndarray):\n        return feature_pb2.Feature(float_list=feature_pb2.FloatList(\n            value=ndarray.flatten().tolist()))\n\n    def _EncodedInt64Feature(self, ndarray):\n        return feature_pb2.Feature(int64_list=feature_pb2.Int64List(\n            value=ndarray.flatten().tolist()))\n\n    def _EncodedBytesFeature(self, tf_encoded):\n        with self.test_session():\n            encoded = tf_encoded.eval()\n\n        def BytesList(value):\n            return feature_pb2.BytesList(value=[value])\n\n        return feature_pb2.Feature(bytes_list=BytesList(encoded))\n\n    def _BytesFeature(self, ndarray):\n        values = ndarray.flatten().tolist()\n        for i in range(len(values)):\n            values[i] = values[i].encode('utf-8')\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=values))\n\n    def _StringFeature(self, value):\n        value = value.encode('utf-8')\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=[value]))\n\n    def _Encoder(self, image, image_format):\n        assert image_format in ['jpeg', 'JPEG', 'png', 'PNG', 'raw', 'RAW']\n        if image_format in ['jpeg', 'JPEG']:\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\n            return image_ops.encode_jpeg(tf_image)\n        if image_format in ['png', 'PNG']:\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\n            return image_ops.encode_png(tf_image)\n        if image_format in ['raw', 'RAW']:\n            return constant_op.constant(image.tostring(), dtype=dtypes.string)\n\n    def GenerateImage(self, image_format, image_shape):\n        \"\"\"Generates an image and an example containing the encoded image.\n\n        Args:\n          image_format: the encoding format of the image.\n          image_shape: the shape of the image to generate.\n\n        Returns:\n          image: the generated image.\n          example: a TF-example with a feature key 'image/encoded' set to the\n            serialized image and a feature key 'image/format' set to the image\n            encoding format ['jpeg', 'JPEG', 'png', 'PNG', 'raw'].\n        \"\"\"\n        num_pixels = image_shape[0] * image_shape[1] * image_shape[2]\n        image = np.linspace(\n            0, num_pixels - 1, num=num_pixels).reshape(image_shape).astype(np.uint8)\n        tf_encoded = self._Encoder(image, image_format)\n        example = example_pb2.Example(features=feature_pb2.Features(feature={\n            'image/encoded': self._EncodedBytesFeature(tf_encoded),\n            'image/format': self._StringFeature(image_format)\n        }))\n\n        return image, example.SerializeToString()\n\n    def DecodeExample(self, serialized_example, item_handler, image_format):\n        \"\"\"Decodes the given serialized example with the specified item handler.\n\n        Args:\n          serialized_example: a serialized TF example string.\n          item_handler: the item handler used to decode the image.\n          image_format: the image format being decoded.\n\n        Returns:\n          the decoded image found in the serialized Example.\n        \"\"\"\n        serialized_example = array_ops.reshape(serialized_example, shape=[])\n        decoder = tfexample_decoder.TFExampleDecoder(\n            keys_to_features={\n                'image/encoded':\n                    parsing_ops.FixedLenFeature(\n                        (), dtypes.string, default_value=''),\n                'image/format':\n                    parsing_ops.FixedLenFeature(\n                        (), dtypes.string, default_value=image_format),\n            },\n            items_to_handlers={'image': item_handler})\n        [tf_image] = decoder.decode(serialized_example, ['image'])\n        return tf_image\n\n    def RunDecodeExample(self, serialized_example, item_handler, image_format):\n        tf_image = self.DecodeExample(serialized_example, item_handler,\n                                      image_format)\n\n        with self.test_session():\n            decoded_image = tf_image.eval()\n\n            # We need to recast them here to avoid some issues with uint8.\n            return decoded_image.astype(np.float32)\n\n    def testDecodeExampleWithPngEncodingAt16Bit(self):\n        image_shape = (2, 3, 3)\n        unused_image, serialized_example = self.GenerateImage(\n            image_format='png', image_shape=image_shape)\n        unused_decoded_image = self.RunDecodeExample(\n            serialized_example,\n            tfexample_decoder.Image(dtype=dtypes.uint16),\n            image_format='png')\n        self.assertAllClose(unused_image, unused_decoded_image)\n\n\nif __name__ == '__main__':\n    test.main()\n\nIt is a modified https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/tfexample_decoder_test.py\nDescribe the problem\nI would like to decode and encode a single channel 16bit (uint16) PNG and it is not possible. I have modified the tests also to create a np.uint16 image, then trying to decode it, but it does not work.\n  def testDecodeExampleWithPngEncodingAt16Bit(self):\n    image_shape = (2, 3, 3)\n    unused_image, serialized_example = self.GenerateImage(\n        image_format='png', image_shape=image_shape, dtype=np.uint16)\n    unused_decoded_image = self.RunDecodeExample(\n          serialized_example,\n          tfexample_decoder.Image(dtype=dtypes.uint16),\n          image_format='png')\n    self.assertAllClose(unused_image, unused_decoded_image)\n\n(modifying the GenerateImage method accordingly).\nI understand that it should be possible since decode_png function allows uint16 as an output type: https://www.tensorflow.org/api_docs/python/tf/image/decode_png\nThe test fails because the program raises\nValueError: Outputs of true_fn and false_fn must have the same type: uint16, uint8\n\nI understand that it is due to the fact that tf.cond needs the same output types from branches.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI have written a test that (IMHO) should not fail, but it fails.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Mint 18\r\n- **TensorFlow installed from (source or binary)**:\r\n`pip install tensorflow==1.8` in a clean environment\r\n- **TensorFlow version (use command below)**:\r\n1.8\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\nPlease run \r\n```\r\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# ==============================================================================\r\n\"\"\"Tests for slim.data.tfexample_decoder.\"\"\"\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\n\r\nfrom tensorflow.contrib.slim.python.slim.data import tfexample_decoder\r\nfrom tensorflow.core.example import example_pb2\r\nfrom tensorflow.core.example import feature_pb2\r\nfrom tensorflow.python.framework import constant_op\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import control_flow_ops\r\nfrom tensorflow.python.ops import image_ops\r\nfrom tensorflow.python.ops import lookup_ops\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.ops import parsing_ops\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass TFExampleDecoderTest(test.TestCase):\r\n\r\n    def _EncodedFloatFeature(self, ndarray):\r\n        return feature_pb2.Feature(float_list=feature_pb2.FloatList(\r\n            value=ndarray.flatten().tolist()))\r\n\r\n    def _EncodedInt64Feature(self, ndarray):\r\n        return feature_pb2.Feature(int64_list=feature_pb2.Int64List(\r\n            value=ndarray.flatten().tolist()))\r\n\r\n    def _EncodedBytesFeature(self, tf_encoded):\r\n        with self.test_session():\r\n            encoded = tf_encoded.eval()\r\n\r\n        def BytesList(value):\r\n            return feature_pb2.BytesList(value=[value])\r\n\r\n        return feature_pb2.Feature(bytes_list=BytesList(encoded))\r\n\r\n    def _BytesFeature(self, ndarray):\r\n        values = ndarray.flatten().tolist()\r\n        for i in range(len(values)):\r\n            values[i] = values[i].encode('utf-8')\r\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=values))\r\n\r\n    def _StringFeature(self, value):\r\n        value = value.encode('utf-8')\r\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=[value]))\r\n\r\n    def _Encoder(self, image, image_format):\r\n        assert image_format in ['jpeg', 'JPEG', 'png', 'PNG', 'raw', 'RAW']\r\n        if image_format in ['jpeg', 'JPEG']:\r\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\r\n            return image_ops.encode_jpeg(tf_image)\r\n        if image_format in ['png', 'PNG']:\r\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\r\n            return image_ops.encode_png(tf_image)\r\n        if image_format in ['raw', 'RAW']:\r\n            return constant_op.constant(image.tostring(), dtype=dtypes.string)\r\n\r\n    def GenerateImage(self, image_format, image_shape):\r\n        \"\"\"Generates an image and an example containing the encoded image.\r\n\r\n        Args:\r\n          image_format: the encoding format of the image.\r\n          image_shape: the shape of the image to generate.\r\n\r\n        Returns:\r\n          image: the generated image.\r\n          example: a TF-example with a feature key 'image/encoded' set to the\r\n            serialized image and a feature key 'image/format' set to the image\r\n            encoding format ['jpeg', 'JPEG', 'png', 'PNG', 'raw'].\r\n        \"\"\"\r\n        num_pixels = image_shape[0] * image_shape[1] * image_shape[2]\r\n        image = np.linspace(\r\n            0, num_pixels - 1, num=num_pixels).reshape(image_shape).astype(np.uint8)\r\n        tf_encoded = self._Encoder(image, image_format)\r\n        example = example_pb2.Example(features=feature_pb2.Features(feature={\r\n            'image/encoded': self._EncodedBytesFeature(tf_encoded),\r\n            'image/format': self._StringFeature(image_format)\r\n        }))\r\n\r\n        return image, example.SerializeToString()\r\n\r\n    def DecodeExample(self, serialized_example, item_handler, image_format):\r\n        \"\"\"Decodes the given serialized example with the specified item handler.\r\n\r\n        Args:\r\n          serialized_example: a serialized TF example string.\r\n          item_handler: the item handler used to decode the image.\r\n          image_format: the image format being decoded.\r\n\r\n        Returns:\r\n          the decoded image found in the serialized Example.\r\n        \"\"\"\r\n        serialized_example = array_ops.reshape(serialized_example, shape=[])\r\n        decoder = tfexample_decoder.TFExampleDecoder(\r\n            keys_to_features={\r\n                'image/encoded':\r\n                    parsing_ops.FixedLenFeature(\r\n                        (), dtypes.string, default_value=''),\r\n                'image/format':\r\n                    parsing_ops.FixedLenFeature(\r\n                        (), dtypes.string, default_value=image_format),\r\n            },\r\n            items_to_handlers={'image': item_handler})\r\n        [tf_image] = decoder.decode(serialized_example, ['image'])\r\n        return tf_image\r\n\r\n    def RunDecodeExample(self, serialized_example, item_handler, image_format):\r\n        tf_image = self.DecodeExample(serialized_example, item_handler,\r\n                                      image_format)\r\n\r\n        with self.test_session():\r\n            decoded_image = tf_image.eval()\r\n\r\n            # We need to recast them here to avoid some issues with uint8.\r\n            return decoded_image.astype(np.float32)\r\n\r\n    def testDecodeExampleWithPngEncodingAt16Bit(self):\r\n        image_shape = (2, 3, 3)\r\n        unused_image, serialized_example = self.GenerateImage(\r\n            image_format='png', image_shape=image_shape)\r\n        unused_decoded_image = self.RunDecodeExample(\r\n            serialized_example,\r\n            tfexample_decoder.Image(dtype=dtypes.uint16),\r\n            image_format='png')\r\n        self.assertAllClose(unused_image, unused_decoded_image)\r\n\r\n\r\nif __name__ == '__main__':\r\n    test.main()\r\n```\r\nIt is a modified https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/tfexample_decoder_test.py\r\n\r\n### Describe the problem\r\nI would like to decode and encode a single channel 16bit (uint16) PNG and it is not possible. I have modified the tests also to create a np.uint16 image, then trying to decode it, but it does not work.\r\n\r\n```\r\n  def testDecodeExampleWithPngEncodingAt16Bit(self):\r\n    image_shape = (2, 3, 3)\r\n    unused_image, serialized_example = self.GenerateImage(\r\n        image_format='png', image_shape=image_shape, dtype=np.uint16)\r\n    unused_decoded_image = self.RunDecodeExample(\r\n          serialized_example,\r\n          tfexample_decoder.Image(dtype=dtypes.uint16),\r\n          image_format='png')\r\n    self.assertAllClose(unused_image, unused_decoded_image)\r\n```\r\n(modifying the `GenerateImage` method accordingly).\r\n\r\nI understand that it should be possible since decode_png function allows uint16 as an output type: https://www.tensorflow.org/api_docs/python/tf/image/decode_png \r\n\r\nThe test fails because the program raises\r\n```\r\nValueError: Outputs of true_fn and false_fn must have the same type: uint16, uint8\r\n```\r\nI understand that it is due to the fact that `tf.cond` needs the same output types from branches.\r\n"}