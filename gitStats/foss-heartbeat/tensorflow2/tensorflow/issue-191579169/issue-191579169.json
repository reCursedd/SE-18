{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5834", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5834/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5834/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5834/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5834", "id": 191579169, "node_id": "MDU6SXNzdWUxOTE1NzkxNjk=", "number": 5834, "title": "TensorForestEstimator with input_fn results in infinite loop for evaluate and predict.", "user": {"login": "martarek", "id": 8918580, "node_id": "MDQ6VXNlcjg5MTg1ODA=", "avatar_url": "https://avatars0.githubusercontent.com/u/8918580?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martarek", "html_url": "https://github.com/martarek", "followers_url": "https://api.github.com/users/martarek/followers", "following_url": "https://api.github.com/users/martarek/following{/other_user}", "gists_url": "https://api.github.com/users/martarek/gists{/gist_id}", "starred_url": "https://api.github.com/users/martarek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martarek/subscriptions", "organizations_url": "https://api.github.com/users/martarek/orgs", "repos_url": "https://api.github.com/users/martarek/repos", "events_url": "https://api.github.com/users/martarek/events{/privacy}", "received_events_url": "https://api.github.com/users/martarek/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 9, "created_at": "2016-11-24T18:57:35Z", "updated_at": "2018-02-05T03:17:41Z", "closed_at": "2017-02-15T15:33:14Z", "author_association": "NONE", "body_html": "<p>When using <code>TensorForestEstimator</code>, using the previous implementation with x= and y= works. However, when trying to convert to the soon-to-be standard of input_fn, I get strange behaviors. Given</p>\n<pre><code>params = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\nnum_trees=10,\nmax_nodes=100,\nnum_classes=2,\nnum_features=features_count)\nclassifier = TensorForestEstimator(params)\n</code></pre>\n<p>calling</p>\n<pre><code>classifier.fit(input_fn=(lambda: training_input_fn(trainset)))\n</code></pre>\n<p>works and completes correctly. The input_fn used is the following :</p>\n<pre><code>features_name = [] # ordered list of all features in the dataset\ndef training_input_fn(dataset):\n        data, target = dataset\n        # 'data' is a numpy array where data[:,i] returns all observations for a given feature\n        # It is reshaped because otherwise I had a concat error\n        features = {features_name[i]: tf.constant(data[:, i], shape=(data.shape[0], 1))\n                    for i in range(len(features_name)) if features_name[i] in DEFAULT_FEATURES}\n        labels = tf.constant(target)\n        return features, labels\n</code></pre>\n<p>However, calling</p>\n<pre><code>classifier.evaluate(input_fn=(lambda: training_input_fn(validset)))\n</code></pre>\n<p>afterwards results in an apparently neverending loop in <code>tf.contrib.learn.python.learn.graph_actions</code> in function <code>run_feeds_iter</code> in the following snippet :</p>\n<pre><code>      try:\n        threads = queue_runner.start_queue_runners(session, coord=coord)\n        for f in feed_dicts:\n          yield session.run(output_dict, f)\n      finally:\n        coord.request_stop()\n        if threads:\n          coord.join(threads, stop_grace_period_secs=120)\n</code></pre>\n<p>The loop seems like never stopping. Also, memory starts increasing slowly but steadily from there (had to stop at 10 GB for this fairly small dataset). The same goes if I try predict on it.<br>\nMy Training dataset is composed of 3633 entries with 183 features and my validation dataset is composed of 2180 entries.</p>\n<h3>Environment info</h3>\n<p>Operating System:<br>\nUbuntu 16.04, running on Python3.5</p>\n<p>Installed version of CUDA and cuDNN:</p>\n<pre><code>-rw-r--r-- 1 root root   558720 Nov 22 10:52 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Nov 22 10:52 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.5\n-rwxr-xr-x 1 root root 79337624 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn_static.a\n</code></pre>\n<p>If installed from source, provide</p>\n<ol>\n<li>The commit hash (<code>git rev-parse HEAD</code>) : <code>a26a5925b0500d0e9cd259989fc0e113fa29e27f</code></li>\n<li>The output of <code>bazel version</code> :</li>\n</ol>\n<p><code>Build label: 0.4.0 Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar Build time: Wed Nov 2 17:54:14 2016 (1478109254) Build timestamp: 1478109254 Build timestamp as int: 1478109254</code></p>", "body_text": "When using TensorForestEstimator, using the previous implementation with x= and y= works. However, when trying to convert to the soon-to-be standard of input_fn, I get strange behaviors. Given\nparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\nnum_trees=10,\nmax_nodes=100,\nnum_classes=2,\nnum_features=features_count)\nclassifier = TensorForestEstimator(params)\n\ncalling\nclassifier.fit(input_fn=(lambda: training_input_fn(trainset)))\n\nworks and completes correctly. The input_fn used is the following :\nfeatures_name = [] # ordered list of all features in the dataset\ndef training_input_fn(dataset):\n        data, target = dataset\n        # 'data' is a numpy array where data[:,i] returns all observations for a given feature\n        # It is reshaped because otherwise I had a concat error\n        features = {features_name[i]: tf.constant(data[:, i], shape=(data.shape[0], 1))\n                    for i in range(len(features_name)) if features_name[i] in DEFAULT_FEATURES}\n        labels = tf.constant(target)\n        return features, labels\n\nHowever, calling\nclassifier.evaluate(input_fn=(lambda: training_input_fn(validset)))\n\nafterwards results in an apparently neverending loop in tf.contrib.learn.python.learn.graph_actions in function run_feeds_iter in the following snippet :\n      try:\n        threads = queue_runner.start_queue_runners(session, coord=coord)\n        for f in feed_dicts:\n          yield session.run(output_dict, f)\n      finally:\n        coord.request_stop()\n        if threads:\n          coord.join(threads, stop_grace_period_secs=120)\n\nThe loop seems like never stopping. Also, memory starts increasing slowly but steadily from there (had to stop at 10 GB for this fairly small dataset). The same goes if I try predict on it.\nMy Training dataset is composed of 3633 entries with 183 features and my validation dataset is composed of 2180 entries.\nEnvironment info\nOperating System:\nUbuntu 16.04, running on Python3.5\nInstalled version of CUDA and cuDNN:\n-rw-r--r-- 1 root root   558720 Nov 22 10:52 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Nov 22 10:52 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxr-xr-x 1 root root 79337624 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from source, provide\n\nThe commit hash (git rev-parse HEAD) : a26a5925b0500d0e9cd259989fc0e113fa29e27f\nThe output of bazel version :\n\nBuild label: 0.4.0 Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar Build time: Wed Nov 2 17:54:14 2016 (1478109254) Build timestamp: 1478109254 Build timestamp as int: 1478109254", "body": "When using `TensorForestEstimator`, using the previous implementation with x= and y= works. However, when trying to convert to the soon-to-be standard of input_fn, I get strange behaviors. Given \r\n\r\n```\r\nparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\r\nnum_trees=10,\r\nmax_nodes=100,\r\nnum_classes=2,\r\nnum_features=features_count)\r\nclassifier = TensorForestEstimator(params)\r\n```\r\n\r\ncalling \r\n```\r\nclassifier.fit(input_fn=(lambda: training_input_fn(trainset)))\r\n```\r\nworks and completes correctly. The input_fn used is the following :\r\n\r\n```\r\nfeatures_name = [] # ordered list of all features in the dataset\r\ndef training_input_fn(dataset):\r\n        data, target = dataset\r\n        # 'data' is a numpy array where data[:,i] returns all observations for a given feature\r\n        # It is reshaped because otherwise I had a concat error\r\n        features = {features_name[i]: tf.constant(data[:, i], shape=(data.shape[0], 1))\r\n                    for i in range(len(features_name)) if features_name[i] in DEFAULT_FEATURES}\r\n        labels = tf.constant(target)\r\n        return features, labels\r\n```\r\n\r\n\r\nHowever, calling \r\n```\r\nclassifier.evaluate(input_fn=(lambda: training_input_fn(validset)))\r\n```\r\nafterwards results in an apparently neverending loop in `tf.contrib.learn.python.learn.graph_actions` in function `run_feeds_iter` in the following snippet :\r\n```\r\n      try:\r\n        threads = queue_runner.start_queue_runners(session, coord=coord)\r\n        for f in feed_dicts:\r\n          yield session.run(output_dict, f)\r\n      finally:\r\n        coord.request_stop()\r\n        if threads:\r\n          coord.join(threads, stop_grace_period_secs=120)\r\n```\r\nThe loop seems like never stopping. Also, memory starts increasing slowly but steadily from there (had to stop at 10 GB for this fairly small dataset). The same goes if I try predict on it. \r\nMy Training dataset is composed of 3633 entries with 183 features and my validation dataset is composed of 2180 entries. \r\n\r\n### Environment info\r\nOperating System: \r\nUbuntu 16.04, running on Python3.5\r\n\r\nInstalled version of CUDA and cuDNN: \r\n```\r\n-rw-r--r-- 1 root root   558720 Nov 22 10:52 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root   415432 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 Nov 22 10:52 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from source, provide \r\n1. The commit hash (`git rev-parse HEAD`) : `a26a5925b0500d0e9cd259989fc0e113fa29e27f`\r\n2. The output of `bazel version` : \r\n\r\n`Build label: 0.4.0\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Nov 2 17:54:14 2016 (1478109254)\r\nBuild timestamp: 1478109254\r\nBuild timestamp as int: 1478109254`"}