{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/263027718", "html_url": "https://github.com/tensorflow/tensorflow/issues/5834#issuecomment-263027718", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5834", "id": 263027718, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MzAyNzcxOA==", "user": {"login": "prb12", "id": 11547801, "node_id": "MDQ6VXNlcjExNTQ3ODAx", "avatar_url": "https://avatars1.githubusercontent.com/u/11547801?v=4", "gravatar_id": "", "url": "https://api.github.com/users/prb12", "html_url": "https://github.com/prb12", "followers_url": "https://api.github.com/users/prb12/followers", "following_url": "https://api.github.com/users/prb12/following{/other_user}", "gists_url": "https://api.github.com/users/prb12/gists{/gist_id}", "starred_url": "https://api.github.com/users/prb12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/prb12/subscriptions", "organizations_url": "https://api.github.com/users/prb12/orgs", "repos_url": "https://api.github.com/users/prb12/repos", "events_url": "https://api.github.com/users/prb12/events{/privacy}", "received_events_url": "https://api.github.com/users/prb12/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-25T22:16:32Z", "updated_at": "2016-11-25T22:16:32Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=18124217\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/gilberthendry\">@gilberthendry</a> Is this the inteneded use of <code>input_fn</code>? - I can't tell from the documentation!</p>\n<p>I don't know anything about <code>TensorForestEstimator</code>, but in other places where an <code>input_fn</code> is used in TensorFlow it has often been to specify code to read a mini-batch from the file system using some sort of IO op, preprocess the samples and insert into a <code>Queue</code> of some kind.  In these other scenarios, the sub-graph created by <code>input_fn</code> is executed repeatedly in a <code>QueueRunner</code> thread.</p>\n<p>In your example, you seem to be reading the entire dataset into a <code>tf.constant</code> and adding it to the graph.  This is probably fine if input_fn is only called once.</p>\n<p>If <code>input_fn</code> was called repeatedly, then you would a) have a huge memory leak by adding large constants to the graph, and b) get dreadful performance by repeatedly changing the graphdef causing all the cached optimized datastructures to be thrown away.</p>\n<p>You could probably check this quickly by adding a print/log statement to <code>training_input_fn</code>.</p>", "body_text": "@gilberthendry Is this the inteneded use of input_fn? - I can't tell from the documentation!\nI don't know anything about TensorForestEstimator, but in other places where an input_fn is used in TensorFlow it has often been to specify code to read a mini-batch from the file system using some sort of IO op, preprocess the samples and insert into a Queue of some kind.  In these other scenarios, the sub-graph created by input_fn is executed repeatedly in a QueueRunner thread.\nIn your example, you seem to be reading the entire dataset into a tf.constant and adding it to the graph.  This is probably fine if input_fn is only called once.\nIf input_fn was called repeatedly, then you would a) have a huge memory leak by adding large constants to the graph, and b) get dreadful performance by repeatedly changing the graphdef causing all the cached optimized datastructures to be thrown away.\nYou could probably check this quickly by adding a print/log statement to training_input_fn.", "body": "@gilberthendry Is this the inteneded use of `input_fn`? - I can't tell from the documentation!\r\n\r\nI don't know anything about `TensorForestEstimator`, but in other places where an `input_fn` is used in TensorFlow it has often been to specify code to read a mini-batch from the file system using some sort of IO op, preprocess the samples and insert into a `Queue` of some kind.  In these other scenarios, the sub-graph created by `input_fn` is executed repeatedly in a `QueueRunner` thread.\r\n\r\nIn your example, you seem to be reading the entire dataset into a `tf.constant` and adding it to the graph.  This is probably fine if input_fn is only called once.\r\n\r\nIf `input_fn` was called repeatedly, then you would a) have a huge memory leak by adding large constants to the graph, and b) get dreadful performance by repeatedly changing the graphdef causing all the cached optimized datastructures to be thrown away.\r\n\r\nYou could probably check this quickly by adding a print/log statement to `training_input_fn`."}