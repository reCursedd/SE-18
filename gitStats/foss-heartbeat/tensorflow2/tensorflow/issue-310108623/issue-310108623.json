{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18123", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18123/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18123/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18123/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18123", "id": 310108623, "node_id": "MDU6SXNzdWUzMTAxMDg2MjM=", "number": 18123, "title": "No float16 batch matrix multiplication support for GPU", "user": {"login": "Kipok", "id": 2354422, "node_id": "MDQ6VXNlcjIzNTQ0MjI=", "avatar_url": "https://avatars0.githubusercontent.com/u/2354422?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Kipok", "html_url": "https://github.com/Kipok", "followers_url": "https://api.github.com/users/Kipok/followers", "following_url": "https://api.github.com/users/Kipok/following{/other_user}", "gists_url": "https://api.github.com/users/Kipok/gists{/gist_id}", "starred_url": "https://api.github.com/users/Kipok/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Kipok/subscriptions", "organizations_url": "https://api.github.com/users/Kipok/orgs", "repos_url": "https://api.github.com/users/Kipok/repos", "events_url": "https://api.github.com/users/Kipok/events{/privacy}", "received_events_url": "https://api.github.com/users/Kipok/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 6, "created_at": "2018-03-30T16:28:18Z", "updated_at": "2018-10-15T21:40:42Z", "closed_at": "2018-10-15T21:40:42Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: b'v1.6.0-rc1-1857-g67e2efa' 1.6.0</li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.10.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7.0</li>\n<li><strong>GPU model and memory</strong>: not relevant</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>import tensorflow as tf\nimport numpy.random as npr\n\nwith tf.device('/gpu:0'):\n    a = tf.constant(npr.rand(10, 5, 5).astype('float16'))\n    b = tf.constant(npr.rand(10, 5, 5).astype('float16'))\n    c = tf.matmul(a, b)\n\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\nsess.run(c)\n</code></pre>\n<h3>Describe the problem</h3>\n<p>The problem is the same as in issue <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"123709642\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/605\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/605/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/605\">#605</a>, but for float16: there is no GPU support for batch matrix multiplication. There is a quick workaround of reshaping the tensors to 2D, multiplying and reshaping back, but that is not possible to do when this function is called inside some TensorFlow classes, like in attention_wrapper.py line 336. And this significantly slows down computation of RNNs with attention on float16.</p>\n<h3>Source code / logs</h3>\n<p>Traceback:</p>\n<pre><code>---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1329     try:\n-&gt; 1330       return fn(*args)\n   1331     except errors.OpError as e:\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1312       # Ensure any changes to the graph are reflected in the runtime.\n-&gt; 1313       self._extend_graph()\n   1314       return self._call_tf_sessionrun(\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _extend_graph(self)\n   1360             tf_session.TF_ExtendGraph(self._session,\n-&gt; 1361                                       graph_def.SerializeToString(), status)\n   1362           self._opened = True\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\n    515             compat.as_text(c_api.TF_Message(self.status.status)),\n--&gt; 516             c_api.TF_GetCode(self.status.status))\n    517     # Delete the underlying status object from memory otherwise it stays alive\n\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n&lt;ipython-input-1-8739d1f2e967&gt; in &lt;module&gt;()\n      8 \n      9 sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\n---&gt; 10 sess.run(c)\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    906     try:\n    907       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 908                          run_metadata_ptr)\n    909       if run_metadata:\n    910         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1141     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1142       results = self._do_run(handle, final_targets, final_fetches,\n-&gt; 1143                              feed_dict_tensor, options, run_metadata)\n   1144     else:\n   1145       results = []\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1322     if handle is None:\n   1323       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-&gt; 1324                            run_metadata)\n   1325     else:\n   1326       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1341         except KeyError:\n   1342           pass\n-&gt; 1343       raise type(e)(node_def, op, message)\n   1344 \n   1345   def _extend_graph(self):\n\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-1-8739d1f2e967&gt;\", line 7, in &lt;module&gt;\n    c = tf.matmul(a, b)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 2082, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1236, in batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3306, in create_op\n    op_def=op_def)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): b'v1.6.0-rc1-1857-g67e2efa' 1.6.0\nPython version: 3.5.2\nBazel version (if compiling from source): 0.10.0\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: 9.0/7.0\nGPU model and memory: not relevant\nExact command to reproduce:\n\nimport tensorflow as tf\nimport numpy.random as npr\n\nwith tf.device('/gpu:0'):\n    a = tf.constant(npr.rand(10, 5, 5).astype('float16'))\n    b = tf.constant(npr.rand(10, 5, 5).astype('float16'))\n    c = tf.matmul(a, b)\n\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\nsess.run(c)\n\nDescribe the problem\nThe problem is the same as in issue #605, but for float16: there is no GPU support for batch matrix multiplication. There is a quick workaround of reshaping the tensors to 2D, multiplying and reshaping back, but that is not possible to do when this function is called inside some TensorFlow classes, like in attention_wrapper.py line 336. And this significantly slows down computation of RNNs with attention on float16.\nSource code / logs\nTraceback:\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1329     try:\n-> 1330       return fn(*args)\n   1331     except errors.OpError as e:\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\n   1312       # Ensure any changes to the graph are reflected in the runtime.\n-> 1313       self._extend_graph()\n   1314       return self._call_tf_sessionrun(\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _extend_graph(self)\n   1360             tf_session.TF_ExtendGraph(self._session,\n-> 1361                                       graph_def.SerializeToString(), status)\n   1362           self._opened = True\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\n    515             compat.as_text(c_api.TF_Message(self.status.status)),\n--> 516             c_api.TF_GetCode(self.status.status))\n    517     # Delete the underlying status object from memory otherwise it stays alive\n\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-1-8739d1f2e967> in <module>()\n      8 \n      9 sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\n---> 10 sess.run(c)\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    906     try:\n    907       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 908                          run_metadata_ptr)\n    909       if run_metadata:\n    910         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1141     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1142       results = self._do_run(handle, final_targets, final_fetches,\n-> 1143                              feed_dict_tensor, options, run_metadata)\n   1144     else:\n   1145       results = []\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1322     if handle is None:\n   1323       return self._do_call(_run_fn, feeds, fetches, targets, options,\n-> 1324                            run_metadata)\n   1325     else:\n   1326       return self._do_call(_prun_fn, handle, feeds, fetches)\n\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n   1341         except KeyError:\n   1342           pass\n-> 1343       raise type(e)(node_def, op, message)\n   1344 \n   1345   def _extend_graph(self):\n\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8739d1f2e967>\", line 7, in <module>\n    c = tf.matmul(a, b)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 2082, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1236, in batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3306, in create_op\n    op_def=op_def)\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_COMPLEX128]\n  device='GPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\n\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: b'v1.6.0-rc1-1857-g67e2efa' 1.6.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: not relevant\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy.random as npr\r\n\r\nwith tf.device('/gpu:0'):\r\n    a = tf.constant(npr.rand(10, 5, 5).astype('float16'))\r\n    b = tf.constant(npr.rand(10, 5, 5).astype('float16'))\r\n    c = tf.matmul(a, b)\r\n\r\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\r\nsess.run(c)\r\n```\r\n\r\n### Describe the problem\r\nThe problem is the same as in issue #605, but for float16: there is no GPU support for batch matrix multiplication. There is a quick workaround of reshaping the tensors to 2D, multiplying and reshaping back, but that is not possible to do when this function is called inside some TensorFlow classes, like in attention_wrapper.py line 336. And this significantly slows down computation of RNNs with attention on float16.\r\n\r\n### Source code / logs\r\nTraceback:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1329     try:\r\n-> 1330       return fn(*args)\r\n   1331     except errors.OpError as e:\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1312       # Ensure any changes to the graph are reflected in the runtime.\r\n-> 1313       self._extend_graph()\r\n   1314       return self._call_tf_sessionrun(\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _extend_graph(self)\r\n   1360             tf_session.TF_ExtendGraph(self._session,\r\n-> 1361                                       graph_def.SerializeToString(), status)\r\n   1362           self._opened = True\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    515             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 516             c_api.TF_GetCode(self.status.status))\r\n    517     # Delete the underlying status object from memory otherwise it stays alive\r\n\r\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n\r\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-1-8739d1f2e967> in <module>()\r\n      8 \r\n      9 sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\r\n---> 10 sess.run(c)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    906     try:\r\n    907       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 908                          run_metadata_ptr)\r\n    909       if run_metadata:\r\n    910         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1141     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1142       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1143                              feed_dict_tensor, options, run_metadata)\r\n   1144     else:\r\n   1145       results = []\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1322     if handle is None:\r\n   1323       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1324                            run_metadata)\r\n   1325     else:\r\n   1326       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n~/Documents/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1341         except KeyError:\r\n   1342           pass\r\n-> 1343       raise type(e)(node_def, op, message)\r\n   1344 \r\n   1345   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n\r\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\r\n\r\nCaused by op 'MatMul', defined at:\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\r\n    self.io_loop.start()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-1-8739d1f2e967>\", line 7, in <module>\r\n    c = tf.matmul(a, b)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 2082, in matmul\r\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1236, in batch_mat_mul\r\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3306, in create_op\r\n    op_def=op_def)\r\n  File \"/home/igitman/Documents/venv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1669, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\nRegistered kernels:\r\n  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_COMPLEX128]\r\n  device='CPU'; T in [DT_COMPLEX64]\r\n  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64]\r\n\r\n\t [[Node: MatMul = BatchMatMul[T=DT_HALF, adj_x=false, adj_y=false, _device=\"/device:GPU:0\"](Const, Const_1)]]\r\n```\r\n"}