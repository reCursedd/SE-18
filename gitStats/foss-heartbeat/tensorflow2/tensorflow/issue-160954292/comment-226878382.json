{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/226878382", "html_url": "https://github.com/tensorflow/tensorflow/issues/2937#issuecomment-226878382", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2937", "id": 226878382, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNjg3ODM4Mg==", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-17T20:51:11Z", "updated_at": "2016-06-17T20:51:11Z", "author_association": "CONTRIBUTOR", "body_html": "<p>In general, TensorFlow prefers its own implementation on GPU, if the performance is close enough. This is because we would have the source code for customization. Conv is a good example where it would take a lot of effort to replicate Cudnn's performance.</p>\n<p>There is still an ongoing investigation how TensorFlow would expose a fused RNN/LSTM implementations. The current Cudnn interface does not provide enough customization to accommodate common variations. In the mean time, it is possible that we can add a wrapper op in TensorFlow/contrib around the current Cudnn implementation, before we can decide what is the best way for long-term support in the TensorFlow core.</p>", "body_text": "In general, TensorFlow prefers its own implementation on GPU, if the performance is close enough. This is because we would have the source code for customization. Conv is a good example where it would take a lot of effort to replicate Cudnn's performance.\nThere is still an ongoing investigation how TensorFlow would expose a fused RNN/LSTM implementations. The current Cudnn interface does not provide enough customization to accommodate common variations. In the mean time, it is possible that we can add a wrapper op in TensorFlow/contrib around the current Cudnn implementation, before we can decide what is the best way for long-term support in the TensorFlow core.", "body": "In general, TensorFlow prefers its own implementation on GPU, if the performance is close enough. This is because we would have the source code for customization. Conv is a good example where it would take a lot of effort to replicate Cudnn's performance. \n\nThere is still an ongoing investigation how TensorFlow would expose a fused RNN/LSTM implementations. The current Cudnn interface does not provide enough customization to accommodate common variations. In the mean time, it is possible that we can add a wrapper op in TensorFlow/contrib around the current Cudnn implementation, before we can decide what is the best way for long-term support in the TensorFlow core. \n"}