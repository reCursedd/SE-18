{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/278910761", "html_url": "https://github.com/tensorflow/tensorflow/issues/7353#issuecomment-278910761", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7353", "id": 278910761, "node_id": "MDEyOklzc3VlQ29tbWVudDI3ODkxMDc2MQ==", "user": {"login": "fesun", "id": 23738439, "node_id": "MDQ6VXNlcjIzNzM4NDM5", "avatar_url": "https://avatars3.githubusercontent.com/u/23738439?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fesun", "html_url": "https://github.com/fesun", "followers_url": "https://api.github.com/users/fesun/followers", "following_url": "https://api.github.com/users/fesun/following{/other_user}", "gists_url": "https://api.github.com/users/fesun/gists{/gist_id}", "starred_url": "https://api.github.com/users/fesun/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fesun/subscriptions", "organizations_url": "https://api.github.com/users/fesun/orgs", "repos_url": "https://api.github.com/users/fesun/repos", "events_url": "https://api.github.com/users/fesun/events{/privacy}", "received_events_url": "https://api.github.com/users/fesun/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-10T10:33:43Z", "updated_at": "2017-02-10T10:33:43Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Something weird is that many workers ran into session timeout just before ending. For example, one cluster has 800 worker processes, after 127 workers successfully ended training and no timeout error occurred, all other workers started to ran into timeout and no worker could successfully finish even one step. After master worker finished reading data and started to save checkpoint, it will hang forever and master worker memory usage is about 2G.<br>\nSomething important information:</p>\n<ol>\n<li>when building up cluster, each worker will only see all parameter servers and is not aware of all other workers, this could avoiding establishing too many tcp connections between workers</li>\n<li>all non-master workers will wait for exit signal variable using the same session for training when they finished processing their data.</li>\n</ol>\n<p>My guess is parameter server is something wrong and can not response any more, so training will timeout and saver will hang forever without any timeout provided. Also 127 is very interesting, could be any 128 limiting?</p>", "body_text": "Something weird is that many workers ran into session timeout just before ending. For example, one cluster has 800 worker processes, after 127 workers successfully ended training and no timeout error occurred, all other workers started to ran into timeout and no worker could successfully finish even one step. After master worker finished reading data and started to save checkpoint, it will hang forever and master worker memory usage is about 2G.\nSomething important information:\n\nwhen building up cluster, each worker will only see all parameter servers and is not aware of all other workers, this could avoiding establishing too many tcp connections between workers\nall non-master workers will wait for exit signal variable using the same session for training when they finished processing their data.\n\nMy guess is parameter server is something wrong and can not response any more, so training will timeout and saver will hang forever without any timeout provided. Also 127 is very interesting, could be any 128 limiting?", "body": "Something weird is that many workers ran into session timeout just before ending. For example, one cluster has 800 worker processes, after 127 workers successfully ended training and no timeout error occurred, all other workers started to ran into timeout and no worker could successfully finish even one step. After master worker finished reading data and started to save checkpoint, it will hang forever and master worker memory usage is about 2G.\r\nSomething important information:\r\n1) when building up cluster, each worker will only see all parameter servers and is not aware of all other workers, this could avoiding establishing too many tcp connections between workers\r\n2) all non-master workers will wait for exit signal variable using the same session for training when they finished processing their data. \r\n\r\nMy guess is parameter server is something wrong and can not response any more, so training will timeout and saver will hang forever without any timeout provided. Also 127 is very interesting, could be any 128 limiting?"}