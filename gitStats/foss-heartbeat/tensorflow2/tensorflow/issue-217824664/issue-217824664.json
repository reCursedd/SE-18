{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8796", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8796/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8796/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8796/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8796", "id": 217824664, "node_id": "MDU6SXNzdWUyMTc4MjQ2NjQ=", "number": 8796, "title": "Distributed mode hangs on in local mode", "user": {"login": "vbod", "id": 5793742, "node_id": "MDQ6VXNlcjU3OTM3NDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/5793742?v=4", "gravatar_id": "", "url": "https://api.github.com/users/vbod", "html_url": "https://github.com/vbod", "followers_url": "https://api.github.com/users/vbod/followers", "following_url": "https://api.github.com/users/vbod/following{/other_user}", "gists_url": "https://api.github.com/users/vbod/gists{/gist_id}", "starred_url": "https://api.github.com/users/vbod/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/vbod/subscriptions", "organizations_url": "https://api.github.com/users/vbod/orgs", "repos_url": "https://api.github.com/users/vbod/repos", "events_url": "https://api.github.com/users/vbod/events{/privacy}", "received_events_url": "https://api.github.com/users/vbod/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 13, "created_at": "2017-03-29T09:59:17Z", "updated_at": "2018-01-23T23:30:22Z", "closed_at": "2018-01-23T23:30:22Z", "author_association": "NONE", "body_html": "<p>Looks like the workers do not start their server when using the estimator API and running in local-distributed mode. The minimalist code down helps reproduce: runs fine with only one process, but when launched with <code>TF_CONFIG={\"cluster\": {\"ps\":[\"localhost:5040\"], \"worker\":[\"localhost:5041\"]}, \"task\":{\"type\":\"ps\",\"index\":0}}</code> (resp. <code>worker</code>), it hangs on. After investigating, looks like in<br>\n<code>tensorflow/contrib/learn/python/learn/experiment.py l.250-258</code>:</p>\n<pre><code># Start the server, if needed. It's important to start the server before\n# we (optionally) sleep for the case where no device_filters are set.\n# Otherwise, the servers will wait to connect to each other before starting\n# to train. We might as well start as soon as we can.\nconfig = self._estimator.config\nif (config.environment != run_config.Environment.LOCAL and\n    config.environment != run_config.Environment.GOOGLE and\n    config.cluster_spec and config.master):\n  self._start_server()\n</code></pre>\n<p>the server is not started when the environment is local, no matter distributed or not. When I force the _start_server() to be executed though, everything works just fine.</p>\n<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I wrote a stackoverflow thread here: <a href=\"http://stackoverflow.com/questions/43076035/tensorflow-minimalist-program-fails-on-distributed-mode\" rel=\"nofollow\">http://stackoverflow.com/questions/43076035/tensorflow-minimalist-program-fails-on-distributed-mode</a></p>\n<h3>Environment info</h3>\n<p>Operating System: Windows-64 bit</p>\n<p>Installed version of CUDA and cuDNN: none, only on CPU<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed: from install in the website (<code>pip install --upgrade tensorflow</code>)</li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>. 1.0.1</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.contrib import layers\n\nDATA_SIZE=10\nDIMENSION=5\n\ndef generate_input_fn():\n    def _input_fn():\n        mid = int(DATA_SIZE/2)\n        data = np.array([np.ones(DIMENSION) if x &lt; mid else -np.ones(DIMENSION) for x in range(DATA_SIZE)])\n        labels = ['0' if x &lt; mid else '1' for x in range(DATA_SIZE)]        \n        table = tf.contrib.lookup.string_to_index_table_from_tensor(tf.constant(['0', '1']))\n        label_tensor = table.lookup(tf.convert_to_tensor(labels, dtype=tf.string))\n        return dict(zip(['features'], [tf.convert_to_tensor(data, dtype=tf.float32)])), label_tensor\n    return _input_fn\n\ndef build_estimator(model_dir):\n    features = layers.real_valued_column('features', dimension=DIMENSION)\n    return tf.contrib.learn.LinearClassifier(\n        feature_columns=[features],\n        model_dir=model_dir)\n\ndef generate_exp_fun():\n    def _exp_fun(output_dir):\n        return tf.contrib.learn.Experiment(\n            build_estimator(output_dir),\n            train_input_fn=generate_input_fn(),\n            eval_input_fn=generate_input_fn(),\n            train_steps=1000)\n    return _exp_fun\n\nif __name__ == '__main__':\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n    learn_runner.run(generate_exp_fun(), 'job_dir')\n</code></pre>\n<h3>What other attempted solutions have you tried?</h3>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).<br>\nIf server is not started, hangs on with log: <code>INFO:tensorflow:Create CheckpointSaverHook.</code></p>", "body_text": "Looks like the workers do not start their server when using the estimator API and running in local-distributed mode. The minimalist code down helps reproduce: runs fine with only one process, but when launched with TF_CONFIG={\"cluster\": {\"ps\":[\"localhost:5040\"], \"worker\":[\"localhost:5041\"]}, \"task\":{\"type\":\"ps\",\"index\":0}} (resp. worker), it hangs on. After investigating, looks like in\ntensorflow/contrib/learn/python/learn/experiment.py l.250-258:\n# Start the server, if needed. It's important to start the server before\n# we (optionally) sleep for the case where no device_filters are set.\n# Otherwise, the servers will wait to connect to each other before starting\n# to train. We might as well start as soon as we can.\nconfig = self._estimator.config\nif (config.environment != run_config.Environment.LOCAL and\n    config.environment != run_config.Environment.GOOGLE and\n    config.cluster_spec and config.master):\n  self._start_server()\n\nthe server is not started when the environment is local, no matter distributed or not. When I force the _start_server() to be executed though, everything works just fine.\nWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI wrote a stackoverflow thread here: http://stackoverflow.com/questions/43076035/tensorflow-minimalist-program-fails-on-distributed-mode\nEnvironment info\nOperating System: Windows-64 bit\nInstalled version of CUDA and cuDNN: none, only on CPU\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed: from install in the website (pip install --upgrade tensorflow)\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\". 1.0.1\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib.learn.python.learn import learn_runner\nfrom tensorflow.contrib import layers\n\nDATA_SIZE=10\nDIMENSION=5\n\ndef generate_input_fn():\n    def _input_fn():\n        mid = int(DATA_SIZE/2)\n        data = np.array([np.ones(DIMENSION) if x < mid else -np.ones(DIMENSION) for x in range(DATA_SIZE)])\n        labels = ['0' if x < mid else '1' for x in range(DATA_SIZE)]        \n        table = tf.contrib.lookup.string_to_index_table_from_tensor(tf.constant(['0', '1']))\n        label_tensor = table.lookup(tf.convert_to_tensor(labels, dtype=tf.string))\n        return dict(zip(['features'], [tf.convert_to_tensor(data, dtype=tf.float32)])), label_tensor\n    return _input_fn\n\ndef build_estimator(model_dir):\n    features = layers.real_valued_column('features', dimension=DIMENSION)\n    return tf.contrib.learn.LinearClassifier(\n        feature_columns=[features],\n        model_dir=model_dir)\n\ndef generate_exp_fun():\n    def _exp_fun(output_dir):\n        return tf.contrib.learn.Experiment(\n            build_estimator(output_dir),\n            train_input_fn=generate_input_fn(),\n            eval_input_fn=generate_input_fn(),\n            train_steps=1000)\n    return _exp_fun\n\nif __name__ == '__main__':\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n    learn_runner.run(generate_exp_fun(), 'job_dir')\n\nWhat other attempted solutions have you tried?\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\nIf server is not started, hangs on with log: INFO:tensorflow:Create CheckpointSaverHook.", "body": "Looks like the workers do not start their server when using the estimator API and running in local-distributed mode. The minimalist code down helps reproduce: runs fine with only one process, but when launched with `TF_CONFIG={\"cluster\": {\"ps\":[\"localhost:5040\"], \"worker\":[\"localhost:5041\"]}, \"task\":{\"type\":\"ps\",\"index\":0}}` (resp. `worker`), it hangs on. After investigating, looks like in\r\n`tensorflow/contrib/learn/python/learn/experiment.py l.250-258`:\r\n\r\n    # Start the server, if needed. It's important to start the server before\r\n    # we (optionally) sleep for the case where no device_filters are set.\r\n    # Otherwise, the servers will wait to connect to each other before starting\r\n    # to train. We might as well start as soon as we can.\r\n    config = self._estimator.config\r\n    if (config.environment != run_config.Environment.LOCAL and\r\n        config.environment != run_config.Environment.GOOGLE and\r\n        config.cluster_spec and config.master):\r\n      self._start_server()\r\nthe server is not started when the environment is local, no matter distributed or not. When I force the _start_server() to be executed though, everything works just fine.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nI wrote a stackoverflow thread here: http://stackoverflow.com/questions/43076035/tensorflow-minimalist-program-fails-on-distributed-mode\r\n\r\n### Environment info\r\nOperating System: Windows-64 bit\r\n\r\nInstalled version of CUDA and cuDNN: none, only on CPU\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: from install in the website (`pip install --upgrade tensorflow`)\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. 1.0.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n    from tensorflow.contrib.learn.python.learn import learn_runner\r\n    from tensorflow.contrib import layers\r\n\r\n    DATA_SIZE=10\r\n    DIMENSION=5\r\n\r\n    def generate_input_fn():\r\n        def _input_fn():\r\n            mid = int(DATA_SIZE/2)\r\n            data = np.array([np.ones(DIMENSION) if x < mid else -np.ones(DIMENSION) for x in range(DATA_SIZE)])\r\n            labels = ['0' if x < mid else '1' for x in range(DATA_SIZE)]        \r\n            table = tf.contrib.lookup.string_to_index_table_from_tensor(tf.constant(['0', '1']))\r\n            label_tensor = table.lookup(tf.convert_to_tensor(labels, dtype=tf.string))\r\n            return dict(zip(['features'], [tf.convert_to_tensor(data, dtype=tf.float32)])), label_tensor\r\n        return _input_fn\r\n\r\n    def build_estimator(model_dir):\r\n        features = layers.real_valued_column('features', dimension=DIMENSION)\r\n        return tf.contrib.learn.LinearClassifier(\r\n            feature_columns=[features],\r\n            model_dir=model_dir)\r\n\r\n    def generate_exp_fun():\r\n        def _exp_fun(output_dir):\r\n            return tf.contrib.learn.Experiment(\r\n                build_estimator(output_dir),\r\n                train_input_fn=generate_input_fn(),\r\n                eval_input_fn=generate_input_fn(),\r\n                train_steps=1000)\r\n        return _exp_fun\r\n\r\n    if __name__ == '__main__':\r\n        tf.logging.set_verbosity(tf.logging.DEBUG)\r\n        learn_runner.run(generate_exp_fun(), 'job_dir')\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\nIf server is not started, hangs on with log: `INFO:tensorflow:Create CheckpointSaverHook.`"}