{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17684", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17684/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17684/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17684/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17684", "id": 304832519, "node_id": "MDU6SXNzdWUzMDQ4MzI1MTk=", "number": 17684, "title": "Error converting the model to TF Lite", "user": {"login": "Neargye", "id": 7997966, "node_id": "MDQ6VXNlcjc5OTc5NjY=", "avatar_url": "https://avatars2.githubusercontent.com/u/7997966?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Neargye", "html_url": "https://github.com/Neargye", "followers_url": "https://api.github.com/users/Neargye/followers", "following_url": "https://api.github.com/users/Neargye/following{/other_user}", "gists_url": "https://api.github.com/users/Neargye/gists{/gist_id}", "starred_url": "https://api.github.com/users/Neargye/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Neargye/subscriptions", "organizations_url": "https://api.github.com/users/Neargye/orgs", "repos_url": "https://api.github.com/users/Neargye/repos", "events_url": "https://api.github.com/users/Neargye/events{/privacy}", "received_events_url": "https://api.github.com/users/Neargye/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2018-03-13T16:12:11Z", "updated_at": "2018-08-11T02:14:44Z", "closed_at": "2018-06-12T16:33:23Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:  Ubuntu 16.04.4</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>:  r1.6 commit: <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/cbc658095ae228f2f557af47e4901d552573aa15/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/cbc658095ae228f2f557af47e4901d552573aa15\"><tt>cbc6580</tt></a></li>\n<li><strong>Python version</strong>: 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.11.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A (build without support CUDA)</li>\n<li><strong>GPU model and memory</strong>: N/A (build without support CUDA)</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Trained model, successfully froze, it works on the tensorflow android, using TensorFlowInferenceInterface.<br>\nI try to convert this into a TF Lite format, but I get an error.</p>\n<h3>Source code / logs</h3>\n<pre><code>bazel-bin/tensorflow/contrib/lite/toco/toco \\\n    --input_file=./test_model/frozen_graph.pb \\\n    --input_format=TENSORFLOW_GRAPHDEF \\\n    --output_file=./test_model/unet.tflite \\\n    --output_format=TFLITE \\\n    --input_array='input' \\\n    --input_data_type=FLOAT \\\n    --input_shape=2,192,320,1 \\\n    --inference_type=FLOAT \\\n    --inference_input_type=FLOAT \\\n    --output_array='final/Sigmoid' \\\n    --v=1\n</code></pre>\n<pre><code>2018-03-13 21:07:12.711948: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 282 operators, 479 arrays (0 quantized)\n2018-03-13 21:07:12.716274: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 282 operators, 479 arrays (0 quantized)\n2018-03-13 21:07:12.716893: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:86] Check failed: mean_shape.dims() == multiplier_shape.dims()\nAborted (core dumped)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04.4\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below):  r1.6 commit: cbc6580\nPython version: 3.5.2\nBazel version (if compiling from source): 0.11.1\nGCC/Compiler version (if compiling from source):  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)\nCUDA/cuDNN version: N/A (build without support CUDA)\nGPU model and memory: N/A (build without support CUDA)\nExact command to reproduce:\n\nDescribe the problem\nTrained model, successfully froze, it works on the tensorflow android, using TensorFlowInferenceInterface.\nI try to convert this into a TF Lite format, but I get an error.\nSource code / logs\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\n    --input_file=./test_model/frozen_graph.pb \\\n    --input_format=TENSORFLOW_GRAPHDEF \\\n    --output_file=./test_model/unet.tflite \\\n    --output_format=TFLITE \\\n    --input_array='input' \\\n    --input_data_type=FLOAT \\\n    --input_shape=2,192,320,1 \\\n    --inference_type=FLOAT \\\n    --inference_input_type=FLOAT \\\n    --output_array='final/Sigmoid' \\\n    --v=1\n\n2018-03-13 21:07:12.711948: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 282 operators, 479 arrays (0 quantized)\n2018-03-13 21:07:12.716274: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 282 operators, 479 arrays (0 quantized)\n2018-03-13 21:07:12.716893: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:86] Check failed: mean_shape.dims() == multiplier_shape.dims()\nAborted (core dumped)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04.4\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:  r1.6 commit: cbc658095ae228f2f557af47e4901d552573aa15\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.11.1\r\n- **GCC/Compiler version (if compiling from source)**:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)\r\n- **CUDA/cuDNN version**: N/A (build without support CUDA)\r\n- **GPU model and memory**: N/A (build without support CUDA)\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nTrained model, successfully froze, it works on the tensorflow android, using TensorFlowInferenceInterface.\r\nI try to convert this into a TF Lite format, but I get an error.\r\n\r\n### Source code / logs\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n    --input_file=./test_model/frozen_graph.pb \\\r\n    --input_format=TENSORFLOW_GRAPHDEF \\\r\n    --output_file=./test_model/unet.tflite \\\r\n    --output_format=TFLITE \\\r\n    --input_array='input' \\\r\n    --input_data_type=FLOAT \\\r\n    --input_shape=2,192,320,1 \\\r\n    --inference_type=FLOAT \\\r\n    --inference_input_type=FLOAT \\\r\n    --output_array='final/Sigmoid' \\\r\n    --v=1\r\n```\r\n```\r\n2018-03-13 21:07:12.711948: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 282 operators, 479 arrays (0 quantized)\r\n2018-03-13 21:07:12.716274: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 282 operators, 479 arrays (0 quantized)\r\n2018-03-13 21:07:12.716893: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:86] Check failed: mean_shape.dims() == multiplier_shape.dims()\r\nAborted (core dumped)\r\n```"}