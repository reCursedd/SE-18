{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/239987174", "html_url": "https://github.com/tensorflow/tensorflow/pull/3756#issuecomment-239987174", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3756", "id": 239987174, "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTk4NzE3NA==", "user": {"login": "anair13", "id": 940868, "node_id": "MDQ6VXNlcjk0MDg2OA==", "avatar_url": "https://avatars2.githubusercontent.com/u/940868?v=4", "gravatar_id": "", "url": "https://api.github.com/users/anair13", "html_url": "https://github.com/anair13", "followers_url": "https://api.github.com/users/anair13/followers", "following_url": "https://api.github.com/users/anair13/following{/other_user}", "gists_url": "https://api.github.com/users/anair13/gists{/gist_id}", "starred_url": "https://api.github.com/users/anair13/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/anair13/subscriptions", "organizations_url": "https://api.github.com/users/anair13/orgs", "repos_url": "https://api.github.com/users/anair13/repos", "events_url": "https://api.github.com/users/anair13/events{/privacy}", "received_events_url": "https://api.github.com/users/anair13/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-16T02:45:28Z", "updated_at": "2016-08-16T02:45:28Z", "author_association": "NONE", "body_html": "<p>Thanks for looking at this everyone. As <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=252225\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/nikitakit\">@nikitakit</a> said, I think it would be good to discuss the approach here (personally, I think this way of implementing both attention and beam search as wrappers is simpler to understand and easier to modify) and make changes as we go.</p>\n<p>I can fix the issue mentioned by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1618736\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/therne\">@therne</a> as I had commented out parts I had not tested, and also contribute some new tests and a sequence to sequence model with attention and beam search.</p>", "body_text": "Thanks for looking at this everyone. As @nikitakit said, I think it would be good to discuss the approach here (personally, I think this way of implementing both attention and beam search as wrappers is simpler to understand and easier to modify) and make changes as we go.\nI can fix the issue mentioned by @therne as I had commented out parts I had not tested, and also contribute some new tests and a sequence to sequence model with attention and beam search.", "body": "Thanks for looking at this everyone. As @nikitakit said, I think it would be good to discuss the approach here (personally, I think this way of implementing both attention and beam search as wrappers is simpler to understand and easier to modify) and make changes as we go.\n\nI can fix the issue mentioned by @therne as I had commented out parts I had not tested, and also contribute some new tests and a sequence to sequence model with attention and beam search.  \n"}