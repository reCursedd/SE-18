{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/241151308", "html_url": "https://github.com/tensorflow/tensorflow/pull/3756#issuecomment-241151308", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3756", "id": 241151308, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MTE1MTMwOA==", "user": {"login": "nikitakit", "id": 252225, "node_id": "MDQ6VXNlcjI1MjIyNQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/252225?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nikitakit", "html_url": "https://github.com/nikitakit", "followers_url": "https://api.github.com/users/nikitakit/followers", "following_url": "https://api.github.com/users/nikitakit/following{/other_user}", "gists_url": "https://api.github.com/users/nikitakit/gists{/gist_id}", "starred_url": "https://api.github.com/users/nikitakit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nikitakit/subscriptions", "organizations_url": "https://api.github.com/users/nikitakit/orgs", "repos_url": "https://api.github.com/users/nikitakit/repos", "events_url": "https://api.github.com/users/nikitakit/events{/privacy}", "received_events_url": "https://api.github.com/users/nikitakit/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-19T22:29:53Z", "updated_at": "2016-08-19T22:31:54Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> All attention code here is by <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=940868\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/anair13\">@anair13</a>. To be honest I'd prefer to keep the beam search and attention discussions separate, because their implementations should be orthogonal. (The beam search code can work with any attention implementation, including the built-in AttentionCellWrapper).</p>\n<p>I would love to build on top of <code>raw_rnn</code>, but unfortunately its API is still not expressive enough to support beam search. Beam search needs to have access to intermediate cell states (not just inputs/outputs), because items that fall off the beam need to have their cell state removed and replaced with that of another item.</p>\n<p>Now if <code>raw_rnn</code> could be modified to receive <code>cell_state</code> into the loop function and output a <code>new_cell_state</code> from it, then it's a different story.</p>", "body_text": "@ebrevdo All attention code here is by @anair13. To be honest I'd prefer to keep the beam search and attention discussions separate, because their implementations should be orthogonal. (The beam search code can work with any attention implementation, including the built-in AttentionCellWrapper).\nI would love to build on top of raw_rnn, but unfortunately its API is still not expressive enough to support beam search. Beam search needs to have access to intermediate cell states (not just inputs/outputs), because items that fall off the beam need to have their cell state removed and replaced with that of another item.\nNow if raw_rnn could be modified to receive cell_state into the loop function and output a new_cell_state from it, then it's a different story.", "body": "@ebrevdo All attention code here is by @anair13. To be honest I'd prefer to keep the beam search and attention discussions separate, because their implementations should be orthogonal. (The beam search code can work with any attention implementation, including the built-in AttentionCellWrapper).\n\nI would love to build on top of `raw_rnn`, but unfortunately its API is still not expressive enough to support beam search. Beam search needs to have access to intermediate cell states (not just inputs/outputs), because items that fall off the beam need to have their cell state removed and replaced with that of another item. \n\nNow if `raw_rnn` could be modified to receive `cell_state` into the loop function and output a `new_cell_state` from it, then it's a different story.\n"}