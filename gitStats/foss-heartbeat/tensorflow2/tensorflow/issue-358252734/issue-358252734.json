{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22158", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22158/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22158/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22158/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22158", "id": 358252734, "node_id": "MDU6SXNzdWUzNTgyNTI3MzQ=", "number": 22158, "title": "Unexpected behavior of per_process_gpu_memory_fraction ", "user": {"login": "EvansDaniel", "id": 15970604, "node_id": "MDQ6VXNlcjE1OTcwNjA0", "avatar_url": "https://avatars0.githubusercontent.com/u/15970604?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EvansDaniel", "html_url": "https://github.com/EvansDaniel", "followers_url": "https://api.github.com/users/EvansDaniel/followers", "following_url": "https://api.github.com/users/EvansDaniel/following{/other_user}", "gists_url": "https://api.github.com/users/EvansDaniel/gists{/gist_id}", "starred_url": "https://api.github.com/users/EvansDaniel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EvansDaniel/subscriptions", "organizations_url": "https://api.github.com/users/EvansDaniel/orgs", "repos_url": "https://api.github.com/users/EvansDaniel/repos", "events_url": "https://api.github.com/users/EvansDaniel/events{/privacy}", "received_events_url": "https://api.github.com/users/EvansDaniel/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-09-08T01:34:29Z", "updated_at": "2018-11-23T18:39:33Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: See below</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: N/A</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary (used pip)</li>\n<li><strong>TensorFlow version (use command below)</strong>:  See below</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: See below</li>\n<li><strong>GPU model and memory</strong>: See below</li>\n<li><strong>Exact command to reproduce</strong>: Just run the script with python</li>\n</ul>\n<h3>System information from your tf env script:</h3>\n<p>== cat /etc/issue ===============================================<br>\nLinux ip-172-31-54-194 4.4.0-1062-aws <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116019590\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/71\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/71/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/71\">#71</a>-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux ip-172-31-54-194 4.4.0-1062-aws <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"116019590\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/71\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/71/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/71\">#71</a>-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy               1.14.5<br>\nprotobuf            3.6.0<br>\ntensorflow-gpu      1.10.0</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.10.0<br>\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34<br>\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34<br>\nSanity check: array([1], dtype=int32)<br>\n/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/<strong>init</strong>.py:36: FutureWarning: Conversion of the second argument of issubdtype from <code>float</code> to <code>np.floating</code> is deprecated. In future, it will be treated as <code>np.float64 == np.dtype(float).type</code>.<br>\nfrom ._conv import register_converters as _register_converters</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/lib/nccl/cuda-9.0/lib:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nSat Sep  8 01:19:08 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |<br>\n| N/A   45C    P0    63W / 300W |      0MiB / 16160MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |<br>\n| N/A   42C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |<br>\n| N/A   42C    P0    43W / 300W |      0MiB / 16160MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+<br>\n|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |<br>\n| N/A   44C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|  No running processes found                                                 |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85<br>\n/usr/local/cuda-9.1/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7<br>\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176<br>\n/usr/local/cuda-9.0/lib64/libcudart_static.a</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>I have written a small example that uses per_process_gpu_memory_fraction. I set it to .1 and allow_growth=false (by default). My expectation when I run nvidia-smi during program execution is that I will see a maximum of 10% of the gpu memory being used. During some trial runs of the program though, I have seen it using around 13%. So I am wondering if this is a bug or if it is expected behavior. If it's expected behavior, why is this happening?</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<h3>Script to reproduce with:</h3>\n<pre><code>import tensorflow as tf\n\nfrom time import sleep\n\ni = tf.constant(0)\nx = tf.constant(10)\nr = tf.add(i,x)\n\n# Use at most 10% of gpu memory \ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=.1)\n\n# sleep is used to see what nvidia-smi says for gpu memory usage, \n# I expect that it will be at most 10% of gpu memory (which is 1616.0 mib for my gpu)\n# but instead I see up to 2120 mib used by the process\nwith tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n        sess.run(r);\n        sleep(10) \n\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): See below\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): binary (used pip)\nTensorFlow version (use command below):  See below\nPython version: 3.6\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: See below\nGPU model and memory: See below\nExact command to reproduce: Just run the script with python\n\nSystem information from your tf env script:\n== cat /etc/issue ===============================================\nLinux ip-172-31-54-194 4.4.0-1062-aws #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux ip-172-31-54-194 4.4.0-1062-aws #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy               1.14.5\nprotobuf            3.6.0\ntensorflow-gpu      1.10.0\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.10.0\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\nSanity check: array([1], dtype=int32)\n/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\nfrom ._conv import register_converters as _register_converters\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/lib/nccl/cuda-9.0/lib:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nSat Sep  8 01:19:08 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n| N/A   45C    P0    63W / 300W |      0MiB / 16160MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n| N/A   42C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n| N/A   42C    P0    43W / 300W |      0MiB / 16160MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n| N/A   44C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85\n/usr/local/cuda-9.1/lib64/libcudart_static.a\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\n/usr/local/cuda-9.0/lib64/libcudart_static.a\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nI have written a small example that uses per_process_gpu_memory_fraction. I set it to .1 and allow_growth=false (by default). My expectation when I run nvidia-smi during program execution is that I will see a maximum of 10% of the gpu memory being used. During some trial runs of the program though, I have seen it using around 13%. So I am wondering if this is a bug or if it is expected behavior. If it's expected behavior, why is this happening?\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\nScript to reproduce with:\nimport tensorflow as tf\n\nfrom time import sleep\n\ni = tf.constant(0)\nx = tf.constant(10)\nr = tf.add(i,x)\n\n# Use at most 10% of gpu memory \ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=.1)\n\n# sleep is used to see what nvidia-smi says for gpu memory usage, \n# I expect that it will be at most 10% of gpu memory (which is 1616.0 mib for my gpu)\n# but instead I see up to 2120 mib used by the process\nwith tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n        sess.run(r);\n        sleep(10)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: See below\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary (used pip)\r\n- **TensorFlow version (use command below)**:  See below \r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A \r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: See below\r\n- **GPU model and memory**: See below \r\n- **Exact command to reproduce**: Just run the script with python \r\n\r\n### System information from your tf env script:\r\n\r\n== cat /etc/issue ===============================================\r\nLinux ip-172-31-54-194 4.4.0-1062-aws #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux ip-172-31-54-194 4.4.0-1062-aws #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy               1.14.5\r\nprotobuf            3.6.0\r\ntensorflow-gpu      1.10.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.0\r\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\r\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\r\nSanity check: array([1], dtype=int32)\r\n/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/lib/nccl/cuda-9.0/lib:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nSat Sep  8 01:19:08 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\r\n| N/A   45C    P0    63W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\r\n| N/A   42C    P0    38W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\r\n| N/A   42C    P0    43W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   44C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.1/lib64/libcudart.so.9.1.85\r\n/usr/local/cuda-9.1/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI have written a small example that uses per_process_gpu_memory_fraction. I set it to .1 and allow_growth=false (by default). My expectation when I run nvidia-smi during program execution is that I will see a maximum of 10% of the gpu memory being used. During some trial runs of the program though, I have seen it using around 13%. So I am wondering if this is a bug or if it is expected behavior. If it's expected behavior, why is this happening?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\n### Script to reproduce with:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom time import sleep\r\n\r\ni = tf.constant(0)\r\nx = tf.constant(10)\r\nr = tf.add(i,x)\r\n\r\n# Use at most 10% of gpu memory \r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=.1)\r\n\r\n# sleep is used to see what nvidia-smi says for gpu memory usage, \r\n# I expect that it will be at most 10% of gpu memory (which is 1616.0 mib for my gpu)\r\n# but instead I see up to 2120 mib used by the process\r\nwith tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\r\n        sess.run(r);\r\n        sleep(10) \r\n\r\n```\r\n\r\n\r\n"}