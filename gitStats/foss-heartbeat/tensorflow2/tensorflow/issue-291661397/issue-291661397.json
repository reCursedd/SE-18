{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16412", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16412/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16412/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16412/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16412", "id": 291661397, "node_id": "MDU6SXNzdWUyOTE2NjEzOTc=", "number": 16412, "title": "Documentation on build from source is unclear", "user": {"login": "David-Levinthal", "id": 8728143, "node_id": "MDQ6VXNlcjg3MjgxNDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/8728143?v=4", "gravatar_id": "", "url": "https://api.github.com/users/David-Levinthal", "html_url": "https://github.com/David-Levinthal", "followers_url": "https://api.github.com/users/David-Levinthal/followers", "following_url": "https://api.github.com/users/David-Levinthal/following{/other_user}", "gists_url": "https://api.github.com/users/David-Levinthal/gists{/gist_id}", "starred_url": "https://api.github.com/users/David-Levinthal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/David-Levinthal/subscriptions", "organizations_url": "https://api.github.com/users/David-Levinthal/orgs", "repos_url": "https://api.github.com/users/David-Levinthal/repos", "events_url": "https://api.github.com/users/David-Levinthal/events{/privacy}", "received_events_url": "https://api.github.com/users/David-Levinthal/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 3, "created_at": "2018-01-25T17:58:48Z", "updated_at": "2018-01-25T19:45:03Z", "closed_at": "2018-01-25T19:45:03Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug or a feature request.</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"<br>\n('v1.4.1-7-gaa03bfc', '1.4.1')<br>\nbuilt and installed from source with<br>\ngit checkout r1.4<br>\nbazel build -c opt --copt=-march=\"haswell\" --config=cuda --verbose_failures --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package &gt;pip_package_build2.log 2&gt;&amp;1<br>\nnote: incompatible path flag is required with R1.4 at this time per <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"283346623\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/15492\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/15492/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/15492\">#15492</a><br>\nubuntu 16.04<br>\nCuda 9.1, cudnn 7.0.4<br>\ngcc --version<br>\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609<br>\nuname -r<br>\n4.4.0-104-generic<br>\nBazel 0.9</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.<br>\nIt is unclear how to build and install the entire package purely from source<br>\nI will attempt to log what I have done so far<br>\nclone and build TF R1.4 for cuda<br>\ninstall wheel into local directory  (sudo pip install /tmp/tensorflow-pkg/tensorflow*.whl -t <del>/mytf_r1.4_c9.1<br>\nexport PYTHONPATH=</del>/mytf_r1.4_c9.1<br>\nmove tensorflow directory</p>\n<p>install common_voice files to ~/Common_voice</p>\n<p>per native client build from source instructions: <a href=\"https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md\">https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md</a><br>\ngit clone tensorflow<br>\ncd tensorflow<br>\ngit checkout r1.4<br>\nln -s ../DeepSpeech/native_client ./<br>\n./configure<br>\nedit native_client/BUILD<br>\ncomment out the following:</p>\n<h1>tfcompile_flags = select({</h1>\n<h1>\"//tensorflow:rpi3\": str('--target_triple=\"armv6-linux-gnueabihf\" --target_cpu=\"cortex-a53\" --target_features=\"+neon-fp-armv8\"'),</h1>\n<h1>\"//conditions:default\": str('')</h1>\n<h1>}),</h1>\n<p>bazel build -c opt --copt=-O3 --incompatible_load_argument_is_label=false //tensorflow:libtensorflow_cc.so //tensorflow:libtensorflow_framework.so //native_client:deepspeech //native_client:deepspeech_utils //native_client:libctc_decoder_with_kenlm.so //native_client:generate_trie<br>\nat this point all the native client binaries are in<br>\n<del>/tensorflow/bazel-bin/native_client<br>\nlevinth@zt-gpu-lin:</del>/DeepSpeech/native_client$ ls ~/tensorflow/bazel-bin/native_client/<br>\ngenerate_trie<br>\ngenerate_trie-2.params<br>\ngenerate_trie.runfiles<br>\ngenerate_trie.runfiles_manifest<br>\nlibctc_decoder_with_kenlm.so<br>\nlibctc_decoder_with_kenlm.so-2.params<br>\nlibctc_decoder_with_kenlm.so.runfiles<br>\nlibctc_decoder_with_kenlm.so.runfiles_manifest<br>\nlibdeepspeech.a<br>\nlibdeepspeech.a-2.params<br>\nlibdeepspeech.pic.a<br>\nlibdeepspeech.pic.a-2.params<br>\nlibdeepspeech.so<br>\nlibdeepspeech.so-2.params<br>\nlibdeepspeech_utils.a<br>\nlibdeepspeech_utils.a-2.params<br>\nlibdeepspeech_utils.pic.a<br>\nlibdeepspeech_utils.pic.a-2.params<br>\nlibdeepspeech_utils.so<br>\nlibdeepspeech_utils.so-2.params<br>\n_objs</p>\n<p>cd ../Deepspeech/native_client<br>\nexport TFDIR ~/tensorflow<br>\nmake deepspeech</p>\n<p>at this point however the native client shared objects are still in bazel-bin/native client and have not been installed. the invocation of Deepspeech.py fails as it cannot find the shared objects<br>\npython DeepSpeech.py --train_files ../Common_voice/cv-valid-train.csv,../Common_voice/cv-other-train.csv --dev_files ../Common_voice/cv-valid-dev.csv --test_files ../Common_voice/cv-valid-test.csv &gt;deepspeech_1.log 2&gt;&amp;1<br>\ntensorflow.python.framework.errors_impl.NotFoundError: native_client/libctc_decoder_with_kenlm.so: cannot open shared object file: No such file or directory</p>\n<p>the native_client/Makefile has sections for bindings and install..so try<br>\nsudo make install<br>\nand this still generates the error as install does not put<br>\n~/tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so<br>\ninto /usr/local/lib<br>\nthough deepspeech.so and deepspeech_utils.so are installed there.</p>\n<h2>manually copy /tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so to ~/DeepSpeech/native_client and set permissions<br>\nat this point the invocation now starts running but complains about</h2>\n<h2>WARNING: libdeepspeech failed to load, resorting to deprecated code<br>\nRefer to README.md for instructions on installing libdeepspeech</h2>\n<p>even though /usr/local/lib is in the $LD_LIBRARY_PATH</p>\n<p>invoking<br>\npython DeepSpeech.py --train_files ../Common_voice/cv-valid-train.csv,../Common_voice/cv-other-train.csv --dev_files ../Common_voice/cv-valid-dev.csv --test_files ../Common_voice/cv-valid-test.csv --display_step 1 --validation_step 10</p>\n<hr>\n<h2>WARNING: libdeepspeech failed to load, resorting to deprecated code<br>\nRefer to README.md for instructions on installing libdeepspeech</h2>\n<p>I STARTING Optimization<br>\nLoading the LM will be faster if you build a binary file.<br>\nReading data/lm/lm.binary<br>\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100<br>\nterminate called after throwing an instance of 'lm::FormatLoadException'<br>\nwhat():  native_client/kenlm/lm/read_arpa.cc:65 in void lm::ReadARPACounts(util::FilePiece&amp;, std::vector&amp;) threw FormatLoadException.<br>\nfirst non-empty line was \"version <a href=\"https://git-lfs.github.com/spec/v1\">https://git-lfs.github.com/spec/v1</a>\" not \\data. Byte: 43</p>\n<p>I clearly have not figured this out<br>\n:-)</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug or a feature request.\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\nPython version:\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n('v1.4.1-7-gaa03bfc', '1.4.1')\nbuilt and installed from source with\ngit checkout r1.4\nbazel build -c opt --copt=-march=\"haswell\" --config=cuda --verbose_failures --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package >pip_package_build2.log 2>&1\nnote: incompatible path flag is required with R1.4 at this time per #15492\nubuntu 16.04\nCuda 9.1, cudnn 7.0.4\ngcc --version\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\nuname -r\n4.4.0-104-generic\nBazel 0.9\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nIt is unclear how to build and install the entire package purely from source\nI will attempt to log what I have done so far\nclone and build TF R1.4 for cuda\ninstall wheel into local directory  (sudo pip install /tmp/tensorflow-pkg/tensorflow*.whl -t /mytf_r1.4_c9.1\nexport PYTHONPATH=/mytf_r1.4_c9.1\nmove tensorflow directory\ninstall common_voice files to ~/Common_voice\nper native client build from source instructions: https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md\ngit clone tensorflow\ncd tensorflow\ngit checkout r1.4\nln -s ../DeepSpeech/native_client ./\n./configure\nedit native_client/BUILD\ncomment out the following:\ntfcompile_flags = select({\n\"//tensorflow:rpi3\": str('--target_triple=\"armv6-linux-gnueabihf\" --target_cpu=\"cortex-a53\" --target_features=\"+neon-fp-armv8\"'),\n\"//conditions:default\": str('')\n}),\nbazel build -c opt --copt=-O3 --incompatible_load_argument_is_label=false //tensorflow:libtensorflow_cc.so //tensorflow:libtensorflow_framework.so //native_client:deepspeech //native_client:deepspeech_utils //native_client:libctc_decoder_with_kenlm.so //native_client:generate_trie\nat this point all the native client binaries are in\n/tensorflow/bazel-bin/native_client\nlevinth@zt-gpu-lin:/DeepSpeech/native_client$ ls ~/tensorflow/bazel-bin/native_client/\ngenerate_trie\ngenerate_trie-2.params\ngenerate_trie.runfiles\ngenerate_trie.runfiles_manifest\nlibctc_decoder_with_kenlm.so\nlibctc_decoder_with_kenlm.so-2.params\nlibctc_decoder_with_kenlm.so.runfiles\nlibctc_decoder_with_kenlm.so.runfiles_manifest\nlibdeepspeech.a\nlibdeepspeech.a-2.params\nlibdeepspeech.pic.a\nlibdeepspeech.pic.a-2.params\nlibdeepspeech.so\nlibdeepspeech.so-2.params\nlibdeepspeech_utils.a\nlibdeepspeech_utils.a-2.params\nlibdeepspeech_utils.pic.a\nlibdeepspeech_utils.pic.a-2.params\nlibdeepspeech_utils.so\nlibdeepspeech_utils.so-2.params\n_objs\ncd ../Deepspeech/native_client\nexport TFDIR ~/tensorflow\nmake deepspeech\nat this point however the native client shared objects are still in bazel-bin/native client and have not been installed. the invocation of Deepspeech.py fails as it cannot find the shared objects\npython DeepSpeech.py --train_files ../Common_voice/cv-valid-train.csv,../Common_voice/cv-other-train.csv --dev_files ../Common_voice/cv-valid-dev.csv --test_files ../Common_voice/cv-valid-test.csv >deepspeech_1.log 2>&1\ntensorflow.python.framework.errors_impl.NotFoundError: native_client/libctc_decoder_with_kenlm.so: cannot open shared object file: No such file or directory\nthe native_client/Makefile has sections for bindings and install..so try\nsudo make install\nand this still generates the error as install does not put\n~/tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so\ninto /usr/local/lib\nthough deepspeech.so and deepspeech_utils.so are installed there.\nmanually copy /tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so to ~/DeepSpeech/native_client and set permissions\nat this point the invocation now starts running but complains about\nWARNING: libdeepspeech failed to load, resorting to deprecated code\nRefer to README.md for instructions on installing libdeepspeech\neven though /usr/local/lib is in the $LD_LIBRARY_PATH\ninvoking\npython DeepSpeech.py --train_files ../Common_voice/cv-valid-train.csv,../Common_voice/cv-other-train.csv --dev_files ../Common_voice/cv-valid-dev.csv --test_files ../Common_voice/cv-valid-test.csv --display_step 1 --validation_step 10\n\nWARNING: libdeepspeech failed to load, resorting to deprecated code\nRefer to README.md for instructions on installing libdeepspeech\nI STARTING Optimization\nLoading the LM will be faster if you build a binary file.\nReading data/lm/lm.binary\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\nterminate called after throwing an instance of 'lm::FormatLoadException'\nwhat():  native_client/kenlm/lm/read_arpa.cc:65 in void lm::ReadARPACounts(util::FilePiece&, std::vector&) threw FormatLoadException.\nfirst non-empty line was \"version https://git-lfs.github.com/spec/v1\" not \\data. Byte: 43\nI clearly have not figured this out\n:-)", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.4.1-7-gaa03bfc', '1.4.1')\r\nbuilt and installed from source with\r\ngit checkout r1.4\r\nbazel build -c opt --copt=-march=\"haswell\" --config=cuda --verbose_failures --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package >pip_package_build2.log 2>&1\r\nnote: incompatible path flag is required with R1.4 at this time per https://github.com/tensorflow/tensorflow/issues/15492\r\nubuntu 16.04\r\nCuda 9.1, cudnn 7.0.4\r\ngcc --version\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nuname -r\r\n4.4.0-104-generic\r\nBazel 0.9\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nIt is unclear how to build and install the entire package purely from source\r\nI will attempt to log what I have done so far\r\nclone and build TF R1.4 for cuda\r\ninstall wheel into local directory  (sudo pip install /tmp/tensorflow-pkg/tensorflow*.whl -t ~/mytf_r1.4_c9.1\r\nexport PYTHONPATH=~/mytf_r1.4_c9.1\r\nmove tensorflow directory\r\n\r\ninstall common_voice files to ~/Common_voice\r\n\r\nper native client build from source instructions: https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md\r\ngit clone tensorflow\r\ncd tensorflow\r\ngit checkout r1.4\r\nln -s ../DeepSpeech/native_client ./\r\n./configure\r\nedit native_client/BUILD\r\ncomment out the following:\r\n#    tfcompile_flags = select({\r\n#        \"//tensorflow:rpi3\": str('--target_triple=\"armv6-linux-gnueabihf\" --target_cpu=\"cortex-a53\" --target_features=\"+neon-fp-armv8\"'),\r\n#        \"//conditions:default\": str('')\r\n#    }),\r\nbazel build -c opt --copt=-O3 --incompatible_load_argument_is_label=false //tensorflow:libtensorflow_cc.so //tensorflow:libtensorflow_framework.so //native_client:deepspeech //native_client:deepspeech_utils //native_client:libctc_decoder_with_kenlm.so //native_client:generate_trie\r\nat this point all the native client binaries are in\r\n~/tensorflow/bazel-bin/native_client\r\nlevinth@zt-gpu-lin:~/DeepSpeech/native_client$ ls ~/tensorflow/bazel-bin/native_client/\r\ngenerate_trie\r\ngenerate_trie-2.params\r\ngenerate_trie.runfiles\r\ngenerate_trie.runfiles_manifest\r\nlibctc_decoder_with_kenlm.so\r\nlibctc_decoder_with_kenlm.so-2.params\r\nlibctc_decoder_with_kenlm.so.runfiles\r\nlibctc_decoder_with_kenlm.so.runfiles_manifest\r\nlibdeepspeech.a\r\nlibdeepspeech.a-2.params\r\nlibdeepspeech.pic.a\r\nlibdeepspeech.pic.a-2.params\r\nlibdeepspeech.so\r\nlibdeepspeech.so-2.params\r\nlibdeepspeech_utils.a\r\nlibdeepspeech_utils.a-2.params\r\nlibdeepspeech_utils.pic.a\r\nlibdeepspeech_utils.pic.a-2.params\r\nlibdeepspeech_utils.so\r\nlibdeepspeech_utils.so-2.params\r\n_objs\r\n\r\ncd ../Deepspeech/native_client\r\nexport TFDIR ~/tensorflow\r\nmake deepspeech\r\n\r\n\r\nat this point however the native client shared objects are still in bazel-bin/native client and have not been installed. the invocation of Deepspeech.py fails as it cannot find the shared objects\r\npython DeepSpeech.py --train_files ../Common_voice/cv-valid-train.csv,../Common_voice/cv-other-train.csv --dev_files ../Common_voice/cv-valid-dev.csv --test_files ../Common_voice/cv-valid-test.csv >deepspeech_1.log 2>&1\r\ntensorflow.python.framework.errors_impl.NotFoundError: native_client/libctc_decoder_with_kenlm.so: cannot open shared object file: No such file or directory\r\n\r\nthe native_client/Makefile has sections for bindings and install..so try\r\nsudo make install\r\nand this still generates the error as install does not put\r\n~/tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so\r\ninto /usr/local/lib \r\nthough deepspeech.so and deepspeech_utils.so are installed there.\r\n\r\nmanually copy /tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so to ~/DeepSpeech/native_client and set permissions\r\nat this point the invocation now starts running but complains about\r\n------------------------------------------------------------------------\r\nWARNING: libdeepspeech failed to load, resorting to deprecated code\r\n         Refer to README.md for instructions on installing libdeepspeech\r\n------------------------------------------------------------------------\r\neven though /usr/local/lib is in the $LD_LIBRARY_PATH\r\n\r\ninvoking\r\npython DeepSpeech.py --train_files ../Common_voice/cv-valid-train.csv,../Common_voice/cv-other-train.csv --dev_files ../Common_voice/cv-valid-dev.csv --test_files ../Common_voice/cv-valid-test.csv --display_step 1 --validation_step 10\r\n\r\n------------------------------------------------------------------------\r\nWARNING: libdeepspeech failed to load, resorting to deprecated code\r\n         Refer to README.md for instructions on installing libdeepspeech\r\n------------------------------------------------------------------------\r\nI STARTING Optimization\r\nLoading the LM will be faster if you build a binary file.\r\nReading data/lm/lm.binary\r\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\nterminate called after throwing an instance of 'lm::FormatLoadException'\r\n  what():  native_client/kenlm/lm/read_arpa.cc:65 in void lm::ReadARPACounts(util::FilePiece&, std::vector<long unsigned int>&) threw FormatLoadException.\r\nfirst non-empty line was \"version https://git-lfs.github.com/spec/v1\" not \\data\\. Byte: 43\r\n\r\nI clearly have not figured this out\r\n:-)\r\n \r\n"}