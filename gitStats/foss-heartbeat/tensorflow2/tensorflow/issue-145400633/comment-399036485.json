{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/399036485", "html_url": "https://github.com/tensorflow/tensorflow/issues/1749#issuecomment-399036485", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1749", "id": 399036485, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTAzNjQ4NQ==", "user": {"login": "frozenscrypt", "id": 25789462, "node_id": "MDQ6VXNlcjI1Nzg5NDYy", "avatar_url": "https://avatars1.githubusercontent.com/u/25789462?v=4", "gravatar_id": "", "url": "https://api.github.com/users/frozenscrypt", "html_url": "https://github.com/frozenscrypt", "followers_url": "https://api.github.com/users/frozenscrypt/followers", "following_url": "https://api.github.com/users/frozenscrypt/following{/other_user}", "gists_url": "https://api.github.com/users/frozenscrypt/gists{/gist_id}", "starred_url": "https://api.github.com/users/frozenscrypt/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/frozenscrypt/subscriptions", "organizations_url": "https://api.github.com/users/frozenscrypt/orgs", "repos_url": "https://api.github.com/users/frozenscrypt/repos", "events_url": "https://api.github.com/users/frozenscrypt/events{/privacy}", "received_events_url": "https://api.github.com/users/frozenscrypt/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-21T09:24:31Z", "updated_at": "2018-06-21T09:24:31Z", "author_association": "NONE", "body_html": "<p>I'm not able to write more than 1.3 million tensors at once. Is there a way I can boost this to say 2 or 3 million tensors? I'm using this code to write tensors</p>\n<p>with tf.python_io.TFRecordWriter(tfrecords_path) as writer:<br>\nfor index, image in enumerate(images):<br>\nfeatures = tf.train.Features(feature={<br>\n'labels': self.int64_feature(labels[index]),<br>\n'images': self.bytes_feature(image),<br>\n'imagenames': self.bytes_feature(imagenames[index])<br>\n})<br>\nexample = tf.train.Example(features=features)<br>\nwriter.write(example.SerializeToString())<br>\nsys.stdout.write('\\r&gt;&gt;Writing {:d}/{:d} {:s} tfrecords'.format(index+1, len(images), imagenames[index]))<br>\nsys.stdout.flush()<br>\nsys.stdout.write('\\n')<br>\nsys.stdout.flush()</p>", "body_text": "I'm not able to write more than 1.3 million tensors at once. Is there a way I can boost this to say 2 or 3 million tensors? I'm using this code to write tensors\nwith tf.python_io.TFRecordWriter(tfrecords_path) as writer:\nfor index, image in enumerate(images):\nfeatures = tf.train.Features(feature={\n'labels': self.int64_feature(labels[index]),\n'images': self.bytes_feature(image),\n'imagenames': self.bytes_feature(imagenames[index])\n})\nexample = tf.train.Example(features=features)\nwriter.write(example.SerializeToString())\nsys.stdout.write('\\r>>Writing {:d}/{:d} {:s} tfrecords'.format(index+1, len(images), imagenames[index]))\nsys.stdout.flush()\nsys.stdout.write('\\n')\nsys.stdout.flush()", "body": "I'm not able to write more than 1.3 million tensors at once. Is there a way I can boost this to say 2 or 3 million tensors? I'm using this code to write tensors\r\n\r\nwith tf.python_io.TFRecordWriter(tfrecords_path) as writer:\r\n            for index, image in enumerate(images):\r\n                features = tf.train.Features(feature={\r\n                    'labels': self.int64_feature(labels[index]),\r\n                    'images': self.bytes_feature(image),\r\n                    'imagenames': self.bytes_feature(imagenames[index])\r\n                })\r\n                example = tf.train.Example(features=features)\r\n                writer.write(example.SerializeToString())\r\n                sys.stdout.write('\\r>>Writing {:d}/{:d} {:s} tfrecords'.format(index+1, len(images), imagenames[index]))\r\n                sys.stdout.flush()\r\n            sys.stdout.write('\\n')\r\nsys.stdout.flush()"}