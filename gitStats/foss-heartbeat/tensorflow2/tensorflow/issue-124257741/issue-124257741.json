{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/643", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/643/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/643/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/643/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/643", "id": 124257741, "node_id": "MDU6SXNzdWUxMjQyNTc3NDE=", "number": 643, "title": "Eliminate TileGrad in favor of reshape followed by reduce_sum", "user": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "girving", "id": 70511, "node_id": "MDQ6VXNlcjcwNTEx", "avatar_url": "https://avatars1.githubusercontent.com/u/70511?v=4", "gravatar_id": "", "url": "https://api.github.com/users/girving", "html_url": "https://github.com/girving", "followers_url": "https://api.github.com/users/girving/followers", "following_url": "https://api.github.com/users/girving/following{/other_user}", "gists_url": "https://api.github.com/users/girving/gists{/gist_id}", "starred_url": "https://api.github.com/users/girving/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/girving/subscriptions", "organizations_url": "https://api.github.com/users/girving/orgs", "repos_url": "https://api.github.com/users/girving/repos", "events_url": "https://api.github.com/users/girving/events{/privacy}", "received_events_url": "https://api.github.com/users/girving/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2015-12-29T19:31:47Z", "updated_at": "2017-02-09T22:37:41Z", "closed_at": "2016-03-08T21:41:00Z", "author_association": "CONTRIBUTOR", "body_html": "<p><code>TileGrad</code> is exactly equivalent to a reshape which splits each dimension into two pieces, an input dimension piece and a tile dimension piece, then does a reduce_sum over all the tile dimensions to get back the input shape.  There is no need for a separate op.</p>\n<p>For example, if <code>x.shape = (2, 3)</code> and we do <code>tf.tile(x, [5, 7])</code>, the tiled tensor has shape <code>(2 * 5, 3 * 7)</code>.  Given a gradient <code>y</code> w.r.t. that output with shape <code>(2 * 5, 3 * 7)</code>, we can recover the input gradient as <code>tf.reduce_sum(tf.reshape(y, [5, 2, 7, 3]), reduction_indices=[0, 2])</code>.</p>\n<p>Note that this works even in the case where <code>multiples</code> has zeros: in that case we'll do a <code>reduce_sum</code> where some of the dimensions we sum over will be zero.  This is well defined even if the result after summation is nonempty: in that case the result is zero.  If sum doesn't already work in that case, it should.</p>", "body_text": "TileGrad is exactly equivalent to a reshape which splits each dimension into two pieces, an input dimension piece and a tile dimension piece, then does a reduce_sum over all the tile dimensions to get back the input shape.  There is no need for a separate op.\nFor example, if x.shape = (2, 3) and we do tf.tile(x, [5, 7]), the tiled tensor has shape (2 * 5, 3 * 7).  Given a gradient y w.r.t. that output with shape (2 * 5, 3 * 7), we can recover the input gradient as tf.reduce_sum(tf.reshape(y, [5, 2, 7, 3]), reduction_indices=[0, 2]).\nNote that this works even in the case where multiples has zeros: in that case we'll do a reduce_sum where some of the dimensions we sum over will be zero.  This is well defined even if the result after summation is nonempty: in that case the result is zero.  If sum doesn't already work in that case, it should.", "body": "`TileGrad` is exactly equivalent to a reshape which splits each dimension into two pieces, an input dimension piece and a tile dimension piece, then does a reduce_sum over all the tile dimensions to get back the input shape.  There is no need for a separate op.\n\nFor example, if `x.shape = (2, 3)` and we do `tf.tile(x, [5, 7])`, the tiled tensor has shape `(2 * 5, 3 * 7)`.  Given a gradient `y` w.r.t. that output with shape `(2 * 5, 3 * 7)`, we can recover the input gradient as `tf.reduce_sum(tf.reshape(y, [5, 2, 7, 3]), reduction_indices=[0, 2])`.\n\nNote that this works even in the case where `multiples` has zeros: in that case we'll do a `reduce_sum` where some of the dimensions we sum over will be zero.  This is well defined even if the result after summation is nonempty: in that case the result is zero.  If sum doesn't already work in that case, it should.\n"}