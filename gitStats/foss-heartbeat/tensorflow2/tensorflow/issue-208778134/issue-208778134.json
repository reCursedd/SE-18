{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7680", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7680/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7680/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7680/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7680", "id": 208778134, "node_id": "MDU6SXNzdWUyMDg3NzgxMzQ=", "number": 7680, "title": "CUDA_ERROR_OUT_OF_MEMORY with tf.contrib.learn (basic linear regression model)", "user": {"login": "gajop", "id": 64901, "node_id": "MDQ6VXNlcjY0OTAx", "avatar_url": "https://avatars1.githubusercontent.com/u/64901?v=4", "gravatar_id": "", "url": "https://api.github.com/users/gajop", "html_url": "https://github.com/gajop", "followers_url": "https://api.github.com/users/gajop/followers", "following_url": "https://api.github.com/users/gajop/following{/other_user}", "gists_url": "https://api.github.com/users/gajop/gists{/gist_id}", "starred_url": "https://api.github.com/users/gajop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/gajop/subscriptions", "organizations_url": "https://api.github.com/users/gajop/orgs", "repos_url": "https://api.github.com/users/gajop/repos", "events_url": "https://api.github.com/users/gajop/events{/privacy}", "received_events_url": "https://api.github.com/users/gajop/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 19, "created_at": "2017-02-20T03:53:06Z", "updated_at": "2017-06-04T04:50:22Z", "closed_at": "2017-06-04T04:50:21Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System: Ubuntu 16.04,  GeForce GTX TITAN X</p>\n<p>Installed version of CUDA and cuDNN:<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):<br>\nls /usr/local/cuda-8.0/lib64/libcud*<br>\n/usr/local/cuda-8.0/lib64/libcudadevrt.a<br>\n/usr/local/cuda-8.0/lib64/libcudart.so<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0<br>\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44<br>\n/usr/local/cuda-8.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.5<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10<br>\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5<br>\n/usr/local/cuda-8.0/lib64/libcudnn_static.a</p>\n<h3>If installed from binary pip package, provide:</h3>\n<ol>\n<li>Installed with pip tensorflow-gpu</li>\n<li>~ python -c \"import tensorflow; print(tensorflow.<strong>version</strong>)<br>\n1.0.0</li>\n</ol>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<p>Using the provided tf.contrib.learn model in get_started/get_started documentation</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nfeatures = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\nestimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\nx = np.array([1., 2., 3., 4.])\ny = np.array([0., -1., -2., -3.])\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4, num_epochs=1000)\nestimator.fit(input_fn=input_fn, steps=10)\n\n</code></pre>\n<p>The Core model works fine.</p>\n<h3>Logs or other output that would be helpful</h3>\n<p>(If logs are large, please upload as attachment or provide link).</p>\n<pre><code>python test-oom.py \nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpew3U6z\nWARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\nWARNING:tensorflow:From /home/gajop/projekti/ubuntu-ranking-dataset-creator/env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\nInstructions for updating:\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:01:00.0\nTotal memory: 11.92GiB\nFree memory: 11.52GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 11.92G (12799180800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n</code></pre>", "body_text": "Environment info\nOperating System: Ubuntu 16.04,  GeForce GTX TITAN X\nInstalled version of CUDA and cuDNN:\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\nls /usr/local/cuda-8.0/lib64/libcud*\n/usr/local/cuda-8.0/lib64/libcudadevrt.a\n/usr/local/cuda-8.0/lib64/libcudart.so\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\n/usr/local/cuda-8.0/lib64/libcudart_static.a\n/usr/local/cuda-8.0/lib64/libcudnn.so\n/usr/local/cuda-8.0/lib64/libcudnn.so.5\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\nIf installed from binary pip package, provide:\n\nInstalled with pip tensorflow-gpu\n~ python -c \"import tensorflow; print(tensorflow.version)\n1.0.0\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\nUsing the provided tf.contrib.learn model in get_started/get_started documentation\nimport tensorflow as tf\nimport numpy as np\n\nfeatures = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\nestimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\nx = np.array([1., 2., 3., 4.])\ny = np.array([0., -1., -2., -3.])\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4, num_epochs=1000)\nestimator.fit(input_fn=input_fn, steps=10)\n\n\nThe Core model works fine.\nLogs or other output that would be helpful\n(If logs are large, please upload as attachment or provide link).\npython test-oom.py \nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpew3U6z\nWARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\nWARNING:tensorflow:From /home/gajop/projekti/ubuntu-ranking-dataset-creator/env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\nInstructions for updating:\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:01:00.0\nTotal memory: 11.92GiB\nFree memory: 11.52GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 11.92G (12799180800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY", "body": "### Environment info\r\nOperating System: Ubuntu 16.04,  GeForce GTX TITAN X\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\nls /usr/local/cuda-8.0/lib64/libcud*\r\n/usr/local/cuda-8.0/lib64/libcudadevrt.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudnn.so\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.10\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n/usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n\r\n### If installed from binary pip package, provide:\r\n\r\n1) Installed with pip tensorflow-gpu\r\n2) ~ python -c \"import tensorflow; print(tensorflow.__version__)\r\n1.0.0\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nUsing the provided tf.contrib.learn model in get_started/get_started documentation\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfeatures = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\r\nestimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\r\nx = np.array([1., 2., 3., 4.])\r\ny = np.array([0., -1., -2., -3.])\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4, num_epochs=1000)\r\nestimator.fit(input_fn=input_fn, steps=10)\r\n\r\n```\r\n\r\nThe Core model works fine.\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n```\r\npython test-oom.py \r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpew3U6z\r\nWARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\r\nWARNING:tensorflow:From /home/gajop/projekti/ubuntu-ranking-dataset-creator/env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX TITAN X\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.52GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 11.92G (12799180800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n```"}