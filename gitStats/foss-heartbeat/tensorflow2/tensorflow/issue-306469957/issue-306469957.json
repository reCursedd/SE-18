{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17824", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17824/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17824/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17824/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17824", "id": 306469957, "node_id": "MDU6SXNzdWUzMDY0Njk5NTc=", "number": 17824, "title": "Feature request: Return true labels from `estimator.predict(...)`", "user": {"login": "lhlmgr", "id": 400331, "node_id": "MDQ6VXNlcjQwMDMzMQ==", "avatar_url": "https://avatars2.githubusercontent.com/u/400331?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lhlmgr", "html_url": "https://github.com/lhlmgr", "followers_url": "https://api.github.com/users/lhlmgr/followers", "following_url": "https://api.github.com/users/lhlmgr/following{/other_user}", "gists_url": "https://api.github.com/users/lhlmgr/gists{/gist_id}", "starred_url": "https://api.github.com/users/lhlmgr/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lhlmgr/subscriptions", "organizations_url": "https://api.github.com/users/lhlmgr/orgs", "repos_url": "https://api.github.com/users/lhlmgr/repos", "events_url": "https://api.github.com/users/lhlmgr/events{/privacy}", "received_events_url": "https://api.github.com/users/lhlmgr/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "karmel", "id": 667809, "node_id": "MDQ6VXNlcjY2NzgwOQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/667809?v=4", "gravatar_id": "", "url": "https://api.github.com/users/karmel", "html_url": "https://github.com/karmel", "followers_url": "https://api.github.com/users/karmel/followers", "following_url": "https://api.github.com/users/karmel/following{/other_user}", "gists_url": "https://api.github.com/users/karmel/gists{/gist_id}", "starred_url": "https://api.github.com/users/karmel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/karmel/subscriptions", "organizations_url": "https://api.github.com/users/karmel/orgs", "repos_url": "https://api.github.com/users/karmel/repos", "events_url": "https://api.github.com/users/karmel/events{/privacy}", "received_events_url": "https://api.github.com/users/karmel/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 20, "created_at": "2018-03-19T13:48:43Z", "updated_at": "2018-10-24T23:16:38Z", "closed_at": "2018-07-11T13:23:07Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello everyone,</p>\n<p>As mentioned in the <a href=\"https://www.tensorflow.org/get_started/custom_estimators#implement_training_evaluation_and_prediction\" rel=\"nofollow\">Getting started with Tensorflow / Custom Estimators</a> one has to know the expected label for the data, since the labels will be discarded during the <code>predict()</code> function.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-c\"><span class=\"pl-c\">#</span> Generate predictions from the model</span>\nexpected <span class=\"pl-k\">=</span> [<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Setosa<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Versicolor<span class=\"pl-pds\">'</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Virginica<span class=\"pl-pds\">'</span></span>]\npredict_x <span class=\"pl-k\">=</span> {\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>SepalLength<span class=\"pl-pds\">'</span></span>: [<span class=\"pl-c1\">5.1</span>, <span class=\"pl-c1\">5.9</span>, <span class=\"pl-c1\">6.9</span>],\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>SepalWidth<span class=\"pl-pds\">'</span></span>: [<span class=\"pl-c1\">3.3</span>, <span class=\"pl-c1\">3.0</span>, <span class=\"pl-c1\">3.1</span>],\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>PetalLength<span class=\"pl-pds\">'</span></span>: [<span class=\"pl-c1\">1.7</span>, <span class=\"pl-c1\">4.2</span>, <span class=\"pl-c1\">5.4</span>],\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>PetalWidth<span class=\"pl-pds\">'</span></span>: [<span class=\"pl-c1\">0.5</span>, <span class=\"pl-c1\">1.5</span>, <span class=\"pl-c1\">2.1</span>],\n}\n\npredictions <span class=\"pl-k\">=</span> classifier.predict(\n    <span class=\"pl-v\">input_fn</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span>:iris_data.eval_input_fn(predict_x,\n                                            <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span>args.batch_size))</pre></div>\n<p>which can be seen <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L486\">here</a></p>\n<div class=\"highlight highlight-source-python\"><pre>     features, input_hooks <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._get_features_from_input_fn(\n        input_fn, model_fn_lib.ModeKeys.<span class=\"pl-c1\">PREDICT</span>)\n    estimator_spec <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._call_model_fn(\n        features, <span class=\"pl-c1\">None</span>, model_fn_lib.ModeKeys.<span class=\"pl-c1\">PREDICT</span>, <span class=\"pl-c1\">self</span>.config)</pre></div>\n<p>I totally agree to discard the labels, and don't pass them to the <code>model_fn</code> function. However, it would be much easier to return them also from the <code>input_fn</code>-function, if they are provided. A simplified solution, without the case distinction of given/not given labels, could be:</p>\n<div class=\"highlight highlight-source-python\"><pre>  <span class=\"pl-k\">def</span> <span class=\"pl-en\">predict</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>,\n              <span class=\"pl-smi\">input_fn</span>,\n              <span class=\"pl-smi\">predict_keys</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n              <span class=\"pl-smi\">hooks</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n              <span class=\"pl-smi\">checkpoint_path</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-s\"><span class=\"pl-pds\">\"\"\"</span>Yields predictions for given features.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Args:</span>\n<span class=\"pl-s\">      input_fn: A function that constructs the features. Prediction continues</span>\n<span class=\"pl-s\">        until `input_fn` raises an end-of-input exception (`OutOfRangeError` or</span>\n<span class=\"pl-s\">        `StopIteration`).</span>\n<span class=\"pl-s\">        See @{$get_started/premade_estimators#create_input_functions} for more</span>\n<span class=\"pl-s\">        information. The function should construct and return one of</span>\n<span class=\"pl-s\">        the following:</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">          * A 'tf.data.Dataset' object: Outputs of `Dataset` object must have</span>\n<span class=\"pl-s\">            same constraints as below.</span>\n<span class=\"pl-s\">          * features: A `Tensor` or a dictionary of string feature name to</span>\n<span class=\"pl-s\">            `Tensor`. features are consumed by `model_fn`. They should satisfy</span>\n<span class=\"pl-s\">            the expectation of `model_fn` from inputs.</span>\n<span class=\"pl-s\">          * A tuple, in which case the first item is extracted as features.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">      predict_keys: list of `str`, name of the keys to predict. It is used if</span>\n<span class=\"pl-s\">        the `EstimatorSpec.predictions` is a `dict`. If `predict_keys` is used</span>\n<span class=\"pl-s\">        then rest of the predictions will be filtered from the dictionary. If</span>\n<span class=\"pl-s\">        `None`, returns all.</span>\n<span class=\"pl-s\">      hooks: List of `SessionRunHook` subclass instances. Used for callbacks</span>\n<span class=\"pl-s\">        inside the prediction call.</span>\n<span class=\"pl-s\">      checkpoint_path: Path of a specific checkpoint to predict. If `None`, the</span>\n<span class=\"pl-s\">        latest checkpoint in `model_dir` is used.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Yields:</span>\n<span class=\"pl-s\">      Evaluated values of `predictions` tensors.</span>\n<span class=\"pl-s\"></span>\n<span class=\"pl-s\">    Raises:</span>\n<span class=\"pl-s\">      ValueError: Could not find a trained model in model_dir.</span>\n<span class=\"pl-s\">      ValueError: if batch length of predictions are not same.</span>\n<span class=\"pl-s\">      ValueError: If there is a conflict between `predict_keys` and</span>\n<span class=\"pl-s\">        `predictions`. For example if `predict_keys` is not `None` but</span>\n<span class=\"pl-s\">        `EstimatorSpec.predictions` is not a `dict`.</span>\n<span class=\"pl-s\">    <span class=\"pl-pds\">\"\"\"</span></span>\n    hooks <span class=\"pl-k\">=</span> _check_hooks_type(hooks)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Check that model has been trained.</span>\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> checkpoint_path:\n      checkpoint_path <span class=\"pl-k\">=</span> saver.latest_checkpoint(<span class=\"pl-c1\">self</span>._model_dir)\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> checkpoint_path:\n      <span class=\"pl-k\">raise</span> <span class=\"pl-c1\">ValueError</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Could not find trained model in model_dir: <span class=\"pl-c1\">{}</span>.<span class=\"pl-pds\">'</span></span>.format(\n          <span class=\"pl-c1\">self</span>._model_dir))\n\n    <span class=\"pl-k\">with</span> ops.Graph().as_default() <span class=\"pl-k\">as</span> g:\n      random_seed.set_random_seed(<span class=\"pl-c1\">self</span>._config.tf_random_seed)\n      <span class=\"pl-c1\">self</span>._create_and_assert_global_step(g)\n      features, labels, input_hooks <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._get_features_and_labels_from_input_fn(\n          input_fn, model_fn_lib.ModeKeys.<span class=\"pl-c1\">PREDICT</span>)\n      estimator_spec <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._call_model_fn(\n          features, <span class=\"pl-c1\">None</span>, model_fn_lib.ModeKeys.<span class=\"pl-c1\">PREDICT</span>, <span class=\"pl-c1\">self</span>.config)\n      predictions <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>._extract_keys(estimator_spec.predictions, predict_keys)\n      all_hooks <span class=\"pl-k\">=</span> <span class=\"pl-c1\">list</span>(input_hooks)\n      all_hooks.extend(hooks)\n      all_hooks.extend(<span class=\"pl-c1\">list</span>(estimator_spec.prediction_hooks <span class=\"pl-k\">or</span> []))\n      <span class=\"pl-k\">with</span> training.MonitoredSession(\n          <span class=\"pl-v\">session_creator</span><span class=\"pl-k\">=</span>training.ChiefSessionCreator(\n              <span class=\"pl-v\">checkpoint_filename_with_path</span><span class=\"pl-k\">=</span>checkpoint_path,\n              <span class=\"pl-v\">master</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._config.master,\n              <span class=\"pl-v\">scaffold</span><span class=\"pl-k\">=</span>estimator_spec.scaffold,\n              <span class=\"pl-v\">config</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">self</span>._session_config),\n          <span class=\"pl-v\">hooks</span><span class=\"pl-k\">=</span>all_hooks) <span class=\"pl-k\">as</span> mon_sess:\n        <span class=\"pl-k\">while</span> <span class=\"pl-k\">not</span> mon_sess.should_stop():\n          preds_evaluated, gt_labels <span class=\"pl-k\">=</span> mon_sess.run([predictions, labels])\n          <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(predictions, <span class=\"pl-c1\">dict</span>):\n            <span class=\"pl-k\">for</span> pred, true_label <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(preds_evaluated, gt_labels):\n              <span class=\"pl-k\">yield</span> pred, true_label\n          <span class=\"pl-k\">else</span>:\n            <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">self</span>._extract_batch_length(preds_evaluated)):\n              <span class=\"pl-k\">yield</span> {\n                  key: value[i]\n                  <span class=\"pl-k\">for</span> key, value <span class=\"pl-k\">in</span> six.iteritems(preds_evaluated)\n              }, gt_labels[i]</pre></div>\n<p>OS Platform and Distribution</p>\n<blockquote>\n<p>Ubuntu 16.04.3 LTS</p>\n</blockquote>\n<p>TensorFlow installed from</p>\n<blockquote>\n<p>pip</p>\n</blockquote>\n<p>TensorFlow version</p>\n<blockquote>\n<p>tensorflow-gpu '1.6.0'</p>\n</blockquote>\n<p>Bazel version</p>\n<blockquote>\n<p>N/A</p>\n</blockquote>\n<p>CUDA/cuDNN version</p>\n<blockquote>\n<p>N/A</p>\n</blockquote>\n<p>GPU model and memory</p>\n<blockquote>\n<p>N/A</p>\n</blockquote>\n<p>Exact command to reproduce</p>\n<blockquote>\n<p>N/A</p>\n</blockquote>", "body_text": "Hello everyone,\nAs mentioned in the Getting started with Tensorflow / Custom Estimators one has to know the expected label for the data, since the labels will be discarded during the predict() function.\n# Generate predictions from the model\nexpected = ['Setosa', 'Versicolor', 'Virginica']\npredict_x = {\n    'SepalLength': [5.1, 5.9, 6.9],\n    'SepalWidth': [3.3, 3.0, 3.1],\n    'PetalLength': [1.7, 4.2, 5.4],\n    'PetalWidth': [0.5, 1.5, 2.1],\n}\n\npredictions = classifier.predict(\n    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n                                            batch_size=args.batch_size))\nwhich can be seen here\n     features, input_hooks = self._get_features_from_input_fn(\n        input_fn, model_fn_lib.ModeKeys.PREDICT)\n    estimator_spec = self._call_model_fn(\n        features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\nI totally agree to discard the labels, and don't pass them to the model_fn function. However, it would be much easier to return them also from the input_fn-function, if they are provided. A simplified solution, without the case distinction of given/not given labels, could be:\n  def predict(self,\n              input_fn,\n              predict_keys=None,\n              hooks=None,\n              checkpoint_path=None):\n    \"\"\"Yields predictions for given features.\n\n    Args:\n      input_fn: A function that constructs the features. Prediction continues\n        until `input_fn` raises an end-of-input exception (`OutOfRangeError` or\n        `StopIteration`).\n        See @{$get_started/premade_estimators#create_input_functions} for more\n        information. The function should construct and return one of\n        the following:\n\n          * A 'tf.data.Dataset' object: Outputs of `Dataset` object must have\n            same constraints as below.\n          * features: A `Tensor` or a dictionary of string feature name to\n            `Tensor`. features are consumed by `model_fn`. They should satisfy\n            the expectation of `model_fn` from inputs.\n          * A tuple, in which case the first item is extracted as features.\n\n      predict_keys: list of `str`, name of the keys to predict. It is used if\n        the `EstimatorSpec.predictions` is a `dict`. If `predict_keys` is used\n        then rest of the predictions will be filtered from the dictionary. If\n        `None`, returns all.\n      hooks: List of `SessionRunHook` subclass instances. Used for callbacks\n        inside the prediction call.\n      checkpoint_path: Path of a specific checkpoint to predict. If `None`, the\n        latest checkpoint in `model_dir` is used.\n\n    Yields:\n      Evaluated values of `predictions` tensors.\n\n    Raises:\n      ValueError: Could not find a trained model in model_dir.\n      ValueError: if batch length of predictions are not same.\n      ValueError: If there is a conflict between `predict_keys` and\n        `predictions`. For example if `predict_keys` is not `None` but\n        `EstimatorSpec.predictions` is not a `dict`.\n    \"\"\"\n    hooks = _check_hooks_type(hooks)\n    # Check that model has been trained.\n    if not checkpoint_path:\n      checkpoint_path = saver.latest_checkpoint(self._model_dir)\n    if not checkpoint_path:\n      raise ValueError('Could not find trained model in model_dir: {}.'.format(\n          self._model_dir))\n\n    with ops.Graph().as_default() as g:\n      random_seed.set_random_seed(self._config.tf_random_seed)\n      self._create_and_assert_global_step(g)\n      features, labels, input_hooks = self._get_features_and_labels_from_input_fn(\n          input_fn, model_fn_lib.ModeKeys.PREDICT)\n      estimator_spec = self._call_model_fn(\n          features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n      predictions = self._extract_keys(estimator_spec.predictions, predict_keys)\n      all_hooks = list(input_hooks)\n      all_hooks.extend(hooks)\n      all_hooks.extend(list(estimator_spec.prediction_hooks or []))\n      with training.MonitoredSession(\n          session_creator=training.ChiefSessionCreator(\n              checkpoint_filename_with_path=checkpoint_path,\n              master=self._config.master,\n              scaffold=estimator_spec.scaffold,\n              config=self._session_config),\n          hooks=all_hooks) as mon_sess:\n        while not mon_sess.should_stop():\n          preds_evaluated, gt_labels = mon_sess.run([predictions, labels])\n          if not isinstance(predictions, dict):\n            for pred, true_label in zip(preds_evaluated, gt_labels):\n              yield pred, true_label\n          else:\n            for i in range(self._extract_batch_length(preds_evaluated)):\n              yield {\n                  key: value[i]\n                  for key, value in six.iteritems(preds_evaluated)\n              }, gt_labels[i]\nOS Platform and Distribution\n\nUbuntu 16.04.3 LTS\n\nTensorFlow installed from\n\npip\n\nTensorFlow version\n\ntensorflow-gpu '1.6.0'\n\nBazel version\n\nN/A\n\nCUDA/cuDNN version\n\nN/A\n\nGPU model and memory\n\nN/A\n\nExact command to reproduce\n\nN/A", "body": "Hello everyone,\r\n\r\nAs mentioned in the [Getting started with Tensorflow / Custom Estimators](https://www.tensorflow.org/get_started/custom_estimators#implement_training_evaluation_and_prediction) one has to know the expected label for the data, since the labels will be discarded during the `predict()` function.\r\n\r\n```python\r\n# Generate predictions from the model\r\nexpected = ['Setosa', 'Versicolor', 'Virginica']\r\npredict_x = {\r\n    'SepalLength': [5.1, 5.9, 6.9],\r\n    'SepalWidth': [3.3, 3.0, 3.1],\r\n    'PetalLength': [1.7, 4.2, 5.4],\r\n    'PetalWidth': [0.5, 1.5, 2.1],\r\n}\r\n\r\npredictions = classifier.predict(\r\n    input_fn=lambda:iris_data.eval_input_fn(predict_x,\r\n                                            batch_size=args.batch_size))\r\n```\r\n\r\nwhich can be seen [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L486)\r\n\r\n```python\r\n     features, input_hooks = self._get_features_from_input_fn(\r\n        input_fn, model_fn_lib.ModeKeys.PREDICT)\r\n    estimator_spec = self._call_model_fn(\r\n        features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\r\n```\r\n\r\nI totally agree to discard the labels, and don't pass them to the `model_fn` function. However, it would be much easier to return them also from the `input_fn`-function, if they are provided. A simplified solution, without the case distinction of given/not given labels, could be:\r\n\r\n```python\r\n  def predict(self,\r\n              input_fn,\r\n              predict_keys=None,\r\n              hooks=None,\r\n              checkpoint_path=None):\r\n    \"\"\"Yields predictions for given features.\r\n\r\n    Args:\r\n      input_fn: A function that constructs the features. Prediction continues\r\n        until `input_fn` raises an end-of-input exception (`OutOfRangeError` or\r\n        `StopIteration`).\r\n        See @{$get_started/premade_estimators#create_input_functions} for more\r\n        information. The function should construct and return one of\r\n        the following:\r\n\r\n          * A 'tf.data.Dataset' object: Outputs of `Dataset` object must have\r\n            same constraints as below.\r\n          * features: A `Tensor` or a dictionary of string feature name to\r\n            `Tensor`. features are consumed by `model_fn`. They should satisfy\r\n            the expectation of `model_fn` from inputs.\r\n          * A tuple, in which case the first item is extracted as features.\r\n\r\n      predict_keys: list of `str`, name of the keys to predict. It is used if\r\n        the `EstimatorSpec.predictions` is a `dict`. If `predict_keys` is used\r\n        then rest of the predictions will be filtered from the dictionary. If\r\n        `None`, returns all.\r\n      hooks: List of `SessionRunHook` subclass instances. Used for callbacks\r\n        inside the prediction call.\r\n      checkpoint_path: Path of a specific checkpoint to predict. If `None`, the\r\n        latest checkpoint in `model_dir` is used.\r\n\r\n    Yields:\r\n      Evaluated values of `predictions` tensors.\r\n\r\n    Raises:\r\n      ValueError: Could not find a trained model in model_dir.\r\n      ValueError: if batch length of predictions are not same.\r\n      ValueError: If there is a conflict between `predict_keys` and\r\n        `predictions`. For example if `predict_keys` is not `None` but\r\n        `EstimatorSpec.predictions` is not a `dict`.\r\n    \"\"\"\r\n    hooks = _check_hooks_type(hooks)\r\n    # Check that model has been trained.\r\n    if not checkpoint_path:\r\n      checkpoint_path = saver.latest_checkpoint(self._model_dir)\r\n    if not checkpoint_path:\r\n      raise ValueError('Could not find trained model in model_dir: {}.'.format(\r\n          self._model_dir))\r\n\r\n    with ops.Graph().as_default() as g:\r\n      random_seed.set_random_seed(self._config.tf_random_seed)\r\n      self._create_and_assert_global_step(g)\r\n      features, labels, input_hooks = self._get_features_and_labels_from_input_fn(\r\n          input_fn, model_fn_lib.ModeKeys.PREDICT)\r\n      estimator_spec = self._call_model_fn(\r\n          features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\r\n      predictions = self._extract_keys(estimator_spec.predictions, predict_keys)\r\n      all_hooks = list(input_hooks)\r\n      all_hooks.extend(hooks)\r\n      all_hooks.extend(list(estimator_spec.prediction_hooks or []))\r\n      with training.MonitoredSession(\r\n          session_creator=training.ChiefSessionCreator(\r\n              checkpoint_filename_with_path=checkpoint_path,\r\n              master=self._config.master,\r\n              scaffold=estimator_spec.scaffold,\r\n              config=self._session_config),\r\n          hooks=all_hooks) as mon_sess:\r\n        while not mon_sess.should_stop():\r\n          preds_evaluated, gt_labels = mon_sess.run([predictions, labels])\r\n          if not isinstance(predictions, dict):\r\n            for pred, true_label in zip(preds_evaluated, gt_labels):\r\n              yield pred, true_label\r\n          else:\r\n            for i in range(self._extract_batch_length(preds_evaluated)):\r\n              yield {\r\n                  key: value[i]\r\n                  for key, value in six.iteritems(preds_evaluated)\r\n              }, gt_labels[i]\r\n```\r\n\r\nOS Platform and Distribution\r\n> Ubuntu 16.04.3 LTS\r\n\r\nTensorFlow installed from\r\n> pip\r\n\r\nTensorFlow version\r\n>  tensorflow-gpu '1.6.0'\r\n\r\nBazel version\r\n> N/A\r\n\r\nCUDA/cuDNN version\r\n> N/A\r\n\r\nGPU model and memory\r\n> N/A\r\n\r\nExact command to reproduce\r\n> N/A\r\n\r\n\r\n"}