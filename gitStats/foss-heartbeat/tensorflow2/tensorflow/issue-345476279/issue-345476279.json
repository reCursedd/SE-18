{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21214", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21214/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21214/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21214/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21214", "id": 345476279, "node_id": "MDU6SXNzdWUzNDU0NzYyNzk=", "number": 21214, "title": "tensorflow softmax_cross_entropy_with_logits_v2 throws ValueError", "user": {"login": "pk00095", "id": 31564289, "node_id": "MDQ6VXNlcjMxNTY0Mjg5", "avatar_url": "https://avatars1.githubusercontent.com/u/31564289?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pk00095", "html_url": "https://github.com/pk00095", "followers_url": "https://api.github.com/users/pk00095/followers", "following_url": "https://api.github.com/users/pk00095/following{/other_user}", "gists_url": "https://api.github.com/users/pk00095/gists{/gist_id}", "starred_url": "https://api.github.com/users/pk00095/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pk00095/subscriptions", "organizations_url": "https://api.github.com/users/pk00095/orgs", "repos_url": "https://api.github.com/users/pk00095/repos", "events_url": "https://api.github.com/users/pk00095/events{/privacy}", "received_events_url": "https://api.github.com/users/pk00095/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 0, "created_at": "2018-07-28T20:21:49Z", "updated_at": "2018-07-28T21:48:04Z", "closed_at": "2018-07-28T21:48:04Z", "author_association": "NONE", "body_html": "<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 14</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>:No</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:binary</li>\n<li><strong>TensorFlow version (use command below)</strong>:1.5.0</li>\n<li><strong>Python version</strong>:2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: No</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: No</li>\n<li><strong>CUDA/cuDNN version</strong>: No</li>\n<li><strong>GPU model and memory</strong>: CPU</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>\nimport tensorflow as tf\nimport numpy as np\n\nnum_columns=24\nnum_classes=4\ntrain_steps = 2\n\n\ndef model():\n\n   ground_truth_input = tf.placeholder(tf.float32,[None,num_classes]) #onehotencoded with depth 4\n   bottleneck_input = tf.placeholder(tf.float32,[None,num_columns])  #num_columns=24 keypoint features\n\n   net = tf.layers.dense(inputs=bottleneck_input,units=100,activation=tf.nn.relu)\n   logits = tf.layers.dense(inputs = net,units=4,activation=None)\n\n   # loss function \n   loss_mean = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ground_truth_input, logits=logits)#,dim=-1)\n\n   with tf.name_scope('train'):\n      optimizer = tf.train.MomentumOptimizer(\n        learning_rate=0.1,\n        use_nesterov=True,\n        momentum=0.9)\n      train_op = optimizer.minimize(loss_mean, global_step=tf.train.get_global_step())\n\n   with tf.name_scope('SoftMax_Layer'):\n      final_tensor = tf.nn.softmax(logits,name='Softmax')\n\n   return train_op, ground_truth_input, bottleneck_input, loss_mean\n\n\ntrainStep, cross_entropy, features, ground_truth = model()\n\nwith tf.Session() as sess:\n   for i in range(2):\n       Label = np.eye(4)[np.random.choice(4,32)]\n       Features = np.random.rand(32,24)\n       train_summary, _ = sess.run([trainStep],feed_dict = {ground_truth : Label, features :Features})\n</code></pre>\n<h3>Describe the problem</h3>\n<p>features are of shape <strong>32x24</strong> and onehot labels are <strong>32x4</strong>. while running the code the softmax cross entropy raises ValueError. have asked <a href=\"https://stackoverflow.com/questions/51574218/tensorflow-softmax-cross-entropy-with-logits-v2-throws-valueerror\" rel=\"nofollow\">this</a> on stackoverflow.</p>\n<p>Originally i feed data from tfrecords generated from csv files. csv file contains 24 columns and one label column. I convert the label to onehot before fedding it to session.</p>\n<h3>Source code / logs</h3>\n<p>Error logs<br>\nTraceback (most recent call last):</p>\n<blockquote>\n<p>File \"dummy.py\", line 57, in <br>\ntrain_summary, _ = sess.run([trainStep],feed_dict = {ground_truth : Label, features :Features})<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1104, in _run<br>\n% (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))<br>\nValueError: Cannot feed value of shape (32, 4) for Tensor u'softmax_cross_entropy_with_logits/Reshape_2:0', which has shape '(?,)'</p>\n</blockquote>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\nTensorFlow installed from (source or binary):binary\nTensorFlow version (use command below):1.5.0\nPython version:2.7.12\nBazel version (if compiling from source): No\nGCC/Compiler version (if compiling from source): No\nCUDA/cuDNN version: No\nGPU model and memory: CPU\nExact command to reproduce:\n\n\nimport tensorflow as tf\nimport numpy as np\n\nnum_columns=24\nnum_classes=4\ntrain_steps = 2\n\n\ndef model():\n\n   ground_truth_input = tf.placeholder(tf.float32,[None,num_classes]) #onehotencoded with depth 4\n   bottleneck_input = tf.placeholder(tf.float32,[None,num_columns])  #num_columns=24 keypoint features\n\n   net = tf.layers.dense(inputs=bottleneck_input,units=100,activation=tf.nn.relu)\n   logits = tf.layers.dense(inputs = net,units=4,activation=None)\n\n   # loss function \n   loss_mean = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ground_truth_input, logits=logits)#,dim=-1)\n\n   with tf.name_scope('train'):\n      optimizer = tf.train.MomentumOptimizer(\n        learning_rate=0.1,\n        use_nesterov=True,\n        momentum=0.9)\n      train_op = optimizer.minimize(loss_mean, global_step=tf.train.get_global_step())\n\n   with tf.name_scope('SoftMax_Layer'):\n      final_tensor = tf.nn.softmax(logits,name='Softmax')\n\n   return train_op, ground_truth_input, bottleneck_input, loss_mean\n\n\ntrainStep, cross_entropy, features, ground_truth = model()\n\nwith tf.Session() as sess:\n   for i in range(2):\n       Label = np.eye(4)[np.random.choice(4,32)]\n       Features = np.random.rand(32,24)\n       train_summary, _ = sess.run([trainStep],feed_dict = {ground_truth : Label, features :Features})\n\nDescribe the problem\nfeatures are of shape 32x24 and onehot labels are 32x4. while running the code the softmax cross entropy raises ValueError. have asked this on stackoverflow.\nOriginally i feed data from tfrecords generated from csv files. csv file contains 24 columns and one label column. I convert the label to onehot before fedding it to session.\nSource code / logs\nError logs\nTraceback (most recent call last):\n\nFile \"dummy.py\", line 57, in \ntrain_summary, _ = sess.run([trainStep],feed_dict = {ground_truth : Label, features :Features})\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1104, in _run\n% (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\nValueError: Cannot feed value of shape (32, 4) for Tensor u'softmax_cross_entropy_with_logits/Reshape_2:0', which has shape '(?,)'", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:No\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.5.0\r\n- **Python version**:2.7.12\r\n- **Bazel version (if compiling from source)**: No\r\n- **GCC/Compiler version (if compiling from source)**: No\r\n- **CUDA/cuDNN version**: No\r\n- **GPU model and memory**: CPU\r\n- **Exact command to reproduce**:\r\n```\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nnum_columns=24\r\nnum_classes=4\r\ntrain_steps = 2\r\n\r\n\r\ndef model():\r\n\r\n   ground_truth_input = tf.placeholder(tf.float32,[None,num_classes]) #onehotencoded with depth 4\r\n   bottleneck_input = tf.placeholder(tf.float32,[None,num_columns])  #num_columns=24 keypoint features\r\n\r\n   net = tf.layers.dense(inputs=bottleneck_input,units=100,activation=tf.nn.relu)\r\n   logits = tf.layers.dense(inputs = net,units=4,activation=None)\r\n\r\n   # loss function \r\n   loss_mean = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ground_truth_input, logits=logits)#,dim=-1)\r\n\r\n   with tf.name_scope('train'):\r\n      optimizer = tf.train.MomentumOptimizer(\r\n        learning_rate=0.1,\r\n        use_nesterov=True,\r\n        momentum=0.9)\r\n      train_op = optimizer.minimize(loss_mean, global_step=tf.train.get_global_step())\r\n\r\n   with tf.name_scope('SoftMax_Layer'):\r\n      final_tensor = tf.nn.softmax(logits,name='Softmax')\r\n\r\n   return train_op, ground_truth_input, bottleneck_input, loss_mean\r\n\r\n\r\ntrainStep, cross_entropy, features, ground_truth = model()\r\n\r\nwith tf.Session() as sess:\r\n   for i in range(2):\r\n       Label = np.eye(4)[np.random.choice(4,32)]\r\n       Features = np.random.rand(32,24)\r\n       train_summary, _ = sess.run([trainStep],feed_dict = {ground_truth : Label, features :Features})\r\n```\r\n\r\n\r\n### Describe the problem\r\nfeatures are of shape **32x24** and onehot labels are **32x4**. while running the code the softmax cross entropy raises ValueError. have asked [this](https://stackoverflow.com/questions/51574218/tensorflow-softmax-cross-entropy-with-logits-v2-throws-valueerror) on stackoverflow.\r\n\r\nOriginally i feed data from tfrecords generated from csv files. csv file contains 24 columns and one label column. I convert the label to onehot before fedding it to session.\r\n### Source code / logs\r\nError logs \r\nTraceback (most recent call last):\r\n > File \"dummy.py\", line 57, in <module>\r\n    train_summary, _ = sess.run([trainStep],feed_dict = {ground_truth : Label, features :Features})\r\n > File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n > File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1104, in _run\r\n    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\r\n>ValueError: Cannot feed value of shape (32, 4) for Tensor u'softmax_cross_entropy_with_logits/Reshape_2:0', which has shape '(?,)'\r\n"}