{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/411820678", "html_url": "https://github.com/tensorflow/tensorflow/issues/21099#issuecomment-411820678", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21099", "id": 411820678, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMTgyMDY3OA==", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-09T16:38:29Z", "updated_at": "2018-08-09T16:38:29Z", "author_association": "MEMBER", "body_html": "<p>The problem here is that the vars are also coming from the cond, not just the grads. Make the cond return the grads and do the zip with variables outside the cond and you should be fine.</p>\n<p>Alternatively, if the actual set of variables to be optimized is conditional, you can call apply_gradients inside the cond and return the train op from both branches.</p>", "body_text": "The problem here is that the vars are also coming from the cond, not just the grads. Make the cond return the grads and do the zip with variables outside the cond and you should be fine.\nAlternatively, if the actual set of variables to be optimized is conditional, you can call apply_gradients inside the cond and return the train op from both branches.", "body": "The problem here is that the vars are also coming from the cond, not just the grads. Make the cond return the grads and do the zip with variables outside the cond and you should be fine.\r\n\r\nAlternatively, if the actual set of variables to be optimized is conditional, you can call apply_gradients inside the cond and return the train op from both branches."}