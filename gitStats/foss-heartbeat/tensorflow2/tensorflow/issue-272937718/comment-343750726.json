{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/343750726", "html_url": "https://github.com/tensorflow/tensorflow/issues/14448#issuecomment-343750726", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/14448", "id": 343750726, "node_id": "MDEyOklzc3VlQ29tbWVudDM0Mzc1MDcyNg==", "user": {"login": "boeddeker", "id": 13744128, "node_id": "MDQ6VXNlcjEzNzQ0MTI4", "avatar_url": "https://avatars3.githubusercontent.com/u/13744128?v=4", "gravatar_id": "", "url": "https://api.github.com/users/boeddeker", "html_url": "https://github.com/boeddeker", "followers_url": "https://api.github.com/users/boeddeker/followers", "following_url": "https://api.github.com/users/boeddeker/following{/other_user}", "gists_url": "https://api.github.com/users/boeddeker/gists{/gist_id}", "starred_url": "https://api.github.com/users/boeddeker/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/boeddeker/subscriptions", "organizations_url": "https://api.github.com/users/boeddeker/orgs", "repos_url": "https://api.github.com/users/boeddeker/repos", "events_url": "https://api.github.com/users/boeddeker/events{/privacy}", "received_events_url": "https://api.github.com/users/boeddeker/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-12T16:54:27Z", "updated_at": "2017-11-12T16:54:27Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Now I have some working code, I extracted the code from 'tf.data.Dataset.from_generator' and modified it to have a similar signature as <code>py_func</code>.<br>\nFurther, I added also a decorator (I prefer the decorator style.). For the decorator I allowed <code>output_type</code>/<code>output_shapes</code> to be callable to dynamic infer the <code>output_type</code>/<code>output_shapes</code>.</p>\n<p>If there is an interest in a PR, I need some feedback on the code and some advise, where I place the code and tests.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> traceback\n\n<span class=\"pl-k\">from</span> tensorflow.python.data.util <span class=\"pl-k\">import</span> nest\n<span class=\"pl-k\">from</span> tensorflow.python.framework <span class=\"pl-k\">import</span> tensor_shape\n<span class=\"pl-k\">from</span> tensorflow.python.ops <span class=\"pl-k\">import</span> script_ops\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">my_py_func</span>(<span class=\"pl-smi\">func</span>, <span class=\"pl-smi\">args</span><span class=\"pl-k\">=</span>(), <span class=\"pl-smi\">kwargs</span><span class=\"pl-k\">=</span>{}, <span class=\"pl-smi\">output_types</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">output_shapes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">stateful</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Low level function</span>\n    \n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">isinstance</span>(args, <span class=\"pl-c1\">list</span>):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Force tuple, nest.flatten interprets list as scalar</span>\n        args <span class=\"pl-k\">=</span> <span class=\"pl-c1\">tuple</span>(args)\n        \n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">callable</span>(output_types):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> If callable, assume same signature and call with tensors and get the types</span>\n        output_types <span class=\"pl-k\">=</span> output_types(<span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n    <span class=\"pl-k\">if</span> <span class=\"pl-c1\">callable</span>(output_shapes):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> If callable, assume same signature and call with tensors and get the shapes</span>\n        output_shapes <span class=\"pl-k\">=</span> output_shapes(<span class=\"pl-k\">*</span>args, <span class=\"pl-k\">**</span>kwargs)\n    \n    flat_output_types <span class=\"pl-k\">=</span> nest.flatten(output_types)\n    \n    args <span class=\"pl-k\">=</span> (args, kwargs)\n        \n    flat_args <span class=\"pl-k\">=</span> nest.flatten(args)\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">python_function_wrapper</span>(<span class=\"pl-k\">*</span><span class=\"pl-smi\">py_args</span>):\n        <span class=\"pl-k\">try</span>:\n            py_args, py_kwargs <span class=\"pl-k\">=</span> nest.pack_sequence_as(args, py_args)\n            ret <span class=\"pl-k\">=</span> func(<span class=\"pl-k\">*</span>py_args, <span class=\"pl-k\">**</span>py_kwargs)\n            nest.assert_shallow_structure(output_types, ret)\n        <span class=\"pl-k\">except</span> <span class=\"pl-c1\">Exception</span>:\n            traceback.print_exc()\n            <span class=\"pl-k\">raise</span>\n        <span class=\"pl-k\">return</span> nest.flatten(ret)\n    \n    flat_values <span class=\"pl-k\">=</span> script_ops.py_func(\n      python_function_wrapper, flat_args, flat_output_types, <span class=\"pl-v\">stateful</span><span class=\"pl-k\">=</span>stateful, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name)\n\n    <span class=\"pl-k\">if</span> output_shapes <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> I am not sure if this is nessesary</span>\n        output_shapes <span class=\"pl-k\">=</span> nest.map_structure_up_to(\n            output_types, tensor_shape.as_shape, output_shapes)\n        flattened_shapes <span class=\"pl-k\">=</span> nest.flatten(output_shapes)\n        <span class=\"pl-k\">for</span> ret_t, shape <span class=\"pl-k\">in</span> <span class=\"pl-c1\">zip</span>(flat_values, flattened_shapes):\n            ret_t.set_shape(shape)\n\n    <span class=\"pl-k\">return</span> nest.pack_sequence_as(output_types, flat_values)\n    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">py_func_decorator</span>(<span class=\"pl-smi\">output_types</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">output_shapes</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>, <span class=\"pl-smi\">stateful</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-smi\">name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>):\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">decorator</span>(<span class=\"pl-smi\">func</span>):\n        <span class=\"pl-k\">def</span> <span class=\"pl-en\">call</span>(<span class=\"pl-k\">*</span><span class=\"pl-smi\">args</span>, <span class=\"pl-k\">**</span><span class=\"pl-smi\">kwargs</span>):\n            <span class=\"pl-k\">return</span> my_py_func(\n                func, \n                args, kwargs, \n                <span class=\"pl-v\">output_types</span><span class=\"pl-k\">=</span>output_types, <span class=\"pl-v\">output_shapes</span><span class=\"pl-k\">=</span>output_shapes, \n                <span class=\"pl-v\">stateful</span><span class=\"pl-k\">=</span>stateful, <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name\n            )\n        <span class=\"pl-k\">return</span> call\n    <span class=\"pl-k\">return</span> decorator\n            \n<span class=\"pl-en\">@py_func_decorator</span>(\n    <span class=\"pl-v\">output_types</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">a</span>, <span class=\"pl-smi\">b</span>: {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>: nest.map_structure(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: x.dtype, a), \n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>: nest.map_structure(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: x.dtype, b),\n    }, \n    <span class=\"pl-v\">output_shapes</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">a</span>, <span class=\"pl-smi\">b</span>: {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>: nest.map_structure(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: x.shape, a), \n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>: nest.map_structure(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>: x.shape, b),\n    },\n)\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">foo</span>(<span class=\"pl-smi\">a</span>, <span class=\"pl-smi\">b</span>):\n    <span class=\"pl-k\">return</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>: a, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>: b}\n    \n<span class=\"pl-k\">def</span> <span class=\"pl-en\">bar</span>(<span class=\"pl-smi\">a</span>, <span class=\"pl-smi\">b</span>):\n    <span class=\"pl-k\">return</span> {<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>: a, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>: b}\n    \na <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">4</span>., <span class=\"pl-c1\">5</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>)\nb <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">4</span>., <span class=\"pl-c1\">5</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>)\nc <span class=\"pl-k\">=</span> tf.constant([<span class=\"pl-c1\">4</span>., <span class=\"pl-c1\">5</span>], <span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>c<span class=\"pl-pds\">'</span></span>)\nout0 <span class=\"pl-k\">=</span> my_py_func(\n    bar, [a, b], <span class=\"pl-v\">output_types</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>: a.dtype, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>: b.dtype}, <span class=\"pl-v\">output_shapes</span><span class=\"pl-k\">=</span>{<span class=\"pl-s\"><span class=\"pl-pds\">'</span>a<span class=\"pl-pds\">'</span></span>: a.shape, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>b<span class=\"pl-pds\">'</span></span>: b.shape})\nout1 <span class=\"pl-k\">=</span> foo(a, b)\nout2 <span class=\"pl-k\">=</span> foo(a, <span class=\"pl-v\">b</span><span class=\"pl-k\">=</span>b)\nout3 <span class=\"pl-k\">=</span> foo(<span class=\"pl-v\">a</span><span class=\"pl-k\">=</span>a, <span class=\"pl-v\">b</span><span class=\"pl-k\">=</span>b)\nout4 <span class=\"pl-k\">=</span> foo(<span class=\"pl-v\">a</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">dict</span>(<span class=\"pl-v\">a</span><span class=\"pl-k\">=</span>a, <span class=\"pl-v\">c</span><span class=\"pl-k\">=</span>c), <span class=\"pl-v\">b</span><span class=\"pl-k\">=</span>b)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>out0<span class=\"pl-pds\">'</span></span>, out0)\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>out1<span class=\"pl-pds\">'</span></span>, out1)\n\n<span class=\"pl-k\">from</span> IPython.lib.pretty <span class=\"pl-k\">import</span> pprint\n\n<span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n    pprint(sess.run([out0]))\n    pprint(sess.run([out1, out2, out3]))\n    pprint(sess.run([out3]))\n</pre></div>", "body_text": "Now I have some working code, I extracted the code from 'tf.data.Dataset.from_generator' and modified it to have a similar signature as py_func.\nFurther, I added also a decorator (I prefer the decorator style.). For the decorator I allowed output_type/output_shapes to be callable to dynamic infer the output_type/output_shapes.\nIf there is an interest in a PR, I need some feedback on the code and some advise, where I place the code and tests.\nimport tensorflow as tf\nimport traceback\n\nfrom tensorflow.python.data.util import nest\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.ops import script_ops\n\ndef my_py_func(func, args=(), kwargs={}, output_types=None, output_shapes=None, stateful=True, name=None):\n    # Low level function\n    \n    if isinstance(args, list):\n        # Force tuple, nest.flatten interprets list as scalar\n        args = tuple(args)\n        \n    if callable(output_types):\n        # If callable, assume same signature and call with tensors and get the types\n        output_types = output_types(*args, **kwargs)\n    if callable(output_shapes):\n        # If callable, assume same signature and call with tensors and get the shapes\n        output_shapes = output_shapes(*args, **kwargs)\n    \n    flat_output_types = nest.flatten(output_types)\n    \n    args = (args, kwargs)\n        \n    flat_args = nest.flatten(args)\n\n    def python_function_wrapper(*py_args):\n        try:\n            py_args, py_kwargs = nest.pack_sequence_as(args, py_args)\n            ret = func(*py_args, **py_kwargs)\n            nest.assert_shallow_structure(output_types, ret)\n        except Exception:\n            traceback.print_exc()\n            raise\n        return nest.flatten(ret)\n    \n    flat_values = script_ops.py_func(\n      python_function_wrapper, flat_args, flat_output_types, stateful=stateful, name=name)\n\n    if output_shapes is not None:\n        # I am not sure if this is nessesary\n        output_shapes = nest.map_structure_up_to(\n            output_types, tensor_shape.as_shape, output_shapes)\n        flattened_shapes = nest.flatten(output_shapes)\n        for ret_t, shape in zip(flat_values, flattened_shapes):\n            ret_t.set_shape(shape)\n\n    return nest.pack_sequence_as(output_types, flat_values)\n    \ndef py_func_decorator(output_types=None, output_shapes=None, stateful=True, name=None):\n    def decorator(func):\n        def call(*args, **kwargs):\n            return my_py_func(\n                func, \n                args, kwargs, \n                output_types=output_types, output_shapes=output_shapes, \n                stateful=stateful, name=name\n            )\n        return call\n    return decorator\n            \n@py_func_decorator(\n    output_types=lambda a, b: {\n        'a': nest.map_structure(lambda x: x.dtype, a), \n        'b': nest.map_structure(lambda x: x.dtype, b),\n    }, \n    output_shapes=lambda a, b: {\n        'a': nest.map_structure(lambda x: x.shape, a), \n        'b': nest.map_structure(lambda x: x.shape, b),\n    },\n)\ndef foo(a, b):\n    return {'a': a, 'b': b}\n    \ndef bar(a, b):\n    return {'a': a, 'b': b}\n    \na = tf.constant([4., 5], name='a')\nb = tf.constant([4., 5], name='b')\nc = tf.constant([4., 5], name='c')\nout0 = my_py_func(\n    bar, [a, b], output_types={'a': a.dtype, 'b': b.dtype}, output_shapes={'a': a.shape, 'b': b.shape})\nout1 = foo(a, b)\nout2 = foo(a, b=b)\nout3 = foo(a=a, b=b)\nout4 = foo(a=dict(a=a, c=c), b=b)\nprint('out0', out0)\nprint('out1', out1)\n\nfrom IPython.lib.pretty import pprint\n\nwith tf.Session() as sess:\n    pprint(sess.run([out0]))\n    pprint(sess.run([out1, out2, out3]))\n    pprint(sess.run([out3]))", "body": "Now I have some working code, I extracted the code from 'tf.data.Dataset.from_generator' and modified it to have a similar signature as `py_func`.\r\nFurther, I added also a decorator (I prefer the decorator style.). For the decorator I allowed `output_type`/`output_shapes` to be callable to dynamic infer the `output_type`/`output_shapes`.\r\n\r\nIf there is an interest in a PR, I need some feedback on the code and some advise, where I place the code and tests.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport traceback\r\n\r\nfrom tensorflow.python.data.util import nest\r\nfrom tensorflow.python.framework import tensor_shape\r\nfrom tensorflow.python.ops import script_ops\r\n\r\ndef my_py_func(func, args=(), kwargs={}, output_types=None, output_shapes=None, stateful=True, name=None):\r\n    # Low level function\r\n    \r\n    if isinstance(args, list):\r\n        # Force tuple, nest.flatten interprets list as scalar\r\n        args = tuple(args)\r\n        \r\n    if callable(output_types):\r\n        # If callable, assume same signature and call with tensors and get the types\r\n        output_types = output_types(*args, **kwargs)\r\n    if callable(output_shapes):\r\n        # If callable, assume same signature and call with tensors and get the shapes\r\n        output_shapes = output_shapes(*args, **kwargs)\r\n    \r\n    flat_output_types = nest.flatten(output_types)\r\n    \r\n    args = (args, kwargs)\r\n        \r\n    flat_args = nest.flatten(args)\r\n\r\n    def python_function_wrapper(*py_args):\r\n        try:\r\n            py_args, py_kwargs = nest.pack_sequence_as(args, py_args)\r\n            ret = func(*py_args, **py_kwargs)\r\n            nest.assert_shallow_structure(output_types, ret)\r\n        except Exception:\r\n            traceback.print_exc()\r\n            raise\r\n        return nest.flatten(ret)\r\n    \r\n    flat_values = script_ops.py_func(\r\n      python_function_wrapper, flat_args, flat_output_types, stateful=stateful, name=name)\r\n\r\n    if output_shapes is not None:\r\n        # I am not sure if this is nessesary\r\n        output_shapes = nest.map_structure_up_to(\r\n            output_types, tensor_shape.as_shape, output_shapes)\r\n        flattened_shapes = nest.flatten(output_shapes)\r\n        for ret_t, shape in zip(flat_values, flattened_shapes):\r\n            ret_t.set_shape(shape)\r\n\r\n    return nest.pack_sequence_as(output_types, flat_values)\r\n    \r\ndef py_func_decorator(output_types=None, output_shapes=None, stateful=True, name=None):\r\n    def decorator(func):\r\n        def call(*args, **kwargs):\r\n            return my_py_func(\r\n                func, \r\n                args, kwargs, \r\n                output_types=output_types, output_shapes=output_shapes, \r\n                stateful=stateful, name=name\r\n            )\r\n        return call\r\n    return decorator\r\n            \r\n@py_func_decorator(\r\n    output_types=lambda a, b: {\r\n        'a': nest.map_structure(lambda x: x.dtype, a), \r\n        'b': nest.map_structure(lambda x: x.dtype, b),\r\n    }, \r\n    output_shapes=lambda a, b: {\r\n        'a': nest.map_structure(lambda x: x.shape, a), \r\n        'b': nest.map_structure(lambda x: x.shape, b),\r\n    },\r\n)\r\ndef foo(a, b):\r\n    return {'a': a, 'b': b}\r\n    \r\ndef bar(a, b):\r\n    return {'a': a, 'b': b}\r\n    \r\na = tf.constant([4., 5], name='a')\r\nb = tf.constant([4., 5], name='b')\r\nc = tf.constant([4., 5], name='c')\r\nout0 = my_py_func(\r\n    bar, [a, b], output_types={'a': a.dtype, 'b': b.dtype}, output_shapes={'a': a.shape, 'b': b.shape})\r\nout1 = foo(a, b)\r\nout2 = foo(a, b=b)\r\nout3 = foo(a=a, b=b)\r\nout4 = foo(a=dict(a=a, c=c), b=b)\r\nprint('out0', out0)\r\nprint('out1', out1)\r\n\r\nfrom IPython.lib.pretty import pprint\r\n\r\nwith tf.Session() as sess:\r\n    pprint(sess.run([out0]))\r\n    pprint(sess.run([out1, out2, out3]))\r\n    pprint(sess.run([out3]))\r\n\r\n```"}