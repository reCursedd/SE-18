{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3640", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3640/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3640/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3640/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3640", "id": 169327990, "node_id": "MDU6SXNzdWUxNjkzMjc5OTA=", "number": 3640, "title": "Output for tfrecords files is not reproducible", "user": {"login": "leachim", "id": 2598597, "node_id": "MDQ6VXNlcjI1OTg1OTc=", "avatar_url": "https://avatars3.githubusercontent.com/u/2598597?v=4", "gravatar_id": "", "url": "https://api.github.com/users/leachim", "html_url": "https://github.com/leachim", "followers_url": "https://api.github.com/users/leachim/followers", "following_url": "https://api.github.com/users/leachim/following{/other_user}", "gists_url": "https://api.github.com/users/leachim/gists{/gist_id}", "starred_url": "https://api.github.com/users/leachim/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/leachim/subscriptions", "organizations_url": "https://api.github.com/users/leachim/orgs", "repos_url": "https://api.github.com/users/leachim/repos", "events_url": "https://api.github.com/users/leachim/events{/privacy}", "received_events_url": "https://api.github.com/users/leachim/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2016-08-04T09:14:50Z", "updated_at": "2016-08-10T00:03:52Z", "closed_at": "2016-08-10T00:03:52Z", "author_association": "NONE", "body_html": "<h3>Environment info</h3>\n<p>Operating System:<br>\nOS: Debian testing stretch<br>\nKernel: x86_64 Linux 4.5.0-1-amd64</p>\n<p>Tensorflow<br>\nVersion: 0.9.0</p>\n<h3>Steps to reproduce</h3>\n<p>Running this script gives a ~/test.tfrecords file.<br>\nRunning the script repeatedly gives different hashes for the file.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n<span class=\"pl-k\">import</span> argparse\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n\n<span class=\"pl-c1\">MAXIMUM_SEQUENCE_LENGTH</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">1000</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">export</span>(<span class=\"pl-smi\">data</span>, <span class=\"pl-smi\">name</span>, <span class=\"pl-smi\">args</span>):\n    num_examples <span class=\"pl-k\">=</span> <span class=\"pl-c1\">len</span>(data)\n\n    fh_output <span class=\"pl-k\">=</span> os.path.join(os.path.expandvars(args.output_directory), name <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>.tfrecords<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Writing<span class=\"pl-pds\">'</span></span>, fh_output)\n    writer <span class=\"pl-k\">=</span> tf.python_io.TFRecordWriter(fh_output)\n    <span class=\"pl-k\">for</span> index <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(num_examples):\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span># prepare things to save</span>\n        seq_x1 <span class=\"pl-k\">=</span> data[index][<span class=\"pl-c1\">0</span>].tostring()\n        seq_x2 <span class=\"pl-k\">=</span> data[index][<span class=\"pl-c1\">1</span>].tostring()\n\n        example <span class=\"pl-k\">=</span> tf.train.Example(<span class=\"pl-v\">features</span><span class=\"pl-k\">=</span>tf.train.Features(<span class=\"pl-v\">feature</span><span class=\"pl-k\">=</span>{\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>x1<span class=\"pl-pds\">'</span></span>: _bytes_feature(seq_x1),\n            <span class=\"pl-s\"><span class=\"pl-pds\">'</span>x2<span class=\"pl-pds\">'</span></span>: _bytes_feature(seq_x2),\n            }))\n        writer.write(example.SerializeToString())\n    writer.close()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_int64_feature</span>(<span class=\"pl-smi\">value</span>):\n    <span class=\"pl-k\">return</span> tf.train.Feature(<span class=\"pl-v\">int64_list</span><span class=\"pl-k\">=</span>tf.train.Int64List(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span>[value]))\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">_bytes_feature</span>(<span class=\"pl-smi\">value</span>):\n    <span class=\"pl-k\">return</span> tf.train.Feature(<span class=\"pl-v\">bytes_list</span><span class=\"pl-k\">=</span>tf.train.BytesList(<span class=\"pl-v\">value</span><span class=\"pl-k\">=</span>[value]))\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    tf.set_random_seed(<span class=\"pl-c1\">11</span>)\n    np.random.seed(<span class=\"pl-c1\">11</span>)\n\n    parser <span class=\"pl-k\">=</span> argparse.ArgumentParser()\n    parser.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--output_directory<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>, <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>$HOME/<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Directory to write the converted result<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> parser.add_argument('--validation_size', type=int, default=3000, help='Number of examples to separate from the training data for the validation set.')</span>\n    args <span class=\"pl-k\">=</span> parser.parse_args()\n\n    train <span class=\"pl-k\">=</span> [( np.zeros(<span class=\"pl-c1\">1000</span>), np.ones(<span class=\"pl-c1\">1000</span>), <span class=\"pl-c1\">500</span> )]\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span># Write data to training file</span>\n    export(train, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>test<span class=\"pl-pds\">'</span></span>, args)</pre></div>\n<p>I wonder why I cannot produce the same binary file again, if I rerun the script. Does this mean the content is different? I didn't find any option to set a seed either.</p>", "body_text": "Environment info\nOperating System:\nOS: Debian testing stretch\nKernel: x86_64 Linux 4.5.0-1-amd64\nTensorflow\nVersion: 0.9.0\nSteps to reproduce\nRunning this script gives a ~/test.tfrecords file.\nRunning the script repeatedly gives different hashes for the file.\nimport os\nimport argparse\n\nimport tensorflow as tf\nimport numpy as np\n\nMAXIMUM_SEQUENCE_LENGTH = 1000\n\ndef export(data, name, args):\n    num_examples = len(data)\n\n    fh_output = os.path.join(os.path.expandvars(args.output_directory), name + '.tfrecords')\n    print('Writing', fh_output)\n    writer = tf.python_io.TFRecordWriter(fh_output)\n    for index in range(num_examples):\n        ## prepare things to save\n        seq_x1 = data[index][0].tostring()\n        seq_x2 = data[index][1].tostring()\n\n        example = tf.train.Example(features=tf.train.Features(feature={\n            'x1': _bytes_feature(seq_x1),\n            'x2': _bytes_feature(seq_x2),\n            }))\n        writer.write(example.SerializeToString())\n    writer.close()\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\nif __name__ == '__main__':\n    tf.set_random_seed(11)\n    np.random.seed(11)\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--output_directory', type=str, default='$HOME/', help='Directory to write the converted result')\n    # parser.add_argument('--validation_size', type=int, default=3000, help='Number of examples to separate from the training data for the validation set.')\n    args = parser.parse_args()\n\n    train = [( np.zeros(1000), np.ones(1000), 500 )]\n\n    ## Write data to training file\n    export(train, 'test', args)\nI wonder why I cannot produce the same binary file again, if I rerun the script. Does this mean the content is different? I didn't find any option to set a seed either.", "body": "### Environment info\n\nOperating System:\nOS: Debian testing stretch  \nKernel: x86_64 Linux 4.5.0-1-amd64\n\nTensorflow\nVersion: 0.9.0\n### Steps to reproduce\n\nRunning this script gives a ~/test.tfrecords file. \nRunning the script repeatedly gives different hashes for the file. \n\n``` python\nimport os\nimport argparse\n\nimport tensorflow as tf\nimport numpy as np\n\nMAXIMUM_SEQUENCE_LENGTH = 1000\n\ndef export(data, name, args):\n    num_examples = len(data)\n\n    fh_output = os.path.join(os.path.expandvars(args.output_directory), name + '.tfrecords')\n    print('Writing', fh_output)\n    writer = tf.python_io.TFRecordWriter(fh_output)\n    for index in range(num_examples):\n        ## prepare things to save\n        seq_x1 = data[index][0].tostring()\n        seq_x2 = data[index][1].tostring()\n\n        example = tf.train.Example(features=tf.train.Features(feature={\n            'x1': _bytes_feature(seq_x1),\n            'x2': _bytes_feature(seq_x2),\n            }))\n        writer.write(example.SerializeToString())\n    writer.close()\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\nif __name__ == '__main__':\n    tf.set_random_seed(11)\n    np.random.seed(11)\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--output_directory', type=str, default='$HOME/', help='Directory to write the converted result')\n    # parser.add_argument('--validation_size', type=int, default=3000, help='Number of examples to separate from the training data for the validation set.')\n    args = parser.parse_args()\n\n    train = [( np.zeros(1000), np.ones(1000), 500 )]\n\n    ## Write data to training file\n    export(train, 'test', args)\n```\n\nI wonder why I cannot produce the same binary file again, if I rerun the script. Does this mean the content is different? I didn't find any option to set a seed either. \n"}