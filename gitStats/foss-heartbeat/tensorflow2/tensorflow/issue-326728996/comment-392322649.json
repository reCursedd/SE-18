{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/392322649", "html_url": "https://github.com/tensorflow/tensorflow/issues/19571#issuecomment-392322649", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19571", "id": 392322649, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MjMyMjY0OQ==", "user": {"login": "mirekphd", "id": 36706320, "node_id": "MDQ6VXNlcjM2NzA2MzIw", "avatar_url": "https://avatars3.githubusercontent.com/u/36706320?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mirekphd", "html_url": "https://github.com/mirekphd", "followers_url": "https://api.github.com/users/mirekphd/followers", "following_url": "https://api.github.com/users/mirekphd/following{/other_user}", "gists_url": "https://api.github.com/users/mirekphd/gists{/gist_id}", "starred_url": "https://api.github.com/users/mirekphd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mirekphd/subscriptions", "organizations_url": "https://api.github.com/users/mirekphd/orgs", "repos_url": "https://api.github.com/users/mirekphd/repos", "events_url": "https://api.github.com/users/mirekphd/events{/privacy}", "received_events_url": "https://api.github.com/users/mirekphd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-27T11:06:39Z", "updated_at": "2018-05-27T11:07:33Z", "author_association": "NONE", "body_html": "<p>For fellow TF users here I illustrate - using the sample code provided above - the two currently available methods to minimize and limit GPU memory usage (which can be combined together):</p>\n<ul>\n<li>allow_growth and</li>\n<li>per_process_gpu_memory_fraction:</li>\n</ul>\n<pre><code># Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Limit GPU memory use\ncfg = tf.ConfigProto()\n# allow dynamic GPU memory allocation (increased as needed,\n# but not released once allocated - requiring python kernel restart)\ncfg.gpu_options.allow_growth=True\n# define the hard limit on GPU memory allocation\n# (caution: can cause OOM errors)\ncfg.gpu_options.per_process_gpu_memory_fraction = 0.20\n\n# Start training (notice we used custom config)\nwith tf.Session(config=cfg) as sess:\n    sess.run(init)\n    [..]\n\n</code></pre>\n<p>Note: to induce python's GPU memory usage to amounts visible in nvidia-smi (larger than the default minimum of 200 MiB used by most frameworks) we need to increase the number of samples in the example above to at least 20k:</p>\n<pre><code>n_samples=20000\n</code></pre>", "body_text": "For fellow TF users here I illustrate - using the sample code provided above - the two currently available methods to minimize and limit GPU memory usage (which can be combined together):\n\nallow_growth and\nper_process_gpu_memory_fraction:\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()\n\n# Limit GPU memory use\ncfg = tf.ConfigProto()\n# allow dynamic GPU memory allocation (increased as needed,\n# but not released once allocated - requiring python kernel restart)\ncfg.gpu_options.allow_growth=True\n# define the hard limit on GPU memory allocation\n# (caution: can cause OOM errors)\ncfg.gpu_options.per_process_gpu_memory_fraction = 0.20\n\n# Start training (notice we used custom config)\nwith tf.Session(config=cfg) as sess:\n    sess.run(init)\n    [..]\n\n\nNote: to induce python's GPU memory usage to amounts visible in nvidia-smi (larger than the default minimum of 200 MiB used by most frameworks) we need to increase the number of samples in the example above to at least 20k:\nn_samples=20000", "body": "For fellow TF users here I illustrate - using the sample code provided above - the two currently available methods to minimize and limit GPU memory usage (which can be combined together):\r\n- allow_growth and \r\n- per_process_gpu_memory_fraction:\r\n\r\n```\r\n# Initialize the variables (i.e. assign their default value)\r\ninit = tf.global_variables_initializer()\r\n\r\n# Limit GPU memory use\r\ncfg = tf.ConfigProto()\r\n# allow dynamic GPU memory allocation (increased as needed,\r\n# but not released once allocated - requiring python kernel restart)\r\ncfg.gpu_options.allow_growth=True\r\n# define the hard limit on GPU memory allocation\r\n# (caution: can cause OOM errors)\r\ncfg.gpu_options.per_process_gpu_memory_fraction = 0.20\r\n\r\n# Start training (notice we used custom config)\r\nwith tf.Session(config=cfg) as sess:\r\n    sess.run(init)\r\n    [..]\r\n\r\n```\r\n\r\nNote: to induce python's GPU memory usage to amounts visible in nvidia-smi (larger than the default minimum of 200 MiB used by most frameworks) we need to increase the number of samples in the example above to at least 20k:\r\n```\r\nn_samples=20000\r\n```\r\n"}