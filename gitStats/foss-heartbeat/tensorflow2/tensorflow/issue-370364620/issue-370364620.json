{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22999", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22999/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22999/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22999/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22999", "id": 370364620, "node_id": "MDU6SXNzdWUzNzAzNjQ2MjA=", "number": 22999, "title": "Tensor is not an element of this graph.", "user": {"login": "epicvrvs", "id": 246385, "node_id": "MDQ6VXNlcjI0NjM4NQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/246385?v=4", "gravatar_id": "", "url": "https://api.github.com/users/epicvrvs", "html_url": "https://github.com/epicvrvs", "followers_url": "https://api.github.com/users/epicvrvs/followers", "following_url": "https://api.github.com/users/epicvrvs/following{/other_user}", "gists_url": "https://api.github.com/users/epicvrvs/gists{/gist_id}", "starred_url": "https://api.github.com/users/epicvrvs/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/epicvrvs/subscriptions", "organizations_url": "https://api.github.com/users/epicvrvs/orgs", "repos_url": "https://api.github.com/users/epicvrvs/repos", "events_url": "https://api.github.com/users/epicvrvs/events{/privacy}", "received_events_url": "https://api.github.com/users/epicvrvs/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "harshini-gadige", "id": 42781361, "node_id": "MDQ6VXNlcjQyNzgxMzYx", "avatar_url": "https://avatars1.githubusercontent.com/u/42781361?v=4", "gravatar_id": "", "url": "https://api.github.com/users/harshini-gadige", "html_url": "https://github.com/harshini-gadige", "followers_url": "https://api.github.com/users/harshini-gadige/followers", "following_url": "https://api.github.com/users/harshini-gadige/following{/other_user}", "gists_url": "https://api.github.com/users/harshini-gadige/gists{/gist_id}", "starred_url": "https://api.github.com/users/harshini-gadige/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/harshini-gadige/subscriptions", "organizations_url": "https://api.github.com/users/harshini-gadige/orgs", "repos_url": "https://api.github.com/users/harshini-gadige/repos", "events_url": "https://api.github.com/users/harshini-gadige/events{/privacy}", "received_events_url": "https://api.github.com/users/harshini-gadige/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-10-15T22:13:38Z", "updated_at": "2018-10-19T07:45:55Z", "closed_at": "2018-10-19T07:45:55Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes.</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10, Version 10.0.17134.285.</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary.</li>\n<li><strong>TensorFlow version (use command below)</strong>: b'v1.11.0-rc2-4-gc19e29306c' 1.11.0.</li>\n<li><strong>Python version</strong>: Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32.</li>\n<li><strong>CUDA/cuDNN version</strong>: CUDA V9.0.176, cuDNN v7.3.1.</li>\n<li><strong>GPU model and memory</strong>: Nvidia GTX 970 4 GB.</li>\n<li><strong>Bazel version</strong>: N/A.</li>\n<li><strong>Mobile platform</strong>: N/A.</li>\n<li><strong>Exact command to reproduce</strong>: <code>python test.py training_dry.wav training_wet.wav validation_dry.wav validation_wet.wav</code></li>\n</ul>\n<h3>Description</h3>\n<p>I'm probably doing something horribly wrong with regard to graph/session handling. I tried to copy examples from the documentation but my code is still failing with the following error:</p>\n<pre><code>C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n  WavFileWarning)\n2018-10-16 00:11:07.807782: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-10-16 00:11:08.164098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:\nname: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253\npciBusID: 0000:01:00.0\ntotalMemory: 4.00GiB freeMemory: 3.31GiB\n2018-10-16 00:11:08.172047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-10-16 00:11:09.229492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-16 00:11:09.234965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0\n2018-10-16 00:11:09.237217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N\n2018-10-16 00:11:09.240415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3023 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2)\nCommencing training.\nIteration 1\nTraceback (most recent call last):\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1050, in _run\n    subfeed, allow_tensor=True, allow_operation=False)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3488, in as_graph_element\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3567, in _as_graph_element_locked\n    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\nValueError: Tensor Tensor(\"Const:0\", shape=(24085052,), dtype=float32) is not an element of this graph.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"train.py\", line 92, in &lt;module&gt;\n    train(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav)\n  File \"train.py\", line 66, in train\n    run_operation(dry_training_wav, wet_training_wav, batch_size, minimize, session)\n  File \"train.py\", line 26, in run_operation\n    operation_output = session.run(operation, feed)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\n    run_metadata_ptr)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1053, in _run\n    'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\nTypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Const:0\", shape=(24085052,), dtype=float32) is not an element of this graph.\n</code></pre>\n<h3>Reproduction</h3>\n<pre><code>import sys\n\nimport scipy.io.wavfile\nimport tensorflow as tf\n\ndef read_wav(path):\n\trate, data = scipy.io.wavfile.read(path)\n\treturn tf.convert_to_tensor(data, dtype = tf.float32)\n\ndef get_batch(data, offset, batch_size):\n\treturn data[offset : offset + batch_size]\n\ndef get_length(tensor):\n\treturn tensor.shape[0].value\n\ndef run_operation(dry_data, wet_data, batch_size, operation, session):\n\toffset = 0\n\toutput = []\n\twhile offset + batch_size &lt; get_length(dry_training_wav):\n\t\tdry_batch = get_batch(dry_data, offset, batch_size)\n\t\twet_batch = get_batch(wet_data, offset, batch_size)\n\t\tfeed = {\n\t\t\tdry_data: dry_batch,\n\t\t\twet_data: wet_batch\n\t\t}\n\t\toperation_output = session.run(operation, feed)\n\t\toutput.append(operation_output)\n\t\toffset += batch_size\n\treturn output\n\ndef get_graph():\n\tgraph = tf.Graph()\n\twith graph.as_default():\n\t\tframe_count = 96\n\t\tlstm_layers = 64\n\n\t\tframe_shape = [frame_count]\n\n\t\tdry_data = tf.placeholder(tf.float32, frame_shape, 'dry_data')\n\t\twet_data = tf.placeholder(tf.float32, frame_shape, 'wet_data')\n\n\t\tlstm = tf.contrib.cudnn_rnn.CudnnLSTM(lstm_layers, frame_count)\n\t\treshaped_dry_data = tf.reshape(dry_data, [1, 1, frame_count])\n\t\tlstm_output, _ = lstm(reshaped_dry_data)\n\t\tflat_lstm_output = tf.reshape(lstm_output, frame_shape)\n\t\tprediction = tf.nn.elu(flat_lstm_output)\n\n\t\tloss = tf.sqrt(tf.losses.mean_squared_error(prediction, wet_data), name = 'loss')\n\t\toptimizer = tf.train.AdamOptimizer()\n\t\tminimize = optimizer.minimize(loss, name = 'minimize')\n\treturn graph\n\ndef train(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav):\n\tgraph = get_graph()\n\twith tf.Session(graph = graph) as session:\n\t\tinitializer = tf.global_variables_initializer()\n\t\tsession.run(initializer)\n\t\titeration = 1\n\t\tdry_data_placeholder = graph.get_operation_by_name('dry_data')\n\t\tbatch_size = dry_data_placeholder.outputs[0].shape[0].value\n\t\tloss = graph.get_operation_by_name('loss')\n\t\tminimize = graph.get_operation_by_name('minimize')\n\t\tprint('Commencing training.')\n\t\twhile True:\n\t\t\tprint(f'Iteration {iteration}')\n\t\t\trun_operation(dry_training_wav, wet_training_wav, batch_size, minimize, session)\n\t\t\tlosses = run_operation(dry_validation_wav, wet_validation_wav, batch_size, loss, session)\n\t\t\tvalidation_loss = sum(losses)\n\t\t\tprint(f'Validation: {validation_loss}')\n\t\t\titeration += 1\n\nif len(sys.argv) != 5:\n\tprint('Usage:')\n\tprint(f'{sys.argv[0]} &lt;dry training WAV file&gt; &lt;wet training WAV file&gt; &lt;dry validation WAV file&gt; &lt;wet validation WAV file&gt;')\n\tsys.exit(1)\n\ndry_training_wav_path = sys.argv[1]\nwet_training_wav_path = sys.argv[2]\n\ndry_validation_wav_path = sys.argv[3]\nwet_validation_wav_path = sys.argv[4]\n\ndry_training_wav = read_wav(dry_training_wav_path)\nwet_training_wav = read_wav(wet_training_wav_path)\n\ndry_validation_wav = read_wav(dry_validation_wav_path)\nwet_validation_wav = read_wav(wet_validation_wav_path)\n\nif get_length(dry_training_wav) != get_length(wet_training_wav) or get_length(dry_validation_wav) != get_length(wet_validation_wav):\n\traise Exception('Dry and wet WAVs must be same length.')\n\ntrain(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav)\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, Version 10.0.17134.285.\nTensorFlow installed from (source or binary): Binary.\nTensorFlow version (use command below): b'v1.11.0-rc2-4-gc19e29306c' 1.11.0.\nPython version: Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32.\nCUDA/cuDNN version: CUDA V9.0.176, cuDNN v7.3.1.\nGPU model and memory: Nvidia GTX 970 4 GB.\nBazel version: N/A.\nMobile platform: N/A.\nExact command to reproduce: python test.py training_dry.wav training_wet.wav validation_dry.wav validation_wet.wav\n\nDescription\nI'm probably doing something horribly wrong with regard to graph/session handling. I tried to copy examples from the documentation but my code is still failing with the following error:\nC:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n  WavFileWarning)\n2018-10-16 00:11:07.807782: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n2018-10-16 00:11:08.164098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:\nname: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253\npciBusID: 0000:01:00.0\ntotalMemory: 4.00GiB freeMemory: 3.31GiB\n2018-10-16 00:11:08.172047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-10-16 00:11:09.229492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-10-16 00:11:09.234965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0\n2018-10-16 00:11:09.237217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N\n2018-10-16 00:11:09.240415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3023 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2)\nCommencing training.\nIteration 1\nTraceback (most recent call last):\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1050, in _run\n    subfeed, allow_tensor=True, allow_operation=False)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3488, in as_graph_element\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3567, in _as_graph_element_locked\n    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\nValueError: Tensor Tensor(\"Const:0\", shape=(24085052,), dtype=float32) is not an element of this graph.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"train.py\", line 92, in <module>\n    train(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav)\n  File \"train.py\", line 66, in train\n    run_operation(dry_training_wav, wet_training_wav, batch_size, minimize, session)\n  File \"train.py\", line 26, in run_operation\n    operation_output = session.run(operation, feed)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\n    run_metadata_ptr)\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1053, in _run\n    'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\nTypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Const:0\", shape=(24085052,), dtype=float32) is not an element of this graph.\n\nReproduction\nimport sys\n\nimport scipy.io.wavfile\nimport tensorflow as tf\n\ndef read_wav(path):\n\trate, data = scipy.io.wavfile.read(path)\n\treturn tf.convert_to_tensor(data, dtype = tf.float32)\n\ndef get_batch(data, offset, batch_size):\n\treturn data[offset : offset + batch_size]\n\ndef get_length(tensor):\n\treturn tensor.shape[0].value\n\ndef run_operation(dry_data, wet_data, batch_size, operation, session):\n\toffset = 0\n\toutput = []\n\twhile offset + batch_size < get_length(dry_training_wav):\n\t\tdry_batch = get_batch(dry_data, offset, batch_size)\n\t\twet_batch = get_batch(wet_data, offset, batch_size)\n\t\tfeed = {\n\t\t\tdry_data: dry_batch,\n\t\t\twet_data: wet_batch\n\t\t}\n\t\toperation_output = session.run(operation, feed)\n\t\toutput.append(operation_output)\n\t\toffset += batch_size\n\treturn output\n\ndef get_graph():\n\tgraph = tf.Graph()\n\twith graph.as_default():\n\t\tframe_count = 96\n\t\tlstm_layers = 64\n\n\t\tframe_shape = [frame_count]\n\n\t\tdry_data = tf.placeholder(tf.float32, frame_shape, 'dry_data')\n\t\twet_data = tf.placeholder(tf.float32, frame_shape, 'wet_data')\n\n\t\tlstm = tf.contrib.cudnn_rnn.CudnnLSTM(lstm_layers, frame_count)\n\t\treshaped_dry_data = tf.reshape(dry_data, [1, 1, frame_count])\n\t\tlstm_output, _ = lstm(reshaped_dry_data)\n\t\tflat_lstm_output = tf.reshape(lstm_output, frame_shape)\n\t\tprediction = tf.nn.elu(flat_lstm_output)\n\n\t\tloss = tf.sqrt(tf.losses.mean_squared_error(prediction, wet_data), name = 'loss')\n\t\toptimizer = tf.train.AdamOptimizer()\n\t\tminimize = optimizer.minimize(loss, name = 'minimize')\n\treturn graph\n\ndef train(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav):\n\tgraph = get_graph()\n\twith tf.Session(graph = graph) as session:\n\t\tinitializer = tf.global_variables_initializer()\n\t\tsession.run(initializer)\n\t\titeration = 1\n\t\tdry_data_placeholder = graph.get_operation_by_name('dry_data')\n\t\tbatch_size = dry_data_placeholder.outputs[0].shape[0].value\n\t\tloss = graph.get_operation_by_name('loss')\n\t\tminimize = graph.get_operation_by_name('minimize')\n\t\tprint('Commencing training.')\n\t\twhile True:\n\t\t\tprint(f'Iteration {iteration}')\n\t\t\trun_operation(dry_training_wav, wet_training_wav, batch_size, minimize, session)\n\t\t\tlosses = run_operation(dry_validation_wav, wet_validation_wav, batch_size, loss, session)\n\t\t\tvalidation_loss = sum(losses)\n\t\t\tprint(f'Validation: {validation_loss}')\n\t\t\titeration += 1\n\nif len(sys.argv) != 5:\n\tprint('Usage:')\n\tprint(f'{sys.argv[0]} <dry training WAV file> <wet training WAV file> <dry validation WAV file> <wet validation WAV file>')\n\tsys.exit(1)\n\ndry_training_wav_path = sys.argv[1]\nwet_training_wav_path = sys.argv[2]\n\ndry_validation_wav_path = sys.argv[3]\nwet_validation_wav_path = sys.argv[4]\n\ndry_training_wav = read_wav(dry_training_wav_path)\nwet_training_wav = read_wav(wet_training_wav_path)\n\ndry_validation_wav = read_wav(dry_validation_wav_path)\nwet_validation_wav = read_wav(wet_validation_wav_path)\n\nif get_length(dry_training_wav) != get_length(wet_training_wav) or get_length(dry_validation_wav) != get_length(wet_validation_wav):\n\traise Exception('Dry and wet WAVs must be same length.')\n\ntrain(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10, Version 10.0.17134.285.\r\n- **TensorFlow installed from (source or binary)**: Binary.\r\n- **TensorFlow version (use command below)**: b'v1.11.0-rc2-4-gc19e29306c' 1.11.0.\r\n- **Python version**: Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32.\r\n- **CUDA/cuDNN version**: CUDA V9.0.176, cuDNN v7.3.1.\r\n- **GPU model and memory**: Nvidia GTX 970 4 GB.\r\n- **Bazel version**: N/A.\r\n- **Mobile platform**: N/A.\r\n- **Exact command to reproduce**: `python test.py training_dry.wav training_wet.wav validation_dry.wav validation_wet.wav`\r\n\r\n### Description\r\n\r\nI'm probably doing something horribly wrong with regard to graph/session handling. I tried to copy examples from the documentation but my code is still failing with the following error:\r\n\r\n```\r\nC:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n  WavFileWarning)\r\n2018-10-16 00:11:07.807782: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-10-16 00:11:08.164098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:\r\nname: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.31GiB\r\n2018-10-16 00:11:08.172047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-10-16 00:11:09.229492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-16 00:11:09.234965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0\r\n2018-10-16 00:11:09.237217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N\r\n2018-10-16 00:11:09.240415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3023 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2)\r\nCommencing training.\r\nIteration 1\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1050, in _run\r\n    subfeed, allow_tensor=True, allow_operation=False)\r\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3488, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3567, in _as_graph_element_locked\r\n    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\r\nValueError: Tensor Tensor(\"Const:0\", shape=(24085052,), dtype=float32) is not an element of this graph.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 92, in <module>\r\n    train(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav)\r\n  File \"train.py\", line 66, in train\r\n    run_operation(dry_training_wav, wet_training_wav, batch_size, minimize, session)\r\n  File \"train.py\", line 26, in run_operation\r\n    operation_output = session.run(operation, feed)\r\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Markov\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1053, in _run\r\n    'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\r\nTypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Const:0\", shape=(24085052,), dtype=float32) is not an element of this graph.\r\n```\r\n\r\n### Reproduction\r\n```\r\nimport sys\r\n\r\nimport scipy.io.wavfile\r\nimport tensorflow as tf\r\n\r\ndef read_wav(path):\r\n\trate, data = scipy.io.wavfile.read(path)\r\n\treturn tf.convert_to_tensor(data, dtype = tf.float32)\r\n\r\ndef get_batch(data, offset, batch_size):\r\n\treturn data[offset : offset + batch_size]\r\n\r\ndef get_length(tensor):\r\n\treturn tensor.shape[0].value\r\n\r\ndef run_operation(dry_data, wet_data, batch_size, operation, session):\r\n\toffset = 0\r\n\toutput = []\r\n\twhile offset + batch_size < get_length(dry_training_wav):\r\n\t\tdry_batch = get_batch(dry_data, offset, batch_size)\r\n\t\twet_batch = get_batch(wet_data, offset, batch_size)\r\n\t\tfeed = {\r\n\t\t\tdry_data: dry_batch,\r\n\t\t\twet_data: wet_batch\r\n\t\t}\r\n\t\toperation_output = session.run(operation, feed)\r\n\t\toutput.append(operation_output)\r\n\t\toffset += batch_size\r\n\treturn output\r\n\r\ndef get_graph():\r\n\tgraph = tf.Graph()\r\n\twith graph.as_default():\r\n\t\tframe_count = 96\r\n\t\tlstm_layers = 64\r\n\r\n\t\tframe_shape = [frame_count]\r\n\r\n\t\tdry_data = tf.placeholder(tf.float32, frame_shape, 'dry_data')\r\n\t\twet_data = tf.placeholder(tf.float32, frame_shape, 'wet_data')\r\n\r\n\t\tlstm = tf.contrib.cudnn_rnn.CudnnLSTM(lstm_layers, frame_count)\r\n\t\treshaped_dry_data = tf.reshape(dry_data, [1, 1, frame_count])\r\n\t\tlstm_output, _ = lstm(reshaped_dry_data)\r\n\t\tflat_lstm_output = tf.reshape(lstm_output, frame_shape)\r\n\t\tprediction = tf.nn.elu(flat_lstm_output)\r\n\r\n\t\tloss = tf.sqrt(tf.losses.mean_squared_error(prediction, wet_data), name = 'loss')\r\n\t\toptimizer = tf.train.AdamOptimizer()\r\n\t\tminimize = optimizer.minimize(loss, name = 'minimize')\r\n\treturn graph\r\n\r\ndef train(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav):\r\n\tgraph = get_graph()\r\n\twith tf.Session(graph = graph) as session:\r\n\t\tinitializer = tf.global_variables_initializer()\r\n\t\tsession.run(initializer)\r\n\t\titeration = 1\r\n\t\tdry_data_placeholder = graph.get_operation_by_name('dry_data')\r\n\t\tbatch_size = dry_data_placeholder.outputs[0].shape[0].value\r\n\t\tloss = graph.get_operation_by_name('loss')\r\n\t\tminimize = graph.get_operation_by_name('minimize')\r\n\t\tprint('Commencing training.')\r\n\t\twhile True:\r\n\t\t\tprint(f'Iteration {iteration}')\r\n\t\t\trun_operation(dry_training_wav, wet_training_wav, batch_size, minimize, session)\r\n\t\t\tlosses = run_operation(dry_validation_wav, wet_validation_wav, batch_size, loss, session)\r\n\t\t\tvalidation_loss = sum(losses)\r\n\t\t\tprint(f'Validation: {validation_loss}')\r\n\t\t\titeration += 1\r\n\r\nif len(sys.argv) != 5:\r\n\tprint('Usage:')\r\n\tprint(f'{sys.argv[0]} <dry training WAV file> <wet training WAV file> <dry validation WAV file> <wet validation WAV file>')\r\n\tsys.exit(1)\r\n\r\ndry_training_wav_path = sys.argv[1]\r\nwet_training_wav_path = sys.argv[2]\r\n\r\ndry_validation_wav_path = sys.argv[3]\r\nwet_validation_wav_path = sys.argv[4]\r\n\r\ndry_training_wav = read_wav(dry_training_wav_path)\r\nwet_training_wav = read_wav(wet_training_wav_path)\r\n\r\ndry_validation_wav = read_wav(dry_validation_wav_path)\r\nwet_validation_wav = read_wav(wet_validation_wav_path)\r\n\r\nif get_length(dry_training_wav) != get_length(wet_training_wav) or get_length(dry_validation_wav) != get_length(wet_validation_wav):\r\n\traise Exception('Dry and wet WAVs must be same length.')\r\n\r\ntrain(dry_training_wav, wet_training_wav, dry_validation_wav, wet_validation_wav)\r\n```"}