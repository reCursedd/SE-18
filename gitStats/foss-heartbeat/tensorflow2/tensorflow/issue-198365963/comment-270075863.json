{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/270075863", "html_url": "https://github.com/tensorflow/tensorflow/issues/6604#issuecomment-270075863", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6604", "id": 270075863, "node_id": "MDEyOklzc3VlQ29tbWVudDI3MDA3NTg2Mw==", "user": {"login": "bodokaiser", "id": 1780466, "node_id": "MDQ6VXNlcjE3ODA0NjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/1780466?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bodokaiser", "html_url": "https://github.com/bodokaiser", "followers_url": "https://api.github.com/users/bodokaiser/followers", "following_url": "https://api.github.com/users/bodokaiser/following{/other_user}", "gists_url": "https://api.github.com/users/bodokaiser/gists{/gist_id}", "starred_url": "https://api.github.com/users/bodokaiser/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bodokaiser/subscriptions", "organizations_url": "https://api.github.com/users/bodokaiser/orgs", "repos_url": "https://api.github.com/users/bodokaiser/repos", "events_url": "https://api.github.com/users/bodokaiser/events{/privacy}", "received_events_url": "https://api.github.com/users/bodokaiser/received_events", "type": "User", "site_admin": false}, "created_at": "2017-01-03T09:27:29Z", "updated_at": "2017-01-03T11:32:22Z", "author_association": "NONE", "body_html": "<p>This problem is not limited to <code>TensorLoggingHook</code> and <code>SummarySaverHook</code> but also to custom <code>SessionRunHook</code>s which at the moment provide the only modular interface to organize such things around your training / testing evaluation.</p>\n<p>As we already have support for <code>init_dict</code> and <code>init_fn</code> on many interfaces (e.g. <code>tf.train.Supervisor</code>, <code>tf.train.Scaffold</code>) I guess it would be consistent to add something similar for evaluation.</p>\n<p>At the moment calls to <code>monitored_session.run(fetches, feed_dict=...)</code> forward this information so I can do:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">class</span> <span class=\"pl-en\">LoggerHook</span>(<span class=\"pl-e\">tf</span>.<span class=\"pl-e\">train</span>.<span class=\"pl-e\">LoggingTensorHook</span>):\n\n    <span class=\"pl-k\">def</span> <span class=\"pl-en\">before_run</span>(<span class=\"pl-smi\"><span class=\"pl-smi\">self</span></span>, <span class=\"pl-smi\">run_context</span>):\n        run_args <span class=\"pl-k\">=</span> <span class=\"pl-c1\">super</span>().before_run(run_context)\n        feed_dict <span class=\"pl-k\">=</span> run_context.original_args.feed_dict\n\n       <span class=\"pl-c\"><span class=\"pl-c\">#</span> extract arguments from `monitored_session.run(...)` out of `feed_dict`</span>\n\n        <span class=\"pl-k\">return</span> run_args</pre></div>\n<p><strong>update</strong><br>\nThis approach fails if a tensor in <code>tensors</code> of <code>tf.train.LoggingTensorHook</code> depends on a <code>tf.placeholder</code> with <a href=\"https://github.com/tensorflow/tensorflow/blob/f1d60927dddd1599135ccb31ec9a8b439e2eaa37/tensorflow/python/training/monitored_session.py#L916-L918\">Same tensor is fed by a SessionRunHook and user.'</a>.</p>\n<p><strong>update2</strong><br>\nIf I use the <code>batch</code> tensors instead of placeholders then everything works fine. Does this mean that we only require placeholder if we want to use \"external\" data (not handled by tensorflow directly)? In this case this feature may only benefit a small target group as most people will use an input queue at this scale.</p>", "body_text": "This problem is not limited to TensorLoggingHook and SummarySaverHook but also to custom SessionRunHooks which at the moment provide the only modular interface to organize such things around your training / testing evaluation.\nAs we already have support for init_dict and init_fn on many interfaces (e.g. tf.train.Supervisor, tf.train.Scaffold) I guess it would be consistent to add something similar for evaluation.\nAt the moment calls to monitored_session.run(fetches, feed_dict=...) forward this information so I can do:\nclass LoggerHook(tf.train.LoggingTensorHook):\n\n    def before_run(self, run_context):\n        run_args = super().before_run(run_context)\n        feed_dict = run_context.original_args.feed_dict\n\n       # extract arguments from `monitored_session.run(...)` out of `feed_dict`\n\n        return run_args\nupdate\nThis approach fails if a tensor in tensors of tf.train.LoggingTensorHook depends on a tf.placeholder with Same tensor is fed by a SessionRunHook and user.'.\nupdate2\nIf I use the batch tensors instead of placeholders then everything works fine. Does this mean that we only require placeholder if we want to use \"external\" data (not handled by tensorflow directly)? In this case this feature may only benefit a small target group as most people will use an input queue at this scale.", "body": "This problem is not limited to `TensorLoggingHook` and `SummarySaverHook` but also to custom `SessionRunHook`s which at the moment provide the only modular interface to organize such things around your training / testing evaluation.\r\n\r\nAs we already have support for `init_dict` and `init_fn` on many interfaces (e.g. `tf.train.Supervisor`, `tf.train.Scaffold`) I guess it would be consistent to add something similar for evaluation.\r\n\r\nAt the moment calls to `monitored_session.run(fetches, feed_dict=...)` forward this information so I can do:\r\n\r\n```python\r\nclass LoggerHook(tf.train.LoggingTensorHook):\r\n\r\n    def before_run(self, run_context):\r\n        run_args = super().before_run(run_context)\r\n        feed_dict = run_context.original_args.feed_dict\r\n\r\n       # extract arguments from `monitored_session.run(...)` out of `feed_dict`\r\n\r\n        return run_args\r\n```\r\n\r\n**update**\r\nThis approach fails if a tensor in `tensors` of `tf.train.LoggingTensorHook` depends on a `tf.placeholder` with [Same tensor is fed by a SessionRunHook and user.'](https://github.com/tensorflow/tensorflow/blob/f1d60927dddd1599135ccb31ec9a8b439e2eaa37/tensorflow/python/training/monitored_session.py#L916-L918).\r\n\r\n**update2**\r\nIf I use the `batch` tensors instead of placeholders then everything works fine. Does this mean that we only require placeholder if we want to use \"external\" data (not handled by tensorflow directly)? In this case this feature may only benefit a small target group as most people will use an input queue at this scale."}