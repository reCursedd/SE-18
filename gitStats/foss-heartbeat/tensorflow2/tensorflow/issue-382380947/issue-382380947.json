{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23860", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23860/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23860/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23860/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23860", "id": 382380947, "node_id": "MDU6SXNzdWUzODIzODA5NDc=", "number": 23860, "title": "Poor memory performance of K.batch_dot under tensorflow backend relative to batched tf.matmul ", "user": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1125315826, "node_id": "MDU6TGFiZWwxMTI1MzE1ODI2", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:cross-posted%20from%20Keras", "name": "stat:cross-posted from Keras", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ymodak", "id": 42785357, "node_id": "MDQ6VXNlcjQyNzg1MzU3", "avatar_url": "https://avatars1.githubusercontent.com/u/42785357?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ymodak", "html_url": "https://github.com/ymodak", "followers_url": "https://api.github.com/users/ymodak/followers", "following_url": "https://api.github.com/users/ymodak/following{/other_user}", "gists_url": "https://api.github.com/users/ymodak/gists{/gist_id}", "starred_url": "https://api.github.com/users/ymodak/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ymodak/subscriptions", "organizations_url": "https://api.github.com/users/ymodak/orgs", "repos_url": "https://api.github.com/users/ymodak/repos", "events_url": "https://api.github.com/users/ymodak/events{/privacy}", "received_events_url": "https://api.github.com/users/ymodak/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 0, "created_at": "2018-11-19T20:29:37Z", "updated_at": "2018-11-21T00:07:37Z", "closed_at": "2018-11-21T00:07:37Z", "author_association": "NONE", "body_html": "<p>[ x] Check that you are up-to-date with the master branch of Keras. You can update with:<br>\npip install git+git://github.com/keras-team/keras.git --upgrade --no-deps</p>\n<p>[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.</p>\n<p>[x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).</p>\n<p>I am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.</p>\n<p>However in K.batch_dot, the elementwise multiplication in the line</p>\n<p>keras/keras/backend/tensorflow_backend.py</p>\n<p>Line 1248 in 75a3503</p>\n<p>result = tf.reduce_sum(x * y, 1)<br>\neats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.<br>\nIn this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.</p>\n<p>import numpy as np<br>\nimport tensorflow as tf<br>\nfrom keras import backend as K</p>\n<p>a = np.random.normal(size=(100, 500, 10000)).astype(np.float32)<br>\nb = np.random.normal(size=(100, 10000, 32)).astype(np.float32)</p>\n<p>a_t = K.placeholder(a.shape)<br>\nb_t = K.placeholder(b.shape)</p>\n<p>td = tf.matmul(a_t, b_t)<br>\nbd = K.batch_dot(a_t, b_t)</p>\n<p>sess = K.get_session()<br>\nsess.run(td, feed_dict={a_t: a, b_t: b})<br>\nsess.run(bd, feed_dict={a_t: a, b_t: b})<br>\nThis fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum).</p>", "body_text": "[ x] Check that you are up-to-date with the master branch of Keras. You can update with:\npip install git+git://github.com/keras-team/keras.git --upgrade --no-deps\n[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.\n[x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\nI am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.\nHowever in K.batch_dot, the elementwise multiplication in the line\nkeras/keras/backend/tensorflow_backend.py\nLine 1248 in 75a3503\nresult = tf.reduce_sum(x * y, 1)\neats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.\nIn this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.\nimport numpy as np\nimport tensorflow as tf\nfrom keras import backend as K\na = np.random.normal(size=(100, 500, 10000)).astype(np.float32)\nb = np.random.normal(size=(100, 10000, 32)).astype(np.float32)\na_t = K.placeholder(a.shape)\nb_t = K.placeholder(b.shape)\ntd = tf.matmul(a_t, b_t)\nbd = K.batch_dot(a_t, b_t)\nsess = K.get_session()\nsess.run(td, feed_dict={a_t: a, b_t: b})\nsess.run(bd, feed_dict={a_t: a, b_t: b})\nThis fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum).", "body": "[ x] Check that you are up-to-date with the master branch of Keras. You can update with:\r\npip install git+git://github.com/keras-team/keras.git --upgrade --no-deps\r\n\r\n[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.\r\n\r\n[x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\r\n\r\nI am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.\r\n\r\nHowever in K.batch_dot, the elementwise multiplication in the line\r\n\r\nkeras/keras/backend/tensorflow_backend.py\r\n\r\nLine 1248 in 75a3503\r\n\r\n result = tf.reduce_sum(x * y, 1) \r\neats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.\r\nIn this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom keras import backend as K\r\n\r\na = np.random.normal(size=(100, 500, 10000)).astype(np.float32)\r\nb = np.random.normal(size=(100, 10000, 32)).astype(np.float32)\r\n\r\na_t = K.placeholder(a.shape)\r\nb_t = K.placeholder(b.shape)\r\n\r\ntd = tf.matmul(a_t, b_t)\r\nbd = K.batch_dot(a_t, b_t)\r\n\r\nsess = K.get_session()\r\nsess.run(td, feed_dict={a_t: a, b_t: b})\r\nsess.run(bd, feed_dict={a_t: a, b_t: b})\r\nThis fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum)."}