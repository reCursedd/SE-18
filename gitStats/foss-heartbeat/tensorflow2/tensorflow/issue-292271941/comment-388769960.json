{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/388769960", "html_url": "https://github.com/tensorflow/tensorflow/issues/16532#issuecomment-388769960", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16532", "id": 388769960, "node_id": "MDEyOklzc3VlQ29tbWVudDM4ODc2OTk2MA==", "user": {"login": "calmzealA", "id": 24890958, "node_id": "MDQ6VXNlcjI0ODkwOTU4", "avatar_url": "https://avatars3.githubusercontent.com/u/24890958?v=4", "gravatar_id": "", "url": "https://api.github.com/users/calmzealA", "html_url": "https://github.com/calmzealA", "followers_url": "https://api.github.com/users/calmzealA/followers", "following_url": "https://api.github.com/users/calmzealA/following{/other_user}", "gists_url": "https://api.github.com/users/calmzealA/gists{/gist_id}", "starred_url": "https://api.github.com/users/calmzealA/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/calmzealA/subscriptions", "organizations_url": "https://api.github.com/users/calmzealA/orgs", "repos_url": "https://api.github.com/users/calmzealA/repos", "events_url": "https://api.github.com/users/calmzealA/events{/privacy}", "received_events_url": "https://api.github.com/users/calmzealA/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-14T10:24:56Z", "updated_at": "2018-05-14T10:24:56Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7102375\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ricardobarroslourenco\">@ricardobarroslourenco</a> got same error.<br>\nTypeError: <strong>init</strong>() got an unexpected keyword argument 'embeddings_metadata'</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/callbacks.py\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/callbacks.py</a></p>\n<p>Comments of TensorBoard shows embeddings_metadata param,<br>\nwhile the <strong>init</strong> do not support.<br>\n`<br>\n@tf_export('keras.callbacks.TensorBoard')<br>\nclass TensorBoard(Callback):</p>\n<h1>pylint: disable=line-too-long</h1>\n<p>\"\"\"Tensorboard basic visualizations.<br>\nThis callback writes a log for TensorBoard, which allows<br>\nyou to visualize dynamic graphs of your training and test<br>\nmetrics, as well as activation histograms for the different<br>\nlayers in your model.<br>\nTensorBoard is a visualization tool provided with TensorFlow.<br>\nIf you have installed TensorFlow with pip, you should be able<br>\nto launch TensorBoard from the command line:</p>\n<div class=\"highlight highlight-source-shell\"><pre>tensorboard --logdir=/full_path_to_your_logs</pre></div>\n<p>You can find more information about TensorBoard<br>\n<a href=\"https://www.tensorflow.org/get_started/summaries_and_tensorboard\" rel=\"nofollow\">here</a>.<br>\nArguments:<br>\nlog_dir: the path of the directory where to save the log<br>\nfiles to be parsed by TensorBoard.<br>\nhistogram_freq: frequency (in epochs) at which to compute activation<br>\nand weight histograms for the layers of the model. If set to 0,<br>\nhistograms won't be computed. Validation data (or split) must be<br>\nspecified for histogram visualizations.<br>\nwrite_graph: whether to visualize the graph in TensorBoard.<br>\nThe log file can become quite large when<br>\nwrite_graph is set to True.<br>\nwrite_grads: whether to visualize gradient histograms in TensorBoard.<br>\n<code>histogram_freq</code> must be greater than 0.<br>\nbatch_size: size of batch of inputs to feed to the network<br>\nfor histograms computation.<br>\nwrite_images: whether to write model weights to visualize as<br>\nimage in TensorBoard.<br>\nembeddings_freq: frequency (in epochs) at which selected embedding<br>\nlayers will be saved.<br>\nembeddings_layer_names: a list of names of layers to keep eye on. If<br>\nNone or empty list all the embedding layer will be watched.<br>\nembeddings_metadata: a dictionary which maps layer name to a file name<br>\nin which metadata for this embedding layer is saved. See the<br>\n<a href=\"https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional\" rel=\"nofollow\">details</a><br>\nabout metadata files format. In case if the same metadata file is<br>\nused for all embedding layers, string can be passed.<br>\n\"\"\"</p>\n<h1>pylint: enable=line-too-long</h1>\n<p>def <strong>init</strong>(self,<br>\nlog_dir='./logs',<br>\nhistogram_freq=0,<br>\nbatch_size=32,<br>\nwrite_graph=True,<br>\nwrite_grads=False,<br>\nwrite_images=False):<br>\nsuper(TensorBoard, self).<strong>init</strong>()<br>\n`</p>", "body_text": "@ricardobarroslourenco got same error.\nTypeError: init() got an unexpected keyword argument 'embeddings_metadata'\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/callbacks.py\nComments of TensorBoard shows embeddings_metadata param,\nwhile the init do not support.\n`\n@tf_export('keras.callbacks.TensorBoard')\nclass TensorBoard(Callback):\npylint: disable=line-too-long\n\"\"\"Tensorboard basic visualizations.\nThis callback writes a log for TensorBoard, which allows\nyou to visualize dynamic graphs of your training and test\nmetrics, as well as activation histograms for the different\nlayers in your model.\nTensorBoard is a visualization tool provided with TensorFlow.\nIf you have installed TensorFlow with pip, you should be able\nto launch TensorBoard from the command line:\ntensorboard --logdir=/full_path_to_your_logs\nYou can find more information about TensorBoard\nhere.\nArguments:\nlog_dir: the path of the directory where to save the log\nfiles to be parsed by TensorBoard.\nhistogram_freq: frequency (in epochs) at which to compute activation\nand weight histograms for the layers of the model. If set to 0,\nhistograms won't be computed. Validation data (or split) must be\nspecified for histogram visualizations.\nwrite_graph: whether to visualize the graph in TensorBoard.\nThe log file can become quite large when\nwrite_graph is set to True.\nwrite_grads: whether to visualize gradient histograms in TensorBoard.\nhistogram_freq must be greater than 0.\nbatch_size: size of batch of inputs to feed to the network\nfor histograms computation.\nwrite_images: whether to write model weights to visualize as\nimage in TensorBoard.\nembeddings_freq: frequency (in epochs) at which selected embedding\nlayers will be saved.\nembeddings_layer_names: a list of names of layers to keep eye on. If\nNone or empty list all the embedding layer will be watched.\nembeddings_metadata: a dictionary which maps layer name to a file name\nin which metadata for this embedding layer is saved. See the\ndetails\nabout metadata files format. In case if the same metadata file is\nused for all embedding layers, string can be passed.\n\"\"\"\npylint: enable=line-too-long\ndef init(self,\nlog_dir='./logs',\nhistogram_freq=0,\nbatch_size=32,\nwrite_graph=True,\nwrite_grads=False,\nwrite_images=False):\nsuper(TensorBoard, self).init()\n`", "body": "@ricardobarroslourenco got same error.\r\nTypeError: __init__() got an unexpected keyword argument 'embeddings_metadata'\r\n\r\n[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/callbacks.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/callbacks.py)\r\n\r\nComments of TensorBoard shows embeddings_metadata param,\r\nwhile the __init__ do not support.\r\n`\r\n@tf_export('keras.callbacks.TensorBoard')\r\nclass TensorBoard(Callback):\r\n  # pylint: disable=line-too-long\r\n  \"\"\"Tensorboard basic visualizations.\r\n  This callback writes a log for TensorBoard, which allows\r\n  you to visualize dynamic graphs of your training and test\r\n  metrics, as well as activation histograms for the different\r\n  layers in your model.\r\n  TensorBoard is a visualization tool provided with TensorFlow.\r\n  If you have installed TensorFlow with pip, you should be able\r\n  to launch TensorBoard from the command line:\r\n  ```sh\r\n  tensorboard --logdir=/full_path_to_your_logs\r\n  ```\r\n  You can find more information about TensorBoard\r\n  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\r\n  Arguments:\r\n      log_dir: the path of the directory where to save the log\r\n          files to be parsed by TensorBoard.\r\n      histogram_freq: frequency (in epochs) at which to compute activation\r\n          and weight histograms for the layers of the model. If set to 0,\r\n          histograms won't be computed. Validation data (or split) must be\r\n          specified for histogram visualizations.\r\n      write_graph: whether to visualize the graph in TensorBoard.\r\n          The log file can become quite large when\r\n          write_graph is set to True.\r\n      write_grads: whether to visualize gradient histograms in TensorBoard.\r\n          `histogram_freq` must be greater than 0.\r\n      batch_size: size of batch of inputs to feed to the network\r\n          for histograms computation.\r\n      write_images: whether to write model weights to visualize as\r\n          image in TensorBoard.\r\n      embeddings_freq: frequency (in epochs) at which selected embedding\r\n          layers will be saved.\r\n      embeddings_layer_names: a list of names of layers to keep eye on. If\r\n          None or empty list all the embedding layer will be watched.\r\n      embeddings_metadata: a dictionary which maps layer name to a file name\r\n          in which metadata for this embedding layer is saved. See the\r\n          [details](https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)\r\n          about metadata files format. In case if the same metadata file is\r\n          used for all embedding layers, string can be passed.\r\n  \"\"\"\r\n\r\n  # pylint: enable=line-too-long\r\n\r\n  def __init__(self,\r\n               log_dir='./logs',\r\n               histogram_freq=0,\r\n               batch_size=32,\r\n               write_graph=True,\r\n               write_grads=False,\r\n               write_images=False):\r\n    super(TensorBoard, self).__init__()\r\n`"}