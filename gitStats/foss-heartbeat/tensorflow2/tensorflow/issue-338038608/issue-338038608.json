{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20531", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20531/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20531/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20531/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20531", "id": 338038608, "node_id": "MDU6SXNzdWUzMzgwMzg2MDg=", "number": 20531, "title": "Problem with callbacks and LSTM : is failing", "user": {"login": "u650080", "id": 7254998, "node_id": "MDQ6VXNlcjcyNTQ5OTg=", "avatar_url": "https://avatars2.githubusercontent.com/u/7254998?v=4", "gravatar_id": "", "url": "https://api.github.com/users/u650080", "html_url": "https://github.com/u650080", "followers_url": "https://api.github.com/users/u650080/followers", "following_url": "https://api.github.com/users/u650080/following{/other_user}", "gists_url": "https://api.github.com/users/u650080/gists{/gist_id}", "starred_url": "https://api.github.com/users/u650080/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/u650080/subscriptions", "organizations_url": "https://api.github.com/users/u650080/orgs", "repos_url": "https://api.github.com/users/u650080/repos", "events_url": "https://api.github.com/users/u650080/events{/privacy}", "received_events_url": "https://api.github.com/users/u650080/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "reedwm", "id": 6510203, "node_id": "MDQ6VXNlcjY1MTAyMDM=", "avatar_url": "https://avatars2.githubusercontent.com/u/6510203?v=4", "gravatar_id": "", "url": "https://api.github.com/users/reedwm", "html_url": "https://github.com/reedwm", "followers_url": "https://api.github.com/users/reedwm/followers", "following_url": "https://api.github.com/users/reedwm/following{/other_user}", "gists_url": "https://api.github.com/users/reedwm/gists{/gist_id}", "starred_url": "https://api.github.com/users/reedwm/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/reedwm/subscriptions", "organizations_url": "https://api.github.com/users/reedwm/orgs", "repos_url": "https://api.github.com/users/reedwm/repos", "events_url": "https://api.github.com/users/reedwm/events{/privacy}", "received_events_url": "https://api.github.com/users/reedwm/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-07-03T20:10:47Z", "updated_at": "2018-08-08T17:41:42Z", "closed_at": "2018-08-08T17:41:42Z", "author_association": "NONE", "body_html": "<p>I try to use callbacks and it is failing with following example, if I use GRU with callbacks is ok but with LSTM is failing:</p>\n<p>This is system info :</p>\n<p>== cat /etc/issue ===============================================<br>\nLinux gpuMachine 4.13.0-45-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115996914\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/50\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/50/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/50\">#50</a>~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux<br>\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"<br>\nVERSION_ID=\"16.04\"<br>\nVERSION_CODENAME=xenial</p>\n<p>== are we in docker =============================================<br>\nNo</p>\n<p>== compiler =====================================================<br>\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609<br>\nCopyright (C) 2015 Free Software Foundation, Inc.<br>\nThis is free software; see the source for copying conditions.  There is NO<br>\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n<p>== uname -a =====================================================<br>\nLinux strategy.ca.alcatel-lucent.com 4.13.0-45-generic <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115996914\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/50\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/50/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/50\">#50</a>~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux</p>\n<p>== check pips ===================================================<br>\nnumpy                             1.14.5<br>\nprotobuf                          3.6.0<br>\ntensorflow                        1.8.0<br>\ntensorflow-gpu                    1.8.0</p>\n<p>== check for virtualenv =========================================<br>\nFalse</p>\n<p>== tensorflow import ============================================<br>\ntf.VERSION = 1.8.0<br>\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072<br>\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072<br>\nSanity check: array([1], dtype=int32)</p>\n<p>== env ==========================================================<br>\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64<br>\nDYLD_LIBRARY_PATH is unset</p>\n<p>== nvidia-smi ===================================================<br>\nTue Jul  3 16:05:54 2018<br>\n+-----------------------------------------------------------------------------+<br>\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |<br>\n|-------------------------------+----------------------+----------------------+<br>\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |<br>\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |<br>\n|===============================+======================+======================|<br>\n|   0  GeForce GTX 107...  Off  | 00000000:02:00.0  On |                  N/A |<br>\n|  0%   43C    P2    41W / 180W |   1141MiB /  8118MiB |      0%      Default |<br>\n+-------------------------------+----------------------+----------------------+</p>\n<p>+-----------------------------------------------------------------------------+<br>\n| Processes:                                                       GPU Memory |<br>\n|  GPU       PID   Type   Process name                             Usage      |<br>\n|=============================================================================|<br>\n|    0     28189      C   ...user1/.conda/envs/tensorflow/bin/python  1007MiB |<br>\n|    0     28294      G   /usr/lib/xorg/Xorg                           122MiB |<br>\n+-----------------------------------------------------------------------------+</p>\n<p>== cuda libs  ===================================================<br>\n/usr/local/cuda-9.0/lib64/libcudart_static.a<br>\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7<br>\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7</p>\n<p>with this example I have problem:</p>\n<pre><code>import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense\nfrom keras.callbacks import TensorBoard\nimport numpy as np\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.1\nsession = tf.Session(config=config)\npath_checkpoint = 'test.keras'\nSEQUENCES = 5\nTIME_STEPS = 10\n\nmodel = Sequential()\nmodel.add(Embedding(100, 4))\nmodel.add(LSTM(32))\nmodel.add(Dense(1))\nmodel.compile(optimizer='rmsprop', loss='mse')\n\ntensor_board = TensorBoard(log_dir='log', batch_size=2, write_graph=False,\nwrite_grads=True, histogram_freq=4)\ncallback_early_stopping = EarlyStopping(monitor='val_loss',\npatience=2, verbose=2)\ncallback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\nmonitor='val_loss',\nverbose=2,\nsave_weights_only=True,\nsave_best_only=True)\ncallback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\nfactor=0.1,\nmin_lr=1e-4,\npatience=0,\nverbose=2)\nx_train = np.random.randint(100, size=(SEQUENCES, TIME_STEPS), dtype='int8')\n\ny_train = np.random.rand(SEQUENCES)\n\nmodel.fit(x_train, y_train, batch_size=2, epochs=4, shuffle=True, callbacks=[callback_reduce_lr,tensor_board,callback_early_stopping,callback_checkpoint])\n</code></pre>\n<p>and I got this <g-emoji class=\"g-emoji\" alias=\"+1\" fallback-src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f44d.png\">\ud83d\udc4d</g-emoji><br>\nError +1<br>\nEpoch 1/4</p>\n<p>FailedPreconditionError Traceback (most recent call last)<br>\nin ()<br>\n36 y_train = np.random.rand(SEQUENCES)<br>\n37<br>\n---&gt; 38 model.fit(x_train, y_train, batch_size=2, epochs=4, shuffle=True, callbacks=[callback_reduce_lr,tensor_board,callback_early_stopping,callback_checkpoint])</p>\n<p>~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)<br>\n1040 initial_epoch=initial_epoch,<br>\n1041 steps_per_epoch=steps_per_epoch,<br>\n-&gt; 1042 validation_steps=validation_steps)<br>\n1043<br>\n1044 def evaluate(self, x=None, y=None,</p>\n<p>~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)<br>\n197 ins_batch[i] = ins_batch[i].toarray()<br>\n198<br>\n--&gt; 199 outs = f(ins_batch)<br>\n200 if not isinstance(outs, list):<br>\n201 outs = [outs]</p>\n<p>~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in call(self, inputs)<br>\n2659 return self._legacy_call(inputs)<br>\n2660<br>\n-&gt; 2661 return self._call(inputs)<br>\n2662 else:<br>\n2663 if py_any(is_tensor(x) for x in inputs):</p>\n<p>~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in _call(self, inputs)<br>\n2629 symbol_vals,<br>\n2630 session)<br>\n-&gt; 2631 fetched = self._callable_fn(*array_vals)<br>\n2632 return fetched[:len(self.outputs)]<br>\n2633</p>\n<p>~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py in call(self, *args)<br>\n1452 else:<br>\n1453 return tf_session.TF_DeprecatedSessionRunCallable(<br>\n-&gt; 1454 self._session._session, self._handle, args, status, None)<br>\n1455<br>\n1456 def del(self):</p>\n<p>~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in exit(self, type_arg, value_arg, traceback_arg)<br>\n517 None, None,<br>\n518 compat.as_text(c_api.TF_Message(self.status.status)),<br>\n--&gt; 519 c_api.TF_GetCode(self.status.status))<br>\n520 # Delete the underlying status object from memory otherwise it stays alive<br>\n521 # as there is a reference to status from this from the traceback due to</p>\n<p>FailedPreconditionError: Attempting to use uninitialized value RMSprop_16/lr<br>\n[[Node: RMSprop_16/lr/read = IdentityT=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]<br>\n[[Node: loss_16/mul/_621 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1571_loss_16/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]</p>", "body_text": "I try to use callbacks and it is failing with following example, if I use GRU with callbacks is ok but with LSTM is failing:\nThis is system info :\n== cat /etc/issue ===============================================\nLinux gpuMachine 4.13.0-45-generic #50~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n== are we in docker =============================================\nNo\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n== uname -a =====================================================\nLinux strategy.ca.alcatel-lucent.com 4.13.0-45-generic #50~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n== check pips ===================================================\nnumpy                             1.14.5\nprotobuf                          3.6.0\ntensorflow                        1.8.0\ntensorflow-gpu                    1.8.0\n== check for virtualenv =========================================\nFalse\n== tensorflow import ============================================\ntf.VERSION = 1.8.0\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\nSanity check: array([1], dtype=int32)\n== env ==========================================================\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64\nDYLD_LIBRARY_PATH is unset\n== nvidia-smi ===================================================\nTue Jul  3 16:05:54 2018\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 107...  Off  | 00000000:02:00.0  On |                  N/A |\n|  0%   43C    P2    41W / 180W |   1141MiB /  8118MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0     28189      C   ...user1/.conda/envs/tensorflow/bin/python  1007MiB |\n|    0     28294      G   /usr/lib/xorg/Xorg                           122MiB |\n+-----------------------------------------------------------------------------+\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/lib64/libcudart_static.a\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\nwith this example I have problem:\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense\nfrom keras.callbacks import TensorBoard\nimport numpy as np\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nconfig = tf.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.1\nsession = tf.Session(config=config)\npath_checkpoint = 'test.keras'\nSEQUENCES = 5\nTIME_STEPS = 10\n\nmodel = Sequential()\nmodel.add(Embedding(100, 4))\nmodel.add(LSTM(32))\nmodel.add(Dense(1))\nmodel.compile(optimizer='rmsprop', loss='mse')\n\ntensor_board = TensorBoard(log_dir='log', batch_size=2, write_graph=False,\nwrite_grads=True, histogram_freq=4)\ncallback_early_stopping = EarlyStopping(monitor='val_loss',\npatience=2, verbose=2)\ncallback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\nmonitor='val_loss',\nverbose=2,\nsave_weights_only=True,\nsave_best_only=True)\ncallback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\nfactor=0.1,\nmin_lr=1e-4,\npatience=0,\nverbose=2)\nx_train = np.random.randint(100, size=(SEQUENCES, TIME_STEPS), dtype='int8')\n\ny_train = np.random.rand(SEQUENCES)\n\nmodel.fit(x_train, y_train, batch_size=2, epochs=4, shuffle=True, callbacks=[callback_reduce_lr,tensor_board,callback_early_stopping,callback_checkpoint])\n\nand I got this \ud83d\udc4d\nError +1\nEpoch 1/4\nFailedPreconditionError Traceback (most recent call last)\nin ()\n36 y_train = np.random.rand(SEQUENCES)\n37\n---> 38 model.fit(x_train, y_train, batch_size=2, epochs=4, shuffle=True, callbacks=[callback_reduce_lr,tensor_board,callback_early_stopping,callback_checkpoint])\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n1040 initial_epoch=initial_epoch,\n1041 steps_per_epoch=steps_per_epoch,\n-> 1042 validation_steps=validation_steps)\n1043\n1044 def evaluate(self, x=None, y=None,\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n197 ins_batch[i] = ins_batch[i].toarray()\n198\n--> 199 outs = f(ins_batch)\n200 if not isinstance(outs, list):\n201 outs = [outs]\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in call(self, inputs)\n2659 return self._legacy_call(inputs)\n2660\n-> 2661 return self._call(inputs)\n2662 else:\n2663 if py_any(is_tensor(x) for x in inputs):\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in _call(self, inputs)\n2629 symbol_vals,\n2630 session)\n-> 2631 fetched = self._callable_fn(*array_vals)\n2632 return fetched[:len(self.outputs)]\n2633\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py in call(self, *args)\n1452 else:\n1453 return tf_session.TF_DeprecatedSessionRunCallable(\n-> 1454 self._session._session, self._handle, args, status, None)\n1455\n1456 def del(self):\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in exit(self, type_arg, value_arg, traceback_arg)\n517 None, None,\n518 compat.as_text(c_api.TF_Message(self.status.status)),\n--> 519 c_api.TF_GetCode(self.status.status))\n520 # Delete the underlying status object from memory otherwise it stays alive\n521 # as there is a reference to status from this from the traceback due to\nFailedPreconditionError: Attempting to use uninitialized value RMSprop_16/lr\n[[Node: RMSprop_16/lr/read = IdentityT=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\n[[Node: loss_16/mul/_621 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1571_loss_16/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]", "body": "I try to use callbacks and it is failing with following example, if I use GRU with callbacks is ok but with LSTM is failing:\r\n\r\n\r\nThis is system info :\r\n\r\n== cat /etc/issue ===============================================\r\nLinux gpuMachine 4.13.0-45-generic #50~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux strategy.ca.alcatel-lucent.com 4.13.0-45-generic #50~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                             1.14.5   \r\nprotobuf                          3.6.0    \r\ntensorflow                        1.8.0    \r\ntensorflow-gpu                    1.8.0    \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda-9.0/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nTue Jul  3 16:05:54 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 107...  Off  | 00000000:02:00.0  On |                  N/A |\r\n|  0%   43C    P2    41W / 180W |   1141MiB /  8118MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     28189      C   ...user1/.conda/envs/tensorflow/bin/python  1007MiB |\r\n|    0     28294      G   /usr/lib/xorg/Xorg                           122MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n\r\n\r\n\r\nwith this example I have problem:\r\n```\r\nimport tensorflow as tf\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Embedding, LSTM, Dense\r\nfrom keras.callbacks import TensorBoard\r\nimport numpy as np\r\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.1\r\nsession = tf.Session(config=config)\r\npath_checkpoint = 'test.keras'\r\nSEQUENCES = 5\r\nTIME_STEPS = 10\r\n\r\nmodel = Sequential()\r\nmodel.add(Embedding(100, 4))\r\nmodel.add(LSTM(32))\r\nmodel.add(Dense(1))\r\nmodel.compile(optimizer='rmsprop', loss='mse')\r\n\r\ntensor_board = TensorBoard(log_dir='log', batch_size=2, write_graph=False,\r\nwrite_grads=True, histogram_freq=4)\r\ncallback_early_stopping = EarlyStopping(monitor='val_loss',\r\npatience=2, verbose=2)\r\ncallback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\r\nmonitor='val_loss',\r\nverbose=2,\r\nsave_weights_only=True,\r\nsave_best_only=True)\r\ncallback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\r\nfactor=0.1,\r\nmin_lr=1e-4,\r\npatience=0,\r\nverbose=2)\r\nx_train = np.random.randint(100, size=(SEQUENCES, TIME_STEPS), dtype='int8')\r\n\r\ny_train = np.random.rand(SEQUENCES)\r\n\r\nmodel.fit(x_train, y_train, batch_size=2, epochs=4, shuffle=True, callbacks=[callback_reduce_lr,tensor_board,callback_early_stopping,callback_checkpoint])\r\n```\r\nand I got this :+1: \r\nError +1\r\nEpoch 1/4\r\n\r\nFailedPreconditionError Traceback (most recent call last)\r\nin ()\r\n36 y_train = np.random.rand(SEQUENCES)\r\n37\r\n---> 38 model.fit(x_train, y_train, batch_size=2, epochs=4, shuffle=True, callbacks=[callback_reduce_lr,tensor_board,callback_early_stopping,callback_checkpoint])\r\n\r\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n1040 initial_epoch=initial_epoch,\r\n1041 steps_per_epoch=steps_per_epoch,\r\n-> 1042 validation_steps=validation_steps)\r\n1043\r\n1044 def evaluate(self, x=None, y=None,\r\n\r\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\r\n197 ins_batch[i] = ins_batch[i].toarray()\r\n198\r\n--> 199 outs = f(ins_batch)\r\n200 if not isinstance(outs, list):\r\n201 outs = [outs]\r\n\r\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in call(self, inputs)\r\n2659 return self._legacy_call(inputs)\r\n2660\r\n-> 2661 return self._call(inputs)\r\n2662 else:\r\n2663 if py_any(is_tensor(x) for x in inputs):\r\n\r\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in _call(self, inputs)\r\n2629 symbol_vals,\r\n2630 session)\r\n-> 2631 fetched = self._callable_fn(*array_vals)\r\n2632 return fetched[:len(self.outputs)]\r\n2633\r\n\r\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py in call(self, *args)\r\n1452 else:\r\n1453 return tf_session.TF_DeprecatedSessionRunCallable(\r\n-> 1454 self._session._session, self._handle, args, status, None)\r\n1455\r\n1456 def del(self):\r\n\r\n~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in exit(self, type_arg, value_arg, traceback_arg)\r\n517 None, None,\r\n518 compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 519 c_api.TF_GetCode(self.status.status))\r\n520 # Delete the underlying status object from memory otherwise it stays alive\r\n521 # as there is a reference to status from this from the traceback due to\r\n\r\nFailedPreconditionError: Attempting to use uninitialized value RMSprop_16/lr\r\n[[Node: RMSprop_16/lr/read = IdentityT=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\r\n[[Node: loss_16/mul/_621 = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1571_loss_16/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\r\n"}