{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313459947", "html_url": "https://github.com/tensorflow/tensorflow/issues/2938#issuecomment-313459947", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2938", "id": 313459947, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzQ1OTk0Nw==", "user": {"login": "jwbono", "id": 3497097, "node_id": "MDQ6VXNlcjM0OTcwOTc=", "avatar_url": "https://avatars2.githubusercontent.com/u/3497097?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jwbono", "html_url": "https://github.com/jwbono", "followers_url": "https://api.github.com/users/jwbono/followers", "following_url": "https://api.github.com/users/jwbono/following{/other_user}", "gists_url": "https://api.github.com/users/jwbono/gists{/gist_id}", "starred_url": "https://api.github.com/users/jwbono/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jwbono/subscriptions", "organizations_url": "https://api.github.com/users/jwbono/orgs", "repos_url": "https://api.github.com/users/jwbono/repos", "events_url": "https://api.github.com/users/jwbono/events{/privacy}", "received_events_url": "https://api.github.com/users/jwbono/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-06T17:12:05Z", "updated_at": "2017-07-06T17:12:05Z", "author_association": "NONE", "body_html": "<p>I'm working with TF v1.2.0.  I have the original issue, where in reshaping the input for tf.nn.dynamic_rnn(), I can set the final dimension with an integer, but the first two must be placeholders. If I reshape with this mixture of tf.placeholders() and Python integers, I don't get the auto-packing:</p>\n<pre><code>tf.reshape(slim.flatten(inputMat),shape=[batch_size,trainLength,h_size]) \n\nValueError: Tried to convert 'shape' to a tensor and failed. Error: Shapes must be equal rank, but are 1 and 0\n\tFrom merging shape 1 with other shapes. for 'Reshape_6/packed' (op: 'Pack') with input shapes: [1], [1], [].\n</code></pre>\n<p>I tried converting the final dimension to a tf.constant() and using tf.stack() to get a shape tensor, but that produced the original error in this thread about shape inference. Here's the code using tf.stack():</p>\n<pre><code>n_inputs = 4\nh_size = 10\n\nrnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\n\nh_size_T = tf.constant(h_size,dtype=tf.int32,shape=[1])\nbatch_size = tf.placeholder(shape=[1],dtype=tf.int32)\ntrainLength = tf.placeholder(shape=[1],dtype=tf.int32)\n\nrawInput = tf.placeholder(shape=[None,n_inputs],\\\n        \t\t\t\t\t\t\t\t dtype=tf.float32)\ninputW = tf.Variable(tf.random_normal([n_inputs,h_size]))\ninputMat = tf.matmul(rawInput,inputW)\n\nshape_input = tf.reshape(tf.stack([batch_size,trainLength,h_size_T]),shape=[3])\ninputFlat = tf.reshape(slim.flatten(inputMat),shape=shape_input)\n\nstate_in = np.zeros([1,h_size])\nrnn,rnn_state = tf.nn.dynamic_rnn(inputs=inputFlat,cell=rnn_cell,\\\n                                  dtype=tf.float32,initial_state=state_in,\\\n                                  scope='main_rnn')\n\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\n</code></pre>\n<p>Any help would be really great. Thanks!</p>", "body_text": "I'm working with TF v1.2.0.  I have the original issue, where in reshaping the input for tf.nn.dynamic_rnn(), I can set the final dimension with an integer, but the first two must be placeholders. If I reshape with this mixture of tf.placeholders() and Python integers, I don't get the auto-packing:\ntf.reshape(slim.flatten(inputMat),shape=[batch_size,trainLength,h_size]) \n\nValueError: Tried to convert 'shape' to a tensor and failed. Error: Shapes must be equal rank, but are 1 and 0\n\tFrom merging shape 1 with other shapes. for 'Reshape_6/packed' (op: 'Pack') with input shapes: [1], [1], [].\n\nI tried converting the final dimension to a tf.constant() and using tf.stack() to get a shape tensor, but that produced the original error in this thread about shape inference. Here's the code using tf.stack():\nn_inputs = 4\nh_size = 10\n\nrnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\n\nh_size_T = tf.constant(h_size,dtype=tf.int32,shape=[1])\nbatch_size = tf.placeholder(shape=[1],dtype=tf.int32)\ntrainLength = tf.placeholder(shape=[1],dtype=tf.int32)\n\nrawInput = tf.placeholder(shape=[None,n_inputs],\\\n        \t\t\t\t\t\t\t\t dtype=tf.float32)\ninputW = tf.Variable(tf.random_normal([n_inputs,h_size]))\ninputMat = tf.matmul(rawInput,inputW)\n\nshape_input = tf.reshape(tf.stack([batch_size,trainLength,h_size_T]),shape=[3])\ninputFlat = tf.reshape(slim.flatten(inputMat),shape=shape_input)\n\nstate_in = np.zeros([1,h_size])\nrnn,rnn_state = tf.nn.dynamic_rnn(inputs=inputFlat,cell=rnn_cell,\\\n                                  dtype=tf.float32,initial_state=state_in,\\\n                                  scope='main_rnn')\n\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\n\nAny help would be really great. Thanks!", "body": "I'm working with TF v1.2.0.  I have the original issue, where in reshaping the input for tf.nn.dynamic_rnn(), I can set the final dimension with an integer, but the first two must be placeholders. If I reshape with this mixture of tf.placeholders() and Python integers, I don't get the auto-packing: \r\n\r\n```\r\ntf.reshape(slim.flatten(inputMat),shape=[batch_size,trainLength,h_size]) \r\n\r\nValueError: Tried to convert 'shape' to a tensor and failed. Error: Shapes must be equal rank, but are 1 and 0\r\n\tFrom merging shape 1 with other shapes. for 'Reshape_6/packed' (op: 'Pack') with input shapes: [1], [1], [].\r\n```\r\n\r\nI tried converting the final dimension to a tf.constant() and using tf.stack() to get a shape tensor, but that produced the original error in this thread about shape inference. Here's the code using tf.stack():\r\n\r\n```\r\nn_inputs = 4\r\nh_size = 10\r\n\r\nrnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=h_size,state_is_tuple=True)\r\n\r\nh_size_T = tf.constant(h_size,dtype=tf.int32,shape=[1])\r\nbatch_size = tf.placeholder(shape=[1],dtype=tf.int32)\r\ntrainLength = tf.placeholder(shape=[1],dtype=tf.int32)\r\n\r\nrawInput = tf.placeholder(shape=[None,n_inputs],\\\r\n        \t\t\t\t\t\t\t\t dtype=tf.float32)\r\ninputW = tf.Variable(tf.random_normal([n_inputs,h_size]))\r\ninputMat = tf.matmul(rawInput,inputW)\r\n\r\nshape_input = tf.reshape(tf.stack([batch_size,trainLength,h_size_T]),shape=[3])\r\ninputFlat = tf.reshape(slim.flatten(inputMat),shape=shape_input)\r\n\r\nstate_in = np.zeros([1,h_size])\r\nrnn,rnn_state = tf.nn.dynamic_rnn(inputs=inputFlat,cell=rnn_cell,\\\r\n                                  dtype=tf.float32,initial_state=state_in,\\\r\n                                  scope='main_rnn')\r\n\r\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.\r\n```\r\nAny help would be really great. Thanks!"}