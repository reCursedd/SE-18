{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/313463558", "html_url": "https://github.com/tensorflow/tensorflow/issues/2938#issuecomment-313463558", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2938", "id": 313463558, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMzQ2MzU1OA==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-06T17:25:49Z", "updated_at": "2017-07-06T17:25:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p>(Please use Stack Overflow for questions like this in future!)</p>\n<p>The problem stems from these definitions:</p>\n<div class=\"highlight highlight-source-python\"><pre>batch_size <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>],<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\ntrainLength <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>],<span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)</pre></div>\n<p>For some reason, the <code>batch_size</code> and <code>trainLength</code> are defined as length-1 vectors, rather than scalars. <code>h_size</code> is a scalar. Auto-packing only works if all of the elements are the same shape. I'd recommend redefining <code>batch_size</code> and <code>trainLength</code> as scalars:</p>\n<div class=\"highlight highlight-source-python\"><pre>batch_size <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)\ntrainLength <span class=\"pl-k\">=</span> tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32)</pre></div>\n<p>...though this will probably have knock-on effects in the rest of your code. Alternatively, you could change the failing statement as follows:</p>\n<div class=\"highlight highlight-source-python\"><pre>tf.reshape(slim.flatten(inputMat), <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[batch_size[<span class=\"pl-c1\">0</span>], trainLength[<span class=\"pl-c1\">0</span>], h_size]) </pre></div>\n<p>...which might cause less trouble in the rest of your program, but it wouldn't pass code review if I were the reviewer :).</p>", "body_text": "(Please use Stack Overflow for questions like this in future!)\nThe problem stems from these definitions:\nbatch_size = tf.placeholder(shape=[1],dtype=tf.int32)\ntrainLength = tf.placeholder(shape=[1],dtype=tf.int32)\nFor some reason, the batch_size and trainLength are defined as length-1 vectors, rather than scalars. h_size is a scalar. Auto-packing only works if all of the elements are the same shape. I'd recommend redefining batch_size and trainLength as scalars:\nbatch_size = tf.placeholder(shape=[], dtype=tf.int32)\ntrainLength = tf.placeholder(shape=[], dtype=tf.int32)\n...though this will probably have knock-on effects in the rest of your code. Alternatively, you could change the failing statement as follows:\ntf.reshape(slim.flatten(inputMat), shape=[batch_size[0], trainLength[0], h_size]) \n...which might cause less trouble in the rest of your program, but it wouldn't pass code review if I were the reviewer :).", "body": "(Please use Stack Overflow for questions like this in future!)\r\n\r\nThe problem stems from these definitions:\r\n\r\n```python\r\nbatch_size = tf.placeholder(shape=[1],dtype=tf.int32)\r\ntrainLength = tf.placeholder(shape=[1],dtype=tf.int32)\r\n```\r\n\r\nFor some reason, the `batch_size` and `trainLength` are defined as length-1 vectors, rather than scalars. `h_size` is a scalar. Auto-packing only works if all of the elements are the same shape. I'd recommend redefining `batch_size` and `trainLength` as scalars:\r\n\r\n```python\r\nbatch_size = tf.placeholder(shape=[], dtype=tf.int32)\r\ntrainLength = tf.placeholder(shape=[], dtype=tf.int32)\r\n```\r\n\r\n...though this will probably have knock-on effects in the rest of your code. Alternatively, you could change the failing statement as follows:\r\n\r\n```python\r\ntf.reshape(slim.flatten(inputMat), shape=[batch_size[0], trainLength[0], h_size]) \r\n```\r\n\r\n...which might cause less trouble in the rest of your program, but it wouldn't pass code review if I were the reviewer :)."}