{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22176", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22176/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22176/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22176/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22176", "id": 358412680, "node_id": "MDU6SXNzdWUzNTg0MTI2ODA=", "number": 22176, "title": "seq2seq.dynamic_decode with float16 inputs on CPU", "user": {"login": "georgesterpu", "id": 6018251, "node_id": "MDQ6VXNlcjYwMTgyNTE=", "avatar_url": "https://avatars0.githubusercontent.com/u/6018251?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgesterpu", "html_url": "https://github.com/georgesterpu", "followers_url": "https://api.github.com/users/georgesterpu/followers", "following_url": "https://api.github.com/users/georgesterpu/following{/other_user}", "gists_url": "https://api.github.com/users/georgesterpu/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgesterpu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgesterpu/subscriptions", "organizations_url": "https://api.github.com/users/georgesterpu/orgs", "repos_url": "https://api.github.com/users/georgesterpu/repos", "events_url": "https://api.github.com/users/georgesterpu/events{/privacy}", "received_events_url": "https://api.github.com/users/georgesterpu/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-09-09T21:11:08Z", "updated_at": "2018-11-09T18:53:39Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Manjaro Linux, testing</li>\n<li><strong>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device</strong>: nice</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.10.1</li>\n<li><strong>Python version</strong>: 3.7.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.16.1</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 7.3.1</li>\n<li><strong>CUDA/cuDNN version</strong>: cuda 9.2.148, cudnn 7.2.1</li>\n<li><strong>GPU model and memory</strong>: gtx 1080</li>\n<li><strong>Exact command to reproduce</strong>:<br>\nI am using my own setup here:<br>\n<a href=\"https://github.com/georgesterpu/Sigmedia-AVSR/blob/master/experiment_tcd_audio.py\">https://github.com/georgesterpu/Sigmedia-AVSR/blob/master/experiment_tcd_audio.py</a><br>\nIf really needed, I could write a minimal example to reproduce the issue.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I have an issue with the code indicated above, when switching to 16 bit precision.<br>\nOn the CPU only, the code crashes with the following error:</p>\n<pre><code>InvalidArgumentError (see above for traceback): indices[0] = 31 is not in [0, 31)\n\t [[Node: Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/Switch, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/GatherNd, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/axis)]]\n</code></pre>\n<p>This is supposed to be the embedding lookup of the input ids to a <code>seq2seq.BasicDecoder</code> taking a <code>seq2seq.ScheduledEmbeddingTrainingHelper</code>. I first created the embedding matrix in float16, then passed it to the <code>embedding</code> argument. As a workaround, I've also created it in float32, passing instead a callable that would cast the retrieved vectors to float16, but the error persists.</p>\n<p>The number <code>31</code> is the size of the vocabulary, and no id is above 30. However, even if I increase the size of the embedding matrix, the error would look like this:<br>\n<code>indices[0] = 132 is not in [0, 132)</code></p>\n<p>The same code runs fine on GPU, but I am aware that error reporting is restricted in this case.</p>\n<p>Could you please help me find out where is the problem and how to fix it ?<br>\nIs <code>seq2seq.dynamic_decode</code> fully supporting float16 data types ?</p>\n<p>Thank you</p>\n<h3>Source code / logs</h3>\n<pre><code>  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 322, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 265, in body\n    decoder_finished) = decoder.step(time, inputs, state)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py\", line 146, in step\n    sample_ids=sample_ids)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py\", line 351, in next_inputs\n    all_finished, lambda: base_next_inputs, maybe_sample)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2057, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py\", line 340, in maybe_sample\n    sampled_next_inputs = self._embedding_fn(sample_ids_sampling)\n  File \"/run/media/john_tukey/work/phd/65.cleanavsr/Sigmedia-AVSR/avsr/decoder_unimodal.py\", line 454, in &lt;lambda&gt;\n    embedding_fun = lambda ids: tf.cast(tf.nn.embedding_lookup(self._embedding_matrix, ids), dtype=self._hparams.dtype)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 310, in embedding_lookup\n    transform_fn=None)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2659, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3142, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[0] = 31 is not in [0, 31)\n\t [[Node: Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/Switch, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/GatherNd, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/axis)]]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro Linux, testing\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: nice\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.10.1\nPython version: 3.7.0\nBazel version (if compiling from source): 0.16.1\nGCC/Compiler version (if compiling from source): 7.3.1\nCUDA/cuDNN version: cuda 9.2.148, cudnn 7.2.1\nGPU model and memory: gtx 1080\nExact command to reproduce:\nI am using my own setup here:\nhttps://github.com/georgesterpu/Sigmedia-AVSR/blob/master/experiment_tcd_audio.py\nIf really needed, I could write a minimal example to reproduce the issue.\n\nDescribe the problem\nI have an issue with the code indicated above, when switching to 16 bit precision.\nOn the CPU only, the code crashes with the following error:\nInvalidArgumentError (see above for traceback): indices[0] = 31 is not in [0, 31)\n\t [[Node: Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/Switch, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/GatherNd, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/axis)]]\n\nThis is supposed to be the embedding lookup of the input ids to a seq2seq.BasicDecoder taking a seq2seq.ScheduledEmbeddingTrainingHelper. I first created the embedding matrix in float16, then passed it to the embedding argument. As a workaround, I've also created it in float32, passing instead a callable that would cast the retrieved vectors to float16, but the error persists.\nThe number 31 is the size of the vocabulary, and no id is above 30. However, even if I increase the size of the embedding matrix, the error would look like this:\nindices[0] = 132 is not in [0, 132)\nThe same code runs fine on GPU, but I am aware that error reporting is restricted in this case.\nCould you please help me find out where is the problem and how to fix it ?\nIs seq2seq.dynamic_decode fully supporting float16 data types ?\nThank you\nSource code / logs\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 322, in dynamic_decode\n    swap_memory=swap_memory)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 265, in body\n    decoder_finished) = decoder.step(time, inputs, state)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py\", line 146, in step\n    sample_ids=sample_ids)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py\", line 351, in next_inputs\n    all_finished, lambda: base_next_inputs, maybe_sample)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2057, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py\", line 340, in maybe_sample\n    sampled_next_inputs = self._embedding_fn(sample_ids_sampling)\n  File \"/run/media/john_tukey/work/phd/65.cleanavsr/Sigmedia-AVSR/avsr/decoder_unimodal.py\", line 454, in <lambda>\n    embedding_fun = lambda ids: tf.cast(tf.nn.embedding_lookup(self._embedding_matrix, ids), dtype=self._hparams.dtype)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 310, in embedding_lookup\n    transform_fn=None)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2659, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3142, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[0] = 31 is not in [0, 31)\n\t [[Node: Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/Switch, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/GatherNd, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/axis)]]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Manjaro Linux, testing\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: nice\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.7.0\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.3.1\r\n- **CUDA/cuDNN version**: cuda 9.2.148, cudnn 7.2.1\r\n- **GPU model and memory**: gtx 1080\r\n- **Exact command to reproduce**:\r\nI am using my own setup here:\r\nhttps://github.com/georgesterpu/Sigmedia-AVSR/blob/master/experiment_tcd_audio.py\r\nIf really needed, I could write a minimal example to reproduce the issue.\r\n\r\n### Describe the problem\r\nI have an issue with the code indicated above, when switching to 16 bit precision.\r\nOn the CPU only, the code crashes with the following error:\r\n\r\n```\r\nInvalidArgumentError (see above for traceback): indices[0] = 31 is not in [0, 31)\r\n\t [[Node: Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/Switch, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/GatherNd, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/axis)]]\r\n``` \r\nThis is supposed to be the embedding lookup of the input ids to a `seq2seq.BasicDecoder` taking a `seq2seq.ScheduledEmbeddingTrainingHelper`. I first created the embedding matrix in float16, then passed it to the `embedding` argument. As a workaround, I've also created it in float32, passing instead a callable that would cast the retrieved vectors to float16, but the error persists.\r\n\r\nThe number `31` is the size of the vocabulary, and no id is above 30. However, even if I increase the size of the embedding matrix, the error would look like this:\r\n`indices[0] = 132 is not in [0, 132)`\r\n\r\nThe same code runs fine on GPU, but I am aware that error reporting is restricted in this case. \r\n\r\nCould you please help me find out where is the problem and how to fix it ?\r\nIs `seq2seq.dynamic_decode` fully supporting float16 data types ?\r\n\r\nThank you\r\n\r\n\r\n### Source code / logs\r\n```\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 322, in dynamic_decode\r\n    swap_memory=swap_memory)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\r\n    return_same_structure)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 265, in body\r\n    decoder_finished) = decoder.step(time, inputs, state)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py\", line 146, in step\r\n    sample_ids=sample_ids)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py\", line 351, in next_inputs\r\n    all_finished, lambda: base_next_inputs, maybe_sample)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2057, in cond\r\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\r\n    original_result = fn()\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/contrib/seq2seq/python/ops/helper.py\", line 340, in maybe_sample\r\n    sampled_next_inputs = self._embedding_fn(sample_ids_sampling)\r\n  File \"/run/media/john_tukey/work/phd/65.cleanavsr/Sigmedia-AVSR/avsr/decoder_unimodal.py\", line 454, in <lambda>\r\n    embedding_fun = lambda ids: tf.cast(tf.nn.embedding_lookup(self._embedding_matrix, ids), dtype=self._hparams.dtype)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 310, in embedding_lookup\r\n    transform_fn=None)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\r\n    result = _clip(array_ops.gather(params[0], ids, name=name),\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2659, in gather\r\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3142, in gather_v2\r\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): indices[0] = 31 is not in [0, 31)\r\n\t [[Node: Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/Switch, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/GatherNd, Decoder/decoder/while/BasicDecoderStep/ScheduledEmbeddingTrainingHelperNextInputs/cond/embedding_lookup/axis)]]\r\n```\r\n"}