{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/312872943", "html_url": "https://github.com/tensorflow/tensorflow/issues/11248#issuecomment-312872943", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11248", "id": 312872943, "node_id": "MDEyOklzc3VlQ29tbWVudDMxMjg3Mjk0Mw==", "user": {"login": "azadef", "id": 8112587, "node_id": "MDQ6VXNlcjgxMTI1ODc=", "avatar_url": "https://avatars0.githubusercontent.com/u/8112587?v=4", "gravatar_id": "", "url": "https://api.github.com/users/azadef", "html_url": "https://github.com/azadef", "followers_url": "https://api.github.com/users/azadef/followers", "following_url": "https://api.github.com/users/azadef/following{/other_user}", "gists_url": "https://api.github.com/users/azadef/gists{/gist_id}", "starred_url": "https://api.github.com/users/azadef/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/azadef/subscriptions", "organizations_url": "https://api.github.com/users/azadef/orgs", "repos_url": "https://api.github.com/users/azadef/repos", "events_url": "https://api.github.com/users/azadef/events{/privacy}", "received_events_url": "https://api.github.com/users/azadef/received_events", "type": "User", "site_admin": false}, "created_at": "2017-07-04T13:04:27Z", "updated_at": "2017-07-04T13:04:27Z", "author_association": "NONE", "body_html": "<p>The problem is solved, I used export_inference_graph from object_detection using this command:</p>\n<p><code>python export_inference_graph \\ --input_type image_tensor \\ --pipeline_config_path path/to/ssd_mobilenets_coco.config \\ --checkpoint_path path/to/model-ckpt \\ --inference_graph_path path/to/inference_graph.pb</code></p>\n<p>I had to make a new config file for coco, I used ssd_mobilenets_pets and changed the num_classes to 90 as in coco and it exported the frozen graph without any error.</p>", "body_text": "The problem is solved, I used export_inference_graph from object_detection using this command:\npython export_inference_graph \\ --input_type image_tensor \\ --pipeline_config_path path/to/ssd_mobilenets_coco.config \\ --checkpoint_path path/to/model-ckpt \\ --inference_graph_path path/to/inference_graph.pb\nI had to make a new config file for coco, I used ssd_mobilenets_pets and changed the num_classes to 90 as in coco and it exported the frozen graph without any error.", "body": "The problem is solved, I used export_inference_graph from object_detection using this command:\r\n\r\n`python export_inference_graph \\\r\n    --input_type image_tensor \\\r\n    --pipeline_config_path path/to/ssd_mobilenets_coco.config \\\r\n    --checkpoint_path path/to/model-ckpt \\\r\n    --inference_graph_path path/to/inference_graph.pb`\r\n\r\nI had to make a new config file for coco, I used ssd_mobilenets_pets and changed the num_classes to 90 as in coco and it exported the frozen graph without any error."}