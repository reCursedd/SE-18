{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18519", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18519/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18519/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18519/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18519", "id": 314344514, "node_id": "MDU6SXNzdWUzMTQzNDQ1MTQ=", "number": 18519, "title": "Tensorflow profiler problem, maybe bug.", "user": {"login": "wswin3k", "id": 12010716, "node_id": "MDQ6VXNlcjEyMDEwNzE2", "avatar_url": "https://avatars2.githubusercontent.com/u/12010716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/wswin3k", "html_url": "https://github.com/wswin3k", "followers_url": "https://api.github.com/users/wswin3k/followers", "following_url": "https://api.github.com/users/wswin3k/following{/other_user}", "gists_url": "https://api.github.com/users/wswin3k/gists{/gist_id}", "starred_url": "https://api.github.com/users/wswin3k/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/wswin3k/subscriptions", "organizations_url": "https://api.github.com/users/wswin3k/orgs", "repos_url": "https://api.github.com/users/wswin3k/repos", "events_url": "https://api.github.com/users/wswin3k/events{/privacy}", "received_events_url": "https://api.github.com/users/wswin3k/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "zhangyaobit", "id": 1034716, "node_id": "MDQ6VXNlcjEwMzQ3MTY=", "avatar_url": "https://avatars3.githubusercontent.com/u/1034716?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangyaobit", "html_url": "https://github.com/zhangyaobit", "followers_url": "https://api.github.com/users/zhangyaobit/followers", "following_url": "https://api.github.com/users/zhangyaobit/following{/other_user}", "gists_url": "https://api.github.com/users/zhangyaobit/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangyaobit/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangyaobit/subscriptions", "organizations_url": "https://api.github.com/users/zhangyaobit/orgs", "repos_url": "https://api.github.com/users/zhangyaobit/repos", "events_url": "https://api.github.com/users/zhangyaobit/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangyaobit/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-04-14T16:59:44Z", "updated_at": "2018-09-28T22:04:01Z", "closed_at": "2018-09-28T22:04:01Z", "author_association": "NONE", "body_html": "<h3>Describe the problem</h3>\n<p>The implementation of topk kernel operation seems faster on my cpu than on gpu(for example below profiler outputs 6us for cpu and 345us for gpu, and result reapeats for other inputs). But that is not the case for this issue, I started some testing on that which lead me to this:</p>\n<p>I extracted the kernel implementation from tf source. Put some time measuring code in Compute around functor call, for real(using std::chrono::time_steady) and cpu(clock() from ctime) time. Compiled it without optimizations, loaded in python as tensorflow library. For cpu the result was much bigger than what profiler printed, 6us(profiler) vs 1432us(clock()), 473us(using std::chrono::time_steady).<br>\nThen I added in functor code thread sleep, only real time duration extended, then I added long for loop and both real and cpu duration got bigger but again profiler output stayed the same as in code without modifications ~6us, what is not proper in my understanding.</p>\n<h3>Source code / logs</h3>\n<p>Here is the python3 code I used:</p>\n<pre><code>import tensorflow as tf\nimport random\n\narr=[[int(100000*random.random())\n    for i in range(100)] for j in range(100)]\n\na = tf.convert_to_tensor(arr)\ntopk_module = tf.load_op_library(\"topk_op.so\")\nb = topk_module.matrix_top_k(a, 10)\n\nbuilder = tf.profiler.ProfileOptionBuilder\nopts = builder(builder.time_and_memory()).order_by('micros').build()\n\n\nwith tf.contrib.tfprof.ProfileContext('/tmp/train_dir',\n                                    trace_steps=[],\n                                    dump_steps=[]) as pctx:\n    with tf.Session() as sess:\n        pctx.trace_next_step()\n        pctx.dump_next_step()\n        x = sess.run(b)\n        pctx.profiler.profile_operations(options=opts)\n</code></pre>\n<p>and snippet from topk_op.cc</p>\n<pre><code>    std::chrono::steady_clock::time_point time_begin_real =\n        std::chrono::steady_clock::now();\n    clock_t time_begin_cpu = clock();\n\n\n    Status s = functor::TopKFunctor&lt;Device, T&gt;::Compute(\n        context, sorted_, k, input, num_rows, num_cols, values, indices);\n    \n    clock_t time_end_cpu = clock();\n    std::chrono::steady_clock::time_point time_end_real =\n        std::chrono::steady_clock::now();\n    //stdout printing\n</code></pre>\n<hr>\n<h3>System information</h3>\n<p>Have I written custom code: yes, can post modified topk op kernel code and makefile if you want<br>\nubuntu 16.04<br>\ntensorflow installed from pip package manager.<br>\ntensorflow 1.7.0<br>\nbazel: n/a, used gcc 4.9.3<br>\ncuda 9.0 cudnn 7.0<br>\ngtx 1050 ti 4GB<br>\nn/a</p>", "body_text": "Describe the problem\nThe implementation of topk kernel operation seems faster on my cpu than on gpu(for example below profiler outputs 6us for cpu and 345us for gpu, and result reapeats for other inputs). But that is not the case for this issue, I started some testing on that which lead me to this:\nI extracted the kernel implementation from tf source. Put some time measuring code in Compute around functor call, for real(using std::chrono::time_steady) and cpu(clock() from ctime) time. Compiled it without optimizations, loaded in python as tensorflow library. For cpu the result was much bigger than what profiler printed, 6us(profiler) vs 1432us(clock()), 473us(using std::chrono::time_steady).\nThen I added in functor code thread sleep, only real time duration extended, then I added long for loop and both real and cpu duration got bigger but again profiler output stayed the same as in code without modifications ~6us, what is not proper in my understanding.\nSource code / logs\nHere is the python3 code I used:\nimport tensorflow as tf\nimport random\n\narr=[[int(100000*random.random())\n    for i in range(100)] for j in range(100)]\n\na = tf.convert_to_tensor(arr)\ntopk_module = tf.load_op_library(\"topk_op.so\")\nb = topk_module.matrix_top_k(a, 10)\n\nbuilder = tf.profiler.ProfileOptionBuilder\nopts = builder(builder.time_and_memory()).order_by('micros').build()\n\n\nwith tf.contrib.tfprof.ProfileContext('/tmp/train_dir',\n                                    trace_steps=[],\n                                    dump_steps=[]) as pctx:\n    with tf.Session() as sess:\n        pctx.trace_next_step()\n        pctx.dump_next_step()\n        x = sess.run(b)\n        pctx.profiler.profile_operations(options=opts)\n\nand snippet from topk_op.cc\n    std::chrono::steady_clock::time_point time_begin_real =\n        std::chrono::steady_clock::now();\n    clock_t time_begin_cpu = clock();\n\n\n    Status s = functor::TopKFunctor<Device, T>::Compute(\n        context, sorted_, k, input, num_rows, num_cols, values, indices);\n    \n    clock_t time_end_cpu = clock();\n    std::chrono::steady_clock::time_point time_end_real =\n        std::chrono::steady_clock::now();\n    //stdout printing\n\n\nSystem information\nHave I written custom code: yes, can post modified topk op kernel code and makefile if you want\nubuntu 16.04\ntensorflow installed from pip package manager.\ntensorflow 1.7.0\nbazel: n/a, used gcc 4.9.3\ncuda 9.0 cudnn 7.0\ngtx 1050 ti 4GB\nn/a", "body": "### Describe the problem\r\nThe implementation of topk kernel operation seems faster on my cpu than on gpu(for example below profiler outputs 6us for cpu and 345us for gpu, and result reapeats for other inputs). But that is not the case for this issue, I started some testing on that which lead me to this:\r\n\r\nI extracted the kernel implementation from tf source. Put some time measuring code in Compute around functor call, for real(using std::chrono::time_steady) and cpu(clock() from ctime) time. Compiled it without optimizations, loaded in python as tensorflow library. For cpu the result was much bigger than what profiler printed, 6us(profiler) vs 1432us(clock()), 473us(using std::chrono::time_steady).\r\nThen I added in functor code thread sleep, only real time duration extended, then I added long for loop and both real and cpu duration got bigger but again profiler output stayed the same as in code without modifications ~6us, what is not proper in my understanding.\r\n### Source code / logs\r\nHere is the python3 code I used:\r\n```\r\nimport tensorflow as tf\r\nimport random\r\n\r\narr=[[int(100000*random.random())\r\n    for i in range(100)] for j in range(100)]\r\n\r\na = tf.convert_to_tensor(arr)\r\ntopk_module = tf.load_op_library(\"topk_op.so\")\r\nb = topk_module.matrix_top_k(a, 10)\r\n\r\nbuilder = tf.profiler.ProfileOptionBuilder\r\nopts = builder(builder.time_and_memory()).order_by('micros').build()\r\n\r\n\r\nwith tf.contrib.tfprof.ProfileContext('/tmp/train_dir',\r\n                                    trace_steps=[],\r\n                                    dump_steps=[]) as pctx:\r\n    with tf.Session() as sess:\r\n        pctx.trace_next_step()\r\n        pctx.dump_next_step()\r\n        x = sess.run(b)\r\n        pctx.profiler.profile_operations(options=opts)\r\n```\r\nand snippet from topk_op.cc\r\n```\r\n    std::chrono::steady_clock::time_point time_begin_real =\r\n        std::chrono::steady_clock::now();\r\n    clock_t time_begin_cpu = clock();\r\n\r\n\r\n    Status s = functor::TopKFunctor<Device, T>::Compute(\r\n        context, sorted_, k, input, num_rows, num_cols, values, indices);\r\n    \r\n    clock_t time_end_cpu = clock();\r\n    std::chrono::steady_clock::time_point time_end_real =\r\n        std::chrono::steady_clock::now();\r\n    //stdout printing\r\n```\r\n------------------------\r\n### System information\r\nHave I written custom code: yes, can post modified topk op kernel code and makefile if you want\r\nubuntu 16.04\r\ntensorflow installed from pip package manager.\r\ntensorflow 1.7.0\r\nbazel: n/a, used gcc 4.9.3\r\ncuda 9.0 cudnn 7.0\r\ngtx 1050 ti 4GB\r\nn/a\r\n"}