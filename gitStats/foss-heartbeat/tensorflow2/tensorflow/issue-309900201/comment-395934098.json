{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/395934098", "html_url": "https://github.com/tensorflow/tensorflow/issues/18103#issuecomment-395934098", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18103", "id": 395934098, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NTkzNDA5OA==", "user": {"login": "rjpower", "id": 607207, "node_id": "MDQ6VXNlcjYwNzIwNw==", "avatar_url": "https://avatars0.githubusercontent.com/u/607207?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rjpower", "html_url": "https://github.com/rjpower", "followers_url": "https://api.github.com/users/rjpower/followers", "following_url": "https://api.github.com/users/rjpower/following{/other_user}", "gists_url": "https://api.github.com/users/rjpower/gists{/gist_id}", "starred_url": "https://api.github.com/users/rjpower/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rjpower/subscriptions", "organizations_url": "https://api.github.com/users/rjpower/orgs", "repos_url": "https://api.github.com/users/rjpower/repos", "events_url": "https://api.github.com/users/rjpower/events{/privacy}", "received_events_url": "https://api.github.com/users/rjpower/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-09T02:48:22Z", "updated_at": "2018-06-09T02:48:22Z", "author_association": "CONTRIBUTOR", "body_html": "<p>You are correct; the issues are related.  The XLA compiler used for TPU compilation requires that all tensors have static shapes.  In the case of TimeDistributed, the underlying layer must have a fixed input length, which appears to be the case here.  Unfortunately, the required wiring of the input length to the maximum iteration count is only available in TF 1.9.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/backend.py#L3195\">https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/backend.py#L3195</a></p>\n<p>You should be able to use this today by installing the TF 1.9 RC0 on your host VM (barring network incompatibilities with the TPU), and in general when TF 1.9 is released.</p>", "body_text": "You are correct; the issues are related.  The XLA compiler used for TPU compilation requires that all tensors have static shapes.  In the case of TimeDistributed, the underlying layer must have a fixed input length, which appears to be the case here.  Unfortunately, the required wiring of the input length to the maximum iteration count is only available in TF 1.9.\nhttps://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/backend.py#L3195\nYou should be able to use this today by installing the TF 1.9 RC0 on your host VM (barring network incompatibilities with the TPU), and in general when TF 1.9 is released.", "body": "You are correct; the issues are related.  The XLA compiler used for TPU compilation requires that all tensors have static shapes.  In the case of TimeDistributed, the underlying layer must have a fixed input length, which appears to be the case here.  Unfortunately, the required wiring of the input length to the maximum iteration count is only available in TF 1.9.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/backend.py#L3195\r\n\r\nYou should be able to use this today by installing the TF 1.9 RC0 on your host VM (barring network incompatibilities with the TPU), and in general when TF 1.9 is released."}