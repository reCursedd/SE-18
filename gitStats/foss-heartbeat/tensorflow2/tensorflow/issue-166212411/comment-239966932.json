{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/239966932", "html_url": "https://github.com/tensorflow/tensorflow/issues/3377#issuecomment-239966932", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3377", "id": 239966932, "node_id": "MDEyOklzc3VlQ29tbWVudDIzOTk2NjkzMg==", "user": {"login": "AaronRocinante", "id": 11368312, "node_id": "MDQ6VXNlcjExMzY4MzEy", "avatar_url": "https://avatars3.githubusercontent.com/u/11368312?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AaronRocinante", "html_url": "https://github.com/AaronRocinante", "followers_url": "https://api.github.com/users/AaronRocinante/followers", "following_url": "https://api.github.com/users/AaronRocinante/following{/other_user}", "gists_url": "https://api.github.com/users/AaronRocinante/gists{/gist_id}", "starred_url": "https://api.github.com/users/AaronRocinante/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AaronRocinante/subscriptions", "organizations_url": "https://api.github.com/users/AaronRocinante/orgs", "repos_url": "https://api.github.com/users/AaronRocinante/repos", "events_url": "https://api.github.com/users/AaronRocinante/events{/privacy}", "received_events_url": "https://api.github.com/users/AaronRocinante/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-16T00:11:25Z", "updated_at": "2016-08-16T00:11:25Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15736910\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/zheng-xq\">@zheng-xq</a> It seems that if we only use one GPU to train the model, then even if we load the data from disk to memory in parallel threads we still have to load the data into the GPU sequentially. Do you mean we should train the models using multiple GPUs so that we can also load the data into GPU in parallel? But in that case for each GPU the loading still has to be sequential.</p>", "body_text": "@zheng-xq It seems that if we only use one GPU to train the model, then even if we load the data from disk to memory in parallel threads we still have to load the data into the GPU sequentially. Do you mean we should train the models using multiple GPUs so that we can also load the data into GPU in parallel? But in that case for each GPU the loading still has to be sequential.", "body": "@zheng-xq It seems that if we only use one GPU to train the model, then even if we load the data from disk to memory in parallel threads we still have to load the data into the GPU sequentially. Do you mean we should train the models using multiple GPUs so that we can also load the data into GPU in parallel? But in that case for each GPU the loading still has to be sequential.\n"}