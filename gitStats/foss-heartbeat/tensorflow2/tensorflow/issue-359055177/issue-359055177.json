{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22213", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22213/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22213/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22213/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/22213", "id": 359055177, "node_id": "MDU6SXNzdWUzNTkwNTUxNzc=", "number": 22213, "title": "how to fix  \"tf.nightly-gpu\" caused \"nan\" problem", "user": {"login": "Q82822", "id": 36806042, "node_id": "MDQ6VXNlcjM2ODA2MDQy", "avatar_url": "https://avatars2.githubusercontent.com/u/36806042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Q82822", "html_url": "https://github.com/Q82822", "followers_url": "https://api.github.com/users/Q82822/followers", "following_url": "https://api.github.com/users/Q82822/following{/other_user}", "gists_url": "https://api.github.com/users/Q82822/gists{/gist_id}", "starred_url": "https://api.github.com/users/Q82822/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Q82822/subscriptions", "organizations_url": "https://api.github.com/users/Q82822/orgs", "repos_url": "https://api.github.com/users/Q82822/repos", "events_url": "https://api.github.com/users/Q82822/events{/privacy}", "received_events_url": "https://api.github.com/users/Q82822/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-09-11T13:46:11Z", "updated_at": "2018-11-15T19:04:34Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<p>Have I written custom code (as opposed to using a stock example script provided in TensorFlow):<br>\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04<br>\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:<br>\nTensorFlow installed from (source or binary): source<br>\nTensorFlow version (use command below): 1.11.0 (use tf-night-gpu)<br>\nPython version:2.7<br>\nBazel version (if compiling from source):<br>\nGCC/Compiler version (if compiling from source):<br>\nCUDA/cuDNN version: 9.0 /7.1<br>\nGPU model and memory:<br>\nExact command to reproduce:</p>\n<h3>Describe the problem</h3>\n<p>I used <code>tf-night-gpu</code> in my project code, but it will be made \"nan\" at the next batch train.<br>\nit only the  <code>tf-night-gpu</code> will happen, it is can work in tensorflow1.10.</p>\n<h3>Source code / logs</h3>\n<p>the minimal code at here , it is just part of my project code. the input is word_index.<br>\nthe batch size = 64<br>\nuse tf-nightly-gpu.<br>\nplatform = jupyter notebook.<br>\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"</p>\n<pre><code>\nclass  RNN_Decoder(tf.keras.Model):\n    def __init__(self, embedding_dim, units, vocab_size):\n        super(RNN_Decoder, self).__init__()\n        self.units = units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    def call(self, x, features, hidden):\n        print('embedding_input:  ', x)\n        x = self.embedding(x)\n        print('embedding_output:  ', x)\n\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\n\nfor epoch in range(20):\n    hidden = decoder.reset_state(batch_size=64)\n    dec_input = tf.expand_dims([tokenizer.word_index['&lt;start&gt;']] * BATCH_SIZE, 1)\n        with tf.GradientTape() as tape:\n            features = encoder(img_tensor)\n            for i in range(1, target.shape[1])\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\n</code></pre>\n<p>---- first batch train input and output------</p>\n<pre><code>('embedding_input ', &lt;tf.Tensor: id=4586198, shape=(64, 1), dtype=int32, numpy=\narray([[3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3]], dtype=int32)&gt;)\n('Embedding_output:  ', &lt;tf.Tensor: id=4586379, shape=(64, 1, 256), dtype=float32, numpy=\narray([[[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       ...,\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]]], dtype=float32)&gt;)\n</code></pre>\n<p>the next batch train , have same keras.layers.Embedding_input:</p>\n<pre><code>`Epoch 1 Batch 0 Loss 2.0415\n(''keras.layers.Embedding_input:: ', &lt;tf.Tensor: id=4607289, shape=(64, 1), dtype=int32, numpy=\narray([[3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3]], dtype=int32)&gt;)\n(''keras.layers.Embedding_output::  ', &lt;tf.Tensor: id=4607374, shape=(64, 1, 256), dtype=float32, numpy=\narray([[[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)&gt;)`\n</code></pre>", "body_text": "System information\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.11.0 (use tf-night-gpu)\nPython version:2.7\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0 /7.1\nGPU model and memory:\nExact command to reproduce:\nDescribe the problem\nI used tf-night-gpu in my project code, but it will be made \"nan\" at the next batch train.\nit only the  tf-night-gpu will happen, it is can work in tensorflow1.10.\nSource code / logs\nthe minimal code at here , it is just part of my project code. the input is word_index.\nthe batch size = 64\nuse tf-nightly-gpu.\nplatform = jupyter notebook.\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"\n\nclass  RNN_Decoder(tf.keras.Model):\n    def __init__(self, embedding_dim, units, vocab_size):\n        super(RNN_Decoder, self).__init__()\n        self.units = units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    def call(self, x, features, hidden):\n        print('embedding_input:  ', x)\n        x = self.embedding(x)\n        print('embedding_output:  ', x)\n\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\n\nfor epoch in range(20):\n    hidden = decoder.reset_state(batch_size=64)\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n        with tf.GradientTape() as tape:\n            features = encoder(img_tensor)\n            for i in range(1, target.shape[1])\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\n\n---- first batch train input and output------\n('embedding_input ', <tf.Tensor: id=4586198, shape=(64, 1), dtype=int32, numpy=\narray([[3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3]], dtype=int32)>)\n('Embedding_output:  ', <tf.Tensor: id=4586379, shape=(64, 1, 256), dtype=float32, numpy=\narray([[[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       ...,\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]],\n\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\n          0.01521399, -0.0496642 ]]], dtype=float32)>)\n\nthe next batch train , have same keras.layers.Embedding_input:\n`Epoch 1 Batch 0 Loss 2.0415\n(''keras.layers.Embedding_input:: ', <tf.Tensor: id=4607289, shape=(64, 1), dtype=int32, numpy=\narray([[3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3],\n       [3]], dtype=int32)>)\n(''keras.layers.Embedding_output::  ', <tf.Tensor: id=4607374, shape=(64, 1, 256), dtype=float32, numpy=\narray([[[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]],\n\n       [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>)`", "body": "\r\n### System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version (use command below): 1.11.0 (use tf-night-gpu)\r\nPython version:2.7\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 9.0 /7.1\r\nGPU model and memory:\r\nExact command to reproduce:\r\n\r\n\r\n### Describe the problem\r\nI used `tf-night-gpu` in my project code, but it will be made \"nan\" at the next batch train.\r\nit only the  `tf-night-gpu` will happen, it is can work in tensorflow1.10.\r\n\r\n\r\n### Source code / logs\r\nthe minimal code at here , it is just part of my project code. the input is word_index.\r\nthe batch size = 64\r\nuse tf-nightly-gpu.\r\nplatform = jupyter notebook.\r\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"\r\n```\r\n\r\nclass  RNN_Decoder(tf.keras.Model):\r\n    def __init__(self, embedding_dim, units, vocab_size):\r\n        super(RNN_Decoder, self).__init__()\r\n        self.units = units\r\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    def call(self, x, features, hidden):\r\n        print('embedding_input:  ', x)\r\n        x = self.embedding(x)\r\n        print('embedding_output:  ', x)\r\n\r\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\r\n\r\nfor epoch in range(20):\r\n    hidden = decoder.reset_state(batch_size=64)\r\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\r\n        with tf.GradientTape() as tape:\r\n            features = encoder(img_tensor)\r\n            for i in range(1, target.shape[1])\r\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\r\n```\r\n\r\n---- first batch train input and output------\r\n```\r\n('embedding_input ', <tf.Tensor: id=4586198, shape=(64, 1), dtype=int32, numpy=\r\narray([[3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3]], dtype=int32)>)\r\n('Embedding_output:  ', <tf.Tensor: id=4586379, shape=(64, 1, 256), dtype=float32, numpy=\r\narray([[[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       ...,\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]]], dtype=float32)>)\r\n```\r\n\r\nthe next batch train , have same keras.layers.Embedding_input:\r\n\r\n```\r\n`Epoch 1 Batch 0 Loss 2.0415\r\n(''keras.layers.Embedding_input:: ', <tf.Tensor: id=4607289, shape=(64, 1), dtype=int32, numpy=\r\narray([[3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3]], dtype=int32)>)\r\n(''keras.layers.Embedding_output::  ', <tf.Tensor: id=4607374, shape=(64, 1, 256), dtype=float32, numpy=\r\narray([[[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>)`\r\n```"}