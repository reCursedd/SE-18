{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/264039518", "html_url": "https://github.com/tensorflow/tensorflow/issues/5907#issuecomment-264039518", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5907", "id": 264039518, "node_id": "MDEyOklzc3VlQ29tbWVudDI2NDAzOTUxOA==", "user": {"login": "yaroslavvb", "id": 23068, "node_id": "MDQ6VXNlcjIzMDY4", "avatar_url": "https://avatars3.githubusercontent.com/u/23068?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yaroslavvb", "html_url": "https://github.com/yaroslavvb", "followers_url": "https://api.github.com/users/yaroslavvb/followers", "following_url": "https://api.github.com/users/yaroslavvb/following{/other_user}", "gists_url": "https://api.github.com/users/yaroslavvb/gists{/gist_id}", "starred_url": "https://api.github.com/users/yaroslavvb/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yaroslavvb/subscriptions", "organizations_url": "https://api.github.com/users/yaroslavvb/orgs", "repos_url": "https://api.github.com/users/yaroslavvb/repos", "events_url": "https://api.github.com/users/yaroslavvb/events{/privacy}", "received_events_url": "https://api.github.com/users/yaroslavvb/received_events", "type": "User", "site_admin": false}, "created_at": "2016-12-01T00:17:49Z", "updated_at": "2016-12-01T18:50:30Z", "author_association": "CONTRIBUTOR", "body_html": "<p>BTW, Marc O'Connoranalyzed this slowness (gRPC transfers bottlenecking at 80-200MB/second when you add large vector of 1's in one worker to variable on another local worker and fetch result into Python on original worker) and found following break-down.</p>\n<p>Out of 1 second:</p>\n<ol>\n<li>Nothing happens (0.2s +- 0.05): main process waits in grpc_competion_queue_pick, other threads wait in std::this_thread::__sleep_for(!)</li>\n<li>Workers active (0.6s +-0.05 plus up to 0.2s overlap with next phase). 90% of time split time between:<br>\na.\tDoRecvTensor (7%), all spent in Tensor::AsProtoTensorContent calling std::string::_M_replace_safe.<br>\nb.\tgrpc_completion_queue_next(26%), split between post_parse_locked calling gpr_unref (11%) and memmove_ssse3_back (15%)<br>\nc.\tDoRunGraph (34%) calling Tensor::AsProtoField (11% all spent in RepeatedField::Reserve), RunGraphResponse::ByteSize (7%) and grpc::Serialize (15%)<br>\nd.\tgrpc::Deserialize(23%)</li>\n<li>Master merges data (0.2s +- 0.05s): All main thread time in TensorProto::MergePartialFromCodedStream, split evenly between self time, RepeatedField::Reserve and CodedInputStream::BytesUntilLimit. This partially overlaps with the previous phase.\u2028</li>\n</ol>", "body_text": "BTW, Marc O'Connoranalyzed this slowness (gRPC transfers bottlenecking at 80-200MB/second when you add large vector of 1's in one worker to variable on another local worker and fetch result into Python on original worker) and found following break-down.\nOut of 1 second:\n\nNothing happens (0.2s +- 0.05): main process waits in grpc_competion_queue_pick, other threads wait in std::this_thread::__sleep_for(!)\nWorkers active (0.6s +-0.05 plus up to 0.2s overlap with next phase). 90% of time split time between:\na.\tDoRecvTensor (7%), all spent in Tensor::AsProtoTensorContent calling std::string::_M_replace_safe.\nb.\tgrpc_completion_queue_next(26%), split between post_parse_locked calling gpr_unref (11%) and memmove_ssse3_back (15%)\nc.\tDoRunGraph (34%) calling Tensor::AsProtoField (11% all spent in RepeatedField::Reserve), RunGraphResponse::ByteSize (7%) and grpc::Serialize (15%)\nd.\tgrpc::Deserialize(23%)\nMaster merges data (0.2s +- 0.05s): All main thread time in TensorProto::MergePartialFromCodedStream, split evenly between self time, RepeatedField::Reserve and CodedInputStream::BytesUntilLimit. This partially overlaps with the previous phase.\u2028", "body": "BTW, Marc O'Connoranalyzed this slowness (gRPC transfers bottlenecking at 80-200MB/second when you add large vector of 1's in one worker to variable on another local worker and fetch result into Python on original worker) and found following break-down.\r\n\r\nOut of 1 second:\r\n1.\tNothing happens (0.2s +- 0.05): main process waits in grpc_competion_queue_pick, other threads wait in std::this_thread::__sleep_for(!)\r\n2.\tWorkers active (0.6s +-0.05 plus up to 0.2s overlap with next phase). 90% of time split time between:\r\n    a.\tDoRecvTensor (7%), all spent in Tensor::AsProtoTensorContent calling std::string::_M_replace_safe.\r\n    b.\tgrpc_completion_queue_next(26%), split between post_parse_locked calling gpr_unref (11%) and memmove_ssse3_back (15%)\r\n    c.\tDoRunGraph (34%) calling Tensor::AsProtoField (11% all spent in RepeatedField::Reserve), RunGraphResponse::ByteSize (7%) and grpc::Serialize (15%)\r\n    d.\tgrpc::Deserialize(23%)\r\n3.\tMaster merges data (0.2s +- 0.05s): All main thread time in TensorProto::MergePartialFromCodedStream, split evenly between self time, RepeatedField::Reserve and CodedInputStream::BytesUntilLimit. This partially overlaps with the previous phase.\u2028\r\n"}