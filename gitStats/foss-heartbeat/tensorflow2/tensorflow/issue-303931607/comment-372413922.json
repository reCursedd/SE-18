{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/372413922", "html_url": "https://github.com/tensorflow/tensorflow/issues/17595#issuecomment-372413922", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17595", "id": 372413922, "node_id": "MDEyOklzc3VlQ29tbWVudDM3MjQxMzkyMg==", "user": {"login": "amirjamez", "id": 8922398, "node_id": "MDQ6VXNlcjg5MjIzOTg=", "avatar_url": "https://avatars3.githubusercontent.com/u/8922398?v=4", "gravatar_id": "", "url": "https://api.github.com/users/amirjamez", "html_url": "https://github.com/amirjamez", "followers_url": "https://api.github.com/users/amirjamez/followers", "following_url": "https://api.github.com/users/amirjamez/following{/other_user}", "gists_url": "https://api.github.com/users/amirjamez/gists{/gist_id}", "starred_url": "https://api.github.com/users/amirjamez/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/amirjamez/subscriptions", "organizations_url": "https://api.github.com/users/amirjamez/orgs", "repos_url": "https://api.github.com/users/amirjamez/repos", "events_url": "https://api.github.com/users/amirjamez/events{/privacy}", "received_events_url": "https://api.github.com/users/amirjamez/received_events", "type": "User", "site_admin": false}, "created_at": "2018-03-12T18:23:39Z", "updated_at": "2018-03-13T19:07:02Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=15676913\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/poxvoculi\">@poxvoculi</a>, Specifically, I was referring to <code>quantize_weight.cc</code> and <code>quantize_node.cc</code>. The way I understood by looking at the code is that it only considers the min and the max and maps the remaining weights inside the span. However, it would be useful to consider <code>0.0f</code> as well and map them to <code>128 tf-8</code> so that the value zero remains unique in the quantized model.<br>\nYes. There are a number of other methods available to do that but each has some pros and cons. The best practice, in my reckoning, here is to produce a signed 8-bits representing the value 0f to 0 tf-8.  Thanks</p>", "body_text": "@poxvoculi, Specifically, I was referring to quantize_weight.cc and quantize_node.cc. The way I understood by looking at the code is that it only considers the min and the max and maps the remaining weights inside the span. However, it would be useful to consider 0.0f as well and map them to 128 tf-8 so that the value zero remains unique in the quantized model.\nYes. There are a number of other methods available to do that but each has some pros and cons. The best practice, in my reckoning, here is to produce a signed 8-bits representing the value 0f to 0 tf-8.  Thanks", "body": "@poxvoculi, Specifically, I was referring to `quantize_weight.cc` and `quantize_node.cc`. The way I understood by looking at the code is that it only considers the min and the max and maps the remaining weights inside the span. However, it would be useful to consider `0.0f` as well and map them to `128 tf-8` so that the value zero remains unique in the quantized model. \r\nYes. There are a number of other methods available to do that but each has some pros and cons. The best practice, in my reckoning, here is to produce a signed 8-bits representing the value 0f to 0 tf-8.  Thanks"}