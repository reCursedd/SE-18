{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/345095492", "html_url": "https://github.com/tensorflow/tensorflow/issues/4965#issuecomment-345095492", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4965", "id": 345095492, "node_id": "MDEyOklzc3VlQ29tbWVudDM0NTA5NTQ5Mg==", "user": {"login": "awav", "id": 24483645, "node_id": "MDQ6VXNlcjI0NDgzNjQ1", "avatar_url": "https://avatars0.githubusercontent.com/u/24483645?v=4", "gravatar_id": "", "url": "https://api.github.com/users/awav", "html_url": "https://github.com/awav", "followers_url": "https://api.github.com/users/awav/followers", "following_url": "https://api.github.com/users/awav/following{/other_user}", "gists_url": "https://api.github.com/users/awav/gists{/gist_id}", "starred_url": "https://api.github.com/users/awav/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/awav/subscriptions", "organizations_url": "https://api.github.com/users/awav/orgs", "repos_url": "https://api.github.com/users/awav/repos", "events_url": "https://api.github.com/users/awav/events{/privacy}", "received_events_url": "https://api.github.com/users/awav/received_events", "type": "User", "site_admin": false}, "created_at": "2017-11-16T23:23:49Z", "updated_at": "2017-11-20T14:50:27Z", "author_association": "NONE", "body_html": "<p>Hello everyone,</p>\n<p>In <em>GPflow 1.0</em> we had to implement our own <em>hmc</em>, <a href=\"https://github.com/GPflow/GPflow/blob/master/gpflow/training/hmc.py\">implementation here</a>. Unfortunately, tensorflow implementation doesn't fit into our requirements.</p>\n<ol>\n<li>GPflow logprob function (objective) doesn't really have simple interface <code>fun(x)</code>. It is a combination of priors, unconstained and constrained values. Building correctly logprob requires GPflow parameter objects, so that we could pull some extra information, not bare list of tensors.</li>\n<li>GPflow objective has more than one parameter, therefore the python function should be <code>fun(x0, x1, ..., xn)</code>, not <code>fun(x)</code>.</li>\n</ol>\n<p>From my point of view first item uncovers the issue with pythonic functions which build objective tensor at each scan, map_fn or while_loop iteration in hmc. The interesting fact is that the objective tensor itself is a \"function\" in tensorflow graph and inputs are some tensorflow variables. So, the best option for GPflow now would be having the <code>tf.train.hmc</code> optimizer with similar protocol as gradient based optimizers have. I'm very interested  in that solution and ready to find time to implement it, but I'm not really sure where to look first in tensorflow.</p>\n<p>Second problem can fairly easy be fixed at tensorflow's hmc. Here is a candidate for <a href=\"https://github.com/awav/tensorflow/blob/awav/hmc-with-multiple-variables/tensorflow/contrib/bayesflow/python/ops/hmc_impl.py#L50\">PR</a>.</p>\n<p><em>Quick notes about hmc implementation in GPflow</em>: because we can't create a pythonic function of the form <code>fun(x0, x1, ...) -&gt; objective_tensor</code>, in each while_loop iteration we have to reuse same input variables, update them via <code>tf.assign</code> and manage execution using <code>control_dependencies</code>.</p>", "body_text": "Hello everyone,\nIn GPflow 1.0 we had to implement our own hmc, implementation here. Unfortunately, tensorflow implementation doesn't fit into our requirements.\n\nGPflow logprob function (objective) doesn't really have simple interface fun(x). It is a combination of priors, unconstained and constrained values. Building correctly logprob requires GPflow parameter objects, so that we could pull some extra information, not bare list of tensors.\nGPflow objective has more than one parameter, therefore the python function should be fun(x0, x1, ..., xn), not fun(x).\n\nFrom my point of view first item uncovers the issue with pythonic functions which build objective tensor at each scan, map_fn or while_loop iteration in hmc. The interesting fact is that the objective tensor itself is a \"function\" in tensorflow graph and inputs are some tensorflow variables. So, the best option for GPflow now would be having the tf.train.hmc optimizer with similar protocol as gradient based optimizers have. I'm very interested  in that solution and ready to find time to implement it, but I'm not really sure where to look first in tensorflow.\nSecond problem can fairly easy be fixed at tensorflow's hmc. Here is a candidate for PR.\nQuick notes about hmc implementation in GPflow: because we can't create a pythonic function of the form fun(x0, x1, ...) -> objective_tensor, in each while_loop iteration we have to reuse same input variables, update them via tf.assign and manage execution using control_dependencies.", "body": "Hello everyone,\r\n\r\nIn _GPflow 1.0_ we had to implement our own _hmc_, [implementation here](https://github.com/GPflow/GPflow/blob/master/gpflow/training/hmc.py). Unfortunately, tensorflow implementation doesn't fit into our requirements.\r\n\r\n1. GPflow logprob function (objective) doesn't really have simple interface `fun(x)`. It is a combination of priors, unconstained and constrained values. Building correctly logprob requires GPflow parameter objects, so that we could pull some extra information, not bare list of tensors.\r\n2. GPflow objective has more than one parameter, therefore the python function should be `fun(x0, x1, ..., xn)`, not `fun(x)`. \r\n\r\nFrom my point of view first item uncovers the issue with pythonic functions which build objective tensor at each scan, map_fn or while_loop iteration in hmc. The interesting fact is that the objective tensor itself is a \"function\" in tensorflow graph and inputs are some tensorflow variables. So, the best option for GPflow now would be having the `tf.train.hmc` optimizer with similar protocol as gradient based optimizers have. I'm very interested  in that solution and ready to find time to implement it, but I'm not really sure where to look first in tensorflow. \r\n\r\nSecond problem can fairly easy be fixed at tensorflow's hmc. Here is a candidate for [PR](https://github.com/awav/tensorflow/blob/awav/hmc-with-multiple-variables/tensorflow/contrib/bayesflow/python/ops/hmc_impl.py#L50).\r\n\r\n_Quick notes about hmc implementation in GPflow_: because we can't create a pythonic function of the form `fun(x0, x1, ...) -> objective_tensor`, in each while_loop iteration we have to reuse same input variables, update them via `tf.assign` and manage execution using `control_dependencies`.\r\n\r\n"}