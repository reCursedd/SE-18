{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16082", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16082/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16082/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16082/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16082", "id": 288242442, "node_id": "MDU6SXNzdWUyODgyNDI0NDI=", "number": 16082, "title": "Connect Apache Beam/Spark to TensorFlow (MonitoredTrainingSession) in a streaming manner?", "user": {"login": "MtDersvan", "id": 7069222, "node_id": "MDQ6VXNlcjcwNjkyMjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7069222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MtDersvan", "html_url": "https://github.com/MtDersvan", "followers_url": "https://api.github.com/users/MtDersvan/followers", "following_url": "https://api.github.com/users/MtDersvan/following{/other_user}", "gists_url": "https://api.github.com/users/MtDersvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/MtDersvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MtDersvan/subscriptions", "organizations_url": "https://api.github.com/users/MtDersvan/orgs", "repos_url": "https://api.github.com/users/MtDersvan/repos", "events_url": "https://api.github.com/users/MtDersvan/events{/privacy}", "received_events_url": "https://api.github.com/users/MtDersvan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 404586558, "node_id": "MDU6TGFiZWw0MDQ1ODY1NTg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:community%20support", "name": "stat:community support", "color": "f4b400", "default": false}, {"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2018-01-12T20:49:42Z", "updated_at": "2018-02-06T23:10:59Z", "closed_at": "2018-02-06T23:10:59Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>Describe the problem</h3>\n<p>I have a lengthy question on <a href=\"https://stackoverflow.com/questions/47986410/optimal-data-streaming-and-processing-solution-for-enormous-datasets-into-tf-dat\" rel=\"nofollow\">SO</a> about this. But in short, is there a way (or a best practice) to pipe big training datasets directly into a distributed setting (e.g. GKE),  especially if they are subjected to a heavy preprocessing?<br>\nI'm basically reaching the limit of what can be sanely stored in TFRecords (they are verbose and heavy).<br>\nThe closest issue was this one (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"256195007\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/12903\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/12903/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/12903\">#12903</a>) and this guide (<a href=\"https://github.com/GoogleCloudPlatform/dataflow-prediction-example\">https://github.com/GoogleCloudPlatform/dataflow-prediction-example</a>) but I do not see a healthy way to implement it (last one with a <code>@singleton</code> looks like a hack and not usable with the <code>tf.Dataset</code> or <code>MonitoredTrainingSession</code>).</p>\n<p>I believe this is a useful issue/feature request for a decent amount of Tensorflow users.</p>", "body_text": "Describe the problem\nI have a lengthy question on SO about this. But in short, is there a way (or a best practice) to pipe big training datasets directly into a distributed setting (e.g. GKE),  especially if they are subjected to a heavy preprocessing?\nI'm basically reaching the limit of what can be sanely stored in TFRecords (they are verbose and heavy).\nThe closest issue was this one (#12903) and this guide (https://github.com/GoogleCloudPlatform/dataflow-prediction-example) but I do not see a healthy way to implement it (last one with a @singleton looks like a hack and not usable with the tf.Dataset or MonitoredTrainingSession).\nI believe this is a useful issue/feature request for a decent amount of Tensorflow users.", "body": "### Describe the problem\r\nI have a lengthy question on [SO](https://stackoverflow.com/questions/47986410/optimal-data-streaming-and-processing-solution-for-enormous-datasets-into-tf-dat) about this. But in short, is there a way (or a best practice) to pipe big training datasets directly into a distributed setting (e.g. GKE),  especially if they are subjected to a heavy preprocessing? \r\nI'm basically reaching the limit of what can be sanely stored in TFRecords (they are verbose and heavy).\r\nThe closest issue was this one (https://github.com/tensorflow/tensorflow/issues/12903) and this guide (https://github.com/GoogleCloudPlatform/dataflow-prediction-example) but I do not see a healthy way to implement it (last one with a `@singleton` looks like a hack and not usable with the `tf.Dataset` or `MonitoredTrainingSession`).\r\n\r\nI believe this is a useful issue/feature request for a decent amount of Tensorflow users. "}