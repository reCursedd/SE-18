{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/357393011", "html_url": "https://github.com/tensorflow/tensorflow/issues/16082#issuecomment-357393011", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16082", "id": 357393011, "node_id": "MDEyOklzc3VlQ29tbWVudDM1NzM5MzAxMQ==", "user": {"login": "MtDersvan", "id": 7069222, "node_id": "MDQ6VXNlcjcwNjkyMjI=", "avatar_url": "https://avatars3.githubusercontent.com/u/7069222?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MtDersvan", "html_url": "https://github.com/MtDersvan", "followers_url": "https://api.github.com/users/MtDersvan/followers", "following_url": "https://api.github.com/users/MtDersvan/following{/other_user}", "gists_url": "https://api.github.com/users/MtDersvan/gists{/gist_id}", "starred_url": "https://api.github.com/users/MtDersvan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MtDersvan/subscriptions", "organizations_url": "https://api.github.com/users/MtDersvan/orgs", "repos_url": "https://api.github.com/users/MtDersvan/repos", "events_url": "https://api.github.com/users/MtDersvan/events{/privacy}", "received_events_url": "https://api.github.com/users/MtDersvan/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-13T00:37:49Z", "updated_at": "2018-01-13T00:37:49Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=6932348\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/yongtang\">@yongtang</a> Yes! I'm subscribed to that PR, and already looked at the kernel (and it looks nice, well done!). Kafka would be a nice option to have.<br>\nThe infrastructure, though, is scattered, and not well documented. For example, Is there a way to stream data directly from Apache Beam/Spark (or even Kafka) to a <code>tf.data.Dataset_from_generator()</code> without dumping data into <code>tfrecords</code> files?<br>\nMaybe just a simple streaming serialization support a la Tensorflow Serving's <code>predict_pb2.PredictRequest()</code>  +  <code>CopyFrom(make_tensor_proto(SerializeToString())</code> can do the trick, as it works really well? (it can still be a <code>tf.Example</code>, <code>tf.SequenceExample</code> proto but in a more convenient online way)</p>", "body_text": "@yongtang Yes! I'm subscribed to that PR, and already looked at the kernel (and it looks nice, well done!). Kafka would be a nice option to have.\nThe infrastructure, though, is scattered, and not well documented. For example, Is there a way to stream data directly from Apache Beam/Spark (or even Kafka) to a tf.data.Dataset_from_generator() without dumping data into tfrecords files?\nMaybe just a simple streaming serialization support a la Tensorflow Serving's predict_pb2.PredictRequest()  +  CopyFrom(make_tensor_proto(SerializeToString()) can do the trick, as it works really well? (it can still be a tf.Example, tf.SequenceExample proto but in a more convenient online way)", "body": "@yongtang Yes! I'm subscribed to that PR, and already looked at the kernel (and it looks nice, well done!). Kafka would be a nice option to have.\r\nThe infrastructure, though, is scattered, and not well documented. For example, Is there a way to stream data directly from Apache Beam/Spark (or even Kafka) to a `tf.data.Dataset_from_generator()` without dumping data into `tfrecords` files? \r\nMaybe just a simple streaming serialization support a la Tensorflow Serving's `predict_pb2.PredictRequest()`  +  `CopyFrom(make_tensor_proto(SerializeToString())` can do the trick, as it works really well? (it can still be a `tf.Example`, `tf.SequenceExample` proto but in a more convenient online way)"}