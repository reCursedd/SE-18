{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/386325951", "html_url": "https://github.com/tensorflow/tensorflow/issues/8421#issuecomment-386325951", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8421", "id": 386325951, "node_id": "MDEyOklzc3VlQ29tbWVudDM4NjMyNTk1MQ==", "user": {"login": "kirk86", "id": 2902390, "node_id": "MDQ6VXNlcjI5MDIzOTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/2902390?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kirk86", "html_url": "https://github.com/kirk86", "followers_url": "https://api.github.com/users/kirk86/followers", "following_url": "https://api.github.com/users/kirk86/following{/other_user}", "gists_url": "https://api.github.com/users/kirk86/gists{/gist_id}", "starred_url": "https://api.github.com/users/kirk86/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kirk86/subscriptions", "organizations_url": "https://api.github.com/users/kirk86/orgs", "repos_url": "https://api.github.com/users/kirk86/repos", "events_url": "https://api.github.com/users/kirk86/events{/privacy}", "received_events_url": "https://api.github.com/users/kirk86/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-03T15:00:16Z", "updated_at": "2018-05-03T15:00:16Z", "author_association": "NONE", "body_html": "<p>I have kind of the same problem, installing from source gives the following error</p>\n<pre><code>Target //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 384.280s, Critical Path: 107.73s\nFAILED: Build did NOT complete successfully\n</code></pre>\n<p>Digging a bit dipper I found multiple errors:</p>\n<pre><code>ERROR: /home/kirk/tensorflow/tensorflow/contrib/mpi_collectives/BUILD:40:1: C++ compilation of rule '//tensorflow/contrib/mpi_collectives:python/ops/_mpi_ops.so' failed (Exit 1)\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:76:18: error: 'se' does not name a type\n using StatusOr = se::port::StatusOr&lt;T&gt;;\n                  ^~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:28: error: 'StatusOr' was not declared in this scope\n typedef std::function&lt;void(StatusOr&lt;Tensor&gt;)&gt; CommunicationDoneCallback;\n                            ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:28: note: suggested alternatives:\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\n using StatusOr = ::xla::StatusOr&lt;T&gt;;\n                                    ^\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\n                 from ./tensorflow/stream_executor/dnn.h:33,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\n class StatusOr : private internal_statusor::StatusOrData&lt;T&gt;,\n       ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:45: error: template argument 1 is invalid\n typedef std::function&lt;void(StatusOr&lt;Tensor&gt;)&gt; CommunicationDoneCallback;\n                                             ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In function 'void tensorflow::contrib::mpi_collectives::{anonymous}::PerformCollectiveOp(tensorflow::contrib::mpi_collectives::{anonymous}::TensorTable&amp;, tensorflow::contrib::mpi_collectives::MPIResponse)':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:14: error: 'StatusOr' was not declared in this scope\n     callback(StatusOr&lt;Tensor&gt;(*output_tensor));\n              ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:14: note: suggested alternatives:\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\n using StatusOr = ::xla::StatusOr&lt;T&gt;;\n                                    ^\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\n                 from ./tensorflow/stream_executor/dnn.h:33,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\n class StatusOr : private internal_statusor::StatusOrData&lt;T&gt;,\n       ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:29: error: expected primary-expression before '&gt;' token\n     callback(StatusOr&lt;Tensor&gt;(*output_tensor));\n                             ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:46: error: 'callback' cannot be used as a function\n     callback(StatusOr&lt;Tensor&gt;(*output_tensor));\n                                              ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:14: error: 'StatusOr' was not declared in this scope\n     callback(StatusOr&lt;Tensor&gt;(status));\n              ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:14: note: suggested alternatives:\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\n using StatusOr = ::xla::StatusOr&lt;T&gt;;\n                                    ^\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\n                 from ./tensorflow/stream_executor/dnn.h:33,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\n class StatusOr : private internal_statusor::StatusOrData&lt;T&gt;,\n       ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:29: error: expected primary-expression before '&gt;' token\n     callback(StatusOr&lt;Tensor&gt;(status));\n                             ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:38: error: 'callback' cannot be used as a function\n     callback(StatusOr&lt;Tensor&gt;(status));\n                                      ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In member function 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback)':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:997:52: error: 'StatusOr' has not been declared\n     auto allreduce_done_callback = [done, context](StatusOr&lt;Tensor&gt; status) {\n                                                    ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:997:60: error: expected ',' or '...' before '&lt;' token\n     auto allreduce_done_callback = [done, context](StatusOr&lt;Tensor&gt; status) {\n                                                            ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In lambda function:\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:998:26: error: 'status' was not declared in this scope\n       context-&gt;SetStatus(status.status());\n                          ^~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In member function 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback)':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1091:52: error: 'StatusOr' has not been declared\n     auto allgather_done_callback = [done, context](StatusOr&lt;Tensor&gt; status) {\n                                                    ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1091:60: error: expected ',' or '...' before '&lt;' token\n     auto allgather_done_callback = [done, context](StatusOr&lt;Tensor&gt; status) {\n                                                            ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In lambda function:\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1092:26: error: 'status' was not declared in this scope\n       context-&gt;SetStatus(status.status());\n                          ^~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1095:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda(int)&gt;' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allgather_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1108:32: error: invalid use of 'auto'\n       allgather_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of&lt;tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;()&gt;':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template&lt;class _Functor, class, class&gt; std::function&lt;_Res(_ArgTypes ...)&gt;::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;; &lt;template-parameter-1-2&gt; = void; &lt;template-parameter-1-3&gt; = &lt;missing&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct result_of&lt;_Functor(_ArgTypes...)&gt;\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct __result_of_success : __success_type&lt;_Tp&gt;\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;)'\n       stream-&gt;ThenDoHostCallback(allgather_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream&amp; stream_executor::Stream::ThenDoHostCallback(std::function&lt;void()&gt;)\n   Stream &amp;ThenDoHostCallback(std::function&lt;void()&gt; callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;' to 'std::function&lt;void()&gt;'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1095:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda(int)&gt;' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allgather_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1108:32: error: invalid use of 'auto'\n       allgather_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of&lt;tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;()&gt;':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template&lt;class _Functor, class, class&gt; std::function&lt;_Res(_ArgTypes ...)&gt;::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;; &lt;template-parameter-1-2&gt; = void; &lt;template-parameter-1-3&gt; = &lt;missing&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct result_of&lt;_Functor(_ArgTypes...)&gt;\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct __result_of_success : __success_type&lt;_Tp&gt;\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;)'\n       stream-&gt;ThenDoHostCallback(allgather_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream&amp; stream_executor::Stream::ThenDoHostCallback(std::function&lt;void()&gt;)\n   Stream &amp;ThenDoHostCallback(std::function&lt;void()&gt; callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;' to 'std::function&lt;void()&gt;'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1001:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda(int)&gt;' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allreduce_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1014:32: error: invalid use of 'auto'\n       allreduce_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of&lt;tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;()&gt;':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template&lt;class _Functor, class, class&gt; std::function&lt;_Res(_ArgTypes ...)&gt;::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;; &lt;template-parameter-1-2&gt; = void; &lt;template-parameter-1-3&gt; = &lt;missing&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct result_of&lt;_Functor(_ArgTypes...)&gt;\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct __result_of_success : __success_type&lt;_Tp&gt;\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;)'\n       stream-&gt;ThenDoHostCallback(allreduce_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream&amp; stream_executor::Stream::ThenDoHostCallback(std::function&lt;void()&gt;)\n   Stream &amp;ThenDoHostCallback(std::function&lt;void()&gt; callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;' to 'std::function&lt;void()&gt;'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1001:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda(int)&gt;' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allreduce_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1014:32: error: invalid use of 'auto'\n       allreduce_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of&lt;tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;()&gt;':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template&lt;class _Functor, class, class&gt; std::function&lt;_Res(_ArgTypes ...)&gt;::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;; &lt;template-parameter-1-2&gt; = void; &lt;template-parameter-1-3&gt; = &lt;missing&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct result_of&lt;_Functor(_ArgTypes...)&gt;\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl&lt;false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;&gt;::type'\n     struct __result_of_success : __success_type&lt;_Tp&gt;\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;&amp;)'\n       stream-&gt;ThenDoHostCallback(allreduce_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream&amp; stream_executor::Stream::ThenDoHostCallback(std::function&lt;void()&gt;)\n   Stream &amp;ThenDoHostCallback(std::function&lt;void()&gt; callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp&lt;Device&gt;::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function&lt;void()&gt;]::&lt;lambda()&gt;' to 'std::function&lt;void()&gt;'\n</code></pre>\n<p>On another note the installation instructions are not helpful if someone uses different distro other than ubuntu.</p>\n<p>Also I've noticed that during the configuration if you set up option to compile with mpi support then there is a problem in linking the correct files. The <code>configure.py</code> sript looks at <code>/usr/lib/libmpi.so</code> but my installation is located at <code>/usr/lib/openmpi/libmpi.so</code> which I had to configure manually.</p>\n<p>Now for the errors that are occurring dose anyone have any idea why do we get them?<br>\nMy baze version is 0.12 the latest release is 0.13? Does that have to do anything or is the gcc version. I have installed on my system 7 and version 6 but the error that I get are from compiling with version 6.</p>\n<p>I hope someone from the dev team can shed some light?</p>", "body_text": "I have kind of the same problem, installing from source gives the following error\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 384.280s, Critical Path: 107.73s\nFAILED: Build did NOT complete successfully\n\nDigging a bit dipper I found multiple errors:\nERROR: /home/kirk/tensorflow/tensorflow/contrib/mpi_collectives/BUILD:40:1: C++ compilation of rule '//tensorflow/contrib/mpi_collectives:python/ops/_mpi_ops.so' failed (Exit 1)\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:76:18: error: 'se' does not name a type\n using StatusOr = se::port::StatusOr<T>;\n                  ^~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:28: error: 'StatusOr' was not declared in this scope\n typedef std::function<void(StatusOr<Tensor>)> CommunicationDoneCallback;\n                            ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:28: note: suggested alternatives:\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\n using StatusOr = ::xla::StatusOr<T>;\n                                    ^\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\n                 from ./tensorflow/stream_executor/dnn.h:33,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\n class StatusOr : private internal_statusor::StatusOrData<T>,\n       ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:45: error: template argument 1 is invalid\n typedef std::function<void(StatusOr<Tensor>)> CommunicationDoneCallback;\n                                             ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In function 'void tensorflow::contrib::mpi_collectives::{anonymous}::PerformCollectiveOp(tensorflow::contrib::mpi_collectives::{anonymous}::TensorTable&, tensorflow::contrib::mpi_collectives::MPIResponse)':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:14: error: 'StatusOr' was not declared in this scope\n     callback(StatusOr<Tensor>(*output_tensor));\n              ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:14: note: suggested alternatives:\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\n using StatusOr = ::xla::StatusOr<T>;\n                                    ^\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\n                 from ./tensorflow/stream_executor/dnn.h:33,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\n class StatusOr : private internal_statusor::StatusOrData<T>,\n       ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:29: error: expected primary-expression before '>' token\n     callback(StatusOr<Tensor>(*output_tensor));\n                             ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:46: error: 'callback' cannot be used as a function\n     callback(StatusOr<Tensor>(*output_tensor));\n                                              ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:14: error: 'StatusOr' was not declared in this scope\n     callback(StatusOr<Tensor>(status));\n              ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:14: note: suggested alternatives:\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\n using StatusOr = ::xla::StatusOr<T>;\n                                    ^\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\n                 from ./tensorflow/stream_executor/dnn.h:33,\n                 from ./tensorflow/stream_executor/stream.h:30,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\n class StatusOr : private internal_statusor::StatusOrData<T>,\n       ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:29: error: expected primary-expression before '>' token\n     callback(StatusOr<Tensor>(status));\n                             ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:38: error: 'callback' cannot be used as a function\n     callback(StatusOr<Tensor>(status));\n                                      ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In member function 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback)':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:997:52: error: 'StatusOr' has not been declared\n     auto allreduce_done_callback = [done, context](StatusOr<Tensor> status) {\n                                                    ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:997:60: error: expected ',' or '...' before '<' token\n     auto allreduce_done_callback = [done, context](StatusOr<Tensor> status) {\n                                                            ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In lambda function:\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:998:26: error: 'status' was not declared in this scope\n       context->SetStatus(status.status());\n                          ^~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In member function 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback)':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1091:52: error: 'StatusOr' has not been declared\n     auto allgather_done_callback = [done, context](StatusOr<Tensor> status) {\n                                                    ^~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1091:60: error: expected ',' or '...' before '<' token\n     auto allgather_done_callback = [done, context](StatusOr<Tensor> status) {\n                                                            ^\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In lambda function:\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1092:26: error: 'status' was not declared in this scope\n       context->SetStatus(status.status());\n                          ^~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1095:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allgather_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1108:32: error: invalid use of 'auto'\n       allgather_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct result_of<_Functor(_ArgTypes...)>\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct __result_of_success : __success_type<_Tp>\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\n       stream->ThenDoHostCallback(allgather_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\n   Stream &ThenDoHostCallback(std::function<void()> callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1095:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allgather_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1108:32: error: invalid use of 'auto'\n       allgather_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct result_of<_Functor(_ArgTypes...)>\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct __result_of_success : __success_type<_Tp>\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\n       stream->ThenDoHostCallback(allgather_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\n   Stream &ThenDoHostCallback(std::function<void()> callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1001:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allreduce_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1014:32: error: invalid use of 'auto'\n       allreduce_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct result_of<_Functor(_ArgTypes...)>\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct __result_of_success : __success_type<_Tp>\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\n       stream->ThenDoHostCallback(allreduce_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\n   Stream &ThenDoHostCallback(std::function<void()> callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1001:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\n     record.callback = allreduce_done_callback;\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1014:32: error: invalid use of 'auto'\n       allreduce_launch_callback();\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct result_of<_Functor(_ArgTypes...)>\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\n     struct __result_of_success : __success_type<_Tp>\n            ^~~~~~~~~~~~~~~~~~~\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\n       stream->ThenDoHostCallback(allreduce_launch_callback);\n       ^~~~~~\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\n   Stream &ThenDoHostCallback(std::function<void()> callback);\n           ^~~~~~~~~~~~~~~~~~\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\n\nOn another note the installation instructions are not helpful if someone uses different distro other than ubuntu.\nAlso I've noticed that during the configuration if you set up option to compile with mpi support then there is a problem in linking the correct files. The configure.py sript looks at /usr/lib/libmpi.so but my installation is located at /usr/lib/openmpi/libmpi.so which I had to configure manually.\nNow for the errors that are occurring dose anyone have any idea why do we get them?\nMy baze version is 0.12 the latest release is 0.13? Does that have to do anything or is the gcc version. I have installed on my system 7 and version 6 but the error that I get are from compiling with version 6.\nI hope someone from the dev team can shed some light?", "body": "I have kind of the same problem, installing from source gives the following error\r\n\r\n```\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 384.280s, Critical Path: 107.73s\r\nFAILED: Build did NOT complete successfully\r\n```\r\nDigging a bit dipper I found multiple errors:\r\n```\r\nERROR: /home/kirk/tensorflow/tensorflow/contrib/mpi_collectives/BUILD:40:1: C++ compilation of rule '//tensorflow/contrib/mpi_collectives:python/ops/_mpi_ops.so' failed (Exit 1)\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:76:18: error: 'se' does not name a type\r\n using StatusOr = se::port::StatusOr<T>;\r\n                  ^~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:28: error: 'StatusOr' was not declared in this scope\r\n typedef std::function<void(StatusOr<Tensor>)> CommunicationDoneCallback;\r\n                            ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:28: note: suggested alternatives:\r\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\r\n                 from ./tensorflow/stream_executor/stream.h:30,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\r\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\r\n using StatusOr = ::xla::StatusOr<T>;\r\n                                    ^\r\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\r\n                 from ./tensorflow/stream_executor/dnn.h:33,\r\n                 from ./tensorflow/stream_executor/stream.h:30,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\r\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\r\n class StatusOr : private internal_statusor::StatusOrData<T>,\r\n       ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:139:45: error: template argument 1 is invalid\r\n typedef std::function<void(StatusOr<Tensor>)> CommunicationDoneCallback;\r\n                                             ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In function 'void tensorflow::contrib::mpi_collectives::{anonymous}::PerformCollectiveOp(tensorflow::contrib::mpi_collectives::{anonymous}::TensorTable&, tensorflow::contrib::mpi_collectives::MPIResponse)':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:14: error: 'StatusOr' was not declared in this scope\r\n     callback(StatusOr<Tensor>(*output_tensor));\r\n              ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:14: note: suggested alternatives:\r\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\r\n                 from ./tensorflow/stream_executor/stream.h:30,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\r\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\r\n using StatusOr = ::xla::StatusOr<T>;\r\n                                    ^\r\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\r\n                 from ./tensorflow/stream_executor/dnn.h:33,\r\n                 from ./tensorflow/stream_executor/stream.h:30,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\r\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\r\n class StatusOr : private internal_statusor::StatusOrData<T>,\r\n       ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:29: error: expected primary-expression before '>' token\r\n     callback(StatusOr<Tensor>(*output_tensor));\r\n                             ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:512:46: error: 'callback' cannot be used as a function\r\n     callback(StatusOr<Tensor>(*output_tensor));\r\n                                              ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:14: error: 'StatusOr' was not declared in this scope\r\n     callback(StatusOr<Tensor>(status));\r\n              ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:14: note: suggested alternatives:\r\nIn file included from ./tensorflow/stream_executor/dnn.h:33:0,\r\n                 from ./tensorflow/stream_executor/stream.h:30,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\r\n./tensorflow/stream_executor/lib/statusor.h:28:36: note:   'stream_executor::port::StatusOr'\r\n using StatusOr = ::xla::StatusOr<T>;\r\n                                    ^\r\nIn file included from ./tensorflow/stream_executor/lib/statusor.h:21:0,\r\n                 from ./tensorflow/stream_executor/dnn.h:33,\r\n                 from ./tensorflow/stream_executor/stream.h:30,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:\r\n./tensorflow/compiler/xla/statusor.h:87:7: note:   'xla::StatusOr'\r\n class StatusOr : private internal_statusor::StatusOrData<T>,\r\n       ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:29: error: expected primary-expression before '>' token\r\n     callback(StatusOr<Tensor>(status));\r\n                             ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:514:38: error: 'callback' cannot be used as a function\r\n     callback(StatusOr<Tensor>(status));\r\n                                      ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In member function 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback)':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:997:52: error: 'StatusOr' has not been declared\r\n     auto allreduce_done_callback = [done, context](StatusOr<Tensor> status) {\r\n                                                    ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:997:60: error: expected ',' or '...' before '<' token\r\n     auto allreduce_done_callback = [done, context](StatusOr<Tensor> status) {\r\n                                                            ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In lambda function:\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:998:26: error: 'status' was not declared in this scope\r\n       context->SetStatus(status.status());\r\n                          ^~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In member function 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback)':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1091:52: error: 'StatusOr' has not been declared\r\n     auto allgather_done_callback = [done, context](StatusOr<Tensor> status) {\r\n                                                    ^~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1091:60: error: expected ',' or '...' before '<' token\r\n     auto allgather_done_callback = [done, context](StatusOr<Tensor> status) {\r\n                                                            ^\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In lambda function:\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1092:26: error: 'status' was not declared in this scope\r\n       context->SetStatus(status.status());\r\n                          ^~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1095:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\r\n     record.callback = allgather_done_callback;\r\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1108:32: error: invalid use of 'auto'\r\n       allgather_launch_callback();\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\r\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct result_of<_Functor(_ArgTypes...)>\r\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct __result_of_success : __success_type<_Tp>\r\n            ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\r\n       stream->ThenDoHostCallback(allgather_launch_callback);\r\n       ^~~~~~\r\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\r\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\r\n   Stream &ThenDoHostCallback(std::function<void()> callback);\r\n           ^~~~~~~~~~~~~~~~~~\r\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1095:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\r\n     record.callback = allgather_done_callback;\r\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1108:32: error: invalid use of 'auto'\r\n       allgather_launch_callback();\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\r\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct result_of<_Functor(_ArgTypes...)>\r\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct __result_of_success : __success_type<_Tp>\r\n            ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1111:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\r\n       stream->ThenDoHostCallback(allgather_launch_callback);\r\n       ^~~~~~\r\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\r\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\r\n   Stream &ThenDoHostCallback(std::function<void()> callback);\r\n           ^~~~~~~~~~~~~~~~~~\r\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllgatherOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1001:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\r\n     record.callback = allreduce_done_callback;\r\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1014:32: error: invalid use of 'auto'\r\n       allreduce_launch_callback();\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\r\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct result_of<_Functor(_ArgTypes...)>\r\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct __result_of_success : __success_type<_Tp>\r\n            ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\r\n       stream->ThenDoHostCallback(allreduce_launch_callback);\r\n       ^~~~~~\r\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\r\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\r\n   Stream &ThenDoHostCallback(std::function<void()> callback);\r\n           ^~~~~~~~~~~~~~~~~~\r\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::GpuDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1001:21: error: cannot convert 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda(int)>' to 'tensorflow::contrib::mpi_collectives::{anonymous}::CommunicationDoneCallback {aka int}' in assignment\r\n     record.callback = allreduce_done_callback;\r\n     ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1014:32: error: invalid use of 'auto'\r\n       allreduce_launch_callback();\r\n       ~~~~~~~~~~~~~~~~~~~~~~~~~^~\r\nIn file included from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/move.h:57:0,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_pair.h:59,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/bits/stl_algobase.h:64,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/deque:60,\r\n                 from /usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/queue:60,\r\n                 from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:18:\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits: In instantiation of 'class std::result_of<tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&()>':\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/functional:1913:9:   required by substitution of 'template<class _Functor, class, class> std::function<_Res(_ArgTypes ...)>::function(_Functor) [with _Functor = tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>; <template-parameter-1-2> = void; <template-parameter-1-3> = <missing>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7:   required from 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]'\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2496:12: error: invalid use of incomplete type 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct result_of<_Functor(_ArgTypes...)>\r\n            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n/usr/lib/gcc/x86_64-pc-linux-gnu/6.4.1/include/c++/type_traits:2291:12: note: declaration of 'std::__result_of_impl<false, false, tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&>::type'\r\n     struct __result_of_success : __success_type<_Tp>\r\n            ^~~~~~~~~~~~~~~~~~~\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc: In instantiation of 'void tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]':\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1130:1:   required from here\r\ntensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:1017:7: error: no matching function for call to 'stream_executor::Stream::ThenDoHostCallback(tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>&)'\r\n       stream->ThenDoHostCallback(allreduce_launch_callback);\r\n       ^~~~~~\r\nIn file included from tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:31:0:\r\n./tensorflow/stream_executor/stream.h:1987:11: note: candidate: stream_executor::Stream& stream_executor::Stream::ThenDoHostCallback(std::function<void()>)\r\n   Stream &ThenDoHostCallback(std::function<void()> callback);\r\n           ^~~~~~~~~~~~~~~~~~\r\n./tensorflow/stream_executor/stream.h:1987:11: note:   no known conversion for argument 1 from 'tensorflow::contrib::mpi_collectives::MPIAllreduceOp<Device>::ComputeAsync(tensorflow::OpKernelContext*, tensorflow::AsyncOpKernel::DoneCallback) [with Device = Eigen::ThreadPoolDevice; tensorflow::AsyncOpKernel::DoneCallback = std::function<void()>]::<lambda()>' to 'std::function<void()>'\r\n```\r\n\r\nOn another note the installation instructions are not helpful if someone uses different distro other than ubuntu.\r\n\r\nAlso I've noticed that during the configuration if you set up option to compile with mpi support then there is a problem in linking the correct files. The `configure.py` sript looks at `/usr/lib/libmpi.so` but my installation is located at `/usr/lib/openmpi/libmpi.so` which I had to configure manually.\r\n\r\nNow for the errors that are occurring dose anyone have any idea why do we get them?\r\nMy baze version is 0.12 the latest release is 0.13? Does that have to do anything or is the gcc version. I have installed on my system 7 and version 6 but the error that I get are from compiling with version 6.\r\n\r\nI hope someone from the dev team can shed some light?"}