{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/300677574", "html_url": "https://github.com/tensorflow/tensorflow/issues/9744#issuecomment-300677574", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9744", "id": 300677574, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMDY3NzU3NA==", "user": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-11T04:13:13Z", "updated_at": "2017-05-11T04:13:13Z", "author_association": "MEMBER", "body_html": "<blockquote>\n<p>I am curious why setting kernel_initializer=init_ops.glorot_uniform_initializer() there wouldn't have an effect?</p>\n</blockquote>\n<p>We should avoid instantiating anything in a class constructor signature, because the instance becomes global to all instances of the class. There are no immediate side effects in this case but it is bad practice and potentially dangerous for the user. For the same reason <code>bias_initializer=init_ops.zeros_initializer()</code>  should be avoided, but it is there for legacy reasons.</p>\n<p>We should instantiate the initializers in the <code>__init__</code> of the class (so as to create new objects for every layer instance rather than a shared object everywhere). Keras achieves this by using default <code>initializer</code> argument values that are serial, i.e. that are simply the names of the initializers, which are then instantiated in the <code>__init__</code>.</p>", "body_text": "I am curious why setting kernel_initializer=init_ops.glorot_uniform_initializer() there wouldn't have an effect?\n\nWe should avoid instantiating anything in a class constructor signature, because the instance becomes global to all instances of the class. There are no immediate side effects in this case but it is bad practice and potentially dangerous for the user. For the same reason bias_initializer=init_ops.zeros_initializer()  should be avoided, but it is there for legacy reasons.\nWe should instantiate the initializers in the __init__ of the class (so as to create new objects for every layer instance rather than a shared object everywhere). Keras achieves this by using default initializer argument values that are serial, i.e. that are simply the names of the initializers, which are then instantiated in the __init__.", "body": "> I am curious why setting kernel_initializer=init_ops.glorot_uniform_initializer() there wouldn't have an effect?\r\n\r\nWe should avoid instantiating anything in a class constructor signature, because the instance becomes global to all instances of the class. There are no immediate side effects in this case but it is bad practice and potentially dangerous for the user. For the same reason `bias_initializer=init_ops.zeros_initializer()`  should be avoided, but it is there for legacy reasons.\r\n\r\nWe should instantiate the initializers in the `__init__` of the class (so as to create new objects for every layer instance rather than a shared object everywhere). Keras achieves this by using default `initializer` argument values that are serial, i.e. that are simply the names of the initializers, which are then instantiated in the `__init__`.\r\n"}