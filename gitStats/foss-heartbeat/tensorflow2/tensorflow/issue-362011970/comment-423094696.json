{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/423094696", "html_url": "https://github.com/tensorflow/tensorflow/issues/22401#issuecomment-423094696", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22401", "id": 423094696, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMzA5NDY5Ng==", "user": {"login": "EwoutH", "id": 15776622, "node_id": "MDQ6VXNlcjE1Nzc2NjIy", "avatar_url": "https://avatars3.githubusercontent.com/u/15776622?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EwoutH", "html_url": "https://github.com/EwoutH", "followers_url": "https://api.github.com/users/EwoutH/followers", "following_url": "https://api.github.com/users/EwoutH/following{/other_user}", "gists_url": "https://api.github.com/users/EwoutH/gists{/gist_id}", "starred_url": "https://api.github.com/users/EwoutH/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EwoutH/subscriptions", "organizations_url": "https://api.github.com/users/EwoutH/orgs", "repos_url": "https://api.github.com/users/EwoutH/repos", "events_url": "https://api.github.com/users/EwoutH/events{/privacy}", "received_events_url": "https://api.github.com/users/EwoutH/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-20T08:38:09Z", "updated_at": "2018-09-20T08:38:09Z", "author_association": "NONE", "body_html": "<p>In addition, <a href=\"https://developer.nvidia.com/tensorrt#tensorrt-whats-new\" rel=\"nofollow\">TensorRT 5</a></p>\n<blockquote>\n<p><strong>What's New in TensorRT 5 and TensorRT inference server</strong><br>\nTensorRT 5 delivers up to 40x faster inference over CPU-only platforms through support for Turing GPUs, new INT8 APIs and optimizations. It uses multi-precision compute to dramatically speed up recommenders, neural machine translation, speech and natural language processing. With TensorRT 5, you can:</p>\n<ul>\n<li>Speed up inference by 40x over CPUs for models such as translation using mixed precision on Turing Tensor Cores</li>\n<li>Optimize inference models with new INT8 APIs and optimizations</li>\n<li>Deploy applications to Xavier-based NVIDIA Drive platforms and the NVIDIA DLA accelerator (FP16 only)</li>\n</ul>\n<p>In addition, TensorRT 5 supports Windows and the CentOS Operating System. TensorRT 5 RC is available for download now to members of the NVIDIA Developer Program.</p>\n</blockquote>", "body_text": "In addition, TensorRT 5\n\nWhat's New in TensorRT 5 and TensorRT inference server\nTensorRT 5 delivers up to 40x faster inference over CPU-only platforms through support for Turing GPUs, new INT8 APIs and optimizations. It uses multi-precision compute to dramatically speed up recommenders, neural machine translation, speech and natural language processing. With TensorRT 5, you can:\n\nSpeed up inference by 40x over CPUs for models such as translation using mixed precision on Turing Tensor Cores\nOptimize inference models with new INT8 APIs and optimizations\nDeploy applications to Xavier-based NVIDIA Drive platforms and the NVIDIA DLA accelerator (FP16 only)\n\nIn addition, TensorRT 5 supports Windows and the CentOS Operating System. TensorRT 5 RC is available for download now to members of the NVIDIA Developer Program.", "body": "In addition, [TensorRT 5](https://developer.nvidia.com/tensorrt#tensorrt-whats-new)\r\n\r\n> **What's New in TensorRT 5 and TensorRT inference server**\r\n> TensorRT 5 delivers up to 40x faster inference over CPU-only platforms through support for Turing GPUs, new INT8 APIs and optimizations. It uses multi-precision compute to dramatically speed up recommenders, neural machine translation, speech and natural language processing. With TensorRT 5, you can:\r\n> - Speed up inference by 40x over CPUs for models such as translation using mixed precision on Turing Tensor Cores\r\n> - Optimize inference models with new INT8 APIs and optimizations\r\n> - Deploy applications to Xavier-based NVIDIA Drive platforms and the NVIDIA DLA accelerator (FP16 only)\r\n> \r\n> In addition, TensorRT 5 supports Windows and the CentOS Operating System. TensorRT 5 RC is available for download now to members of the NVIDIA Developer Program."}