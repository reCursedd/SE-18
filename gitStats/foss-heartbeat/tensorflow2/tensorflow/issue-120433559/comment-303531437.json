{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/303531437", "html_url": "https://github.com/tensorflow/tensorflow/issues/410#issuecomment-303531437", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/410", "id": 303531437, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzUzMTQzNw==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-23T21:03:04Z", "updated_at": "2017-05-23T21:03:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1629692\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/CJxD\">@CJxD</a> It's possible that the new <code>tf.contrib.data</code> module could solve your problem. It's available in TensorFlow 1.2rc0, and there is some preliminary documentation here:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/README.md\">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/README.md</a></p>\n<p>Assuming you have two text files, line delimited, I think the solution would look something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre>image_filenames <span class=\"pl-k\">=</span> tf.contrib.data.TextLineDataset(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>image_index.txt<span class=\"pl-pds\">\"</span></span>)\nimages <span class=\"pl-k\">=</span> image_filenames.map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">filename</span>: tf.image.decode_image(tf.read_file(filename)))\noutput_target_strings <span class=\"pl-k\">=</span> tf.contrib.data.TextLineDataset(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output_targets.txt<span class=\"pl-pds\">\"</span></span>)\noutput_target_values <span class=\"pl-k\">=</span> output_target_strings.map(<span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">target</span>: <span class=\"pl-c1\">...</span>)  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Insert type conversion code here.</span>\n\ncombined <span class=\"pl-k\">=</span> tf.contrib.data.Dataset.zip((images, output_targets)).repeat().batch(<span class=\"pl-c1\">BATCH_SIZE</span>)\niterator <span class=\"pl-k\">=</span> combined.make_one_shot_iterator()\nnext_element <span class=\"pl-k\">=</span> iterator.get_next()\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span></pre></div>\n<p>Note that building everything into a TFRecord file would have better I/O characteristics as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=719020\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/panmari\">@panmari</a> notes, but this might work well for initial experimentation.</p>", "body_text": "@CJxD It's possible that the new tf.contrib.data module could solve your problem. It's available in TensorFlow 1.2rc0, and there is some preliminary documentation here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/README.md\nAssuming you have two text files, line delimited, I think the solution would look something like this:\nimage_filenames = tf.contrib.data.TextLineDataset(\"image_index.txt\")\nimages = image_filenames.map(lambda filename: tf.image.decode_image(tf.read_file(filename)))\noutput_target_strings = tf.contrib.data.TextLineDataset(\"output_targets.txt\")\noutput_target_values = output_target_strings.map(lambda target: ...)  # Insert type conversion code here.\n\ncombined = tf.contrib.data.Dataset.zip((images, output_targets)).repeat().batch(BATCH_SIZE)\niterator = combined.make_one_shot_iterator()\nnext_element = iterator.get_next()\n# ...\nNote that building everything into a TFRecord file would have better I/O characteristics as @panmari notes, but this might work well for initial experimentation.", "body": "@CJxD It's possible that the new `tf.contrib.data` module could solve your problem. It's available in TensorFlow 1.2rc0, and there is some preliminary documentation here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/README.md\r\n\r\nAssuming you have two text files, line delimited, I think the solution would look something like this:\r\n\r\n```python\r\nimage_filenames = tf.contrib.data.TextLineDataset(\"image_index.txt\")\r\nimages = image_filenames.map(lambda filename: tf.image.decode_image(tf.read_file(filename)))\r\noutput_target_strings = tf.contrib.data.TextLineDataset(\"output_targets.txt\")\r\noutput_target_values = output_target_strings.map(lambda target: ...)  # Insert type conversion code here.\r\n\r\ncombined = tf.contrib.data.Dataset.zip((images, output_targets)).repeat().batch(BATCH_SIZE)\r\niterator = combined.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n# ...\r\n```\r\n\r\nNote that building everything into a TFRecord file would have better I/O characteristics as @panmari notes, but this might work well for initial experimentation."}