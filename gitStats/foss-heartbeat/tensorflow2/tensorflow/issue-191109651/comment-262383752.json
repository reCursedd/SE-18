{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262383752", "html_url": "https://github.com/tensorflow/tensorflow/issues/5789#issuecomment-262383752", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789", "id": 262383752, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjM4Mzc1Mg==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-22T22:22:52Z", "updated_at": "2016-11-22T22:22:52Z", "author_association": "MEMBER", "body_html": "<p>We are able to run TF on machines that have 8 k80 cards, which appear as 16 GPUs, 8 GPUs (4 cards) on each of two separate PCIe buses (each bus connected to one CPU socket).  In this configuration cudaDeviceCanAccessPeer returns false for GPUs on different buses, so cudaDeviceEnablePeerAccess gets called only for GPUs on the same bus.  I'm guessing that your system architecture is different, so that cudaDeviceCanAccessPeer returns true for all pairs among 16 GPUs.  In that case you're going to need to restrict visibility of the GPUs within a process to 8, as discussed in <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"186925619\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5362\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5362/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5362\">#5362</a>.</p>", "body_text": "We are able to run TF on machines that have 8 k80 cards, which appear as 16 GPUs, 8 GPUs (4 cards) on each of two separate PCIe buses (each bus connected to one CPU socket).  In this configuration cudaDeviceCanAccessPeer returns false for GPUs on different buses, so cudaDeviceEnablePeerAccess gets called only for GPUs on the same bus.  I'm guessing that your system architecture is different, so that cudaDeviceCanAccessPeer returns true for all pairs among 16 GPUs.  In that case you're going to need to restrict visibility of the GPUs within a process to 8, as discussed in #5362.", "body": "We are able to run TF on machines that have 8 k80 cards, which appear as 16 GPUs, 8 GPUs (4 cards) on each of two separate PCIe buses (each bus connected to one CPU socket).  In this configuration cudaDeviceCanAccessPeer returns false for GPUs on different buses, so cudaDeviceEnablePeerAccess gets called only for GPUs on the same bus.  I'm guessing that your system architecture is different, so that cudaDeviceCanAccessPeer returns true for all pairs among 16 GPUs.  In that case you're going to need to restrict visibility of the GPUs within a process to 8, as discussed in #5362.  "}