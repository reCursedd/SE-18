{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/309082578", "html_url": "https://github.com/tensorflow/tensorflow/issues/5789#issuecomment-309082578", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789", "id": 309082578, "node_id": "MDEyOklzc3VlQ29tbWVudDMwOTA4MjU3OA==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-06-16T17:13:23Z", "updated_at": "2017-06-16T17:13:23Z", "author_association": "MEMBER", "body_html": "<p>Closing.  NCCL is the solution NVIDIA created to help navigate this issue but it is not always the right choice.  I did not do a lot of testing on the p2.16x large but in testing on a variety of sytems 4x Titan X, 8x k80 on GCE, 8x K80 on AWS and 8x P100 on DGX-1 I found the approach for how to deal with variable update ranges and is also different based on the model.  The results are <a href=\"https://www.tensorflow.org/performance/benchmarks\" rel=\"nofollow\">here</a>, which also contains links to details about different approaches of variable management.  At this point the p2.16xlarge is not as desirable as 8x P100s, which work well with NCCL or just CPU as the variable CPU.</p>", "body_text": "Closing.  NCCL is the solution NVIDIA created to help navigate this issue but it is not always the right choice.  I did not do a lot of testing on the p2.16x large but in testing on a variety of sytems 4x Titan X, 8x k80 on GCE, 8x K80 on AWS and 8x P100 on DGX-1 I found the approach for how to deal with variable update ranges and is also different based on the model.  The results are here, which also contains links to details about different approaches of variable management.  At this point the p2.16xlarge is not as desirable as 8x P100s, which work well with NCCL or just CPU as the variable CPU.", "body": "Closing.  NCCL is the solution NVIDIA created to help navigate this issue but it is not always the right choice.  I did not do a lot of testing on the p2.16x large but in testing on a variety of sytems 4x Titan X, 8x k80 on GCE, 8x K80 on AWS and 8x P100 on DGX-1 I found the approach for how to deal with variable update ranges and is also different based on the model.  The results are [here](https://www.tensorflow.org/performance/benchmarks), which also contains links to details about different approaches of variable management.  At this point the p2.16xlarge is not as desirable as 8x P100s, which work well with NCCL or just CPU as the variable CPU.  "}