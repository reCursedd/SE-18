{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/331317909", "html_url": "https://github.com/tensorflow/tensorflow/issues/5789#issuecomment-331317909", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789", "id": 331317909, "node_id": "MDEyOklzc3VlQ29tbWVudDMzMTMxNzkwOQ==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-09-22T00:31:02Z", "updated_at": "2017-09-22T00:31:02Z", "author_association": "MEMBER", "body_html": "<div class=\"email-fragment\">Yeah, I realized I missed the mark with my comment.  16 gpus in one server\nis rare and at this point newer hardware makes the setup less interesting.\nI thought about it when I tested but I just did not find it useful as it is\nmore of an oddity.  P100s and V100s are very unlikely to ever be configured\nlike that and I do not think nvlink supports more than 8.  I end up wrong\nalot but when I am wrong I will benchmark it.  :-).</div>\n<span class=\"email-hidden-toggle\"><a href=\"#\">\u2026</a></span><div class=\"email-hidden-reply\">\n<div class=\"email-quoted-reply\">On Sep 21, 2017 5:17 PM, \"Bairen Yi\" ***@***.***&gt; wrote:\n <a class=\"user-mention\" href=\"https://github.com/tfboyd\">@tfboyd</a> &lt;<a href=\"https://github.com/tfboyd\">https://github.com/tfboyd</a>&gt; Thanks for the heads up!\n\n I'm actually quite interested in the 16 GPUs setup on AWS. All to all\n peering seems to be unlikely as those 16 GPUs are not connected directly\n through a single PCIe switch (according to Mu Li's PhD thesis).\n\n Any reason why we don't have single node 16 GPUs benchmark result included\n in the TF CNN benchmarks page?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n &lt;<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"191109651\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5789\" href=\"https://github.com/tensorflow/tensorflow/issues/5789#issuecomment-331315735\">#5789 (comment)</a>&gt;,\n or mute the thread\n &lt;<a href=\"https://github.com/notifications/unsubscribe-auth/AWZesp6p_wUYrWXWBrorsdu2CK7Ygivcks5skvy1gaJpZM4K54NB\">https://github.com/notifications/unsubscribe-auth/AWZesp6p_wUYrWXWBrorsdu2CK7Ygivcks5skvy1gaJpZM4K54NB</a>&gt;\n .\n</div>\n<div class=\"email-fragment\"></div>\n</div>", "body_text": "Yeah, I realized I missed the mark with my comment.  16 gpus in one server\nis rare and at this point newer hardware makes the setup less interesting.\nI thought about it when I tested but I just did not find it useful as it is\nmore of an oddity.  P100s and V100s are very unlikely to ever be configured\nlike that and I do not think nvlink supports more than 8.  I end up wrong\nalot but when I am wrong I will benchmark it.  :-).\n\u2026\nOn Sep 21, 2017 5:17 PM, \"Bairen Yi\" ***@***.***> wrote:\n @tfboyd <https://github.com/tfboyd> Thanks for the heads up!\n\n I'm actually quite interested in the 16 GPUs setup on AWS. All to all\n peering seems to be unlikely as those 16 GPUs are not connected directly\n through a single PCIe switch (according to Mu Li's PhD thesis).\n\n Any reason why we don't have single node 16 GPUs benchmark result included\n in the TF CNN benchmarks page?\n\n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <#5789 (comment)>,\n or mute the thread\n <https://github.com/notifications/unsubscribe-auth/AWZesp6p_wUYrWXWBrorsdu2CK7Ygivcks5skvy1gaJpZM4K54NB>\n .", "body": "Yeah, I realized I missed the mark with my comment.  16 gpus in one server\nis rare and at this point newer hardware makes the setup less interesting.\nI thought about it when I tested but I just did not find it useful as it is\nmore of an oddity.  P100s and V100s are very unlikely to ever be configured\nlike that and I do not think nvlink supports more than 8.  I end up wrong\nalot but when I am wrong I will benchmark it.  :-).\n\nOn Sep 21, 2017 5:17 PM, \"Bairen Yi\" <notifications@github.com> wrote:\n\n> @tfboyd <https://github.com/tfboyd> Thanks for the heads up!\n>\n> I'm actually quite interested in the 16 GPUs setup on AWS. All to all\n> peering seems to be unlikely as those 16 GPUs are not connected directly\n> through a single PCIe switch (according to Mu Li's PhD thesis).\n>\n> Any reason why we don't have single node 16 GPUs benchmark result included\n> in the TF CNN benchmarks page?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/5789#issuecomment-331315735>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AWZesp6p_wUYrWXWBrorsdu2CK7Ygivcks5skvy1gaJpZM4K54NB>\n> .\n>\n"}