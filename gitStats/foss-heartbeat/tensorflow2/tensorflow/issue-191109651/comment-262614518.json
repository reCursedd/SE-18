{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/262614518", "html_url": "https://github.com/tensorflow/tensorflow/issues/5789#issuecomment-262614518", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789", "id": 262614518, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MjYxNDUxOA==", "user": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-23T19:50:41Z", "updated_at": "2016-11-23T19:50:41Z", "author_association": "MEMBER", "body_html": "<p>It seems difficult to have a nice, fully-automatic solution.  The consequence of enabling peer access is slightly faster inter-GPU memory copies, with less CPU memory interface contention.  If you're using 16 GPUs that can all feasibly be peered to each other, but only 8 can be with respect to any one, the choice of which ones are most useful to peer depends very much on how your model is structured, and maybe secondarily on the underlying system topology.   So, a useful contribution might be some kind of startup option that allows explicitly specifying which GPUs to peer, overriding the default behavior of trying to make every feasible peering.</p>", "body_text": "It seems difficult to have a nice, fully-automatic solution.  The consequence of enabling peer access is slightly faster inter-GPU memory copies, with less CPU memory interface contention.  If you're using 16 GPUs that can all feasibly be peered to each other, but only 8 can be with respect to any one, the choice of which ones are most useful to peer depends very much on how your model is structured, and maybe secondarily on the underlying system topology.   So, a useful contribution might be some kind of startup option that allows explicitly specifying which GPUs to peer, overriding the default behavior of trying to make every feasible peering.", "body": "It seems difficult to have a nice, fully-automatic solution.  The consequence of enabling peer access is slightly faster inter-GPU memory copies, with less CPU memory interface contention.  If you're using 16 GPUs that can all feasibly be peered to each other, but only 8 can be with respect to any one, the choice of which ones are most useful to peer depends very much on how your model is structured, and maybe secondarily on the underlying system topology.   So, a useful contribution might be some kind of startup option that allows explicitly specifying which GPUs to peer, overriding the default behavior of trying to make every feasible peering."}