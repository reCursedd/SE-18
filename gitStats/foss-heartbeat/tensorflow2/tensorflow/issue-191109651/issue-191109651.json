{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5789/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5789", "id": 191109651, "node_id": "MDU6SXNzdWUxOTExMDk2NTE=", "number": 5789, "title": "Improve CUDA peer to peer access to support Amazon P2 instances", "user": {"login": "Mistobaan", "id": 112599, "node_id": "MDQ6VXNlcjExMjU5OQ==", "avatar_url": "https://avatars1.githubusercontent.com/u/112599?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Mistobaan", "html_url": "https://github.com/Mistobaan", "followers_url": "https://api.github.com/users/Mistobaan/followers", "following_url": "https://api.github.com/users/Mistobaan/following{/other_user}", "gists_url": "https://api.github.com/users/Mistobaan/gists{/gist_id}", "starred_url": "https://api.github.com/users/Mistobaan/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Mistobaan/subscriptions", "organizations_url": "https://api.github.com/users/Mistobaan/orgs", "repos_url": "https://api.github.com/users/Mistobaan/repos", "events_url": "https://api.github.com/users/Mistobaan/events{/privacy}", "received_events_url": "https://api.github.com/users/Mistobaan/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "poxvoculi", "id": 15676913, "node_id": "MDQ6VXNlcjE1Njc2OTEz", "avatar_url": "https://avatars2.githubusercontent.com/u/15676913?v=4", "gravatar_id": "", "url": "https://api.github.com/users/poxvoculi", "html_url": "https://github.com/poxvoculi", "followers_url": "https://api.github.com/users/poxvoculi/followers", "following_url": "https://api.github.com/users/poxvoculi/following{/other_user}", "gists_url": "https://api.github.com/users/poxvoculi/gists{/gist_id}", "starred_url": "https://api.github.com/users/poxvoculi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/poxvoculi/subscriptions", "organizations_url": "https://api.github.com/users/poxvoculi/orgs", "repos_url": "https://api.github.com/users/poxvoculi/repos", "events_url": "https://api.github.com/users/poxvoculi/events{/privacy}", "received_events_url": "https://api.github.com/users/poxvoculi/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 15, "created_at": "2016-11-22T20:00:34Z", "updated_at": "2017-09-22T16:09:32Z", "closed_at": "2017-06-16T17:13:23Z", "author_association": "CONTRIBUTOR", "body_html": "<p>If you try to run Tensorflow on a machine that has more than 8 GPU you will receive an error or Warning saying: CUDA_ERROR_TOO_MANY_PEERS.</p>\n<p>From the Nvidia forums seems that this is documented behavior:</p>\n<p><a href=\"http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#peer-to-peer-memory-access\" rel=\"nofollow\">http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#peer-to-peer-memory-access</a></p>\n<blockquote>\n<p>Peer-to-peer memory access must be enabled between two devices by calling cudaDeviceEnablePeerAccess() as illustrated in the following code sample. Each device can support a system-wide maximum of eight peer connections.</p>\n</blockquote>\n<p>TF is doing a full NxN peer access map, each 16x16 and that would explain the error on 16 gpus machines.</p>\n<p>The challenge is figuring out which GPUs should peer with each other.<br>\nWe do the full NxN right now since we don't yet have a better answer about the physical topology of the devices.  (E.g., how do you know that the first 8 are all physically the first die, and the second 8 are all physically the second die?)  If such an API exists and we can query it reliably, that might be a better solution.</p>\n<p>All the code is in one file: gpu_device.cc</p>\n<p>related Issues:</p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"186925619\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/5362\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/5362/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/5362\">#5362</a></li>\n</ul>", "body_text": "If you try to run Tensorflow on a machine that has more than 8 GPU you will receive an error or Warning saying: CUDA_ERROR_TOO_MANY_PEERS.\nFrom the Nvidia forums seems that this is documented behavior:\nhttp://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#peer-to-peer-memory-access\n\nPeer-to-peer memory access must be enabled between two devices by calling cudaDeviceEnablePeerAccess() as illustrated in the following code sample. Each device can support a system-wide maximum of eight peer connections.\n\nTF is doing a full NxN peer access map, each 16x16 and that would explain the error on 16 gpus machines.\nThe challenge is figuring out which GPUs should peer with each other.\nWe do the full NxN right now since we don't yet have a better answer about the physical topology of the devices.  (E.g., how do you know that the first 8 are all physically the first die, and the second 8 are all physically the second die?)  If such an API exists and we can query it reliably, that might be a better solution.\nAll the code is in one file: gpu_device.cc\nrelated Issues:\n\n#5362", "body": "If you try to run Tensorflow on a machine that has more than 8 GPU you will receive an error or Warning saying: CUDA_ERROR_TOO_MANY_PEERS.\r\n\r\nFrom the Nvidia forums seems that this is documented behavior:\r\n\r\nhttp://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#peer-to-peer-memory-access\r\n\r\n> Peer-to-peer memory access must be enabled between two devices by calling cudaDeviceEnablePeerAccess() as illustrated in the following code sample. Each device can support a system-wide maximum of eight peer connections.\r\n\r\nTF is doing a full NxN peer access map, each 16x16 and that would explain the error on 16 gpus machines.\r\n\r\nThe challenge is figuring out which GPUs should peer with each other. \r\n We do the full NxN right now since we don't yet have a better answer about the physical topology of the devices.  (E.g., how do you know that the first 8 are all physically the first die, and the second 8 are all physically the second die?)  If such an API exists and we can query it reliably, that might be a better solution.\r\n\r\nAll the code is in one file: gpu_device.cc\r\n\r\nrelated Issues: \r\n- https://github.com/tensorflow/tensorflow/issues/5362"}