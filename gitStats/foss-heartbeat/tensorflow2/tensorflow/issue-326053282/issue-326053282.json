{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19527", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19527/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19527/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19527/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19527", "id": 326053282, "node_id": "MDU6SXNzdWUzMjYwNTMyODI=", "number": 19527, "title": "SIGSEGV at TensorFlowInferenceInterface.run", "user": {"login": "tobirudi9", "id": 32922353, "node_id": "MDQ6VXNlcjMyOTIyMzUz", "avatar_url": "https://avatars2.githubusercontent.com/u/32922353?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tobirudi9", "html_url": "https://github.com/tobirudi9", "followers_url": "https://api.github.com/users/tobirudi9/followers", "following_url": "https://api.github.com/users/tobirudi9/following{/other_user}", "gists_url": "https://api.github.com/users/tobirudi9/gists{/gist_id}", "starred_url": "https://api.github.com/users/tobirudi9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tobirudi9/subscriptions", "organizations_url": "https://api.github.com/users/tobirudi9/orgs", "repos_url": "https://api.github.com/users/tobirudi9/repos", "events_url": "https://api.github.com/users/tobirudi9/events{/privacy}", "received_events_url": "https://api.github.com/users/tobirudi9/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-05-24T10:09:44Z", "updated_at": "2018-11-21T21:00:04Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution</strong> : Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary, pip</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.7.0</li>\n<li><strong>Python version</strong>: 2.7.14</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>: 9.0/7</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>I'm running Inference on an small Style Transfer Model on Android using TF Mobile.<br>\nMy App crashes on Motorola Nexus 6 with the following Error after i call:</p>\n<p><code>inferenceInterface.run(new String[]{OUTPUT_NODE});</code></p>\n<p><strong>Fatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 24385</strong><br>\n<a href=\"https://github.com/tensorflow/tensorflow/files/2034709/log.txt\">log.txt</a></p>\n<p>I'm using Andoird Studio and integrated TFMobile on Android using the AAR:</p>\n<pre><code>allprojects {\n    repositories {\n        jcenter()\n    }\n}\n\ndependencies {\n    implementation 'org.tensorflow:tensorflow-android:+'\n}\n</code></pre>\n<p>I'm using a model similar to the popular feed forward model described by Johnson and optimized using graph transform tool:</p>\n<pre><code>bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n--in_graph=wave.pb \\\n--out_graph=wave_optimized.pb \\\n--inputs='input_image' \\\n--outputs='output_image' \\\n--transforms='\n  add_default_attributes\n  strip_unused_nodes\n  remove_nodes(op=Identity, op=CheckNumerics)\n  fuse_resize_and_conv\n  fuse_resize_pad_and_conv\n  fold_constants(ignore_errors=true)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  strip_unused_nodes\n  sort_by_execution_order'\n</code></pre>\n<ul>\n<li>It only happens if the input image size gets to large, e.g. 600x600. So it could be simply a memory / CPU problem.</li>\n<li><strong>But</strong> it seems to be phone specific: I can scale up the images up to 1200x1200 on other phones and the app doesn't crash (it only takes for about 10 seconds)</li>\n<li>I'm not doing Real-Time-Style-Transfer as in the TF Stylize App, i simply run inference on selected images and i'm testing with different input sizes</li>\n</ul>\n<p>I know the error may be hard to reproduce and the main focus is now on TFLite (but TFLite doesn't support Style Transfer yet, as far as i know).<br>\nI could also life with the fact that i have to further downscale the images to avoid the crash but maybe someone has an idea about:</p>\n<ul>\n<li>what is going wrong</li>\n<li>why it only crashes on certain phones</li>\n<li>how i can get more specific information why it crashes</li>\n</ul>\n<p>Thanks for any tips</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution : Ubuntu 16.04\nTensorFlow installed from (source or binary): binary, pip\nTensorFlow version (use command below): 1.7.0\nPython version: 2.7.14\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version: 9.0/7\nGPU model and memory:\nExact command to reproduce:\n\nI'm running Inference on an small Style Transfer Model on Android using TF Mobile.\nMy App crashes on Motorola Nexus 6 with the following Error after i call:\ninferenceInterface.run(new String[]{OUTPUT_NODE});\nFatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 24385\nlog.txt\nI'm using Andoird Studio and integrated TFMobile on Android using the AAR:\nallprojects {\n    repositories {\n        jcenter()\n    }\n}\n\ndependencies {\n    implementation 'org.tensorflow:tensorflow-android:+'\n}\n\nI'm using a model similar to the popular feed forward model described by Johnson and optimized using graph transform tool:\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n--in_graph=wave.pb \\\n--out_graph=wave_optimized.pb \\\n--inputs='input_image' \\\n--outputs='output_image' \\\n--transforms='\n  add_default_attributes\n  strip_unused_nodes\n  remove_nodes(op=Identity, op=CheckNumerics)\n  fuse_resize_and_conv\n  fuse_resize_pad_and_conv\n  fold_constants(ignore_errors=true)\n  fold_batch_norms\n  fold_old_batch_norms\n  quantize_weights\n  strip_unused_nodes\n  sort_by_execution_order'\n\n\nIt only happens if the input image size gets to large, e.g. 600x600. So it could be simply a memory / CPU problem.\nBut it seems to be phone specific: I can scale up the images up to 1200x1200 on other phones and the app doesn't crash (it only takes for about 10 seconds)\nI'm not doing Real-Time-Style-Transfer as in the TF Stylize App, i simply run inference on selected images and i'm testing with different input sizes\n\nI know the error may be hard to reproduce and the main focus is now on TFLite (but TFLite doesn't support Style Transfer yet, as far as i know).\nI could also life with the fact that i have to further downscale the images to avoid the crash but maybe someone has an idea about:\n\nwhat is going wrong\nwhy it only crashes on certain phones\nhow i can get more specific information why it crashes\n\nThanks for any tips", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution** : Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary, pip\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0/7\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nI'm running Inference on an small Style Transfer Model on Android using TF Mobile.\r\nMy App crashes on Motorola Nexus 6 with the following Error after i call:\r\n\r\n`inferenceInterface.run(new String[]{OUTPUT_NODE});`\r\n\r\n **Fatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 24385**\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/2034709/log.txt)\r\n\r\nI'm using Andoird Studio and integrated TFMobile on Android using the AAR:\r\n```\r\nallprojects {\r\n    repositories {\r\n        jcenter()\r\n    }\r\n}\r\n\r\ndependencies {\r\n    implementation 'org.tensorflow:tensorflow-android:+'\r\n}\r\n```\r\nI'm using a model similar to the popular feed forward model described by Johnson and optimized using graph transform tool:\r\n\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=wave.pb \\\r\n--out_graph=wave_optimized.pb \\\r\n--inputs='input_image' \\\r\n--outputs='output_image' \\\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes\r\n  remove_nodes(op=Identity, op=CheckNumerics)\r\n  fuse_resize_and_conv\r\n  fuse_resize_pad_and_conv\r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n```\r\n\r\n- It only happens if the input image size gets to large, e.g. 600x600. So it could be simply a memory / CPU problem.\r\n- **But** it seems to be phone specific: I can scale up the images up to 1200x1200 on other phones and the app doesn't crash (it only takes for about 10 seconds)\r\n- I'm not doing Real-Time-Style-Transfer as in the TF Stylize App, i simply run inference on selected images and i'm testing with different input sizes\r\n\r\nI know the error may be hard to reproduce and the main focus is now on TFLite (but TFLite doesn't support Style Transfer yet, as far as i know).\r\nI could also life with the fact that i have to further downscale the images to avoid the crash but maybe someone has an idea about: \r\n\r\n- what is going wrong\r\n- why it only crashes on certain phones\r\n- how i can get more specific information why it crashes\r\n\r\nThanks for any tips\r\n\r\n \r\n\r\n\r\n"}