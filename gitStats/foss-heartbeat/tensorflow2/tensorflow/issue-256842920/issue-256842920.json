{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12980", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12980/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12980/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12980/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12980", "id": 256842920, "node_id": "MDU6SXNzdWUyNTY4NDI5MjA=", "number": 12980, "title": "Blocking of tf.contrib.StagingArea get() and put() operations", "user": {"login": "ghost", "id": 10137, "node_id": "MDQ6VXNlcjEwMTM3", "avatar_url": "https://avatars3.githubusercontent.com/u/10137?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ghost", "html_url": "https://github.com/ghost", "followers_url": "https://api.github.com/users/ghost/followers", "following_url": "https://api.github.com/users/ghost/following{/other_user}", "gists_url": "https://api.github.com/users/ghost/gists{/gist_id}", "starred_url": "https://api.github.com/users/ghost/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ghost/subscriptions", "organizations_url": "https://api.github.com/users/ghost/orgs", "repos_url": "https://api.github.com/users/ghost/repos", "events_url": "https://api.github.com/users/ghost/events{/privacy}", "received_events_url": "https://api.github.com/users/ghost/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "ekelsen", "id": 2533174, "node_id": "MDQ6VXNlcjI1MzMxNzQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/2533174?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ekelsen", "html_url": "https://github.com/ekelsen", "followers_url": "https://api.github.com/users/ekelsen/followers", "following_url": "https://api.github.com/users/ekelsen/following{/other_user}", "gists_url": "https://api.github.com/users/ekelsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/ekelsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ekelsen/subscriptions", "organizations_url": "https://api.github.com/users/ekelsen/orgs", "repos_url": "https://api.github.com/users/ekelsen/repos", "events_url": "https://api.github.com/users/ekelsen/events{/privacy}", "received_events_url": "https://api.github.com/users/ekelsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 12, "created_at": "2017-09-11T21:08:45Z", "updated_at": "2018-03-25T17:55:53Z", "closed_at": "2018-03-25T17:55:53Z", "author_association": "NONE", "body_html": "<p><strong>Work Environment</strong><br>\nTensorFlow release version : 1.3.0-rc2<br>\nTensorFlow git version : v1.3.0-rc1-994-gb93fd37<br>\nOperating System : CentOS Linux release 7.2.1511 (Core)</p>\n<p>I am using TensorFlow StagingArea ops for increasing the efficiency of my input pipeline. Here is a part of my code snippet which constructs the input pipeline :</p>\n<pre><code>    train_put_op_list = []\n    train_get_op_list = []\n    val_put_op_list = []\n    val_get_op_list = []\n    with tf.variable_scope(tf.get_variable_scope()) as vscope:\n        for i in range(4):\n            with tf.device('/gpu:%d'%i):\n                with tf.name_scope('GPU-Tower-%d'%i) as scope:\n                    trainstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\n                                                                 shapes=[[64, 221, 221, 3],[64]],\n                                                                      capacity=0)\n                    valstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\n                                                                      shapes=[[128, 221, 221, 3],[128]],\n                                                                      capacity=0)\n                    train_put_op_list.append(trainstagingarea.put(train_iterator.get_next()))\n                    val_put_op_list.append(valstagingarea.put(val_iterator.get_next()))\n                    train_get_op_list.append(trainstagingarea.get())\n                    val_get_op_list.append(valstagingarea.get())\n                    with tf.device('/cpu:0'):\n                        worktype = tf.get_variable(\"wt\",[], initializer=tf.zeros_initializer(), trainable=False)\n                    workcondition = tf.equal(worktype, 1)\n                    #elem = tf.cond(workcondition, lambda: train_iterator.get_next(), lambda: val_iterator.get_next())\n                    elem = tf.cond(workcondition, lambda: train_get_op_list[i], lambda: val_get_op_list[i])\n                    # This is followed by the network construction and optimizer \n</code></pre>\n<p>Now at the time of execution, I first run the put() ops a couple of times and then go on to run the iterations. It is shown below :</p>\n<pre><code>with tf.Session(config=config) as sess:\n        sess.run(init_op)\n        sess.run(iterator_training_op)\n        sess.run(iterator_validation_op)\n        sess.run(tf.assign(worktype, 0))\n        for i in range(4):\n            sess.run(train_put_op_list)\n            sess.run(val_put_op_list)\n        writer = tf.summary.FileWriter('.', graph=tf.get_default_graph())\n        epoch = 0\n        iter = 0\n        previous = 0\n        while(epoch&lt;10):\n            try:\n                if(PROCESSINGTYPE is 'validation'):\n                    sess.run(val_put_op_list)\n                    [val_accu, summaries, numsamp] = sess.run([running_accuracy, validation_summary_op, processed])\n                    previous+=numsamp\n                    print(\"Running Accuracy = {} : Number of sample processed = {} \".format(val_accu, previous))\n                else:\n                    sess.run(train_put_op_list)\n                    [loss_value, _, train_accu, summaries, batch_accu, numsamp] = sess.run([total_loss, apply_gradient_op, running_accuracy, training_summary_op, batch_accuracy, pr\\\nocessed])\n                    #Remaining part of the code (not important for question)\n\n</code></pre>\n<p>The use of StagingArea improves the speed substantially (almost 3-4 times). However, the code hangs due to some block. I am not sure if the block comes from get() or put() operations. Here is the actual output :</p>\n<pre><code>\n# Validation is done first and the following is the output\nRunning Accuracy = 0.0 : Number of sample processed = 512\nRunning Accuracy = 0.00390625 : Number of sample processed = 1024\nRunning Accuracy = 0.0 : Number of sample processed = 1536\nRunning Accuracy = 0.001953125 : Number of sample processed = 2048\n# The code hangs here\n</code></pre>\n<p>You can notice that in the beginning of <code>tf.Session() as sess:</code>, the <code>get()</code> and <code>put()</code> ops were run for <code>4</code> times. The output is limited to 4 lines as well. This means that,<br>\n<code>sess.run(val_put_op_list)</code> within the <code>while</code> loop does not do anything. So, when the <code>get()</code> is called by <code>sess.run(running_accuracy)...</code>, the <code>StagingArea</code> is found empty after <code>4</code> lines and hence a blocking happens.</p>\n<ul>\n<li>Am I correct in my analysis of the problem ?</li>\n<li>What is the correct way to use the <code>get()</code> and <code>put()</code> ops here ?</li>\n<li>If <code>StagingArea</code> is full and <code>put()</code> is blocked, would that also block the whole code ? TensorFlow documentation does not say anything about it.</li>\n</ul>", "body_text": "Work Environment\nTensorFlow release version : 1.3.0-rc2\nTensorFlow git version : v1.3.0-rc1-994-gb93fd37\nOperating System : CentOS Linux release 7.2.1511 (Core)\nI am using TensorFlow StagingArea ops for increasing the efficiency of my input pipeline. Here is a part of my code snippet which constructs the input pipeline :\n    train_put_op_list = []\n    train_get_op_list = []\n    val_put_op_list = []\n    val_get_op_list = []\n    with tf.variable_scope(tf.get_variable_scope()) as vscope:\n        for i in range(4):\n            with tf.device('/gpu:%d'%i):\n                with tf.name_scope('GPU-Tower-%d'%i) as scope:\n                    trainstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\n                                                                 shapes=[[64, 221, 221, 3],[64]],\n                                                                      capacity=0)\n                    valstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\n                                                                      shapes=[[128, 221, 221, 3],[128]],\n                                                                      capacity=0)\n                    train_put_op_list.append(trainstagingarea.put(train_iterator.get_next()))\n                    val_put_op_list.append(valstagingarea.put(val_iterator.get_next()))\n                    train_get_op_list.append(trainstagingarea.get())\n                    val_get_op_list.append(valstagingarea.get())\n                    with tf.device('/cpu:0'):\n                        worktype = tf.get_variable(\"wt\",[], initializer=tf.zeros_initializer(), trainable=False)\n                    workcondition = tf.equal(worktype, 1)\n                    #elem = tf.cond(workcondition, lambda: train_iterator.get_next(), lambda: val_iterator.get_next())\n                    elem = tf.cond(workcondition, lambda: train_get_op_list[i], lambda: val_get_op_list[i])\n                    # This is followed by the network construction and optimizer \n\nNow at the time of execution, I first run the put() ops a couple of times and then go on to run the iterations. It is shown below :\nwith tf.Session(config=config) as sess:\n        sess.run(init_op)\n        sess.run(iterator_training_op)\n        sess.run(iterator_validation_op)\n        sess.run(tf.assign(worktype, 0))\n        for i in range(4):\n            sess.run(train_put_op_list)\n            sess.run(val_put_op_list)\n        writer = tf.summary.FileWriter('.', graph=tf.get_default_graph())\n        epoch = 0\n        iter = 0\n        previous = 0\n        while(epoch<10):\n            try:\n                if(PROCESSINGTYPE is 'validation'):\n                    sess.run(val_put_op_list)\n                    [val_accu, summaries, numsamp] = sess.run([running_accuracy, validation_summary_op, processed])\n                    previous+=numsamp\n                    print(\"Running Accuracy = {} : Number of sample processed = {} \".format(val_accu, previous))\n                else:\n                    sess.run(train_put_op_list)\n                    [loss_value, _, train_accu, summaries, batch_accu, numsamp] = sess.run([total_loss, apply_gradient_op, running_accuracy, training_summary_op, batch_accuracy, pr\\\nocessed])\n                    #Remaining part of the code (not important for question)\n\n\nThe use of StagingArea improves the speed substantially (almost 3-4 times). However, the code hangs due to some block. I am not sure if the block comes from get() or put() operations. Here is the actual output :\n\n# Validation is done first and the following is the output\nRunning Accuracy = 0.0 : Number of sample processed = 512\nRunning Accuracy = 0.00390625 : Number of sample processed = 1024\nRunning Accuracy = 0.0 : Number of sample processed = 1536\nRunning Accuracy = 0.001953125 : Number of sample processed = 2048\n# The code hangs here\n\nYou can notice that in the beginning of tf.Session() as sess:, the get() and put() ops were run for 4 times. The output is limited to 4 lines as well. This means that,\nsess.run(val_put_op_list) within the while loop does not do anything. So, when the get() is called by sess.run(running_accuracy)..., the StagingArea is found empty after 4 lines and hence a blocking happens.\n\nAm I correct in my analysis of the problem ?\nWhat is the correct way to use the get() and put() ops here ?\nIf StagingArea is full and put() is blocked, would that also block the whole code ? TensorFlow documentation does not say anything about it.", "body": "**Work Environment**\r\nTensorFlow release version : 1.3.0-rc2\r\nTensorFlow git version : v1.3.0-rc1-994-gb93fd37\r\nOperating System : CentOS Linux release 7.2.1511 (Core)\r\n\r\nI am using TensorFlow StagingArea ops for increasing the efficiency of my input pipeline. Here is a part of my code snippet which constructs the input pipeline :\r\n```\r\n    train_put_op_list = []\r\n    train_get_op_list = []\r\n    val_put_op_list = []\r\n    val_get_op_list = []\r\n    with tf.variable_scope(tf.get_variable_scope()) as vscope:\r\n        for i in range(4):\r\n            with tf.device('/gpu:%d'%i):\r\n                with tf.name_scope('GPU-Tower-%d'%i) as scope:\r\n                    trainstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\r\n                                                                 shapes=[[64, 221, 221, 3],[64]],\r\n                                                                      capacity=0)\r\n                    valstagingarea = tf.contrib.staging.StagingArea(dtypes=[tf.float32, tf.int32],\r\n                                                                      shapes=[[128, 221, 221, 3],[128]],\r\n                                                                      capacity=0)\r\n                    train_put_op_list.append(trainstagingarea.put(train_iterator.get_next()))\r\n                    val_put_op_list.append(valstagingarea.put(val_iterator.get_next()))\r\n                    train_get_op_list.append(trainstagingarea.get())\r\n                    val_get_op_list.append(valstagingarea.get())\r\n                    with tf.device('/cpu:0'):\r\n                        worktype = tf.get_variable(\"wt\",[], initializer=tf.zeros_initializer(), trainable=False)\r\n                    workcondition = tf.equal(worktype, 1)\r\n                    #elem = tf.cond(workcondition, lambda: train_iterator.get_next(), lambda: val_iterator.get_next())\r\n                    elem = tf.cond(workcondition, lambda: train_get_op_list[i], lambda: val_get_op_list[i])\r\n                    # This is followed by the network construction and optimizer \r\n```\r\nNow at the time of execution, I first run the put() ops a couple of times and then go on to run the iterations. It is shown below :\r\n```\r\nwith tf.Session(config=config) as sess:\r\n        sess.run(init_op)\r\n        sess.run(iterator_training_op)\r\n        sess.run(iterator_validation_op)\r\n        sess.run(tf.assign(worktype, 0))\r\n        for i in range(4):\r\n            sess.run(train_put_op_list)\r\n            sess.run(val_put_op_list)\r\n        writer = tf.summary.FileWriter('.', graph=tf.get_default_graph())\r\n        epoch = 0\r\n        iter = 0\r\n        previous = 0\r\n        while(epoch<10):\r\n            try:\r\n                if(PROCESSINGTYPE is 'validation'):\r\n                    sess.run(val_put_op_list)\r\n                    [val_accu, summaries, numsamp] = sess.run([running_accuracy, validation_summary_op, processed])\r\n                    previous+=numsamp\r\n                    print(\"Running Accuracy = {} : Number of sample processed = {} \".format(val_accu, previous))\r\n                else:\r\n                    sess.run(train_put_op_list)\r\n                    [loss_value, _, train_accu, summaries, batch_accu, numsamp] = sess.run([total_loss, apply_gradient_op, running_accuracy, training_summary_op, batch_accuracy, pr\\\r\nocessed])\r\n                    #Remaining part of the code (not important for question)\r\n\r\n```\r\nThe use of StagingArea improves the speed substantially (almost 3-4 times). However, the code hangs due to some block. I am not sure if the block comes from get() or put() operations. Here is the actual output :\r\n```\r\n\r\n# Validation is done first and the following is the output\r\nRunning Accuracy = 0.0 : Number of sample processed = 512\r\nRunning Accuracy = 0.00390625 : Number of sample processed = 1024\r\nRunning Accuracy = 0.0 : Number of sample processed = 1536\r\nRunning Accuracy = 0.001953125 : Number of sample processed = 2048\r\n# The code hangs here\r\n```\r\nYou can notice that in the beginning of `tf.Session() as sess:`, the `get()` and `put()` ops were run for `4` times. The output is limited to 4 lines as well. This means that, \r\n`sess.run(val_put_op_list)` within the `while` loop does not do anything. So, when the `get()` is called by `sess.run(running_accuracy)...`, the `StagingArea` is found empty after `4` lines and hence a blocking happens.\r\n\r\n - Am I correct in my analysis of the problem ?\r\n - What is the correct way to use the `get()` and `put()` ops here ?\r\n - If `StagingArea` is full and `put()` is blocked, would that also block the whole code ? TensorFlow documentation does not say anything about it."}