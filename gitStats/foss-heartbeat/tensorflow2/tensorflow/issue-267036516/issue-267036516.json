{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13844", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13844/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13844/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13844/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13844", "id": 267036516, "node_id": "MDU6SXNzdWUyNjcwMzY1MTY=", "number": 13844, "title": "Saving large graphs to S3 fails with InternalError: : Unable to connect to endpoint", "user": {"login": "smurching", "id": 2358483, "node_id": "MDQ6VXNlcjIzNTg0ODM=", "avatar_url": "https://avatars1.githubusercontent.com/u/2358483?v=4", "gravatar_id": "", "url": "https://api.github.com/users/smurching", "html_url": "https://github.com/smurching", "followers_url": "https://api.github.com/users/smurching/followers", "following_url": "https://api.github.com/users/smurching/following{/other_user}", "gists_url": "https://api.github.com/users/smurching/gists{/gist_id}", "starred_url": "https://api.github.com/users/smurching/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/smurching/subscriptions", "organizations_url": "https://api.github.com/users/smurching/orgs", "repos_url": "https://api.github.com/users/smurching/repos", "events_url": "https://api.github.com/users/smurching/events{/privacy}", "received_events_url": "https://api.github.com/users/smurching/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2017-10-20T01:24:35Z", "updated_at": "2018-09-14T02:36:07Z", "closed_at": "2018-02-26T19:42:54Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes; modified Tensorflow <a href=\"https://www.tensorflow.org/programmers_guide/saved_model\" rel=\"nofollow\">save/load example code</a> to save a few large tensors to S3</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version</strong>:<br>\nGit version: <code>v1.3.0-rc1-3504-g27767d8</code><br>\nTensorflow version: <code>1.4.0-rc1</code></li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: N/A</li>\n<li><strong>CUDA/cuDNN version</strong>: 8.0</li>\n<li><strong>GPU model and memory</strong>: Nvidia Tesla K80 (12 GiB RAM)</li>\n<li><strong>Exact command to reproduce</strong>: Run the code in <a href=\"https://gist.github.com/smurching/8766a9d91c148ef7d89292b6dd4da5b8\">this gist</a> in a Python shell. You'll need access to an S3 bucket for which you have write permissions.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm trying to save a large (~380 MB) graph to S3, but my call to <code>tf.Saver.save()</code> crashes after ~1 min with what appears to be an AWS SDK error (<code>InternalError: : Unable to connect to endpoint</code>).</p>\n<p>If the error is indeed AWS related, it'd be helpful to wrap it in something to indicate that the error isn't coming from tensorflow. Here's the stacktrace:</p>\n<pre><code>---------------------------------------------------------------------------\nInternalError                             Traceback (most recent call last)\n&lt;command-5036518&gt; in &lt;module&gt;()\n----&gt; 1 test_save(num_tensors=10, tensor_size=10000000, save_path=\"s3://&lt;redacted_s3_bucket_name&gt;/model.ckpt\")\n\n&lt;command-5036204&gt; in test_save(num_tensors, tensor_size, save_path)\n     18     sess.run(init_op)\n     19     # Save the variables to disk.\n---&gt; 20     save_path = saver.save(sess, save_path)\n     21     print(\"Model saved in file: %s\" % save_path)\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\n   1571           model_checkpoint_path = sess.run(\n   1572               self.saver_def.save_tensor_name,\n-&gt; 1573               {self.saver_def.filename_tensor_name: checkpoint_file})\n   1574         else:\n   1575           self._build_eager(\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    887     try:\n    888       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 889                          run_metadata_ptr)\n    890       if run_metadata:\n    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1119       results = self._do_run(handle, final_targets, final_fetches,\n-&gt; 1120                              feed_dict_tensor, options, run_metadata)\n   1121     else:\n   1122       results = []\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1315     if handle is None:\n   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n-&gt; 1317                            options, run_metadata)\n   1318     else:\n   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n   1334         except KeyError:\n   1335           pass\n-&gt; 1336       raise type(e)(node_def, op, message)\n   1337 \n   1338   def _extend_graph(self):\n\nInternalError: : Unable to connect to endpoint\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]\n\nCaused by op u'save/SaveV2', defined at:\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 990, in &lt;module&gt;\n    launch_process()\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 986, in launch_process\n    shell.executor.run()\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 263, in run\n    self.shell.shell.run_cell(command_id, cmd, store_history=True)\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 572, in run_cell\n    super(IPythonShell, self).run_cell(raw_cell, store_history, silent, shell_futures)\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2741, in run_cell\n    interactivity=interactivity, compiler=compiler)\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2833, in run_ast_nodes\n    if self.run_code(code):\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2883, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;command-5036518&gt;\", line 1, in &lt;module&gt;\n    test_save(num_tensors=10, tensor_size=10000000, save_path=\"s3://databricks-mllib/tmp/s3-save-failure/model.ckpt\")\n  File \"&lt;command-5036204&gt;\", line 13, in test_save\n    saver = tf.train.Saver()\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): : Unable to connect to endpoint\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]\n</code></pre>\n<p>If I run the same code but checkpoint to my local filesystem the save op runs without error.<br>\nThe error also only seems to occur for large graphs (running the <a href=\"https://gist.github.com/smurching/8766a9d91c148ef7d89292b6dd4da5b8\">linked gist</a> with smaller/fewer tensors works)</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes; modified Tensorflow save/load example code to save a few large tensors to S3\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version:\nGit version: v1.3.0-rc1-3504-g27767d8\nTensorflow version: 1.4.0-rc1\nPython version: 2.7.12\nBazel version (if compiling from source): N/A\nCUDA/cuDNN version: 8.0\nGPU model and memory: Nvidia Tesla K80 (12 GiB RAM)\nExact command to reproduce: Run the code in this gist in a Python shell. You'll need access to an S3 bucket for which you have write permissions.\n\nDescribe the problem\nI'm trying to save a large (~380 MB) graph to S3, but my call to tf.Saver.save() crashes after ~1 min with what appears to be an AWS SDK error (InternalError: : Unable to connect to endpoint).\nIf the error is indeed AWS related, it'd be helpful to wrap it in something to indicate that the error isn't coming from tensorflow. Here's the stacktrace:\n---------------------------------------------------------------------------\nInternalError                             Traceback (most recent call last)\n<command-5036518> in <module>()\n----> 1 test_save(num_tensors=10, tensor_size=10000000, save_path=\"s3://<redacted_s3_bucket_name>/model.ckpt\")\n\n<command-5036204> in test_save(num_tensors, tensor_size, save_path)\n     18     sess.run(init_op)\n     19     # Save the variables to disk.\n---> 20     save_path = saver.save(sess, save_path)\n     21     print(\"Model saved in file: %s\" % save_path)\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\n   1571           model_checkpoint_path = sess.run(\n   1572               self.saver_def.save_tensor_name,\n-> 1573               {self.saver_def.filename_tensor_name: checkpoint_file})\n   1574         else:\n   1575           self._build_eager(\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    887     try:\n    888       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 889                          run_metadata_ptr)\n    890       if run_metadata:\n    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\n   1119       results = self._do_run(handle, final_targets, final_fetches,\n-> 1120                              feed_dict_tensor, options, run_metadata)\n   1121     else:\n   1122       results = []\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1315     if handle is None:\n   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n-> 1317                            options, run_metadata)\n   1318     else:\n   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\n\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n   1334         except KeyError:\n   1335           pass\n-> 1336       raise type(e)(node_def, op, message)\n   1337 \n   1338   def _extend_graph(self):\n\nInternalError: : Unable to connect to endpoint\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]\n\nCaused by op u'save/SaveV2', defined at:\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 990, in <module>\n    launch_process()\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 986, in launch_process\n    shell.executor.run()\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 263, in run\n    self.shell.shell.run_cell(command_id, cmd, store_history=True)\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 572, in run_cell\n    super(IPythonShell, self).run_cell(raw_cell, store_history, silent, shell_futures)\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2741, in run_cell\n    interactivity=interactivity, compiler=compiler)\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2833, in run_ast_nodes\n    if self.run_code(code):\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2883, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<command-5036518>\", line 1, in <module>\n    test_save(num_tensors=10, tensor_size=10000000, save_path=\"s3://databricks-mllib/tmp/s3-save-failure/model.ckpt\")\n  File \"<command-5036204>\", line 13, in test_save\n    saver = tf.train.Saver()\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): : Unable to connect to endpoint\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]\n\nIf I run the same code but checkpoint to my local filesystem the save op runs without error.\nThe error also only seems to occur for large graphs (running the linked gist with smaller/fewer tensors works)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes; modified Tensorflow [save/load example code](https://www.tensorflow.org/programmers_guide/saved_model) to save a few large tensors to S3\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version**:\r\nGit version: `v1.3.0-rc1-3504-g27767d8`\r\nTensorflow version: `1.4.0-rc1`\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: Nvidia Tesla K80 (12 GiB RAM)\r\n- **Exact command to reproduce**: Run the code in [this gist](https://gist.github.com/smurching/8766a9d91c148ef7d89292b6dd4da5b8) in a Python shell. You'll need access to an S3 bucket for which you have write permissions.\r\n\r\n### Describe the problem\r\nI'm trying to save a large (~380 MB) graph to S3, but my call to `tf.Saver.save()` crashes after ~1 min with what appears to be an AWS SDK error (`InternalError: : Unable to connect to endpoint`).\r\n\r\nIf the error is indeed AWS related, it'd be helpful to wrap it in something to indicate that the error isn't coming from tensorflow. Here's the stacktrace:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInternalError                             Traceback (most recent call last)\r\n<command-5036518> in <module>()\r\n----> 1 test_save(num_tensors=10, tensor_size=10000000, save_path=\"s3://<redacted_s3_bucket_name>/model.ckpt\")\r\n\r\n<command-5036204> in test_save(num_tensors, tensor_size, save_path)\r\n     18     sess.run(init_op)\r\n     19     # Save the variables to disk.\r\n---> 20     save_path = saver.save(sess, save_path)\r\n     21     print(\"Model saved in file: %s\" % save_path)\r\n\r\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\r\n   1571           model_checkpoint_path = sess.run(\r\n   1572               self.saver_def.save_tensor_name,\r\n-> 1573               {self.saver_def.filename_tensor_name: checkpoint_file})\r\n   1574         else:\r\n   1575           self._build_eager(\r\n\r\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    887     try:\r\n    888       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 889                          run_metadata_ptr)\r\n    890       if run_metadata:\r\n    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1119       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1120                              feed_dict_tensor, options, run_metadata)\r\n   1121     else:\r\n   1122       results = []\r\n\r\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1315     if handle is None:\r\n   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\r\n-> 1317                            options, run_metadata)\r\n   1318     else:\r\n   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\r\n\r\n/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n   1334         except KeyError:\r\n   1335           pass\r\n-> 1336       raise type(e)(node_def, op, message)\r\n   1337 \r\n   1338   def _extend_graph(self):\r\n\r\nInternalError: : Unable to connect to endpoint\r\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]\r\n\r\nCaused by op u'save/SaveV2', defined at:\r\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 990, in <module>\r\n    launch_process()\r\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 986, in launch_process\r\n    shell.executor.run()\r\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 263, in run\r\n    self.shell.shell.run_cell(command_id, cmd, store_history=True)\r\n  File \"/tmp/1509404428358-0/PythonShell.py\", line 572, in run_cell\r\n    super(IPythonShell, self).run_cell(raw_cell, store_history, silent, shell_futures)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2741, in run_cell\r\n    interactivity=interactivity, compiler=compiler)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2833, in run_ast_nodes\r\n    if self.run_code(code):\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2883, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<command-5036518>\", line 1, in <module>\r\n    test_save(num_tensors=10, tensor_size=10000000, save_path=\"s3://databricks-mllib/tmp/s3-save-failure/model.ckpt\")\r\n  File \"<command-5036204>\", line 13, in test_save\r\n    saver = tf.train.Saver()\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\r\n    self.build()\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\r\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\r\n    tensors)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\r\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInternalError (see above for traceback): : Unable to connect to endpoint\r\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, v0/_1, v1/_3, v2/_5, v3/_7, v4/_9, v5/_11, v6/_13, v7/_15, v8/_17, v9/_19)]]\r\n```\r\n\r\nIf I run the same code but checkpoint to my local filesystem the save op runs without error.\r\nThe error also only seems to occur for large graphs (running the [linked gist](https://gist.github.com/smurching/8766a9d91c148ef7d89292b6dd4da5b8) with smaller/fewer tensors works)\r\n\r\n\r\n\r\n"}