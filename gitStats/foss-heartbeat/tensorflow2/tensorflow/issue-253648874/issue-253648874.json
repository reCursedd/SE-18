{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12683", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12683/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12683/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12683/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12683", "id": 253648874, "node_id": "MDU6SXNzdWUyNTM2NDg4NzQ=", "number": 12683, "title": "XLA leads to core dump", "user": {"login": "hzhangxyz", "id": 11623447, "node_id": "MDQ6VXNlcjExNjIzNDQ3", "avatar_url": "https://avatars0.githubusercontent.com/u/11623447?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hzhangxyz", "html_url": "https://github.com/hzhangxyz", "followers_url": "https://api.github.com/users/hzhangxyz/followers", "following_url": "https://api.github.com/users/hzhangxyz/following{/other_user}", "gists_url": "https://api.github.com/users/hzhangxyz/gists{/gist_id}", "starred_url": "https://api.github.com/users/hzhangxyz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hzhangxyz/subscriptions", "organizations_url": "https://api.github.com/users/hzhangxyz/orgs", "repos_url": "https://api.github.com/users/hzhangxyz/repos", "events_url": "https://api.github.com/users/hzhangxyz/events{/privacy}", "received_events_url": "https://api.github.com/users/hzhangxyz/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 299643928, "node_id": "MDU6TGFiZWwyOTk2NDM5Mjg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:contributions%20welcome", "name": "stat:contributions welcome", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bixia1", "id": 35820639, "node_id": "MDQ6VXNlcjM1ODIwNjM5", "avatar_url": "https://avatars1.githubusercontent.com/u/35820639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bixia1", "html_url": "https://github.com/bixia1", "followers_url": "https://api.github.com/users/bixia1/followers", "following_url": "https://api.github.com/users/bixia1/following{/other_user}", "gists_url": "https://api.github.com/users/bixia1/gists{/gist_id}", "starred_url": "https://api.github.com/users/bixia1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bixia1/subscriptions", "organizations_url": "https://api.github.com/users/bixia1/orgs", "repos_url": "https://api.github.com/users/bixia1/repos", "events_url": "https://api.github.com/users/bixia1/events{/privacy}", "received_events_url": "https://api.github.com/users/bixia1/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bixia1", "id": 35820639, "node_id": "MDQ6VXNlcjM1ODIwNjM5", "avatar_url": "https://avatars1.githubusercontent.com/u/35820639?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bixia1", "html_url": "https://github.com/bixia1", "followers_url": "https://api.github.com/users/bixia1/followers", "following_url": "https://api.github.com/users/bixia1/following{/other_user}", "gists_url": "https://api.github.com/users/bixia1/gists{/gist_id}", "starred_url": "https://api.github.com/users/bixia1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bixia1/subscriptions", "organizations_url": "https://api.github.com/users/bixia1/orgs", "repos_url": "https://api.github.com/users/bixia1/repos", "events_url": "https://api.github.com/users/bixia1/events{/privacy}", "received_events_url": "https://api.github.com/users/bixia1/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 13, "created_at": "2017-08-29T12:56:28Z", "updated_at": "2018-02-16T21:39:48Z", "closed_at": "2018-02-06T20:09:28Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<p><a href=\"http://paste.ubuntu.com/25424565/\" rel=\"nofollow\">output of tf_env_collect.sh</a></p>\n<h4>Tensorflow</h4>\n<p>Tensorflow compiled from the source v1.3.0(<a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/9e76bf324f6bac63137a02bb6e6ec9120703ea9b/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/9e76bf324f6bac63137a02bb6e6ec9120703ea9b\"><tt>9e76bf3</tt></a>)</p>\n<p>with cuda, with xla, without mpi, without mkl</p>\n<h4>OS</h4>\n<p>CentOS 7</p>\n<p>out put of <code>uname -a</code>:</p>\n<p>Linux zhanghao 3.10.0-514.26.2.el7.x86_64 <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"115886302\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1\">#1</a> SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>\n<h4>python</h4>\n<p>Python 2.7.13 |Intel Corporation| (default, Apr 27 2017, 15:33:46)</p>\n<p>[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux2</p>\n<h4>Bezel</h4>\n<p>Build label: 0.5.2<br>\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar<br>\nBuild time: Tue Jun 27 13:27:03 2017 (1498570023)<br>\nBuild timestamp: 1498570023<br>\nBuild timestamp as int: 1498570023</p>\n<h4>GPU</h4>\n<p>CUDA 8.0 cuDNN 6.0.21<br>\nGPU: GeForce GTX 950M</p>\n<h3>Describe the problem</h3>\n<p>core dump when use xla with gpu,</p>\n<p>BTW, if use cpu only, xla won't lead to core dump</p>\n<h3>Source code</h3>\n<p>This is code to reproduce the bug</p>\n<pre><code>import tensorflow as tf\nimport sys\nD = 2\nA = tf.random_normal(shape=[D, D, 2], dtype=tf.float32,name=\"A\")\nB = tf.random_normal(shape=[D, D, 2], dtype=tf.float32, name=\"B\")\nE = tf.ones(shape=[D], dtype=tf.float32, name=\"EBA\")\nH = tf.reshape(tf.constant([[0.25,0,0,0],[0,-0.25,0.5,0],[0,0.5,-0.25,0],[0,0,0,0.25]],\n                           dtype=tf.float32),[2,2,2,2],name=\"Hamiltonian\")\nEA = tf.multiply(A,tf.reshape(E,[D,1,1]))\nAB = tf.tensordot(EA,B,[[1],[0]],name=\"AB\")\nS, U, V = tf.svd(tf.reshape(AB,[2*D,2*D]))\nUU = tf.transpose(tf.multiply(tf.reshape(U[:,:D],[D,2,D]),tf.reshape(E,[D,1,1])),[0,2,1],name=\"nA\")\ndata = UU / tf.reduce_max(UU)\nconfig = tf.ConfigProto()\nif len(sys.argv)&gt;1:\n    config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\nsess = tf.Session(config=config)\nsess.run(tf.global_variables_initializer())\nprint sess.run(data)\n</code></pre>\n<p>save as MPS.py and run <code>python MPS.py</code> and get:</p>\n<pre><code>2017-08-29 20:51:54.856662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-29 20:51:54.857232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX 950M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\npciBusID 0000:0a:00.0\nTotal memory: 3.95GiB\nFree memory: 3.92GiB\n2017-08-29 20:51:54.857292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0\n2017-08-29 20:51:54.857301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y\n2017-08-29 20:51:54.857312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)\n[[[ 0.64684284 -0.48666194]\n  [-0.56722689 -0.19181968]]\n\n [[ 0.34154066  0.77098727]\n  [ 1.         -0.0881796 ]]]\n</code></pre>\n<p>and then run <code>python MPS.py -</code>, and get:</p>\n<pre><code>2017-08-29 20:52:18.127327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-29 20:52:18.127719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX 950M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\npciBusID 0000:0a:00.0\nTotal memory: 3.95GiB\nFree memory: 3.92GiB\n2017-08-29 20:52:18.127780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0\n2017-08-29 20:52:18.127789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y\n2017-08-29 20:52:18.127799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)\n2017-08-29 20:52:18.319392: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-08-29 20:52:18.319435: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Executor present with 1 visible devices\n2017-08-29 20:52:18.319739: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\n2017-08-29 20:52:18.320615: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x7f59008c0350 executing computations on platform CUDA. Devices:\n2017-08-29 20:52:18.320640: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0\n2017-08-29 20:52:18.474432: F tensorflow/compiler/xla/util.cc:183] Check failed: p1.size() == p2.size() (3 vs. 0)\n[1]    14077 abort (core dumped)  python MPS.py -\n</code></pre>", "body_text": "System information\noutput of tf_env_collect.sh\nTensorflow\nTensorflow compiled from the source v1.3.0(9e76bf3)\nwith cuda, with xla, without mpi, without mkl\nOS\nCentOS 7\nout put of uname -a:\nLinux zhanghao 3.10.0-514.26.2.el7.x86_64 #1 SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\npython\nPython 2.7.13 |Intel Corporation| (default, Apr 27 2017, 15:33:46)\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux2\nBezel\nBuild label: 0.5.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Tue Jun 27 13:27:03 2017 (1498570023)\nBuild timestamp: 1498570023\nBuild timestamp as int: 1498570023\nGPU\nCUDA 8.0 cuDNN 6.0.21\nGPU: GeForce GTX 950M\nDescribe the problem\ncore dump when use xla with gpu,\nBTW, if use cpu only, xla won't lead to core dump\nSource code\nThis is code to reproduce the bug\nimport tensorflow as tf\nimport sys\nD = 2\nA = tf.random_normal(shape=[D, D, 2], dtype=tf.float32,name=\"A\")\nB = tf.random_normal(shape=[D, D, 2], dtype=tf.float32, name=\"B\")\nE = tf.ones(shape=[D], dtype=tf.float32, name=\"EBA\")\nH = tf.reshape(tf.constant([[0.25,0,0,0],[0,-0.25,0.5,0],[0,0.5,-0.25,0],[0,0,0,0.25]],\n                           dtype=tf.float32),[2,2,2,2],name=\"Hamiltonian\")\nEA = tf.multiply(A,tf.reshape(E,[D,1,1]))\nAB = tf.tensordot(EA,B,[[1],[0]],name=\"AB\")\nS, U, V = tf.svd(tf.reshape(AB,[2*D,2*D]))\nUU = tf.transpose(tf.multiply(tf.reshape(U[:,:D],[D,2,D]),tf.reshape(E,[D,1,1])),[0,2,1],name=\"nA\")\ndata = UU / tf.reduce_max(UU)\nconfig = tf.ConfigProto()\nif len(sys.argv)>1:\n    config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\nsess = tf.Session(config=config)\nsess.run(tf.global_variables_initializer())\nprint sess.run(data)\n\nsave as MPS.py and run python MPS.py and get:\n2017-08-29 20:51:54.856662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-29 20:51:54.857232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX 950M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\npciBusID 0000:0a:00.0\nTotal memory: 3.95GiB\nFree memory: 3.92GiB\n2017-08-29 20:51:54.857292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0\n2017-08-29 20:51:54.857301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y\n2017-08-29 20:51:54.857312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)\n[[[ 0.64684284 -0.48666194]\n  [-0.56722689 -0.19181968]]\n\n [[ 0.34154066  0.77098727]\n  [ 1.         -0.0881796 ]]]\n\nand then run python MPS.py -, and get:\n2017-08-29 20:52:18.127327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-08-29 20:52:18.127719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\nname: GeForce GTX 950M\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\npciBusID 0000:0a:00.0\nTotal memory: 3.95GiB\nFree memory: 3.92GiB\n2017-08-29 20:52:18.127780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0\n2017-08-29 20:52:18.127789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y\n2017-08-29 20:52:18.127799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)\n2017-08-29 20:52:18.319392: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\n2017-08-29 20:52:18.319435: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Executor present with 1 visible devices\n2017-08-29 20:52:18.319739: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\n2017-08-29 20:52:18.320615: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x7f59008c0350 executing computations on platform CUDA. Devices:\n2017-08-29 20:52:18.320640: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0\n2017-08-29 20:52:18.474432: F tensorflow/compiler/xla/util.cc:183] Check failed: p1.size() == p2.size() (3 vs. 0)\n[1]    14077 abort (core dumped)  python MPS.py -", "body": "### System information\r\n\r\n[output of tf_env_collect.sh](http://paste.ubuntu.com/25424565/)\r\n\r\n#### Tensorflow\r\n\r\nTensorflow compiled from the source v1.3.0(9e76bf3)\r\n\r\nwith cuda, with xla, without mpi, without mkl\r\n\r\n#### OS\r\nCentOS 7\r\n\r\nout put of `uname -a`:\r\n\r\nLinux zhanghao 3.10.0-514.26.2.el7.x86_64 #1 SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n#### python\r\nPython 2.7.13 |Intel Corporation| (default, Apr 27 2017, 15:33:46)\r\n\r\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux2\r\n\r\n#### Bezel\r\nBuild label: 0.5.2\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Jun 27 13:27:03 2017 (1498570023)\r\nBuild timestamp: 1498570023\r\nBuild timestamp as int: 1498570023\r\n\r\n#### GPU\r\nCUDA 8.0 cuDNN 6.0.21\r\nGPU: GeForce GTX 950M\r\n\r\n### Describe the problem\r\ncore dump when use xla with gpu,\r\n\r\nBTW, if use cpu only, xla won't lead to core dump\r\n\r\n### Source code\r\nThis is code to reproduce the bug\r\n```\r\nimport tensorflow as tf\r\nimport sys\r\nD = 2\r\nA = tf.random_normal(shape=[D, D, 2], dtype=tf.float32,name=\"A\")\r\nB = tf.random_normal(shape=[D, D, 2], dtype=tf.float32, name=\"B\")\r\nE = tf.ones(shape=[D], dtype=tf.float32, name=\"EBA\")\r\nH = tf.reshape(tf.constant([[0.25,0,0,0],[0,-0.25,0.5,0],[0,0.5,-0.25,0],[0,0,0,0.25]],\r\n                           dtype=tf.float32),[2,2,2,2],name=\"Hamiltonian\")\r\nEA = tf.multiply(A,tf.reshape(E,[D,1,1]))\r\nAB = tf.tensordot(EA,B,[[1],[0]],name=\"AB\")\r\nS, U, V = tf.svd(tf.reshape(AB,[2*D,2*D]))\r\nUU = tf.transpose(tf.multiply(tf.reshape(U[:,:D],[D,2,D]),tf.reshape(E,[D,1,1])),[0,2,1],name=\"nA\")\r\ndata = UU / tf.reduce_max(UU)\r\nconfig = tf.ConfigProto()\r\nif len(sys.argv)>1:\r\n    config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\r\nsess = tf.Session(config=config)\r\nsess.run(tf.global_variables_initializer())\r\nprint sess.run(data)\r\n```\r\nsave as MPS.py and run `python MPS.py` and get:\r\n```\r\n2017-08-29 20:51:54.856662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-08-29 20:51:54.857232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\r\nname: GeForce GTX 950M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\r\npciBusID 0000:0a:00.0\r\nTotal memory: 3.95GiB\r\nFree memory: 3.92GiB\r\n2017-08-29 20:51:54.857292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0\r\n2017-08-29 20:51:54.857301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y\r\n2017-08-29 20:51:54.857312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)\r\n[[[ 0.64684284 -0.48666194]\r\n  [-0.56722689 -0.19181968]]\r\n\r\n [[ 0.34154066  0.77098727]\r\n  [ 1.         -0.0881796 ]]]\r\n```\r\nand then run `python MPS.py -`, and get:\r\n```\r\n2017-08-29 20:52:18.127327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-08-29 20:52:18.127719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:\r\nname: GeForce GTX 950M\r\nmajor: 5 minor: 0 memoryClockRate (GHz) 1.124\r\npciBusID 0000:0a:00.0\r\nTotal memory: 3.95GiB\r\nFree memory: 3.92GiB\r\n2017-08-29 20:52:18.127780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0\r\n2017-08-29 20:52:18.127789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y\r\n2017-08-29 20:52:18.127799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:0a:00.0)\r\n2017-08-29 20:52:18.319392: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\n2017-08-29 20:52:18.319435: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Executor present with 1 visible devices\r\n2017-08-29 20:52:18.319739: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices\r\n2017-08-29 20:52:18.320615: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x7f59008c0350 executing computations on platform CUDA. Devices:\r\n2017-08-29 20:52:18.320640: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0\r\n2017-08-29 20:52:18.474432: F tensorflow/compiler/xla/util.cc:183] Check failed: p1.size() == p2.size() (3 vs. 0)\r\n[1]    14077 abort (core dumped)  python MPS.py -\r\n```"}