{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17540", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17540/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17540/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17540/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17540", "id": 303366821, "node_id": "MDU6SXNzdWUzMDMzNjY4MjE=", "number": 17540, "title": "Protobuf size explosion for TFLite", "user": {"login": "nestle1993", "id": 18111038, "node_id": "MDQ6VXNlcjE4MTExMDM4", "avatar_url": "https://avatars2.githubusercontent.com/u/18111038?v=4", "gravatar_id": "", "url": "https://api.github.com/users/nestle1993", "html_url": "https://github.com/nestle1993", "followers_url": "https://api.github.com/users/nestle1993/followers", "following_url": "https://api.github.com/users/nestle1993/following{/other_user}", "gists_url": "https://api.github.com/users/nestle1993/gists{/gist_id}", "starred_url": "https://api.github.com/users/nestle1993/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/nestle1993/subscriptions", "organizations_url": "https://api.github.com/users/nestle1993/orgs", "repos_url": "https://api.github.com/users/nestle1993/repos", "events_url": "https://api.github.com/users/nestle1993/events{/privacy}", "received_events_url": "https://api.github.com/users/nestle1993/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aselle", "id": 326106, "node_id": "MDQ6VXNlcjMyNjEwNg==", "avatar_url": "https://avatars1.githubusercontent.com/u/326106?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aselle", "html_url": "https://github.com/aselle", "followers_url": "https://api.github.com/users/aselle/followers", "following_url": "https://api.github.com/users/aselle/following{/other_user}", "gists_url": "https://api.github.com/users/aselle/gists{/gist_id}", "starred_url": "https://api.github.com/users/aselle/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aselle/subscriptions", "organizations_url": "https://api.github.com/users/aselle/orgs", "repos_url": "https://api.github.com/users/aselle/repos", "events_url": "https://api.github.com/users/aselle/events{/privacy}", "received_events_url": "https://api.github.com/users/aselle/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 16, "created_at": "2018-03-08T06:04:56Z", "updated_at": "2018-11-19T22:59:45Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04.3 LTS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: tf 1.6.0</li>\n<li><strong>Python version</strong>: Python 3.5.2</li>\n<li><strong>Bazel version (if compiling from source)</strong>: bazel release 0.7.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: gcc 4.9.4</li>\n<li><strong>CUDA/cuDNN version</strong>: /</li>\n<li><strong>GPU model and memory</strong>: /</li>\n<li><strong>Exact command to reproduce</strong>:<br>\n<code>bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/tmp/gru_rnn.pb --input_format=TENSORFLOW_GRAPHDEF  --input_types=FLOAT --output_format=TFLITE --output_file=/tmp/gru_rnn.tflite --inference_type=FLOAT --inference_input_type=FLOAT --output_arrays=model/softmax,model/rnn_states</code></li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I successfully built a tflite model for mobile usage on November, 2017, and the size of .tflite was almost the same as .pb (no quantized), which was bout 950k.</p>\n<p>However, when I try to convert the same .pb to tflite model with tensorflow 1.6 master branch (HEAD commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/f7acdf2ed5e0b9c50c1c5f4b80163255aa9e8073/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/f7acdf2ed5e0b9c50c1c5f4b80163255aa9e8073\"><tt>f7acdf2</tt></a>), I find that the size of the .tflite file is 17M, <strong>which is 17x larger than before!!</strong></p>\n<p>So I make a binary search of the commits in <code>tensorflow/contrib/lite</code> history, then I find out at which commit that thing changes: the commit <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/90ce80131a8b5213d9f3eb9649d63921db7874a4/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/90ce80131a8b5213d9f3eb9649d63921db7874a4\"><tt>90ce801</tt></a> can produce 950k .tflite model, but right after it <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/528d0c5e4d148655b797368fd55fe6304730fece/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/528d0c5e4d148655b797368fd55fe6304730fece\"><tt>528d0c5</tt></a> will make the tflite model become 17M.</p>\n<p>Here are some additional information:</p>\n<ul>\n<li>Both of these two tflite models can be successfully run on mobile.</li>\n<li>I did not check the commits (if there have) between these two, since I only trace the <code>/tensorflow/contrib/lite</code> history.</li>\n<li>I guess the problem happened due to some of the operations I used in my frozen graph, in which I have 2 layer gru and some linear transforms. But I cannot upload the .pb file here...</li>\n</ul>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.3 LTS\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): tf 1.6.0\nPython version: Python 3.5.2\nBazel version (if compiling from source): bazel release 0.7.0\nGCC/Compiler version (if compiling from source): gcc 4.9.4\nCUDA/cuDNN version: /\nGPU model and memory: /\nExact command to reproduce:\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/tmp/gru_rnn.pb --input_format=TENSORFLOW_GRAPHDEF  --input_types=FLOAT --output_format=TFLITE --output_file=/tmp/gru_rnn.tflite --inference_type=FLOAT --inference_input_type=FLOAT --output_arrays=model/softmax,model/rnn_states\n\nDescribe the problem\nI successfully built a tflite model for mobile usage on November, 2017, and the size of .tflite was almost the same as .pb (no quantized), which was bout 950k.\nHowever, when I try to convert the same .pb to tflite model with tensorflow 1.6 master branch (HEAD commit f7acdf2), I find that the size of the .tflite file is 17M, which is 17x larger than before!!\nSo I make a binary search of the commits in tensorflow/contrib/lite history, then I find out at which commit that thing changes: the commit 90ce801 can produce 950k .tflite model, but right after it 528d0c5 will make the tflite model become 17M.\nHere are some additional information:\n\nBoth of these two tflite models can be successfully run on mobile.\nI did not check the commits (if there have) between these two, since I only trace the /tensorflow/contrib/lite history.\nI guess the problem happened due to some of the operations I used in my frozen graph, in which I have 2 layer gru and some linear transforms. But I cannot upload the .pb file here...", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: tf 1.6.0\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: bazel release 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc 4.9.4\r\n- **CUDA/cuDNN version**: /\r\n- **GPU model and memory**: /\r\n- **Exact command to reproduce**: \r\n`bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/tmp/gru_rnn.pb --input_format=TENSORFLOW_GRAPHDEF  --input_types=FLOAT --output_format=TFLITE --output_file=/tmp/gru_rnn.tflite --inference_type=FLOAT --inference_input_type=FLOAT --output_arrays=model/softmax,model/rnn_states`\r\n\r\n\r\n### Describe the problem\r\nI successfully built a tflite model for mobile usage on November, 2017, and the size of .tflite was almost the same as .pb (no quantized), which was bout 950k.\r\n\r\nHowever, when I try to convert the same .pb to tflite model with tensorflow 1.6 master branch (HEAD commit f7acdf2ed5e0b9c50c1c5f4b80163255aa9e8073), I find that the size of the .tflite file is 17M, **which is 17x larger than before!!**\r\n\r\nSo I make a binary search of the commits in `tensorflow/contrib/lite` history, then I find out at which commit that thing changes: the commit 90ce80131a8b5213d9f3eb9649d63921db7874a4 can produce 950k .tflite model, but right after it 528d0c5e4d148655b797368fd55fe6304730fece will make the tflite model become 17M.\r\n\r\nHere are some additional information:\r\n  - Both of these two tflite models can be successfully run on mobile.\r\n  - I did not check the commits (if there have) between these two, since I only trace the `/tensorflow/contrib/lite` history.\r\n  - I guess the problem happened due to some of the operations I used in my frozen graph, in which I have 2 layer gru and some linear transforms. But I cannot upload the .pb file here..."}