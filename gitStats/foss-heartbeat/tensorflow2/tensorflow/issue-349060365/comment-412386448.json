{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/412386448", "html_url": "https://github.com/tensorflow/tensorflow/issues/21515#issuecomment-412386448", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21515", "id": 412386448, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMjM4NjQ0OA==", "user": {"login": "EdwardLin2014", "id": 8342812, "node_id": "MDQ6VXNlcjgzNDI4MTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/8342812?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EdwardLin2014", "html_url": "https://github.com/EdwardLin2014", "followers_url": "https://api.github.com/users/EdwardLin2014/followers", "following_url": "https://api.github.com/users/EdwardLin2014/following{/other_user}", "gists_url": "https://api.github.com/users/EdwardLin2014/gists{/gist_id}", "starred_url": "https://api.github.com/users/EdwardLin2014/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EdwardLin2014/subscriptions", "organizations_url": "https://api.github.com/users/EdwardLin2014/orgs", "repos_url": "https://api.github.com/users/EdwardLin2014/repos", "events_url": "https://api.github.com/users/EdwardLin2014/events{/privacy}", "received_events_url": "https://api.github.com/users/EdwardLin2014/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-13T01:22:28Z", "updated_at": "2018-08-13T01:23:38Z", "author_association": "NONE", "body_html": "<p>Opps... my fault, as I never experience nondeterministic before, and I thought randomness is different from nondeterministic.....<br>\nI have checked the CPU computation, there is no different(error) between each run.</p>\n<p>Nevertheless, I have changed the print code as follows, so that we know how severe this nondeterministic issue is.</p>\n<pre><code>print('--------------------------------------------------')\nprint('Check whether they have the same values in each session')\nprint('Number of variables equal in each session? %r' % (len(vars1) == len(vars2)))\nprint('Number of variables? %d' % len(vars1))\nprint('Before Training: ')\nprint('lossValue? %r' % (lossValue_eval1==lossValue_eval2))\ncheck_gvs_BT = np.zeros((len(vars1),2))\nfor i in range(len(vars1)):\n    for j in range(2):\n        check_gvs_BT[i][j] = (np.sum(np.abs(gvs_eval1[i][j] - gvs_eval2[i][j])))/(gvs_eval1[i][j].shape[0]*gvs_eval1[i][j].shape[1]*gvs_eval1[i][j].shape[2]*gvs_eval1[i][j].shape[3])\nprint('gvs? %r' % (np.sum(check_gvs_BT)==0))\nprint('gvs error sum? %.16f' % np.sum(check_gvs_BT))\nprint('gvs error average? %.16f' % (np.sum(check_gvs_BT)/(len(vars1)*2)))\nprint('After Training: ')\nprint('lossValue? %r' % (lossValue1_eval1==lossValue1_eval2))\ncheck_gvs_AT = np.zeros((14,2))\nfor i in range(len(vars2)):\n    for j in range(2):\n        check_gvs_AT[i][j] = (np.sum(np.abs(gvs1_eval1[i][j] - gvs1_eval2[i][j])))/(gvs1_eval1[i][j].shape[0]*gvs1_eval1[i][j].shape[1]*gvs1_eval1[i][j].shape[2]*gvs1_eval1[i][j].shape[3])\nprint('gvs? %r' % (np.sum(check_gvs_AT)==0))\nprint('gvs error sum? %.16f' % np.sum(check_gvs_AT))\nprint('gvs error average? %.16f' % (np.sum(check_gvs_AT)/(len(vars1)*2)))\n</code></pre>\n<p>You may experience the following result with GPU<br>\nNVIDIA Tesla V100-SXM2-16GB<br>\nBefore Training<br>\n(1st run)                                         (2nd run)                           (3rd run)<br>\nError Sum: 0.5033042114695341\t0.5967776937724014\t0.3815979222670251<br>\nError Ave: 0.0179751504096262\t0.0213134890633001\t0.0136284972238223<br>\nAfter Training<br>\n(1st run)                                         (2nd run)                           (3rd run)<br>\nError Sum: 0.0042671012194780\t0.0052051065843201 \t0.0050405413446461<br>\nError Sum: 0.0001523964721242\t0.0001858966630114 \t0.0001800193337374</p>\n<p>NVIDIA GeForce GTX 1080 Ti 11GB<br>\nBefore Training<br>\n(1st run)                                         (2nd run)                           (3rd run)<br>\nError Sum: 0.2072482638888889\t0.2625868055555556 \t 0.2703993055555556<br>\nError Ave: 0.0074017237103175\t0.0093781001984127\t 0.0096571180555556<br>\nAfter Training<br>\n(1st run)                                         (2nd run)                           (3rd run)<br>\nError Sum: 0.0030042860243056\t0.0021870930989583 \t 0.0028618706597222<br>\nError Sum: 0.0001072959294395\t0.0000781104678199 \t 0.0001022096664187</p>", "body_text": "Opps... my fault, as I never experience nondeterministic before, and I thought randomness is different from nondeterministic.....\nI have checked the CPU computation, there is no different(error) between each run.\nNevertheless, I have changed the print code as follows, so that we know how severe this nondeterministic issue is.\nprint('--------------------------------------------------')\nprint('Check whether they have the same values in each session')\nprint('Number of variables equal in each session? %r' % (len(vars1) == len(vars2)))\nprint('Number of variables? %d' % len(vars1))\nprint('Before Training: ')\nprint('lossValue? %r' % (lossValue_eval1==lossValue_eval2))\ncheck_gvs_BT = np.zeros((len(vars1),2))\nfor i in range(len(vars1)):\n    for j in range(2):\n        check_gvs_BT[i][j] = (np.sum(np.abs(gvs_eval1[i][j] - gvs_eval2[i][j])))/(gvs_eval1[i][j].shape[0]*gvs_eval1[i][j].shape[1]*gvs_eval1[i][j].shape[2]*gvs_eval1[i][j].shape[3])\nprint('gvs? %r' % (np.sum(check_gvs_BT)==0))\nprint('gvs error sum? %.16f' % np.sum(check_gvs_BT))\nprint('gvs error average? %.16f' % (np.sum(check_gvs_BT)/(len(vars1)*2)))\nprint('After Training: ')\nprint('lossValue? %r' % (lossValue1_eval1==lossValue1_eval2))\ncheck_gvs_AT = np.zeros((14,2))\nfor i in range(len(vars2)):\n    for j in range(2):\n        check_gvs_AT[i][j] = (np.sum(np.abs(gvs1_eval1[i][j] - gvs1_eval2[i][j])))/(gvs1_eval1[i][j].shape[0]*gvs1_eval1[i][j].shape[1]*gvs1_eval1[i][j].shape[2]*gvs1_eval1[i][j].shape[3])\nprint('gvs? %r' % (np.sum(check_gvs_AT)==0))\nprint('gvs error sum? %.16f' % np.sum(check_gvs_AT))\nprint('gvs error average? %.16f' % (np.sum(check_gvs_AT)/(len(vars1)*2)))\n\nYou may experience the following result with GPU\nNVIDIA Tesla V100-SXM2-16GB\nBefore Training\n(1st run)                                         (2nd run)                           (3rd run)\nError Sum: 0.5033042114695341\t0.5967776937724014\t0.3815979222670251\nError Ave: 0.0179751504096262\t0.0213134890633001\t0.0136284972238223\nAfter Training\n(1st run)                                         (2nd run)                           (3rd run)\nError Sum: 0.0042671012194780\t0.0052051065843201 \t0.0050405413446461\nError Sum: 0.0001523964721242\t0.0001858966630114 \t0.0001800193337374\nNVIDIA GeForce GTX 1080 Ti 11GB\nBefore Training\n(1st run)                                         (2nd run)                           (3rd run)\nError Sum: 0.2072482638888889\t0.2625868055555556 \t 0.2703993055555556\nError Ave: 0.0074017237103175\t0.0093781001984127\t 0.0096571180555556\nAfter Training\n(1st run)                                         (2nd run)                           (3rd run)\nError Sum: 0.0030042860243056\t0.0021870930989583 \t 0.0028618706597222\nError Sum: 0.0001072959294395\t0.0000781104678199 \t 0.0001022096664187", "body": "Opps... my fault, as I never experience nondeterministic before, and I thought randomness is different from nondeterministic.....\r\nI have checked the CPU computation, there is no different(error) between each run. \r\n\r\nNevertheless, I have changed the print code as follows, so that we know how severe this nondeterministic issue is. \r\n\r\n```\r\nprint('--------------------------------------------------')\r\nprint('Check whether they have the same values in each session')\r\nprint('Number of variables equal in each session? %r' % (len(vars1) == len(vars2)))\r\nprint('Number of variables? %d' % len(vars1))\r\nprint('Before Training: ')\r\nprint('lossValue? %r' % (lossValue_eval1==lossValue_eval2))\r\ncheck_gvs_BT = np.zeros((len(vars1),2))\r\nfor i in range(len(vars1)):\r\n    for j in range(2):\r\n        check_gvs_BT[i][j] = (np.sum(np.abs(gvs_eval1[i][j] - gvs_eval2[i][j])))/(gvs_eval1[i][j].shape[0]*gvs_eval1[i][j].shape[1]*gvs_eval1[i][j].shape[2]*gvs_eval1[i][j].shape[3])\r\nprint('gvs? %r' % (np.sum(check_gvs_BT)==0))\r\nprint('gvs error sum? %.16f' % np.sum(check_gvs_BT))\r\nprint('gvs error average? %.16f' % (np.sum(check_gvs_BT)/(len(vars1)*2)))\r\nprint('After Training: ')\r\nprint('lossValue? %r' % (lossValue1_eval1==lossValue1_eval2))\r\ncheck_gvs_AT = np.zeros((14,2))\r\nfor i in range(len(vars2)):\r\n    for j in range(2):\r\n        check_gvs_AT[i][j] = (np.sum(np.abs(gvs1_eval1[i][j] - gvs1_eval2[i][j])))/(gvs1_eval1[i][j].shape[0]*gvs1_eval1[i][j].shape[1]*gvs1_eval1[i][j].shape[2]*gvs1_eval1[i][j].shape[3])\r\nprint('gvs? %r' % (np.sum(check_gvs_AT)==0))\r\nprint('gvs error sum? %.16f' % np.sum(check_gvs_AT))\r\nprint('gvs error average? %.16f' % (np.sum(check_gvs_AT)/(len(vars1)*2)))\r\n```\r\nYou may experience the following result with GPU\r\nNVIDIA Tesla V100-SXM2-16GB\r\nBefore Training\r\n(1st run)                                         (2nd run)                           (3rd run)\r\nError Sum: 0.5033042114695341\t0.5967776937724014\t0.3815979222670251\r\nError Ave: 0.0179751504096262\t0.0213134890633001\t0.0136284972238223\r\nAfter Training\r\n(1st run)                                         (2nd run)                           (3rd run)\r\nError Sum: 0.0042671012194780\t0.0052051065843201 \t0.0050405413446461\r\nError Sum: 0.0001523964721242\t0.0001858966630114 \t0.0001800193337374\r\n\r\nNVIDIA GeForce GTX 1080 Ti 11GB\r\nBefore Training\r\n(1st run)                                         (2nd run)                           (3rd run)\r\nError Sum: 0.2072482638888889\t0.2625868055555556 \t 0.2703993055555556\t\r\nError Ave: 0.0074017237103175\t0.0093781001984127\t 0.0096571180555556\r\nAfter Training\r\n(1st run)                                         (2nd run)                           (3rd run)\r\nError Sum: 0.0030042860243056\t0.0021870930989583 \t 0.0028618706597222\r\nError Sum: 0.0001072959294395\t0.0000781104678199 \t 0.0001022096664187"}