{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9935", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9935/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9935/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9935/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9935", "id": 229029874, "node_id": "MDU6SXNzdWUyMjkwMjk4NzQ=", "number": 9935, "title": "Unable to freeze Keras layers in a Tensorflow workflow.", "user": {"login": "Caselles", "id": 19774802, "node_id": "MDQ6VXNlcjE5Nzc0ODAy", "avatar_url": "https://avatars3.githubusercontent.com/u/19774802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Caselles", "html_url": "https://github.com/Caselles", "followers_url": "https://api.github.com/users/Caselles/followers", "following_url": "https://api.github.com/users/Caselles/following{/other_user}", "gists_url": "https://api.github.com/users/Caselles/gists{/gist_id}", "starred_url": "https://api.github.com/users/Caselles/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Caselles/subscriptions", "organizations_url": "https://api.github.com/users/Caselles/orgs", "repos_url": "https://api.github.com/users/Caselles/repos", "events_url": "https://api.github.com/users/Caselles/events{/privacy}", "received_events_url": "https://api.github.com/users/Caselles/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2017-05-16T13:19:26Z", "updated_at": "2017-05-16T21:00:17Z", "closed_at": "2017-05-16T21:00:17Z", "author_association": "NONE", "body_html": "<p>I'm trying to freeze Keras layers in a Tensorflow workflow. It seems that the flag trainable does not work in tf.contrib.keras. This is how I define the graph :</p>\n<p><code>sess = tf.Session()</code></p>\n<p><code>K.set_session(sess)</code></p>\n<p><code>labels = tf.placeholder(tf.float32, shape=(None, 1))</code><br>\n<code>user_id_input = tf.placeholder(tf.float32, shape=(None, 1))</code><br>\n<code>item_id_input = tf.placeholder(tf.float32, shape=(None, 1))</code></p>\n<p><code>max_user_id = all_ratings['user_id'].max()</code><br>\n<code>max_item_id = all_ratings['item_id'].max()</code></p>\n<p><code>embedding_size = 30</code><br>\n<code>user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id+1, input_length=1, name='user_embedding', trainable=all_trainable)(user_id_input)</code><br>\n<code>item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id+1, input_length=1, name='item_embedding', trainable=all_trainable)(item_id_input)</code></p>\n<p><code>user_vecs = Flatten()(user_embedding)</code><br>\n<code>item_vecs = Flatten()(item_embedding)</code></p>\n<p><code>input_vecs = concatenate([user_vecs, item_vecs])</code></p>\n<p><code>x = Dense(30, activation='relu')(input_vecs)</code><br>\n<code>x1 = Dropout(0.5)(x)</code><br>\n<code>x2 = Dense(30, activation='relu')(x1)</code><br>\n<code>y = Dense(1, activation='sigmoid')(x2)</code></p>\n<p><code>loss = tf.reduce_mean(binary_crossentropy(labels, y))</code></p>\n<p><code>train_step = tf.train.AdamOptimizer(0.004).minimize(loss)</code></p>\n<p>Then I just train the model :</p>\n<p><code>with sess.as_default():</code></p>\n<p><code>train_step.run(..)</code></p>\n<p>Everything is working fine when the trainable flag is set to <code>True</code>. Then when I set it to <code>False</code>, it does not freeze the layers.</p>\n<p>I also tried to minimize only over the variable that I want to train by using <code>train_step_freeze = tf.train.AdamOptimizer(0.004).minimize(loss, var_list=[user_embedding]) </code>, and I get :</p>\n<p><code>('Trying to optimize unsupported type ', &lt;tf.Tensor 'Placeholder_33:0' shape=(?, 1) dtype=float32&gt;)</code></p>\n<p>Is it possible to use Keras layers in Tensorflow and freeze them ?</p>", "body_text": "I'm trying to freeze Keras layers in a Tensorflow workflow. It seems that the flag trainable does not work in tf.contrib.keras. This is how I define the graph :\nsess = tf.Session()\nK.set_session(sess)\nlabels = tf.placeholder(tf.float32, shape=(None, 1))\nuser_id_input = tf.placeholder(tf.float32, shape=(None, 1))\nitem_id_input = tf.placeholder(tf.float32, shape=(None, 1))\nmax_user_id = all_ratings['user_id'].max()\nmax_item_id = all_ratings['item_id'].max()\nembedding_size = 30\nuser_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id+1, input_length=1, name='user_embedding', trainable=all_trainable)(user_id_input)\nitem_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id+1, input_length=1, name='item_embedding', trainable=all_trainable)(item_id_input)\nuser_vecs = Flatten()(user_embedding)\nitem_vecs = Flatten()(item_embedding)\ninput_vecs = concatenate([user_vecs, item_vecs])\nx = Dense(30, activation='relu')(input_vecs)\nx1 = Dropout(0.5)(x)\nx2 = Dense(30, activation='relu')(x1)\ny = Dense(1, activation='sigmoid')(x2)\nloss = tf.reduce_mean(binary_crossentropy(labels, y))\ntrain_step = tf.train.AdamOptimizer(0.004).minimize(loss)\nThen I just train the model :\nwith sess.as_default():\ntrain_step.run(..)\nEverything is working fine when the trainable flag is set to True. Then when I set it to False, it does not freeze the layers.\nI also tried to minimize only over the variable that I want to train by using train_step_freeze = tf.train.AdamOptimizer(0.004).minimize(loss, var_list=[user_embedding]) , and I get :\n('Trying to optimize unsupported type ', <tf.Tensor 'Placeholder_33:0' shape=(?, 1) dtype=float32>)\nIs it possible to use Keras layers in Tensorflow and freeze them ?", "body": "I'm trying to freeze Keras layers in a Tensorflow workflow. It seems that the flag trainable does not work in tf.contrib.keras. This is how I define the graph : \r\n\r\n`sess = tf.Session()`\r\n\r\n`K.set_session(sess)`\r\n    \r\n`labels = tf.placeholder(tf.float32, shape=(None, 1))`\r\n`user_id_input = tf.placeholder(tf.float32, shape=(None, 1))`\r\n`item_id_input = tf.placeholder(tf.float32, shape=(None, 1))`\r\n\r\n    \r\n\r\n`max_user_id = all_ratings['user_id'].max()`\r\n`max_item_id = all_ratings['item_id'].max()`\r\n\r\n`embedding_size = 30`\r\n`user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id+1,\r\n                           input_length=1, name='user_embedding', trainable=all_trainable)(user_id_input)`\r\n`item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id+1,\r\n                           input_length=1, name='item_embedding', trainable=all_trainable)(item_id_input)`\r\n\r\n\r\n\r\n`user_vecs = Flatten()(user_embedding)`\r\n`item_vecs = Flatten()(item_embedding)`\r\n\r\n\r\n`input_vecs = concatenate([user_vecs, item_vecs])`\r\n\r\n`x = Dense(30, activation='relu')(input_vecs)`\r\n`x1 = Dropout(0.5)(x)`\r\n`x2 = Dense(30, activation='relu')(x1)`\r\n`y = Dense(1, activation='sigmoid')(x2)`\r\n\r\n`loss = tf.reduce_mean(binary_crossentropy(labels, y))`\r\n\r\n`train_step = tf.train.AdamOptimizer(0.004).minimize(loss)`\r\n\r\nThen I just train the model : \r\n\r\n`with sess.as_default():`\r\n\r\n`train_step.run(..)`\r\n\r\nEverything is working fine when the trainable flag is set to `True`. Then when I set it to `False`, it does not freeze the layers.\r\n\r\nI also tried to minimize only over the variable that I want to train by using `train_step_freeze = tf.train.AdamOptimizer(0.004).minimize(loss, var_list=[user_embedding]) `, and I get : \r\n\r\n`('Trying to optimize unsupported type ', <tf.Tensor 'Placeholder_33:0' shape=(?, 1) dtype=float32>)`\r\n\r\nIs it possible to use Keras layers in Tensorflow and freeze them ? \r\n\r\n\r\n\r\n"}