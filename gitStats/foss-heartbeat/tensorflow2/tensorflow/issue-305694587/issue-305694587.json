{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17744", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17744/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17744/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17744/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/17744", "id": 305694587, "node_id": "MDU6SXNzdWUzMDU2OTQ1ODc=", "number": 17744, "title": "TFSLIM UnknownError Input/Output Error.", "user": {"login": "mukul12", "id": 22413687, "node_id": "MDQ6VXNlcjIyNDEzNjg3", "avatar_url": "https://avatars3.githubusercontent.com/u/22413687?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mukul12", "html_url": "https://github.com/mukul12", "followers_url": "https://api.github.com/users/mukul12/followers", "following_url": "https://api.github.com/users/mukul12/following{/other_user}", "gists_url": "https://api.github.com/users/mukul12/gists{/gist_id}", "starred_url": "https://api.github.com/users/mukul12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mukul12/subscriptions", "organizations_url": "https://api.github.com/users/mukul12/orgs", "repos_url": "https://api.github.com/users/mukul12/repos", "events_url": "https://api.github.com/users/mukul12/events{/privacy}", "received_events_url": "https://api.github.com/users/mukul12/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rohan100jain", "id": 144114, "node_id": "MDQ6VXNlcjE0NDExNA==", "avatar_url": "https://avatars2.githubusercontent.com/u/144114?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rohan100jain", "html_url": "https://github.com/rohan100jain", "followers_url": "https://api.github.com/users/rohan100jain/followers", "following_url": "https://api.github.com/users/rohan100jain/following{/other_user}", "gists_url": "https://api.github.com/users/rohan100jain/gists{/gist_id}", "starred_url": "https://api.github.com/users/rohan100jain/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rohan100jain/subscriptions", "organizations_url": "https://api.github.com/users/rohan100jain/orgs", "repos_url": "https://api.github.com/users/rohan100jain/repos", "events_url": "https://api.github.com/users/rohan100jain/events{/privacy}", "received_events_url": "https://api.github.com/users/rohan100jain/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-03-15T19:45:22Z", "updated_at": "2018-05-26T18:48:55Z", "closed_at": "2018-05-26T18:37:47Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<p><a href=\"https://stackoverflow.com/questions/tagged/tensorflow\" rel=\"nofollow\">https://stackoverflow.com/questions/tagged/tensorflow</a></p>\n<p>If you open a GitHub issue, here is our policy:</p>\n<ol>\n<li>It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).</li>\n<li>The form below must be filled out.</li>\n<li>It shouldn't be a TensorBoard issue. Those go <a href=\"https://github.com/tensorflow/tensorboard/issues\">here</a>.</li>\n</ol>\n<p><strong>Here's why we have that policy</strong>: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.</p>\n<hr>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>:</li>\n<li><strong>Python version</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>You can collect some of this information using our environment capture script:</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\">https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh</a></p>\n<p>You can obtain the TensorFlow version with</p>\n<p>python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</p>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<p>I have created tfrecord files and am getting the following error during my training:</p>\n<p>INFO:tensorflow:global step 3338: loss: 0.4686 (2.67 sec/step)<br>\nstep=1217<br>\nINFO:tensorflow:global step 3339: loss: 0.4468 (2.57 sec/step)<br>\nstep=1218<br>\nINFO:tensorflow:global step 3340: loss: 0.4400 (2.66 sec/step)<br>\nstep=1219<br>\nINFO:tensorflow:global step 3341: loss: 0.5029 (2.76 sec/step)<br>\nstep=1220<br>\nINFO:tensorflow:global step 3342: loss: 0.3761 (43.48 sec/step)<br>\nINFO:tensorflow:Error reported to Coordinator: &lt;class 'tensorflow.python.framework.errors_impl.UnknownError'&gt;, /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error<br>\n[[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]<br>\nTraceback (most recent call last):<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1361, in _do_call<br>\nreturn fn(*args)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn<br>\ntarget_list, status, run_metadata)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in <strong>exit</strong><br>\nc_api.TF_GetCode(self.status.status))<br>\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)<br>\n[[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 990, in managed_session<br>\nyield sess<br>\nFile \"train_alz.py\", line 282, in run<br>\nsummaries = sess.run(my_summary_op)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 905, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1137, in _run<br>\nfeed_dict_tensor, options, run_metadata)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1355, in _do_run<br>\noptions, run_metadata)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1374, in _do_call<br>\nraise type(e)(node_def, op, message)<br>\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)<br>\n[[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]</p>\n<p>Caused by op 'batch', defined at:<br>\nFile \"train_alz.py\", line 304, in <br>\nrun()<br>\nFile \"train_alz.py\", line 184, in run<br>\nimages, _, labels = load_batch(dataset, batch_size=batch_size)<br>\nFile \"train_alz.py\", line 168, in load_batch<br>\nallow_smaller_final_batch = True)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 989, in batch<br>\nname=name)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 761, in _batch<br>\ndequeued = queue.dequeue_up_to(batch_size, name=name)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 527, in dequeue_up_to<br>\nself._queue_ref, n=n, component_types=self._dtypes, name=name)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 2557, in _queue_dequeue_up_to_v2<br>\ncomponent_types=component_types, timeout_ms=timeout_ms, name=name)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op<br>\nop_def=op_def)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in <strong>init</strong><br>\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access</p>\n<p>OutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)<br>\n[[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \"train_alz.py\", line 304, in <br>\nrun()<br>\nFile \"train_alz.py\", line 300, in run<br>\nsv.saver.save(sess, sv.save_path, global_step = sv.global_step)<br>\nFile \"/usr/lib/python3.6/contextlib.py\", line 99, in <strong>exit</strong><br>\nself.gen.throw(type, value, traceback)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 1000, in managed_session<br>\nself.stop(close_summary_writer=close_summary_writer)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 828, in stop<br>\nignore_live_threads=ignore_live_threads)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join<br>\nsix.reraise(*self._exc_info_to_raise)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise<br>\nraise value<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 252, in _run<br>\nenqueue_callable()<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1259, in _single_operation_run<br>\nNone)<br>\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in <strong>exit</strong><br>\nc_api.TF_GetCode(self.status.status))<br>\ntensorflow.python.framework.errors_impl.UnknownError: /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error<br>\n[[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]</p>\n<p>I am a newbie to tensorflow and would really appreciate any help!</p>", "body_text": "Please go to Stack Overflow for help and support:\nhttps://stackoverflow.com/questions/tagged/tensorflow\nIf you open a GitHub issue, here is our policy:\n\nIt must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\nThe form below must be filled out.\nIt shouldn't be a TensorBoard issue. Those go here.\n\nHere's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\n\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\nPython version:\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nYou can collect some of this information using our environment capture script:\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\nYou can obtain the TensorFlow version with\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\nI have created tfrecord files and am getting the following error during my training:\nINFO:tensorflow:global step 3338: loss: 0.4686 (2.67 sec/step)\nstep=1217\nINFO:tensorflow:global step 3339: loss: 0.4468 (2.57 sec/step)\nstep=1218\nINFO:tensorflow:global step 3340: loss: 0.4400 (2.66 sec/step)\nstep=1219\nINFO:tensorflow:global step 3341: loss: 0.5029 (2.76 sec/step)\nstep=1220\nINFO:tensorflow:global step 3342: loss: 0.3761 (43.48 sec/step)\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnknownError'>, /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error\n[[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]\nTraceback (most recent call last):\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\nreturn fn(*args)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\ntarget_list, status, run_metadata)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in exit\nc_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)\n[[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 990, in managed_session\nyield sess\nFile \"train_alz.py\", line 282, in run\nsummaries = sess.run(my_summary_op)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 905, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1137, in _run\nfeed_dict_tensor, options, run_metadata)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\noptions, run_metadata)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\nraise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)\n[[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]\nCaused by op 'batch', defined at:\nFile \"train_alz.py\", line 304, in \nrun()\nFile \"train_alz.py\", line 184, in run\nimages, _, labels = load_batch(dataset, batch_size=batch_size)\nFile \"train_alz.py\", line 168, in load_batch\nallow_smaller_final_batch = True)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 989, in batch\nname=name)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 761, in _batch\ndequeued = queue.dequeue_up_to(batch_size, name=name)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 527, in dequeue_up_to\nself._queue_ref, n=n, component_types=self._dtypes, name=name)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 2557, in _queue_dequeue_up_to_v2\ncomponent_types=component_types, timeout_ms=timeout_ms, name=name)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\nop_def=op_def)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\nop_def=op_def)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in init\nself._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\nOutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)\n[[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"train_alz.py\", line 304, in \nrun()\nFile \"train_alz.py\", line 300, in run\nsv.saver.save(sess, sv.save_path, global_step = sv.global_step)\nFile \"/usr/lib/python3.6/contextlib.py\", line 99, in exit\nself.gen.throw(type, value, traceback)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 1000, in managed_session\nself.stop(close_summary_writer=close_summary_writer)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 828, in stop\nignore_live_threads=ignore_live_threads)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\nsix.reraise(*self._exc_info_to_raise)\nFile \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\nraise value\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 252, in _run\nenqueue_callable()\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1259, in _single_operation_run\nNone)\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in exit\nc_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.UnknownError: /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error\n[[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]\nI am a newbie to tensorflow and would really appreciate any help!", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\nI have created tfrecord files and am getting the following error during my training:\r\n\r\nINFO:tensorflow:global step 3338: loss: 0.4686 (2.67 sec/step)\r\nstep=1217\r\nINFO:tensorflow:global step 3339: loss: 0.4468 (2.57 sec/step)\r\nstep=1218\r\nINFO:tensorflow:global step 3340: loss: 0.4400 (2.66 sec/step)\r\nstep=1219\r\nINFO:tensorflow:global step 3341: loss: 0.5029 (2.76 sec/step)\r\nstep=1220\r\nINFO:tensorflow:global step 3342: loss: 0.3761 (43.48 sec/step)\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnknownError'>, /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error\r\n\t [[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\r\n    target_list, status, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)\r\n\t [[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 990, in managed_session\r\n    yield sess\r\n  File \"train_alz.py\", line 282, in run\r\n    summaries = sess.run(my_summary_op)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1137, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1374, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)\r\n\t [[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]\r\n\r\nCaused by op 'batch', defined at:\r\n  File \"train_alz.py\", line 304, in <module>\r\n    run()\r\n  File \"train_alz.py\", line 184, in run\r\n    images, _, labels = load_batch(dataset, batch_size=batch_size)\r\n  File \"train_alz.py\", line 168, in load_batch\r\n    allow_smaller_final_batch = True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 989, in batch\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py\", line 761, in _batch\r\n    dequeued = queue.dequeue_up_to(batch_size, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 527, in dequeue_up_to\r\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 2557, in _queue_dequeue_up_to_v2\r\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nOutOfRangeError (see above for traceback): FIFOQueue '_3_batch/fifo_queue' is closed and has insufficient elements (requested 32, current size 0)\r\n\t [[Node: batch = QueueDequeueUpToV2[component_types=[DT_FLOAT, DT_UINT8, DT_INT64], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](batch/fifo_queue, batch/n)]]\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train_alz.py\", line 304, in <module>\r\n    run()\r\n  File \"train_alz.py\", line 300, in run\r\n    sv.saver.save(sess, sv.save_path, global_step = sv.global_step)\r\n  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 1000, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/supervisor.py\", line 828, in stop\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 252, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1259, in _single_operation_run\r\n    None)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.UnknownError: /content/drive/app/images/train/fmri_train_00000-of-00001.tfrecord; Input/output error\r\n\t [[Node: parallel_read/ReaderReadV2 = ReaderReadV2[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](parallel_read/TFRecordReaderV2, parallel_read/filenames)]]\r\n\r\nI am a newbie to tensorflow and would really appreciate any help!"}