{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8524", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8524/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8524/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8524/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/8524", "id": 215226148, "node_id": "MDU6SXNzdWUyMTUyMjYxNDg=", "number": 8524, "title": "Asking for TF's official implementation of the inception v3 model's distributed training", "user": {"login": "Dav-Jay", "id": 11131378, "node_id": "MDQ6VXNlcjExMTMxMzc4", "avatar_url": "https://avatars2.githubusercontent.com/u/11131378?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dav-Jay", "html_url": "https://github.com/Dav-Jay", "followers_url": "https://api.github.com/users/Dav-Jay/followers", "following_url": "https://api.github.com/users/Dav-Jay/following{/other_user}", "gists_url": "https://api.github.com/users/Dav-Jay/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dav-Jay/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dav-Jay/subscriptions", "organizations_url": "https://api.github.com/users/Dav-Jay/orgs", "repos_url": "https://api.github.com/users/Dav-Jay/repos", "events_url": "https://api.github.com/users/Dav-Jay/events{/privacy}", "received_events_url": "https://api.github.com/users/Dav-Jay/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-03-18T22:26:40Z", "updated_at": "2017-03-19T14:24:14Z", "closed_at": "2017-03-19T14:24:14Z", "author_association": "NONE", "body_html": "<p>From the recorded video of TF dev summit held about one month ago, I got to know the newest distributed TF 1.0 is able to achieve 57x speed up for the inception v3 model on a server of 8 nodes/ 8 gpus and the codes will be released. Since I am far away from getting such a good scaling performance using my own distributed implementation, I have been looking forward to seeing and studying from the training codes from TF. Could anyone tell me the progress now? Thanks!</p>", "body_text": "From the recorded video of TF dev summit held about one month ago, I got to know the newest distributed TF 1.0 is able to achieve 57x speed up for the inception v3 model on a server of 8 nodes/ 8 gpus and the codes will be released. Since I am far away from getting such a good scaling performance using my own distributed implementation, I have been looking forward to seeing and studying from the training codes from TF. Could anyone tell me the progress now? Thanks!", "body": "From the recorded video of TF dev summit held about one month ago, I got to know the newest distributed TF 1.0 is able to achieve 57x speed up for the inception v3 model on a server of 8 nodes/ 8 gpus and the codes will be released. Since I am far away from getting such a good scaling performance using my own distributed implementation, I have been looking forward to seeing and studying from the training codes from TF. Could anyone tell me the progress now? Thanks!"}