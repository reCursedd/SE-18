{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/79218199", "pull_request_review_id": 397889, "id": 79218199, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDc5MjE4MTk5", "diff_hunk": "@@ -203,6 +204,27 @@ def _BiasAddGrad(op, received_grad):\n   return (received_grad, gen_nn_ops.bias_add_grad(out_backprop=received_grad,\n                                                   data_format=data_format))\n \n+@ops.RegisterGradient(\"BiasAddGrad\")\n+def _BiasAddGradGrad(op, received_grad):\n+  \"\"\"Gradient for the BiasAddGrad op.\n+\n+  Args:\n+    op: BiasAddGrad op for which we are calculating gradients.\n+    received_grad: The gradients passed to the BiasAddGrad op.\n+    \n+  Returns:\n+    A single gradient Tensor for the input to BiasAddGrad (which\n+    is the gradient of the bias term in BiasAdd)\n+  \"\"\"\n+  \n+  try:\n+    data_format = op.get_attr(\"data_format\")\n+  except ValueError:\n+    data_format = None\n+    \n+  zeros = gen_array_ops._zeros_like(op.inputs[0])\n+  return gen_nn_ops._bias_add(zeros, received_grad, data_format=data_format)", "path": "tensorflow/python/ops/nn_grad.py", "position": null, "original_position": 31, "commit_id": "3f7374316e116450ad6c2ba76cb5c55f24c2297f", "original_commit_id": "b21319bb2dca5c11ad133e530e91412032d62fea", "user": {"login": "zheng-xq", "id": 15736910, "node_id": "MDQ6VXNlcjE1NzM2OTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/15736910?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zheng-xq", "html_url": "https://github.com/zheng-xq", "followers_url": "https://api.github.com/users/zheng-xq/followers", "following_url": "https://api.github.com/users/zheng-xq/following{/other_user}", "gists_url": "https://api.github.com/users/zheng-xq/gists{/gist_id}", "starred_url": "https://api.github.com/users/zheng-xq/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zheng-xq/subscriptions", "organizations_url": "https://api.github.com/users/zheng-xq/orgs", "repos_url": "https://api.github.com/users/zheng-xq/repos", "events_url": "https://api.github.com/users/zheng-xq/events{/privacy}", "received_events_url": "https://api.github.com/users/zheng-xq/received_events", "type": "User", "site_admin": false}, "body": "In cases where the shapes are known, I think a broadcasting op such as tf.tile will be better. Since it avoids allocating the zero input array and add the unnecessary zeros. However, tf.tile in its current form may be slower. So a bit benchmarking is needed for that path. I'll leave it up to you whether you want to try that. \n\nAlso we need to add a test using compute_gradient_errort to make sure this passes the gradient checker. \n", "created_at": "2016-09-16T17:48:58Z", "updated_at": "2016-09-23T17:41:48Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4411#discussion_r79218199", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4411", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/79218199"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4411#discussion_r79218199"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4411"}}, "body_html": "<p>In cases where the shapes are known, I think a broadcasting op such as tf.tile will be better. Since it avoids allocating the zero input array and add the unnecessary zeros. However, tf.tile in its current form may be slower. So a bit benchmarking is needed for that path. I'll leave it up to you whether you want to try that.</p>\n<p>Also we need to add a test using compute_gradient_errort to make sure this passes the gradient checker.</p>", "body_text": "In cases where the shapes are known, I think a broadcasting op such as tf.tile will be better. Since it avoids allocating the zero input array and add the unnecessary zeros. However, tf.tile in its current form may be slower. So a bit benchmarking is needed for that path. I'll leave it up to you whether you want to try that.\nAlso we need to add a test using compute_gradient_errort to make sure this passes the gradient checker."}