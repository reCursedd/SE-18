{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/241065088", "html_url": "https://github.com/tensorflow/tensorflow/issues/3801#issuecomment-241065088", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3801", "id": 241065088, "node_id": "MDEyOklzc3VlQ29tbWVudDI0MTA2NTA4OA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-08-19T16:24:45Z", "updated_at": "2016-08-19T16:24:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5205204\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alquraishi\">@alquraishi</a> it's wasteful (in terms of both memory usage <em>and</em> calls to <code>cond</code> within <code>dynamic_rnn</code>) to create a padded tensor past the max sequence length, and dynamic_rnn is trying to be as efficient as possible given constraints of wanting correctness.  since the user is able to change the shape from step to step, it is up to the user to do this correctly.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=3147213\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lingz\">@lingz</a> static unroll in <code>rnn</code> means you have a fixed number of input tensors and you run through all of them.  dynamic unroll in <code>rnn</code> means you stop calculating the RNNCell past the maximum sequence_length value, and fill in the rest of the outputs with zeros.</p>\n<p>you cannot optimize calculations per example and per step; because tensorflow relies on vectorized calculations.  the best you can do is perform calculations up to the max sequence_length, zeroing out the outputs of examples that have finished as you go along,  then past the max sequence_length you can exit the calculation early as i explained in the previous paragraph.</p>\n<p>long story short: early stopping in <code>rnn</code> relies on <code>sequence_length</code>, but is wasteful in <code>dynamic_rnn</code>.  <code>dynamic_rnn</code> relies on the fact that your input shape can vary from step to step to perform <strong>true</strong> dynamic stopping.  there is no per-example per-time dynamic stopping anywhere due to vectorization of operations.</p>\n<p>if you would like to update the documentation clarifying these points, please submit a PR and I will be happy to review.  we can then reference this issue in the PR.</p>", "body_text": "@alquraishi it's wasteful (in terms of both memory usage and calls to cond within dynamic_rnn) to create a padded tensor past the max sequence length, and dynamic_rnn is trying to be as efficient as possible given constraints of wanting correctness.  since the user is able to change the shape from step to step, it is up to the user to do this correctly.\n@lingz static unroll in rnn means you have a fixed number of input tensors and you run through all of them.  dynamic unroll in rnn means you stop calculating the RNNCell past the maximum sequence_length value, and fill in the rest of the outputs with zeros.\nyou cannot optimize calculations per example and per step; because tensorflow relies on vectorized calculations.  the best you can do is perform calculations up to the max sequence_length, zeroing out the outputs of examples that have finished as you go along,  then past the max sequence_length you can exit the calculation early as i explained in the previous paragraph.\nlong story short: early stopping in rnn relies on sequence_length, but is wasteful in dynamic_rnn.  dynamic_rnn relies on the fact that your input shape can vary from step to step to perform true dynamic stopping.  there is no per-example per-time dynamic stopping anywhere due to vectorization of operations.\nif you would like to update the documentation clarifying these points, please submit a PR and I will be happy to review.  we can then reference this issue in the PR.", "body": "@alquraishi it's wasteful (in terms of both memory usage _and_ calls to `cond` within `dynamic_rnn`) to create a padded tensor past the max sequence length, and dynamic_rnn is trying to be as efficient as possible given constraints of wanting correctness.  since the user is able to change the shape from step to step, it is up to the user to do this correctly.\n\n@lingz static unroll in `rnn` means you have a fixed number of input tensors and you run through all of them.  dynamic unroll in `rnn` means you stop calculating the RNNCell past the maximum sequence_length value, and fill in the rest of the outputs with zeros.\n\nyou cannot optimize calculations per example and per step; because tensorflow relies on vectorized calculations.  the best you can do is perform calculations up to the max sequence_length, zeroing out the outputs of examples that have finished as you go along,  then past the max sequence_length you can exit the calculation early as i explained in the previous paragraph.\n\nlong story short: early stopping in `rnn` relies on `sequence_length`, but is wasteful in `dynamic_rnn`.  `dynamic_rnn` relies on the fact that your input shape can vary from step to step to perform **true** dynamic stopping.  there is no per-example per-time dynamic stopping anywhere due to vectorization of operations.\n\nif you would like to update the documentation clarifying these points, please submit a PR and I will be happy to review.  we can then reference this issue in the PR.\n"}