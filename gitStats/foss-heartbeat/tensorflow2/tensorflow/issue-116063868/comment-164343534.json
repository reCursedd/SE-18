{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/164343534", "html_url": "https://github.com/tensorflow/tensorflow/issues/86#issuecomment-164343534", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/86", "id": 164343534, "node_id": "MDEyOklzc3VlQ29tbWVudDE2NDM0MzUzNA==", "user": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "created_at": "2015-12-14T05:07:07Z", "updated_at": "2015-12-14T05:07:07Z", "author_association": "MEMBER", "body_html": "<p>We're working on making more kernels runnable on GPUs. In the code, you can tell which kernels support GPU by going to the core/kernels directory to see which ops have .cu.cc cuda files. If you want to help out, pick a CPU only kernel and write a GPU capable version either by using Eigen (for example, see the argmax or the adjust_contrast kernels), or write a plain cuda kernel (for example, see the check_numerics_op).</p>\n<p>In order to avoid duplicating work, I would create an issue called \"XX_op does not have a GPU kernel\", and then leave a comment that you're starting work on this. Then we won't do that internally without checking in with you first.</p>\n<p>Finally, when you have something written, you have to submit a patch through tensorflow.googlesource.com (instructions are <a href=\"https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md\">here</a>).</p>", "body_text": "We're working on making more kernels runnable on GPUs. In the code, you can tell which kernels support GPU by going to the core/kernels directory to see which ops have .cu.cc cuda files. If you want to help out, pick a CPU only kernel and write a GPU capable version either by using Eigen (for example, see the argmax or the adjust_contrast kernels), or write a plain cuda kernel (for example, see the check_numerics_op).\nIn order to avoid duplicating work, I would create an issue called \"XX_op does not have a GPU kernel\", and then leave a comment that you're starting work on this. Then we won't do that internally without checking in with you first.\nFinally, when you have something written, you have to submit a patch through tensorflow.googlesource.com (instructions are here).", "body": "We're working on making more kernels runnable on GPUs. In the code, you can tell which kernels support GPU by going to the core/kernels directory to see which ops have .cu.cc cuda files. If you want to help out, pick a CPU only kernel and write a GPU capable version either by using Eigen (for example, see the argmax or the adjust_contrast kernels), or write a plain cuda kernel (for example, see the check_numerics_op).\n\nIn order to avoid duplicating work, I would create an issue called \"XX_op does not have a GPU kernel\", and then leave a comment that you're starting work on this. Then we won't do that internally without checking in with you first.\n\nFinally, when you have something written, you have to submit a patch through tensorflow.googlesource.com (instructions are [here](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md)). \n"}