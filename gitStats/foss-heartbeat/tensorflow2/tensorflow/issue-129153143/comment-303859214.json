{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/303859214", "html_url": "https://github.com/tensorflow/tensorflow/issues/908#issuecomment-303859214", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/908", "id": 303859214, "node_id": "MDEyOklzc3VlQ29tbWVudDMwMzg1OTIxNA==", "user": {"login": "edubergeek", "id": 3590782, "node_id": "MDQ6VXNlcjM1OTA3ODI=", "avatar_url": "https://avatars2.githubusercontent.com/u/3590782?v=4", "gravatar_id": "", "url": "https://api.github.com/users/edubergeek", "html_url": "https://github.com/edubergeek", "followers_url": "https://api.github.com/users/edubergeek/followers", "following_url": "https://api.github.com/users/edubergeek/following{/other_user}", "gists_url": "https://api.github.com/users/edubergeek/gists{/gist_id}", "starred_url": "https://api.github.com/users/edubergeek/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/edubergeek/subscriptions", "organizations_url": "https://api.github.com/users/edubergeek/orgs", "repos_url": "https://api.github.com/users/edubergeek/repos", "events_url": "https://api.github.com/users/edubergeek/events{/privacy}", "received_events_url": "https://api.github.com/users/edubergeek/received_events", "type": "User", "site_admin": false}, "created_at": "2017-05-24T21:38:24Z", "updated_at": "2017-05-24T21:40:06Z", "author_association": "NONE", "body_html": "<p>Many thanks to <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=959847\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/martin-gorner\">@martin-gorner</a> for the code examples above. It was very helpful to me.<br>\nNow here is my derived code for an 8x8x32x64 conv2d layer that works with TensorFlow 1.1 (order of parameters shifted for some methods). Maybe this helps someone else.</p>\n<pre><code>  f2=32\n  f3=64\n\n  W3 = weight_variable([8, 8, f2, f3]) # hidden layer 3 has f2 input channels and f3 output channels\n  b3 = bias_variable([f3])\n  l3 = tf.nn.relu(conv2d(a2, W3) + b3) # a2 is downsampled activations from layer_2\n  a3 = max_pool_2x2(l3)\n\n  # visualize 32 x 64 learned feature filters as 32 (input channel) images \n  # each input channel is seen as an 8x8 (64 output channels) grid of 8x8x1 (grayscale) filters\n  with tf.name_scope('layer_3'):\n    W3_a = W3                                           # [8, 8, 32, 64]\n    #W3pad= tf.zeros([8, 8, 32, n])             # [8, 8, 32, n]  - n zero kernels for padding\n    #W3_b = tf.concat([W3_a, W3pad], 3)  # [8, 8, 32, 64]\n    # in my case I have exactly 64 output channels so I assign W3_b to W3_a\n    # comment the assignment below and uncomment the tf.zeros and tf.concat statements above to pad\n    # fewer than 64 output channels to exactly 64. You have to change \"n\" of course!\n    W3_b = W3_a\n    W3_c = tf.split(W3_b, 64, 3)                  # 64 x [8, 8, 32, 1]\n    W3_row0 = tf.concat(W3_c[0:8], 0)       # [64, 8, 32, 1]\n    W3_row1 = tf.concat(W3_c[8:16], 0)     # [64, 8, 32, 1]\n    W3_row2 = tf.concat(W3_c[16:24], 0)    # [64, 8, 32, 1]\n    W3_row3 = tf.concat(W3_c[24:32], 0)    # [64, 8, 32, 1]\n    W3_row4 = tf.concat(W3_c[32:40], 0)    # [64, 8, 32, 1]\n    W3_row5 = tf.concat(W3_c[40:48], 0)    # [64, 8, 32, 1]\n    W3_row6 = tf.concat(W3_c[48:56], 0)    # [64, 8, 32, 1]\n    W3_row7 = tf.concat(W3_c[56:64], 0)    # [64, 8, 32, 1]\n    W3_d = tf.concat([W3_row0, W3_row1, W3_row2, W3_row3, W3_row4, W3_row5, W3_row6, W3_row7], 1) # [64, 64, 32, 1]\n    W3_e = tf.reshape(W3_d, [1, 64, 64, 32])\n    W3_f = tf.split(W3_e, 32, 3)                    # 32 x [1, 64, 64, 1]\n    W3_g = tf.concat(W3_f[0:32], 0)             # [32, 64, 64, 1]\n    tf.summary.image(\"filter\", W3_g, 32)\n\n</code></pre>", "body_text": "Many thanks to @martin-gorner for the code examples above. It was very helpful to me.\nNow here is my derived code for an 8x8x32x64 conv2d layer that works with TensorFlow 1.1 (order of parameters shifted for some methods). Maybe this helps someone else.\n  f2=32\n  f3=64\n\n  W3 = weight_variable([8, 8, f2, f3]) # hidden layer 3 has f2 input channels and f3 output channels\n  b3 = bias_variable([f3])\n  l3 = tf.nn.relu(conv2d(a2, W3) + b3) # a2 is downsampled activations from layer_2\n  a3 = max_pool_2x2(l3)\n\n  # visualize 32 x 64 learned feature filters as 32 (input channel) images \n  # each input channel is seen as an 8x8 (64 output channels) grid of 8x8x1 (grayscale) filters\n  with tf.name_scope('layer_3'):\n    W3_a = W3                                           # [8, 8, 32, 64]\n    #W3pad= tf.zeros([8, 8, 32, n])             # [8, 8, 32, n]  - n zero kernels for padding\n    #W3_b = tf.concat([W3_a, W3pad], 3)  # [8, 8, 32, 64]\n    # in my case I have exactly 64 output channels so I assign W3_b to W3_a\n    # comment the assignment below and uncomment the tf.zeros and tf.concat statements above to pad\n    # fewer than 64 output channels to exactly 64. You have to change \"n\" of course!\n    W3_b = W3_a\n    W3_c = tf.split(W3_b, 64, 3)                  # 64 x [8, 8, 32, 1]\n    W3_row0 = tf.concat(W3_c[0:8], 0)       # [64, 8, 32, 1]\n    W3_row1 = tf.concat(W3_c[8:16], 0)     # [64, 8, 32, 1]\n    W3_row2 = tf.concat(W3_c[16:24], 0)    # [64, 8, 32, 1]\n    W3_row3 = tf.concat(W3_c[24:32], 0)    # [64, 8, 32, 1]\n    W3_row4 = tf.concat(W3_c[32:40], 0)    # [64, 8, 32, 1]\n    W3_row5 = tf.concat(W3_c[40:48], 0)    # [64, 8, 32, 1]\n    W3_row6 = tf.concat(W3_c[48:56], 0)    # [64, 8, 32, 1]\n    W3_row7 = tf.concat(W3_c[56:64], 0)    # [64, 8, 32, 1]\n    W3_d = tf.concat([W3_row0, W3_row1, W3_row2, W3_row3, W3_row4, W3_row5, W3_row6, W3_row7], 1) # [64, 64, 32, 1]\n    W3_e = tf.reshape(W3_d, [1, 64, 64, 32])\n    W3_f = tf.split(W3_e, 32, 3)                    # 32 x [1, 64, 64, 1]\n    W3_g = tf.concat(W3_f[0:32], 0)             # [32, 64, 64, 1]\n    tf.summary.image(\"filter\", W3_g, 32)", "body": "Many thanks to @martin-gorner for the code examples above. It was very helpful to me.\r\nNow here is my derived code for an 8x8x32x64 conv2d layer that works with TensorFlow 1.1 (order of parameters shifted for some methods). Maybe this helps someone else.\r\n\r\n```\r\n  f2=32\r\n  f3=64\r\n\r\n  W3 = weight_variable([8, 8, f2, f3]) # hidden layer 3 has f2 input channels and f3 output channels\r\n  b3 = bias_variable([f3])\r\n  l3 = tf.nn.relu(conv2d(a2, W3) + b3) # a2 is downsampled activations from layer_2\r\n  a3 = max_pool_2x2(l3)\r\n\r\n  # visualize 32 x 64 learned feature filters as 32 (input channel) images \r\n  # each input channel is seen as an 8x8 (64 output channels) grid of 8x8x1 (grayscale) filters\r\n  with tf.name_scope('layer_3'):\r\n    W3_a = W3                                           # [8, 8, 32, 64]\r\n    #W3pad= tf.zeros([8, 8, 32, n])             # [8, 8, 32, n]  - n zero kernels for padding\r\n    #W3_b = tf.concat([W3_a, W3pad], 3)  # [8, 8, 32, 64]\r\n    # in my case I have exactly 64 output channels so I assign W3_b to W3_a\r\n    # comment the assignment below and uncomment the tf.zeros and tf.concat statements above to pad\r\n    # fewer than 64 output channels to exactly 64. You have to change \"n\" of course!\r\n    W3_b = W3_a\r\n    W3_c = tf.split(W3_b, 64, 3)                  # 64 x [8, 8, 32, 1]\r\n    W3_row0 = tf.concat(W3_c[0:8], 0)       # [64, 8, 32, 1]\r\n    W3_row1 = tf.concat(W3_c[8:16], 0)     # [64, 8, 32, 1]\r\n    W3_row2 = tf.concat(W3_c[16:24], 0)    # [64, 8, 32, 1]\r\n    W3_row3 = tf.concat(W3_c[24:32], 0)    # [64, 8, 32, 1]\r\n    W3_row4 = tf.concat(W3_c[32:40], 0)    # [64, 8, 32, 1]\r\n    W3_row5 = tf.concat(W3_c[40:48], 0)    # [64, 8, 32, 1]\r\n    W3_row6 = tf.concat(W3_c[48:56], 0)    # [64, 8, 32, 1]\r\n    W3_row7 = tf.concat(W3_c[56:64], 0)    # [64, 8, 32, 1]\r\n    W3_d = tf.concat([W3_row0, W3_row1, W3_row2, W3_row3, W3_row4, W3_row5, W3_row6, W3_row7], 1) # [64, 64, 32, 1]\r\n    W3_e = tf.reshape(W3_d, [1, 64, 64, 32])\r\n    W3_f = tf.split(W3_e, 32, 3)                    # 32 x [1, 64, 64, 1]\r\n    W3_g = tf.concat(W3_f[0:32], 0)             # [32, 64, 64, 1]\r\n    tf.summary.image(\"filter\", W3_g, 32)\r\n\r\n```"}