{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/410487365", "html_url": "https://github.com/tensorflow/tensorflow/issues/20585#issuecomment-410487365", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20585", "id": 410487365, "node_id": "MDEyOklzc3VlQ29tbWVudDQxMDQ4NzM2NQ==", "user": {"login": "junshi15", "id": 12075848, "node_id": "MDQ6VXNlcjEyMDc1ODQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/12075848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junshi15", "html_url": "https://github.com/junshi15", "followers_url": "https://api.github.com/users/junshi15/followers", "following_url": "https://api.github.com/users/junshi15/following{/other_user}", "gists_url": "https://api.github.com/users/junshi15/gists{/gist_id}", "starred_url": "https://api.github.com/users/junshi15/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junshi15/subscriptions", "organizations_url": "https://api.github.com/users/junshi15/orgs", "repos_url": "https://api.github.com/users/junshi15/repos", "events_url": "https://api.github.com/users/junshi15/events{/privacy}", "received_events_url": "https://api.github.com/users/junshi15/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-05T00:55:45Z", "updated_at": "2018-08-05T00:55:45Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> I just realized there could still be a bug in tensorflow.<br>\nIndeed, the code above works perfectly. Note I used the following \"lookup-then-transpose\" to handle time_major:</p>\n<div class=\"highlight highlight-source-python\"><pre>        encoder_emb_inp <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(\n           embedding_encoder, source)\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.time_major:\n            <span class=\"pl-c\"><span class=\"pl-c\">#</span> swap (batch, time) axes if time_major</span>\n            encoder_emb_inp<span class=\"pl-k\">=</span>tf.transpose(encoder_emb_inp, [<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">2</span>])</pre></div>\n<p>Another approach could be \"transpose-then-lookup\":</p>\n<div class=\"highlight highlight-source-python\"><pre>      source <span class=\"pl-k\">=</span> np.ones((batch_size, src_len), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>)\n      <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.time_major:\n          source <span class=\"pl-k\">=</span> tf.transpose(source)\n      <span class=\"pl-c1\">...</span>\n      <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>encoder<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> decoder_scope:\n        encoder_emb_inp <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(\n           embedding_encoder, source)</pre></div>\n<p>the latter causes non-chief worker to hang. There is no error message, the worker just keeps starting master sessions. I found the latter hung because it is the approach taken by tensorflow/nmt, which you co-authored (thanks for the great contribution, I benefit enormously from the nmt code). When I try to extended nmt to distributed setting, I found the issue.</p>\n<p>Do you know why \"transpose-then-lookup\" causes the non-chief worker to hang? I attached the \"transpose-then-lookup\" code for your reference.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> argparse\n<span class=\"pl-k\">import</span> sys\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> time\n<span class=\"pl-c1\">FLAGS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">None</span>\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">_</span>):\n  ps_hosts <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.ps_hosts.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>)\n  worker_hosts <span class=\"pl-k\">=</span> <span class=\"pl-c1\">FLAGS</span>.worker_hosts.split(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>,<span class=\"pl-pds\">\"</span></span>)\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a cluster from the parameter server and worker hosts.</span>\n  cluster <span class=\"pl-k\">=</span> tf.train.ClusterSpec({<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>: ps_hosts, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>: worker_hosts})\n\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create and start a server for the local task.</span>\n  server <span class=\"pl-k\">=</span> tf.train.Server(cluster,\n                           <span class=\"pl-v\">job_name</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.job_name,\n                           <span class=\"pl-v\">task_index</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.task_index)\n  <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.job_name <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ps<span class=\"pl-pds\">\"</span></span>:\n    server.join()\n  <span class=\"pl-k\">elif</span> <span class=\"pl-c1\">FLAGS</span>.job_name <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>worker<span class=\"pl-pds\">\"</span></span>:\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Assigns ops to the local worker by default.</span>\n    <span class=\"pl-k\">with</span> tf.device(tf.train.replica_device_setter(\n        <span class=\"pl-v\">worker_device</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/job:worker/task:<span class=\"pl-c1\">%d</span><span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">%</span> <span class=\"pl-c1\">FLAGS</span>.task_index,\n        <span class=\"pl-v\">cluster</span><span class=\"pl-k\">=</span>cluster)):\n\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> Build model...</span>\n\n      batch_size <span class=\"pl-k\">=</span> <span class=\"pl-c1\">24</span>\n      src_len <span class=\"pl-k\">=</span> <span class=\"pl-c1\">25</span>\n      source <span class=\"pl-k\">=</span> np.ones((batch_size, src_len), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>)\n\n      <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.time_major:\n          source <span class=\"pl-k\">=</span> tf.transpose(source)\n\n      embedding_encoder <span class=\"pl-k\">=</span> tf.get_variable(\n          <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>embedding_encoder<span class=\"pl-pds\">\"</span></span>, (<span class=\"pl-c1\">99</span>, <span class=\"pl-c1\">128</span>), tf.float32)\n\n      embedding_decoder <span class=\"pl-k\">=</span> tf.get_variable(\n          <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>embedding_decoder<span class=\"pl-pds\">\"</span></span>, (<span class=\"pl-c1\">99</span>, <span class=\"pl-c1\">128</span>), tf.float32)\n\n      <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>encoder<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> decoder_scope:\n        encoder_emb_inp <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(\n           embedding_encoder, source)\n\n        encoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.BasicLSTMCell(\n          <span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>,\n          <span class=\"pl-v\">forget_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>)\n        sequence_length<span class=\"pl-k\">=</span>tf.fill([batch_size], src_len)\n\n        encoder_outputs, encoder_state <span class=\"pl-k\">=</span> tf.nn.dynamic_rnn(\n            encoder_cell,\n            encoder_emb_inp,\n            <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32,\n            <span class=\"pl-v\">sequence_length</span><span class=\"pl-k\">=</span>sequence_length,\n            <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.time_major,\n            <span class=\"pl-v\">swap_memory</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>)\n\n      <span class=\"pl-k\">with</span> tf.variable_scope(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>decoder<span class=\"pl-pds\">\"</span></span>) <span class=\"pl-k\">as</span> decoder_scope:\n        target_input <span class=\"pl-k\">=</span> np.ones((batch_size, src_len), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>)\n\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">FLAGS</span>.time_major:\n            target_input <span class=\"pl-k\">=</span> tf.transpose(target_input)\n\n        decoder_emb_inp <span class=\"pl-k\">=</span> tf.nn.embedding_lookup(\n            embedding_decoder, target_input) \n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Helper</span>\n        helper <span class=\"pl-k\">=</span> tf.contrib.seq2seq.TrainingHelper(\n            decoder_emb_inp, sequence_length,\n            <span class=\"pl-v\">time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.time_major)\n\n        decoder_cell <span class=\"pl-k\">=</span> tf.contrib.rnn.BasicLSTMCell(\n            <span class=\"pl-v\">num_units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">256</span>,\n            <span class=\"pl-v\">forget_bias</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.0</span>)\n        decoder_initial_state <span class=\"pl-k\">=</span> encoder_state\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Decoder</span>\n        my_decoder <span class=\"pl-k\">=</span> tf.contrib.seq2seq.BasicDecoder(\n            decoder_cell,\n            helper,\n            decoder_initial_state)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> Dynamic decoding</span>\n        decoder_outputs, final_context_state, _ <span class=\"pl-k\">=</span> tf.contrib.seq2seq.dynamic_decode(\n            my_decoder,\n            <span class=\"pl-v\">output_time_major</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.time_major,\n            <span class=\"pl-v\">swap_memory</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>,\n            <span class=\"pl-v\">scope</span><span class=\"pl-k\">=</span>decoder_scope)\n\n      global_step <span class=\"pl-k\">=</span> tf.train.get_or_create_global_step()\n      \n      train_op <span class=\"pl-k\">=</span> decoder_outputs\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> The StopAtStepHook handles stopping after running given steps.</span>\n    hooks<span class=\"pl-k\">=</span>[tf.train.StopAtStepHook(<span class=\"pl-v\">last_step</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">100</span>)]\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> The MonitoredTrainingSession takes care of session initialization,</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> restoring from a checkpoint, saving to a checkpoint, and closing when done</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> or an error occurs.</span>\n    <span class=\"pl-k\">with</span> tf.train.MonitoredTrainingSession(<span class=\"pl-v\">master</span><span class=\"pl-k\">=</span>server.target,\n                                           <span class=\"pl-v\">is_chief</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">FLAGS</span>.task_index <span class=\"pl-k\">==</span> <span class=\"pl-c1\">0</span>),\n                                           <span class=\"pl-v\">checkpoint_dir</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">FLAGS</span>.out_dir,\n                                           <span class=\"pl-v\">hooks</span><span class=\"pl-k\">=</span>hooks) <span class=\"pl-k\">as</span> mon_sess:\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> This is an infinite while loop since global_step does not increment at all.</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> In a real training, global_step is passed to an optimizer, then increments</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> after each step.</span>\n      <span class=\"pl-k\">while</span> <span class=\"pl-k\">not</span> mon_sess.should_stop():\n        x <span class=\"pl-k\">=</span> mon_sess.run(train_op)\n        global_step_val <span class=\"pl-k\">=</span> global_step.eval(<span class=\"pl-v\">session</span><span class=\"pl-k\">=</span>mon_sess)\n        <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>global_step = <span class=\"pl-c1\">{0}</span>, time_major is <span class=\"pl-c1\">{1}</span><span class=\"pl-pds\">'</span></span>.format(global_step_val, <span class=\"pl-c1\">FLAGS</span>.time_major))\n\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>__main__<span class=\"pl-pds\">\"</span></span>:\n  parser <span class=\"pl-k\">=</span> argparse.ArgumentParser()\n  parser.register(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>bool<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">v</span>: v.lower() <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>true<span class=\"pl-pds\">\"</span></span>)\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Flags for defining the tf.train.ClusterSpec</span>\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--ps_hosts<span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Comma-separated list of hostname:port pairs<span class=\"pl-pds\">\"</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--worker_hosts<span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Comma-separated list of hostname:port pairs<span class=\"pl-pds\">\"</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--job_name<span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>One of 'ps', 'worker'<span class=\"pl-pds\">\"</span></span>\n  )\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> Flags for defining the tf.train.Server</span>\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--task_index<span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">int</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0</span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Index of task within the job<span class=\"pl-pds\">\"</span></span>\n  )\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--out_dir<span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n      <span class=\"pl-v\">default</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>output dir<span class=\"pl-pds\">\"</span></span>\n  )\n\n  parser.add_argument(\n      <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--time_major<span class=\"pl-pds\">\"</span></span>,\n      <span class=\"pl-v\">action</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>store_true<span class=\"pl-pds\">'</span></span>,\n      <span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>time major<span class=\"pl-pds\">\"</span></span>\n  )\n  <span class=\"pl-c1\">FLAGS</span>, unparsed <span class=\"pl-k\">=</span> parser.parse_known_args()\n  tf.app.run(<span class=\"pl-v\">main</span><span class=\"pl-k\">=</span>main, <span class=\"pl-v\">argv</span><span class=\"pl-k\">=</span>[sys.argv[<span class=\"pl-c1\">0</span>]] <span class=\"pl-k\">+</span> unparsed)</pre></div>", "body_text": "@ebrevdo I just realized there could still be a bug in tensorflow.\nIndeed, the code above works perfectly. Note I used the following \"lookup-then-transpose\" to handle time_major:\n        encoder_emb_inp = tf.nn.embedding_lookup(\n           embedding_encoder, source)\n        if FLAGS.time_major:\n            # swap (batch, time) axes if time_major\n            encoder_emb_inp=tf.transpose(encoder_emb_inp, [1, 0, 2])\nAnother approach could be \"transpose-then-lookup\":\n      source = np.ones((batch_size, src_len), dtype=int)\n      if FLAGS.time_major:\n          source = tf.transpose(source)\n      ...\n      with tf.variable_scope(\"encoder\") as decoder_scope:\n        encoder_emb_inp = tf.nn.embedding_lookup(\n           embedding_encoder, source)\nthe latter causes non-chief worker to hang. There is no error message, the worker just keeps starting master sessions. I found the latter hung because it is the approach taken by tensorflow/nmt, which you co-authored (thanks for the great contribution, I benefit enormously from the nmt code). When I try to extended nmt to distributed setting, I found the issue.\nDo you know why \"transpose-then-lookup\" causes the non-chief worker to hang? I attached the \"transpose-then-lookup\" code for your reference.\nimport argparse\nimport sys\n\nimport tensorflow as tf\nimport numpy as np\nimport time\nFLAGS = None\n\ndef main(_):\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\n\n  # Create a cluster from the parameter server and worker hosts.\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n  # Create and start a server for the local task.\n  server = tf.train.Server(cluster,\n                           job_name=FLAGS.job_name,\n                           task_index=FLAGS.task_index)\n  if FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n\n    # Assigns ops to the local worker by default.\n    with tf.device(tf.train.replica_device_setter(\n        worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n        cluster=cluster)):\n\n      # Build model...\n\n      batch_size = 24\n      src_len = 25\n      source = np.ones((batch_size, src_len), dtype=int)\n\n      if FLAGS.time_major:\n          source = tf.transpose(source)\n\n      embedding_encoder = tf.get_variable(\n          \"embedding_encoder\", (99, 128), tf.float32)\n\n      embedding_decoder = tf.get_variable(\n          \"embedding_decoder\", (99, 128), tf.float32)\n\n      with tf.variable_scope(\"encoder\") as decoder_scope:\n        encoder_emb_inp = tf.nn.embedding_lookup(\n           embedding_encoder, source)\n\n        encoder_cell = tf.contrib.rnn.BasicLSTMCell(\n          num_units=256,\n          forget_bias=1.0)\n        sequence_length=tf.fill([batch_size], src_len)\n\n        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n            encoder_cell,\n            encoder_emb_inp,\n            dtype=tf.float32,\n            sequence_length=sequence_length,\n            time_major=FLAGS.time_major,\n            swap_memory=True)\n\n      with tf.variable_scope(\"decoder\") as decoder_scope:\n        target_input = np.ones((batch_size, src_len), dtype=int)\n\n        if FLAGS.time_major:\n            target_input = tf.transpose(target_input)\n\n        decoder_emb_inp = tf.nn.embedding_lookup(\n            embedding_decoder, target_input) \n\n        # Helper\n        helper = tf.contrib.seq2seq.TrainingHelper(\n            decoder_emb_inp, sequence_length,\n            time_major=FLAGS.time_major)\n\n        decoder_cell = tf.contrib.rnn.BasicLSTMCell(\n            num_units=256,\n            forget_bias=1.0)\n        decoder_initial_state = encoder_state\n\n        # Decoder\n        my_decoder = tf.contrib.seq2seq.BasicDecoder(\n            decoder_cell,\n            helper,\n            decoder_initial_state)\n\n        # Dynamic decoding\n        decoder_outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n            my_decoder,\n            output_time_major=FLAGS.time_major,\n            swap_memory=True,\n            scope=decoder_scope)\n\n      global_step = tf.train.get_or_create_global_step()\n      \n      train_op = decoder_outputs\n\n    # The StopAtStepHook handles stopping after running given steps.\n    hooks=[tf.train.StopAtStepHook(last_step=100)]\n\n    # The MonitoredTrainingSession takes care of session initialization,\n    # restoring from a checkpoint, saving to a checkpoint, and closing when done\n    # or an error occurs.\n    with tf.train.MonitoredTrainingSession(master=server.target,\n                                           is_chief=(FLAGS.task_index == 0),\n                                           checkpoint_dir=FLAGS.out_dir,\n                                           hooks=hooks) as mon_sess:\n      # This is an infinite while loop since global_step does not increment at all.\n      # In a real training, global_step is passed to an optimizer, then increments\n      # after each step.\n      while not mon_sess.should_stop():\n        x = mon_sess.run(train_op)\n        global_step_val = global_step.eval(session=mon_sess)\n        print('global_step = {0}, time_major is {1}'.format(global_step_val, FLAGS.time_major))\n\n\nif __name__ == \"__main__\":\n  parser = argparse.ArgumentParser()\n  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n  # Flags for defining the tf.train.ClusterSpec\n  parser.add_argument(\n      \"--ps_hosts\",\n      type=str,\n      default=\"\",\n      help=\"Comma-separated list of hostname:port pairs\"\n  )\n  parser.add_argument(\n      \"--worker_hosts\",\n      type=str,\n      default=\"\",\n      help=\"Comma-separated list of hostname:port pairs\"\n  )\n  parser.add_argument(\n      \"--job_name\",\n      type=str,\n      default=\"\",\n      help=\"One of 'ps', 'worker'\"\n  )\n  # Flags for defining the tf.train.Server\n  parser.add_argument(\n      \"--task_index\",\n      type=int,\n      default=0,\n      help=\"Index of task within the job\"\n  )\n  parser.add_argument(\n      \"--out_dir\",\n      type=str,\n      default=\"\",\n      help=\"output dir\"\n  )\n\n  parser.add_argument(\n      \"--time_major\",\n      action='store_true',\n      help=\"time major\"\n  )\n  FLAGS, unparsed = parser.parse_known_args()\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)", "body": "@ebrevdo I just realized there could still be a bug in tensorflow. \r\nIndeed, the code above works perfectly. Note I used the following \"lookup-then-transpose\" to handle time_major:\r\n```python\r\n        encoder_emb_inp = tf.nn.embedding_lookup(\r\n           embedding_encoder, source)\r\n        if FLAGS.time_major:\r\n            # swap (batch, time) axes if time_major\r\n            encoder_emb_inp=tf.transpose(encoder_emb_inp, [1, 0, 2])\r\n```\r\nAnother approach could be \"transpose-then-lookup\":\r\n```python\r\n      source = np.ones((batch_size, src_len), dtype=int)\r\n      if FLAGS.time_major:\r\n          source = tf.transpose(source)\r\n      ...\r\n      with tf.variable_scope(\"encoder\") as decoder_scope:\r\n        encoder_emb_inp = tf.nn.embedding_lookup(\r\n           embedding_encoder, source)\r\n```\r\nthe latter causes non-chief worker to hang. There is no error message, the worker just keeps starting master sessions. I found the latter hung because it is the approach taken by tensorflow/nmt, which you co-authored (thanks for the great contribution, I benefit enormously from the nmt code). When I try to extended nmt to distributed setting, I found the issue.\r\n\r\nDo you know why \"transpose-then-lookup\" causes the non-chief worker to hang? I attached the \"transpose-then-lookup\" code for your reference.\r\n\r\n```python\r\nimport argparse\r\nimport sys\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\nFLAGS = None\r\n\r\ndef main(_):\r\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\r\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\r\n\r\n  # Create a cluster from the parameter server and worker hosts.\r\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\r\n\r\n  # Create and start a server for the local task.\r\n  server = tf.train.Server(cluster,\r\n                           job_name=FLAGS.job_name,\r\n                           task_index=FLAGS.task_index)\r\n  if FLAGS.job_name == \"ps\":\r\n    server.join()\r\n  elif FLAGS.job_name == \"worker\":\r\n\r\n    # Assigns ops to the local worker by default.\r\n    with tf.device(tf.train.replica_device_setter(\r\n        worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\r\n        cluster=cluster)):\r\n\r\n      # Build model...\r\n\r\n      batch_size = 24\r\n      src_len = 25\r\n      source = np.ones((batch_size, src_len), dtype=int)\r\n\r\n      if FLAGS.time_major:\r\n          source = tf.transpose(source)\r\n\r\n      embedding_encoder = tf.get_variable(\r\n          \"embedding_encoder\", (99, 128), tf.float32)\r\n\r\n      embedding_decoder = tf.get_variable(\r\n          \"embedding_decoder\", (99, 128), tf.float32)\r\n\r\n      with tf.variable_scope(\"encoder\") as decoder_scope:\r\n        encoder_emb_inp = tf.nn.embedding_lookup(\r\n           embedding_encoder, source)\r\n\r\n        encoder_cell = tf.contrib.rnn.BasicLSTMCell(\r\n          num_units=256,\r\n          forget_bias=1.0)\r\n        sequence_length=tf.fill([batch_size], src_len)\r\n\r\n        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\r\n            encoder_cell,\r\n            encoder_emb_inp,\r\n            dtype=tf.float32,\r\n            sequence_length=sequence_length,\r\n            time_major=FLAGS.time_major,\r\n            swap_memory=True)\r\n\r\n      with tf.variable_scope(\"decoder\") as decoder_scope:\r\n        target_input = np.ones((batch_size, src_len), dtype=int)\r\n\r\n        if FLAGS.time_major:\r\n            target_input = tf.transpose(target_input)\r\n\r\n        decoder_emb_inp = tf.nn.embedding_lookup(\r\n            embedding_decoder, target_input) \r\n\r\n        # Helper\r\n        helper = tf.contrib.seq2seq.TrainingHelper(\r\n            decoder_emb_inp, sequence_length,\r\n            time_major=FLAGS.time_major)\r\n\r\n        decoder_cell = tf.contrib.rnn.BasicLSTMCell(\r\n            num_units=256,\r\n            forget_bias=1.0)\r\n        decoder_initial_state = encoder_state\r\n\r\n        # Decoder\r\n        my_decoder = tf.contrib.seq2seq.BasicDecoder(\r\n            decoder_cell,\r\n            helper,\r\n            decoder_initial_state)\r\n\r\n        # Dynamic decoding\r\n        decoder_outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\r\n            my_decoder,\r\n            output_time_major=FLAGS.time_major,\r\n            swap_memory=True,\r\n            scope=decoder_scope)\r\n\r\n      global_step = tf.train.get_or_create_global_step()\r\n      \r\n      train_op = decoder_outputs\r\n\r\n    # The StopAtStepHook handles stopping after running given steps.\r\n    hooks=[tf.train.StopAtStepHook(last_step=100)]\r\n\r\n    # The MonitoredTrainingSession takes care of session initialization,\r\n    # restoring from a checkpoint, saving to a checkpoint, and closing when done\r\n    # or an error occurs.\r\n    with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                           is_chief=(FLAGS.task_index == 0),\r\n                                           checkpoint_dir=FLAGS.out_dir,\r\n                                           hooks=hooks) as mon_sess:\r\n      # This is an infinite while loop since global_step does not increment at all.\r\n      # In a real training, global_step is passed to an optimizer, then increments\r\n      # after each step.\r\n      while not mon_sess.should_stop():\r\n        x = mon_sess.run(train_op)\r\n        global_step_val = global_step.eval(session=mon_sess)\r\n        print('global_step = {0}, time_major is {1}'.format(global_step_val, FLAGS.time_major))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  parser = argparse.ArgumentParser()\r\n  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\r\n  # Flags for defining the tf.train.ClusterSpec\r\n  parser.add_argument(\r\n      \"--ps_hosts\",\r\n      type=str,\r\n      default=\"\",\r\n      help=\"Comma-separated list of hostname:port pairs\"\r\n  )\r\n  parser.add_argument(\r\n      \"--worker_hosts\",\r\n      type=str,\r\n      default=\"\",\r\n      help=\"Comma-separated list of hostname:port pairs\"\r\n  )\r\n  parser.add_argument(\r\n      \"--job_name\",\r\n      type=str,\r\n      default=\"\",\r\n      help=\"One of 'ps', 'worker'\"\r\n  )\r\n  # Flags for defining the tf.train.Server\r\n  parser.add_argument(\r\n      \"--task_index\",\r\n      type=int,\r\n      default=0,\r\n      help=\"Index of task within the job\"\r\n  )\r\n  parser.add_argument(\r\n      \"--out_dir\",\r\n      type=str,\r\n      default=\"\",\r\n      help=\"output dir\"\r\n  )\r\n\r\n  parser.add_argument(\r\n      \"--time_major\",\r\n      action='store_true',\r\n      help=\"time major\"\r\n  )\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n```"}