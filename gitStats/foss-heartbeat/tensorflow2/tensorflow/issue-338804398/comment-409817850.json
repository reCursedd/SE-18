{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409817850", "html_url": "https://github.com/tensorflow/tensorflow/issues/20585#issuecomment-409817850", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20585", "id": 409817850, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTgxNzg1MA==", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "created_at": "2018-08-02T06:14:09Z", "updated_at": "2018-08-02T06:14:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I think there's an error you're not seeing in the logs.</p>\n<p>if FLAGS.time_major:<br>\nsequence_length=np.ones(src_len, dtype=int)*batch_size<br>\nelse:<br>\nsequence_length=np.ones(batch_size, dtype=int)*src_len</p>\n<p>This is problematic. You should always have a vector of size batch_size, regardless of time_major or not.  In your case you may even be able to just skip passing in this argument.</p>", "body_text": "I think there's an error you're not seeing in the logs.\nif FLAGS.time_major:\nsequence_length=np.ones(src_len, dtype=int)*batch_size\nelse:\nsequence_length=np.ones(batch_size, dtype=int)*src_len\nThis is problematic. You should always have a vector of size batch_size, regardless of time_major or not.  In your case you may even be able to just skip passing in this argument.", "body": "I think there's an error you're not seeing in the logs.\r\n\r\n  if FLAGS.time_major:\r\n            sequence_length=np.ones(src_len, dtype=int)*batch_size\r\n        else:\r\n            sequence_length=np.ones(batch_size, dtype=int)*src_len\r\n\r\nThis is problematic. You should always have a vector of size batch_size, regardless of time_major or not.  In your case you may even be able to just skip passing in this argument."}