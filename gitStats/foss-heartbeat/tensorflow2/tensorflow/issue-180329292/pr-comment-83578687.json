{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/83578687", "pull_request_review_id": 2352239, "id": 83578687, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgzNTc4Njg3", "diff_hunk": "@@ -20,15 +20,185 @@\n from __future__ import division\n from __future__ import print_function\n \n+from tensorflow.python.ops import tensor_array_ops\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import variable_scope as vs\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import rnn\n \n+from tensorflow.contrib.layers import fully_connected\n+\n+from functools import partial\n \n __all__ = [\"rnn_decoder\",\n            \"rnn_decoder_attention\"]\n \n+\"\"\"Used to project encoder state in `rnn_decoder`\"\"\"\n+encoder_projection = partial(fully_connected, activation_fn=math_ops.tanh)\n \n-def rnn_decoder(*args, **kwargs):\n-  pass\n+\n+def rnn_decoder(cell, decoder_inputs, initial_state,\n+                sequence_length, decoder_fn,\n+                encoder_projection=encoder_projection,\n+                parallel_iterations=None, swap_memory=False,\n+                time_major=False, scope=None):\n+  \"\"\"RNN decoder for a sequence-to-sequence model specified by RNNCell 'cell'.\n+\n+  The 'rnn_decoder' is similar to the 'tf.python.ops.rnn.dynamic_rnn'. As the\n+  decoder does not make any assumptions of sequence length of the input or how\n+  many steps it can decode, since 'rnn_decoder' uses dynamic unrolling. This\n+  allows `decoder_inputs` to have [None] in the sequence length of the decoder\n+  inputs.\n+\n+  The parameter decoder_inputs is nessesary for both training and evaluation.\n+  During training it is feed at every timestep. During evaluation it is only\n+  feed at time==0, as the decoder needs the `start-of-sequence` symbol, known\n+  from Sutskever et al., 2014 https://arxiv.org/abs/1409.3215, at the\n+  beginning of decoding.\n+\n+  The parameter sequence length is nessesary as it determines how many\n+  timesteps to decode for each sample. TODO: Could make it optional for\n+  training.\n+\n+  Args:\n+    cell: An instance of RNNCell.\n+    inputs: The RNN inputs.\n+      If `time_major == False` (default), this must be a `Tensor` of shape:\n+        `[batch_size, max_time, ...]`.\n+      If `time_major == True`, this must be a `Tensor` of shape:\n+        `[max_time, batch_size, ...]`.\n+      The input to `cell` at each time step will be a `Tensor` with dimensions\n+      `[batch_size, ...]`.\n+    sequence_length: An int32/int64 vector sized `[batch_size]`.\n+    initial_state: An initial state for the RNN.\n+      Must be [batch_size, num_features], where num_features does not have to\n+      match the cell.state_size. As a projection is performed at the beginning\n+      of the decoding.\n+    decoder_fn: A function that takes a state and returns an embedding.\n+      The decoder function is closely related to `_extract_argmax_and_embed`.\n+      Here is an example of a `decoder_fn`:\n+      def decoder_fn(embeddings, weight, bias):\n+        def dec_fn(state):\n+          prev = tf.matmul(state, weight) + bias", "path": "tensorflow/contrib/seq2seq/python/ops/layers.py", "position": null, "original_position": 66, "commit_id": "cf9f5d32c2d618e7dd98fe222b92aec1a3cf9dd4", "original_commit_id": "e148d284d3d8bd8670186e917867962f599938ae", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "`prev = tf.contrib.layers.linear(state)`... etc...\n", "created_at": "2016-10-17T05:15:12Z", "updated_at": "2016-11-30T17:47:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#discussion_r83578687", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4686", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/83578687"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4686#discussion_r83578687"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4686"}}, "body_html": "<p><code>prev = tf.contrib.layers.linear(state)</code>... etc...</p>", "body_text": "prev = tf.contrib.layers.linear(state)... etc..."}