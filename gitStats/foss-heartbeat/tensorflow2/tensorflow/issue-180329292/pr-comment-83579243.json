{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/83579243", "pull_request_review_id": 2352239, "id": 83579243, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDgzNTc5MjQz", "diff_hunk": "@@ -20,15 +20,185 @@\n from __future__ import division\n from __future__ import print_function\n \n+from tensorflow.python.ops import tensor_array_ops\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import variable_scope as vs\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import rnn\n \n+from tensorflow.contrib.layers import fully_connected\n+\n+from functools import partial\n \n __all__ = [\"rnn_decoder\",\n            \"rnn_decoder_attention\"]\n \n+\"\"\"Used to project encoder state in `rnn_decoder`\"\"\"\n+encoder_projection = partial(fully_connected, activation_fn=math_ops.tanh)\n \n-def rnn_decoder(*args, **kwargs):\n-  pass\n+\n+def rnn_decoder(cell, decoder_inputs, initial_state,\n+                sequence_length, decoder_fn,\n+                encoder_projection=encoder_projection,\n+                parallel_iterations=None, swap_memory=False,\n+                time_major=False, scope=None):\n+  \"\"\"RNN decoder for a sequence-to-sequence model specified by RNNCell 'cell'.\n+\n+  The 'rnn_decoder' is similar to the 'tf.python.ops.rnn.dynamic_rnn'. As the\n+  decoder does not make any assumptions of sequence length of the input or how\n+  many steps it can decode, since 'rnn_decoder' uses dynamic unrolling. This\n+  allows `decoder_inputs` to have [None] in the sequence length of the decoder\n+  inputs.\n+\n+  The parameter decoder_inputs is nessesary for both training and evaluation.\n+  During training it is feed at every timestep. During evaluation it is only\n+  feed at time==0, as the decoder needs the `start-of-sequence` symbol, known\n+  from Sutskever et al., 2014 https://arxiv.org/abs/1409.3215, at the\n+  beginning of decoding.\n+\n+  The parameter sequence length is nessesary as it determines how many\n+  timesteps to decode for each sample. TODO: Could make it optional for\n+  training.\n+\n+  Args:\n+    cell: An instance of RNNCell.\n+    inputs: The RNN inputs.\n+      If `time_major == False` (default), this must be a `Tensor` of shape:\n+        `[batch_size, max_time, ...]`.\n+      If `time_major == True`, this must be a `Tensor` of shape:\n+        `[max_time, batch_size, ...]`.\n+      The input to `cell` at each time step will be a `Tensor` with dimensions\n+      `[batch_size, ...]`.\n+    sequence_length: An int32/int64 vector sized `[batch_size]`.\n+    initial_state: An initial state for the RNN.\n+      Must be [batch_size, num_features], where num_features does not have to\n+      match the cell.state_size. As a projection is performed at the beginning\n+      of the decoding.\n+    decoder_fn: A function that takes a state and returns an embedding.\n+      The decoder function is closely related to `_extract_argmax_and_embed`.\n+      Here is an example of a `decoder_fn`:\n+      def decoder_fn(embeddings, weight, bias):\n+        def dec_fn(state):\n+          prev = tf.matmul(state, weight) + bias\n+          return tf.gather(embeddings, tf.argmax(prev, 1))\n+        return dec_fn\n+    encoder_projection: (optional) given that the encoder might have a\n+      different size than the decoder, we project the intial state as\n+      described in Bahdanau, 2014 (https://arxiv.org/abs/1409.0473).\n+      The optional `encoder_projection` is a\n+      `tf.contrib.layers.fully_connected` with\n+      `activation_fn=tf.python.ops.nn.tanh`.\n+    parallel_iterations: (Default: 32).  The number of iterations to run in\n+      parallel.  Those operations which do not have any temporal dependency\n+      and can be run in parallel, will be.  This parameter trades off\n+      time for space.  Values >> 1 use more memory but take less time,\n+      while smaller values use less memory but computations take longer.\n+    swap_memory: Transparently swap the tensors produced in forward inference\n+      but needed for back prop from GPU to CPU.  This allows training RNNs\n+      which would typically not fit on a single GPU, with very minimal (or no)\n+      performance penalty.\n+    time_major: The shape format of the `inputs` and `outputs` Tensors.\n+      If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n+      If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n+      Using `time_major = True` is a bit more efficient because it avoids\n+      transposes at the beginning and end of the RNN calculation.  However,\n+      most TensorFlow data is batch-major, so by default this function\n+      accepts input and emits output in batch-major form.\n+    scope: VariableScope for the created subgraph; defaults to \"RNN\".\n+  Returns:", "path": "tensorflow/contrib/seq2seq/python/ops/layers.py", "position": null, "original_position": 92, "commit_id": "cf9f5d32c2d618e7dd98fe222b92aec1a3cf9dd4", "original_commit_id": "e148d284d3d8bd8670186e917867962f599938ae", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "this is completely inconsistent with your code; which returns something really different.\n", "created_at": "2016-10-17T05:23:02Z", "updated_at": "2016-11-30T17:47:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#discussion_r83579243", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4686", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/83579243"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4686#discussion_r83579243"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4686"}}, "body_html": "<p>this is completely inconsistent with your code; which returns something really different.</p>", "body_text": "this is completely inconsistent with your code; which returns something really different."}