{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/255303779", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#issuecomment-255303779", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4686", "id": 255303779, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NTMwMzc3OQ==", "user": {"login": "alrojo", "id": 12167999, "node_id": "MDQ6VXNlcjEyMTY3OTk5", "avatar_url": "https://avatars1.githubusercontent.com/u/12167999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alrojo", "html_url": "https://github.com/alrojo", "followers_url": "https://api.github.com/users/alrojo/followers", "following_url": "https://api.github.com/users/alrojo/following{/other_user}", "gists_url": "https://api.github.com/users/alrojo/gists{/gist_id}", "starred_url": "https://api.github.com/users/alrojo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alrojo/subscriptions", "organizations_url": "https://api.github.com/users/alrojo/orgs", "repos_url": "https://api.github.com/users/alrojo/repos", "events_url": "https://api.github.com/users/alrojo/events{/privacy}", "received_events_url": "https://api.github.com/users/alrojo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-21T06:24:32Z", "updated_at": "2016-10-21T06:28:36Z", "author_association": "CONTRIBUTOR", "body_html": "<p>I have tried coding the <code>decoder_fn</code> and avoiding users handling tensor_arrays. However, I kept coming back to the <code>decoder_fn</code> essentially being equal to the <code>loop_fn</code> and the <code>rnn_decoder</code> just being a wrapper for <code>loop_fn</code>.</p>\n<p>Instead (or perhaps as an extension to the <code>decoder_fn</code>), I made <code>rnn_decoder</code> into a class and modularized all tasks in the <code>loop_fn</code> call so the user can provide custom functions for <code>new_state</code>, <code>new_input</code>, <code>new_output</code>, <code>new_loop_state</code>, all with access to <code>self</code> allowing calls to input_ta and similar if needed. This will allow the user to only have to change the \"modules\" they need when injecting new code. E.g. I only had to change the <code>input_fn</code> (a few lines of code) when going from training to evaluating. And without having tested it, I also think that you only need to change <code>input_fn</code> for attention support.</p>\n<p>My hopes is that this will achieve the equivalent of what our <code>decoder_fn</code> is described to do, but with even less code.</p>\n<p>As a result, the decoder_train and decoder_eval are now separated (you call them with different <code>input_fn</code>) and I made an <code>input_fn</code> with the eos and embedding loop_up for early stopping.</p>\n<p>I just finished running the code with no bugs \u00bd hour ago, so I won't be able to submit a clean commit tonight, but I will be at Google tomorrow by 10 to code with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=396613\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lmthang\">@lmthang</a>. If you want more descriptions, see the code or want to discuss feel free to come by.</p>\n<p>EDIT: here is the <code>loop_fn</code> from the \"new\" <code>rnn_decoder</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">loop_fn</span>(<span class=\"pl-smi\">time</span>, <span class=\"pl-smi\">cell_output</span>, <span class=\"pl-smi\">cell_state</span>, <span class=\"pl-smi\">loop_state</span>):\n      elements_finished <span class=\"pl-k\">=</span> (time <span class=\"pl-k\">&gt;=</span> <span class=\"pl-c1\">self</span>.sequence_length) <span class=\"pl-c\"><span class=\"pl-c\">#</span><span class=\"pl-k\">TODO</span> handle seq_len=None</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get s_t, y_t</span>\n      emit_output <span class=\"pl-k\">=</span> cell_output\n      <span class=\"pl-k\">if</span> cell_output <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        next_cell_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.state\n      <span class=\"pl-k\">else</span>:\n        next_cell_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.state_fn(<span class=\"pl-c1\">self</span>, cell_state)\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get x_{t+1}</span>\n      next_input, elements_finished <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.inputs_fn(<span class=\"pl-c1\">self</span>, time, next_cell_state, elements_finished)\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get loop_state</span>\n      next_loop_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.loop_fn(<span class=\"pl-c1\">self</span>, loop_state)\n      <span class=\"pl-k\">return</span> (elements_finished, next_input, next_cell_state,\n              emit_output, next_loop_state)</pre></div>", "body_text": "I have tried coding the decoder_fn and avoiding users handling tensor_arrays. However, I kept coming back to the decoder_fn essentially being equal to the loop_fn and the rnn_decoder just being a wrapper for loop_fn.\nInstead (or perhaps as an extension to the decoder_fn), I made rnn_decoder into a class and modularized all tasks in the loop_fn call so the user can provide custom functions for new_state, new_input, new_output, new_loop_state, all with access to self allowing calls to input_ta and similar if needed. This will allow the user to only have to change the \"modules\" they need when injecting new code. E.g. I only had to change the input_fn (a few lines of code) when going from training to evaluating. And without having tested it, I also think that you only need to change input_fn for attention support.\nMy hopes is that this will achieve the equivalent of what our decoder_fn is described to do, but with even less code.\nAs a result, the decoder_train and decoder_eval are now separated (you call them with different input_fn) and I made an input_fn with the eos and embedding loop_up for early stopping.\nI just finished running the code with no bugs \u00bd hour ago, so I won't be able to submit a clean commit tonight, but I will be at Google tomorrow by 10 to code with @lmthang. If you want more descriptions, see the code or want to discuss feel free to come by.\nEDIT: here is the loop_fn from the \"new\" rnn_decoder:\n    def loop_fn(time, cell_output, cell_state, loop_state):\n      elements_finished = (time >= self.sequence_length) #TODO handle seq_len=None\n      # get s_t, y_t\n      emit_output = cell_output\n      if cell_output is None:\n        next_cell_state = self.state\n      else:\n        next_cell_state = self.state_fn(self, cell_state)\n      # get x_{t+1}\n      next_input, elements_finished = self.inputs_fn(self, time, next_cell_state, elements_finished)\n      # get loop_state\n      next_loop_state = self.loop_fn(self, loop_state)\n      return (elements_finished, next_input, next_cell_state,\n              emit_output, next_loop_state)", "body": "I have tried coding the `decoder_fn` and avoiding users handling tensor_arrays. However, I kept coming back to the `decoder_fn` essentially being equal to the `loop_fn` and the `rnn_decoder` just being a wrapper for `loop_fn`.\n\nInstead (or perhaps as an extension to the `decoder_fn`), I made `rnn_decoder` into a class and modularized all tasks in the `loop_fn` call so the user can provide custom functions for `new_state`, `new_input`, `new_output`, `new_loop_state`, all with access to `self` allowing calls to input_ta and similar if needed. This will allow the user to only have to change the \"modules\" they need when injecting new code. E.g. I only had to change the `input_fn` (a few lines of code) when going from training to evaluating. And without having tested it, I also think that you only need to change `input_fn` for attention support.\n\nMy hopes is that this will achieve the equivalent of what our `decoder_fn` is described to do, but with even less code.\n\nAs a result, the decoder_train and decoder_eval are now separated (you call them with different `input_fn`) and I made an `input_fn` with the eos and embedding loop_up for early stopping.\n\nI just finished running the code with no bugs \u00bd hour ago, so I won't be able to submit a clean commit tonight, but I will be at Google tomorrow by 10 to code with @lmthang. If you want more descriptions, see the code or want to discuss feel free to come by.\n\nEDIT: here is the `loop_fn` from the \"new\" `rnn_decoder`:\n\n``` python\n    def loop_fn(time, cell_output, cell_state, loop_state):\n      elements_finished = (time >= self.sequence_length) #TODO handle seq_len=None\n      # get s_t, y_t\n      emit_output = cell_output\n      if cell_output is None:\n        next_cell_state = self.state\n      else:\n        next_cell_state = self.state_fn(self, cell_state)\n      # get x_{t+1}\n      next_input, elements_finished = self.inputs_fn(self, time, next_cell_state, elements_finished)\n      # get loop_state\n      next_loop_state = self.loop_fn(self, loop_state)\n      return (elements_finished, next_input, next_cell_state,\n              emit_output, next_loop_state)\n```\n"}