{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256213900", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#issuecomment-256213900", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4686", "id": 256213900, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NjIxMzkwMA==", "user": {"login": "alrojo", "id": 12167999, "node_id": "MDQ6VXNlcjEyMTY3OTk5", "avatar_url": "https://avatars1.githubusercontent.com/u/12167999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alrojo", "html_url": "https://github.com/alrojo", "followers_url": "https://api.github.com/users/alrojo/followers", "following_url": "https://api.github.com/users/alrojo/following{/other_user}", "gists_url": "https://api.github.com/users/alrojo/gists{/gist_id}", "starred_url": "https://api.github.com/users/alrojo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alrojo/subscriptions", "organizations_url": "https://api.github.com/users/alrojo/orgs", "repos_url": "https://api.github.com/users/alrojo/repos", "events_url": "https://api.github.com/users/alrojo/events{/privacy}", "received_events_url": "https://api.github.com/users/alrojo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-26T00:03:28Z", "updated_at": "2016-10-26T00:10:24Z", "author_association": "CONTRIBUTOR", "body_html": "<blockquote>\n<p>we had discussed a clean API on friday; but this seems like a big diversion from that.</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p>why does decoder_fn need self?</p>\n</blockquote>\n<p>From previous answer:</p>\n<blockquote>\n<p>I have tried coding the <code>decoder_fn</code> and avoiding users handling tensor_arrays. However, I kept coming back to the <code>decoder_fn</code> essentially being equal to the <code>loop_fn</code> and the <code>rnn_decoder</code> just being a wrapper for <code>loop_fn</code>.</p>\n<p>Instead (or perhaps as an extension to the <code>decoder_fn</code>), I made <code>rnn_decoder</code> into a class and modularized all tasks in the <code>loop_fn</code> call so the user can provide custom functions for <code>new_state</code>, <code>new_input</code>, <code>new_output</code>, <code>new_loop_state</code>, all with access to <code>self</code> allowing calls to input_ta and similar if needed. This will allow the user to only have to change the \"modules\" they need when injecting new code. E.g. I only had to change the <code>input_fn</code> (a few lines of code) when going from training to evaluating. And without having tested it, I also think that you only need to change <code>input_fn</code> for attention support.</p>\n<p>My hopes is that this will achieve the equivalent of what our <code>decoder_fn</code> is described to do, but with even less code.</p>\n<p>As a result, the decoder_train and decoder_eval are now separated (you call them with different <code>input_fn</code>) and I made an <code>input_fn</code> with the eos and embedding loop_up for early stopping.</p>\n<p>I just finished running the code with no bugs \u00bd hour ago, so I won't be able to submit a clean commit tonight, but I will be at Google tomorrow by 10 to code with <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=396613\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lmthang\">@lmthang</a>. If you want more descriptions, see the code or want to discuss feel free to come by.</p>\n<p>EDIT: here is the <code>loop_fn</code> from the \"new\" <code>rnn_decoder</code>:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">def</span> <span class=\"pl-en\">loop_fn</span>(<span class=\"pl-smi\">time</span>, <span class=\"pl-smi\">cell_output</span>, <span class=\"pl-smi\">cell_state</span>, <span class=\"pl-smi\">loop_state</span>):\n      elements_finished <span class=\"pl-k\">=</span> (time <span class=\"pl-k\">&gt;=</span> <span class=\"pl-c1\">self</span>.sequence_length) <span class=\"pl-c\"><span class=\"pl-c\">#</span><span class=\"pl-k\">TODO</span> handle seq_len=None</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get s_t, y_t</span>\n      emit_output <span class=\"pl-k\">=</span> cell_output\n      <span class=\"pl-k\">if</span> cell_output <span class=\"pl-k\">is</span> <span class=\"pl-c1\">None</span>:\n        next_cell_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.state\n      <span class=\"pl-k\">else</span>:\n        next_cell_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.state_fn(<span class=\"pl-c1\">self</span>, cell_state)\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get x_{t+1}</span>\n      next_input, elements_finished <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.inputs_fn(<span class=\"pl-c1\">self</span>, time, next_cell_state, elements_finished)\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get loop_state</span>\n      next_loop_state <span class=\"pl-k\">=</span> <span class=\"pl-c1\">self</span>.loop_fn(<span class=\"pl-c1\">self</span>, loop_state)\n      <span class=\"pl-k\">return</span> (elements_finished, next_input, next_cell_state,\n              emit_output, next_loop_state)</pre></div>\n</blockquote>\n<p>Then given Lukasz Answer:</p>\n<blockquote>\n<p>I'm not convinced about your grouping of functions. For example, you enforce that state_fn only takes state. But for beam search, it'll have to have access to the context of the beam to re-group the states.</p>\n</blockquote>\n<p>I changed the interface to take the entire <code>loop_fn</code> instead (named  <code>decoder_fn</code>) with access to <code>self</code> instead of the four functions used above to allow maximal customization. Leaving the <code>rnn_decoder</code> a wrapper for <code>raw_rnn</code> to handle things like <a href=\"https://github.com/alrojo/tensorflow/blob/dynamic_decoder/tensorflow/contrib/seq2seq/python/ops/seq2seq.py#L258\">this</a>.</p>\n<p>The reason for access to self is to get access to some of the processed variables in <code>rnn_decoder</code>, such as: <code>inputs_ta</code>, <code>sequence_length</code>, <code>input_depth</code>, <code>batch_size</code>, <code>dtype</code>, <code>state</code>, <code>time_major</code> (will be used for attention) and future variables.</p>\n<blockquote>\n<p>decoder_fn should not know anything about inputs_ta</p>\n</blockquote>\n<p>Often the main difference between training, evaluating, attention is to switch the input part. For this we need access to <code>inputs_ta</code>, <a href=\"https://github.com/alrojo/tensorflow/blob/dynamic_decoder/tensorflow/contrib/seq2seq/python/ops/decoder_fn.py#L52\">see here</a>.</p>\n<blockquote>\n<p>variables are accessible via vs.get_variable(); there's no need to store them anywhere</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p>batch_size can be inferred from the input shapes.</p>\n</blockquote>\n<p>Alternatively to using classes and <code>self</code> to store information, I guess we could either allow <code>rnn_decoder</code> to pass a <code>**kwargs</code> argument or store all of the above in <code>tf.Variable</code>'s and then use <code>vs.get_variable();</code>? (I might need to read a bit more about using <code>vs.get_variable</code> for the latter).</p>\n<p>Please let me know what you think on the current architecture of having <code>rnn_decoder</code> as a wrapper for <code>raw_rnn</code> with <code>decoder_fn</code> supplying the <code>loop_fn</code> and if yes, if we should use a <code>**kwargs</code> architecture or <code>tf.Variable</code> architecture to send variables in-between the <code>rnn_decoder</code> and <code>decoder_fn</code> instead of using classes and <code>self</code>.</p>", "body_text": "we had discussed a clean API on friday; but this seems like a big diversion from that.\n\nand\n\nwhy does decoder_fn need self?\n\nFrom previous answer:\n\nI have tried coding the decoder_fn and avoiding users handling tensor_arrays. However, I kept coming back to the decoder_fn essentially being equal to the loop_fn and the rnn_decoder just being a wrapper for loop_fn.\nInstead (or perhaps as an extension to the decoder_fn), I made rnn_decoder into a class and modularized all tasks in the loop_fn call so the user can provide custom functions for new_state, new_input, new_output, new_loop_state, all with access to self allowing calls to input_ta and similar if needed. This will allow the user to only have to change the \"modules\" they need when injecting new code. E.g. I only had to change the input_fn (a few lines of code) when going from training to evaluating. And without having tested it, I also think that you only need to change input_fn for attention support.\nMy hopes is that this will achieve the equivalent of what our decoder_fn is described to do, but with even less code.\nAs a result, the decoder_train and decoder_eval are now separated (you call them with different input_fn) and I made an input_fn with the eos and embedding loop_up for early stopping.\nI just finished running the code with no bugs \u00bd hour ago, so I won't be able to submit a clean commit tonight, but I will be at Google tomorrow by 10 to code with @lmthang. If you want more descriptions, see the code or want to discuss feel free to come by.\nEDIT: here is the loop_fn from the \"new\" rnn_decoder:\n    def loop_fn(time, cell_output, cell_state, loop_state):\n      elements_finished = (time >= self.sequence_length) #TODO handle seq_len=None\n      # get s_t, y_t\n      emit_output = cell_output\n      if cell_output is None:\n        next_cell_state = self.state\n      else:\n        next_cell_state = self.state_fn(self, cell_state)\n      # get x_{t+1}\n      next_input, elements_finished = self.inputs_fn(self, time, next_cell_state, elements_finished)\n      # get loop_state\n      next_loop_state = self.loop_fn(self, loop_state)\n      return (elements_finished, next_input, next_cell_state,\n              emit_output, next_loop_state)\n\nThen given Lukasz Answer:\n\nI'm not convinced about your grouping of functions. For example, you enforce that state_fn only takes state. But for beam search, it'll have to have access to the context of the beam to re-group the states.\n\nI changed the interface to take the entire loop_fn instead (named  decoder_fn) with access to self instead of the four functions used above to allow maximal customization. Leaving the rnn_decoder a wrapper for raw_rnn to handle things like this.\nThe reason for access to self is to get access to some of the processed variables in rnn_decoder, such as: inputs_ta, sequence_length, input_depth, batch_size, dtype, state, time_major (will be used for attention) and future variables.\n\ndecoder_fn should not know anything about inputs_ta\n\nOften the main difference between training, evaluating, attention is to switch the input part. For this we need access to inputs_ta, see here.\n\nvariables are accessible via vs.get_variable(); there's no need to store them anywhere\n\nand\n\nbatch_size can be inferred from the input shapes.\n\nAlternatively to using classes and self to store information, I guess we could either allow rnn_decoder to pass a **kwargs argument or store all of the above in tf.Variable's and then use vs.get_variable();? (I might need to read a bit more about using vs.get_variable for the latter).\nPlease let me know what you think on the current architecture of having rnn_decoder as a wrapper for raw_rnn with decoder_fn supplying the loop_fn and if yes, if we should use a **kwargs architecture or tf.Variable architecture to send variables in-between the rnn_decoder and decoder_fn instead of using classes and self.", "body": "> we had discussed a clean API on friday; but this seems like a big diversion from that.\n\nand\n\n> why does decoder_fn need self?\n\nFrom previous answer:\n\n> I have tried coding the `decoder_fn` and avoiding users handling tensor_arrays. However, I kept coming back to the `decoder_fn` essentially being equal to the `loop_fn` and the `rnn_decoder` just being a wrapper for `loop_fn`.\n> \n> Instead (or perhaps as an extension to the `decoder_fn`), I made `rnn_decoder` into a class and modularized all tasks in the `loop_fn` call so the user can provide custom functions for `new_state`, `new_input`, `new_output`, `new_loop_state`, all with access to `self` allowing calls to input_ta and similar if needed. This will allow the user to only have to change the \"modules\" they need when injecting new code. E.g. I only had to change the `input_fn` (a few lines of code) when going from training to evaluating. And without having tested it, I also think that you only need to change `input_fn` for attention support.\n> \n> My hopes is that this will achieve the equivalent of what our `decoder_fn` is described to do, but with even less code.\n> \n> As a result, the decoder_train and decoder_eval are now separated (you call them with different `input_fn`) and I made an `input_fn` with the eos and embedding loop_up for early stopping.\n> \n> I just finished running the code with no bugs \u00bd hour ago, so I won't be able to submit a clean commit tonight, but I will be at Google tomorrow by 10 to code with @lmthang. If you want more descriptions, see the code or want to discuss feel free to come by.\n> \n> EDIT: here is the `loop_fn` from the \"new\" `rnn_decoder`:\n> \n> ``` python\n>     def loop_fn(time, cell_output, cell_state, loop_state):\n>       elements_finished = (time >= self.sequence_length) #TODO handle seq_len=None\n>       # get s_t, y_t\n>       emit_output = cell_output\n>       if cell_output is None:\n>         next_cell_state = self.state\n>       else:\n>         next_cell_state = self.state_fn(self, cell_state)\n>       # get x_{t+1}\n>       next_input, elements_finished = self.inputs_fn(self, time, next_cell_state, elements_finished)\n>       # get loop_state\n>       next_loop_state = self.loop_fn(self, loop_state)\n>       return (elements_finished, next_input, next_cell_state,\n>               emit_output, next_loop_state)\n> ```\n\nThen given Lukasz Answer:\n\n> I'm not convinced about your grouping of functions. For example, you enforce that state_fn only takes state. But for beam search, it'll have to have access to the context of the beam to re-group the states.\n\nI changed the interface to take the entire `loop_fn` instead (named  `decoder_fn`) with access to `self` instead of the four functions used above to allow maximal customization. Leaving the `rnn_decoder` a wrapper for `raw_rnn` to handle things like [this](https://github.com/alrojo/tensorflow/blob/dynamic_decoder/tensorflow/contrib/seq2seq/python/ops/seq2seq.py#L258).\n\nThe reason for access to self is to get access to some of the processed variables in `rnn_decoder`, such as: `inputs_ta`, `sequence_length`, `input_depth`, `batch_size`, `dtype`, `state`, `time_major` (will be used for attention) and future variables.\n\n> decoder_fn should not know anything about inputs_ta\n\nOften the main difference between training, evaluating, attention is to switch the input part. For this we need access to `inputs_ta`, [see here](https://github.com/alrojo/tensorflow/blob/dynamic_decoder/tensorflow/contrib/seq2seq/python/ops/decoder_fn.py#L52).\n\n> variables are accessible via vs.get_variable(); there's no need to store them anywhere\n\nand\n\n> batch_size can be inferred from the input shapes.\n\nAlternatively to using classes and `self` to store information, I guess we could either allow `rnn_decoder` to pass a `**kwargs` argument or store all of the above in `tf.Variable`'s and then use `vs.get_variable();`? (I might need to read a bit more about using `vs.get_variable` for the latter).\n\nPlease let me know what you think on the current architecture of having `rnn_decoder` as a wrapper for `raw_rnn` with `decoder_fn` supplying the `loop_fn` and if yes, if we should use a `**kwargs` architecture or `tf.Variable` architecture to send variables in-between the `rnn_decoder` and `decoder_fn` instead of using classes and `self`.\n"}