{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/260105241", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#issuecomment-260105241", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4686", "id": 260105241, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MDEwNTI0MQ==", "user": {"login": "lmthang", "id": 396613, "node_id": "MDQ6VXNlcjM5NjYxMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/396613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmthang", "html_url": "https://github.com/lmthang", "followers_url": "https://api.github.com/users/lmthang/followers", "following_url": "https://api.github.com/users/lmthang/following{/other_user}", "gists_url": "https://api.github.com/users/lmthang/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmthang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmthang/subscriptions", "organizations_url": "https://api.github.com/users/lmthang/orgs", "repos_url": "https://api.github.com/users/lmthang/repos", "events_url": "https://api.github.com/users/lmthang/events{/privacy}", "received_events_url": "https://api.github.com/users/lmthang/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-12T06:30:03Z", "updated_at": "2016-11-12T06:30:03Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12167999\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alrojo\">@alrojo</a>: one more thing, the way we obtain the <code>batch_size</code> from <code>encoder_state</code> in <code>simple_decoder_fn_inference</code> is not correct when encoder_state is a tuple, e.g., when using BasicLSTMCell. Perhaps, we can pass <code>batch_size</code> as another argument to that <code>simple_decoder_fn_inference</code>?</p>", "body_text": "@alrojo: one more thing, the way we obtain the batch_size from encoder_state in simple_decoder_fn_inference is not correct when encoder_state is a tuple, e.g., when using BasicLSTMCell. Perhaps, we can pass batch_size as another argument to that simple_decoder_fn_inference?", "body": "@alrojo: one more thing, the way we obtain the `batch_size` from `encoder_state` in `simple_decoder_fn_inference` is not correct when encoder_state is a tuple, e.g., when using BasicLSTMCell. Perhaps, we can pass `batch_size` as another argument to that `simple_decoder_fn_inference`?\n"}