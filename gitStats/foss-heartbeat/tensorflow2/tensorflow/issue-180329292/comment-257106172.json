{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257106172", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#issuecomment-257106172", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4686", "id": 257106172, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzEwNjE3Mg==", "user": {"login": "alrojo", "id": 12167999, "node_id": "MDQ6VXNlcjEyMTY3OTk5", "avatar_url": "https://avatars1.githubusercontent.com/u/12167999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alrojo", "html_url": "https://github.com/alrojo", "followers_url": "https://api.github.com/users/alrojo/followers", "following_url": "https://api.github.com/users/alrojo/following{/other_user}", "gists_url": "https://api.github.com/users/alrojo/gists{/gist_id}", "starred_url": "https://api.github.com/users/alrojo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alrojo/subscriptions", "organizations_url": "https://api.github.com/users/alrojo/orgs", "repos_url": "https://api.github.com/users/alrojo/repos", "events_url": "https://api.github.com/users/alrojo/events{/privacy}", "received_events_url": "https://api.github.com/users/alrojo/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-29T17:59:36Z", "updated_at": "2016-10-29T18:01:02Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Regarding attention, we would need to \"concat\" something extra to the input.</p>\n<p>We can do this by either adding the input to the <code>decoder_fn</code> or by reformulating the following:</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-c\"><span class=\"pl-c\">#</span> call decoder function</span>\n    <span class=\"pl-k\">if</span> inputs <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>: <span class=\"pl-c\"><span class=\"pl-c\">#</span> training</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get next_cell_input</span>\n      <span class=\"pl-k\">if</span> cell_state <span class=\"pl-k\">==</span> <span class=\"pl-c1\">None</span>:\n        next_cell_input <span class=\"pl-k\">=</span> inputs_ta.read(<span class=\"pl-c1\">0</span>)\n      <span class=\"pl-k\">else</span>:\n        batch_size <span class=\"pl-k\">=</span> array_ops.shape(done)[<span class=\"pl-c1\">0</span>]\n        next_cell_input <span class=\"pl-k\">=</span> control_flow_ops.cond(\n            tf.equal(time, max_time),\n            <span class=\"pl-k\">lambda</span>: array_ops.zeros([batch_size, input_depth], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype),\n            <span class=\"pl-k\">lambda</span>: inputs_ta.read(time))\n      (next_done, next_cell_state, _, emit_output, next_context_state) <span class=\"pl-k\">=</span> (\n          decoder_fn(cell_state, cell_output, context_state))</pre></div>\n<p>into the following</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-c\"><span class=\"pl-c\">#</span> call decoder function</span>\n    <span class=\"pl-k\">if</span> inputs <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>: <span class=\"pl-c\"><span class=\"pl-c\">#</span> training</span>\n      <span class=\"pl-c\"><span class=\"pl-c\">#</span> get next_cell_input</span>\n      <span class=\"pl-k\">if</span> cell_state <span class=\"pl-k\">==</span> <span class=\"pl-c1\">None</span>:\n        next_cell_input <span class=\"pl-k\">=</span> inputs_ta.read(<span class=\"pl-c1\">0</span>)\n      <span class=\"pl-k\">else</span>:\n        batch_size <span class=\"pl-k\">=</span> array_ops.shape(done)[<span class=\"pl-c1\">0</span>]\n        next_cell_input <span class=\"pl-k\">=</span> control_flow_ops.cond(\n            tf.equal(time, max_time),\n            <span class=\"pl-k\">lambda</span>: array_ops.zeros([batch_size, input_depth], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>dtype),\n            <span class=\"pl-k\">lambda</span>: inputs_ta.read(time))\n      (next_done, next_cell_state, additional_input, emit_output, next_context_state) <span class=\"pl-k\">=</span> (\n          decoder_fn(cell_state, cell_output, context_state))\n      <span class=\"pl-k\">if</span> additional_input <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">None</span>:\n          <span class=\"pl-c\"><span class=\"pl-c\">#</span> concat along feature dimension</span>\n          next_cell_input <span class=\"pl-k\">=</span> tf.concat(<span class=\"pl-v\">concat_dim</span><span class=\"pl-k\">=</span><span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>, [next_cell_input, additional_input])</pre></div>", "body_text": "Regarding attention, we would need to \"concat\" something extra to the input.\nWe can do this by either adding the input to the decoder_fn or by reformulating the following:\n    # call decoder function\n    if inputs is not None: # training\n      # get next_cell_input\n      if cell_state == None:\n        next_cell_input = inputs_ta.read(0)\n      else:\n        batch_size = array_ops.shape(done)[0]\n        next_cell_input = control_flow_ops.cond(\n            tf.equal(time, max_time),\n            lambda: array_ops.zeros([batch_size, input_depth], dtype=dtype),\n            lambda: inputs_ta.read(time))\n      (next_done, next_cell_state, _, emit_output, next_context_state) = (\n          decoder_fn(cell_state, cell_output, context_state))\ninto the following\n    # call decoder function\n    if inputs is not None: # training\n      # get next_cell_input\n      if cell_state == None:\n        next_cell_input = inputs_ta.read(0)\n      else:\n        batch_size = array_ops.shape(done)[0]\n        next_cell_input = control_flow_ops.cond(\n            tf.equal(time, max_time),\n            lambda: array_ops.zeros([batch_size, input_depth], dtype=dtype),\n            lambda: inputs_ta.read(time))\n      (next_done, next_cell_state, additional_input, emit_output, next_context_state) = (\n          decoder_fn(cell_state, cell_output, context_state))\n      if additional_input is not None:\n          # concat along feature dimension\n          next_cell_input = tf.concat(concat_dim=-1, [next_cell_input, additional_input])", "body": "Regarding attention, we would need to \"concat\" something extra to the input.\n\nWe can do this by either adding the input to the `decoder_fn` or by reformulating the following:\n\n``` python\n    # call decoder function\n    if inputs is not None: # training\n      # get next_cell_input\n      if cell_state == None:\n        next_cell_input = inputs_ta.read(0)\n      else:\n        batch_size = array_ops.shape(done)[0]\n        next_cell_input = control_flow_ops.cond(\n            tf.equal(time, max_time),\n            lambda: array_ops.zeros([batch_size, input_depth], dtype=dtype),\n            lambda: inputs_ta.read(time))\n      (next_done, next_cell_state, _, emit_output, next_context_state) = (\n          decoder_fn(cell_state, cell_output, context_state))\n```\n\ninto the following\n\n``` python\n    # call decoder function\n    if inputs is not None: # training\n      # get next_cell_input\n      if cell_state == None:\n        next_cell_input = inputs_ta.read(0)\n      else:\n        batch_size = array_ops.shape(done)[0]\n        next_cell_input = control_flow_ops.cond(\n            tf.equal(time, max_time),\n            lambda: array_ops.zeros([batch_size, input_depth], dtype=dtype),\n            lambda: inputs_ta.read(time))\n      (next_done, next_cell_state, additional_input, emit_output, next_context_state) = (\n          decoder_fn(cell_state, cell_output, context_state))\n      if additional_input is not None:\n          # concat along feature dimension\n          next_cell_input = tf.concat(concat_dim=-1, [next_cell_input, additional_input])\n```\n"}