{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/261242612", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#issuecomment-261242612", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4686", "id": 261242612, "node_id": "MDEyOklzc3VlQ29tbWVudDI2MTI0MjYxMg==", "user": {"login": "jihunchoi", "id": 1898501, "node_id": "MDQ6VXNlcjE4OTg1MDE=", "avatar_url": "https://avatars2.githubusercontent.com/u/1898501?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jihunchoi", "html_url": "https://github.com/jihunchoi", "followers_url": "https://api.github.com/users/jihunchoi/followers", "following_url": "https://api.github.com/users/jihunchoi/following{/other_user}", "gists_url": "https://api.github.com/users/jihunchoi/gists{/gist_id}", "starred_url": "https://api.github.com/users/jihunchoi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jihunchoi/subscriptions", "organizations_url": "https://api.github.com/users/jihunchoi/orgs", "repos_url": "https://api.github.com/users/jihunchoi/repos", "events_url": "https://api.github.com/users/jihunchoi/events{/privacy}", "received_events_url": "https://api.github.com/users/jihunchoi/received_events", "type": "User", "site_admin": false}, "created_at": "2016-11-17T13:10:29Z", "updated_at": "2016-11-18T06:03:53Z", "author_association": "CONTRIBUTOR", "body_html": "<p>Hello, I have tested the latest commit of this pull request, and find that an error occurs when using with <code>MultiRNNCell</code> of LSTMCell.<br>\nA single-layer LSTMCell seems to work fine (I've tested the LSTMCell with state_is_tuple option), however when I wrap the cell with MultiRNNCell, the following exception is raised.</p>\n<pre><code>ValueError: The two structures don't have the same number of elements. \nFirst structure: Tensor(\"Train/Model/simple_decoder_fn_train/packed:0\", shape=(4, 2, ?, 1024), dtype=float32),\nsecond structure: (LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024)).\n</code></pre>\n<p>EDIT:<br>\nI found that the problem is due to the following lines.</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name, <span class=\"pl-v\">default_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>simple_decoder_fn_train<span class=\"pl-pds\">'</span></span>,\n                       <span class=\"pl-v\">values</span><span class=\"pl-k\">=</span>[encoder_state]):\n        <span class=\"pl-k\">if</span> <span class=\"pl-c1\">type</span>(encoder_state) <span class=\"pl-k\">is</span> <span class=\"pl-k\">not</span> tf.nn.rnn_cell.LSTMStateTuple:\n            encoder_state <span class=\"pl-k\">=</span> tf.convert_to_tensor(encoder_state)</pre></div>\n<p>When we use MultiRNNCell of LSTMCell, the type of its state is not LSTMStateTuple but tuple, and consequently, it passes the if condition and the state is packed into a [num_layers, 2, batch_size, hidden_dim] tensor.<br>\nThus, I think we need to detect whether the cell is LSTMCell (with state_is_tuple option) using a smarter way.</p>\n<p>Below are my clumsy workaround codes.</p>\n<div class=\"highlight highlight-source-python\"><pre>    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span>name, <span class=\"pl-v\">default_name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>simple_decoder_fn_train<span class=\"pl-pds\">'</span></span>,\n                       <span class=\"pl-v\">values</span><span class=\"pl-k\">=</span>[encoder_state]):\n        <span class=\"pl-k\">if</span> (<span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(encoder_state, tf.nn.rnn_cell.LSTMStateTuple)\n                <span class=\"pl-k\">and</span> <span class=\"pl-k\">not</span> <span class=\"pl-c1\">isinstance</span>(encoder_state, <span class=\"pl-c1\">tuple</span>)):\n            encoder_state <span class=\"pl-k\">=</span> tf.convert_to_tensor(encoder_state)</pre></div>", "body_text": "Hello, I have tested the latest commit of this pull request, and find that an error occurs when using with MultiRNNCell of LSTMCell.\nA single-layer LSTMCell seems to work fine (I've tested the LSTMCell with state_is_tuple option), however when I wrap the cell with MultiRNNCell, the following exception is raised.\nValueError: The two structures don't have the same number of elements. \nFirst structure: Tensor(\"Train/Model/simple_decoder_fn_train/packed:0\", shape=(4, 2, ?, 1024), dtype=float32),\nsecond structure: (LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024)).\n\nEDIT:\nI found that the problem is due to the following lines.\n    with tf.name_scope(name=name, default_name='simple_decoder_fn_train',\n                       values=[encoder_state]):\n        if type(encoder_state) is not tf.nn.rnn_cell.LSTMStateTuple:\n            encoder_state = tf.convert_to_tensor(encoder_state)\nWhen we use MultiRNNCell of LSTMCell, the type of its state is not LSTMStateTuple but tuple, and consequently, it passes the if condition and the state is packed into a [num_layers, 2, batch_size, hidden_dim] tensor.\nThus, I think we need to detect whether the cell is LSTMCell (with state_is_tuple option) using a smarter way.\nBelow are my clumsy workaround codes.\n    with tf.name_scope(name=name, default_name='simple_decoder_fn_train',\n                       values=[encoder_state]):\n        if (not isinstance(encoder_state, tf.nn.rnn_cell.LSTMStateTuple)\n                and not isinstance(encoder_state, tuple)):\n            encoder_state = tf.convert_to_tensor(encoder_state)", "body": "Hello, I have tested the latest commit of this pull request, and find that an error occurs when using with `MultiRNNCell` of LSTMCell.\nA single-layer LSTMCell seems to work fine (I've tested the LSTMCell with state_is_tuple option), however when I wrap the cell with MultiRNNCell, the following exception is raised.\n\n```\nValueError: The two structures don't have the same number of elements. \nFirst structure: Tensor(\"Train/Model/simple_decoder_fn_train/packed:0\", shape=(4, 2, ?, 1024), dtype=float32),\nsecond structure: (LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024), LSTMStateTuple(c=1024, h=1024)).\n```\n\nEDIT:\nI found that the problem is due to the following lines.\n\n``` python\n    with tf.name_scope(name=name, default_name='simple_decoder_fn_train',\n                       values=[encoder_state]):\n        if type(encoder_state) is not tf.nn.rnn_cell.LSTMStateTuple:\n            encoder_state = tf.convert_to_tensor(encoder_state)\n```\n\nWhen we use MultiRNNCell of LSTMCell, the type of its state is not LSTMStateTuple but tuple, and consequently, it passes the if condition and the state is packed into a [num_layers, 2, batch_size, hidden_dim] tensor.\nThus, I think we need to detect whether the cell is LSTMCell (with state_is_tuple option) using a smarter way.\n\nBelow are my clumsy workaround codes.\n\n``` python\n    with tf.name_scope(name=name, default_name='simple_decoder_fn_train',\n                       values=[encoder_state]):\n        if (not isinstance(encoder_state, tf.nn.rnn_cell.LSTMStateTuple)\n                and not isinstance(encoder_state, tuple)):\n            encoder_state = tf.convert_to_tensor(encoder_state)\n```\n"}