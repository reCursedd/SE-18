{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/90123432", "pull_request_review_id": 10647864, "id": 90123432, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDkwMTIzNDMy", "diff_hunk": "@@ -0,0 +1,121 @@\n+# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\n+\"\"\"Tests for contrib.seq2seq.python.ops.seq2seq.\"\"\"\n+# pylint: disable=unused-import,g-bad-import-order\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+# pylint: enable=unused-import\n+\n+import tensorflow as tf\n+from tensorflow.contrib import layers\n+\n+class Seq2SeqTest(tf.test.TestCase):\n+\n+  # test a default call of rnn_decoder\n+  def test_rnn_decoder(self):\n+    pass\n+\n+  # test default call with time_major=True\n+  def test_dynamic_rnn_decoder_time_major(self):\n+    with self.test_session() as sess:\n+      with tf.variable_scope(\"root\", initializer=\n+                             tf.constant_initializer(0.5)) as varscope:\n+        # Define inputs/outputs to model\n+        batch_size = 2\n+        encoder_embedding_size = 3\n+        decoder_embedding_size = 4\n+        encoder_hidden_size = 5\n+        decoder_hidden_size = encoder_hidden_size\n+        input_sequence_length = 6\n+        decoder_sequence_length = 7\n+        num_decoder_symbols = 20\n+        start_of_sequence_id = end_of_sequence_id = 1\n+        decoder_embeddings = tf.get_variable('decoder_embeddings',\n+            [num_decoder_symbols, decoder_embedding_size],\n+            initializer=tf.random_normal_initializer(stddev=0.1))\n+        inputs = tf.constant(0.5, shape=[input_sequence_length, batch_size,\n+                                         encoder_embedding_size])\n+        decoder_inputs = tf.constant(0.4, shape=[decoder_sequence_length,\n+                                                 batch_size,\n+                                                 decoder_embedding_size])\n+        decoder_length = tf.constant(decoder_sequence_length, dtype=tf.int32,\n+                                     shape=[batch_size,])\n+        # setting up weights for computing the final output\n+        output_fn = lambda x: layers.linear(x, num_decoder_symbols,\n+                                            scope=varscope)\n+\n+        # Define model\n+        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n+            cell=tf.nn.rnn_cell.GRUCell(encoder_hidden_size), inputs=inputs,\n+            dtype=tf.float32, time_major=True, scope=\"rnn\")\n+\n+        # Train decoder\n+        decoder_cell = tf.nn.rnn_cell.GRUCell(decoder_hidden_size)\n+        decoder_fn_train = tf.contrib.seq2seq.simple_decoder_fn_train(\n+            encoder_state=encoder_state)\n+        decoder_outputs_train, decoder_state_train = (\n+          tf.contrib.seq2seq.dynamic_rnn_decoder(\n+              cell=decoder_cell,\n+              decoder_fn=decoder_fn_train,\n+              inputs=decoder_inputs,\n+              sequence_length=decoder_length,\n+              time_major=True))", "path": "tensorflow/contrib/seq2seq/python/kernel_tests/seq2seq_test.py", "position": null, "original_position": 76, "commit_id": "cf9f5d32c2d618e7dd98fe222b92aec1a3cf9dd4", "original_commit_id": "5b99add0a74cc96cb9d1b2401433e769ecab7539", "user": {"login": "ebrevdo", "id": 1794715, "node_id": "MDQ6VXNlcjE3OTQ3MTU=", "avatar_url": "https://avatars0.githubusercontent.com/u/1794715?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ebrevdo", "html_url": "https://github.com/ebrevdo", "followers_url": "https://api.github.com/users/ebrevdo/followers", "following_url": "https://api.github.com/users/ebrevdo/following{/other_user}", "gists_url": "https://api.github.com/users/ebrevdo/gists{/gist_id}", "starred_url": "https://api.github.com/users/ebrevdo/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ebrevdo/subscriptions", "organizations_url": "https://api.github.com/users/ebrevdo/orgs", "repos_url": "https://api.github.com/users/ebrevdo/repos", "events_url": "https://api.github.com/users/ebrevdo/events{/privacy}", "received_events_url": "https://api.github.com/users/ebrevdo/received_events", "type": "User", "site_admin": false}, "body": "this leads to an error:\r\n\r\n\r\n    name, \"\".join(traceback.format_list(tb))))\r\nValueError: Variable root/rnn/gru_cell/gates/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\r\n\r\n\r\ndue to a change i recently pushed.  this is because you're using the \"rnn\" scope twice.  what you should do is:\r\n\r\nwith tf.variable_scope(\"rnn\") as scope:\r\n  tf.nn.dynamic_rnn(..., scope=scope)\r\n\r\nscope.set_reuse()\r\n... = tf.contrib.seq2seq.dynamic_rnn_decoder(..., scope=scope)\r\n...\r\n... = tf.contrib.seq2seq.dynamic_rnn_decoder(..., scope=scope)", "created_at": "2016-11-29T21:56:00Z", "updated_at": "2016-11-30T17:47:01Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#discussion_r90123432", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4686", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/90123432"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/4686#discussion_r90123432"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/4686"}}, "body_html": "<p>this leads to an error:</p>\n<pre><code>name, \"\".join(traceback.format_list(tb))))\n</code></pre>\n<p>ValueError: Variable root/rnn/gru_cell/gates/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:</p>\n<p>due to a change i recently pushed.  this is because you're using the \"rnn\" scope twice.  what you should do is:</p>\n<p>with tf.variable_scope(\"rnn\") as scope:<br>\ntf.nn.dynamic_rnn(..., scope=scope)</p>\n<p>scope.set_reuse()<br>\n... = tf.contrib.seq2seq.dynamic_rnn_decoder(..., scope=scope)<br>\n...<br>\n... = tf.contrib.seq2seq.dynamic_rnn_decoder(..., scope=scope)</p>", "body_text": "this leads to an error:\nname, \"\".join(traceback.format_list(tb))))\n\nValueError: Variable root/rnn/gru_cell/gates/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\ndue to a change i recently pushed.  this is because you're using the \"rnn\" scope twice.  what you should do is:\nwith tf.variable_scope(\"rnn\") as scope:\ntf.nn.dynamic_rnn(..., scope=scope)\nscope.set_reuse()\n... = tf.contrib.seq2seq.dynamic_rnn_decoder(..., scope=scope)\n...\n... = tf.contrib.seq2seq.dynamic_rnn_decoder(..., scope=scope)"}