{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/257134463", "html_url": "https://github.com/tensorflow/tensorflow/pull/4686#issuecomment-257134463", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4686", "id": 257134463, "node_id": "MDEyOklzc3VlQ29tbWVudDI1NzEzNDQ2Mw==", "user": {"login": "lmthang", "id": 396613, "node_id": "MDQ6VXNlcjM5NjYxMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/396613?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lmthang", "html_url": "https://github.com/lmthang", "followers_url": "https://api.github.com/users/lmthang/followers", "following_url": "https://api.github.com/users/lmthang/following{/other_user}", "gists_url": "https://api.github.com/users/lmthang/gists{/gist_id}", "starred_url": "https://api.github.com/users/lmthang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lmthang/subscriptions", "organizations_url": "https://api.github.com/users/lmthang/orgs", "repos_url": "https://api.github.com/users/lmthang/repos", "events_url": "https://api.github.com/users/lmthang/events{/privacy}", "received_events_url": "https://api.github.com/users/lmthang/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-30T06:23:01Z", "updated_at": "2016-10-30T06:26:15Z", "author_association": "NONE", "body_html": "<p>Hi <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12167999\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/alrojo\">@alrojo</a>,</p>\n<p>Thanks for the update! Let's use functions instead of classes as <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> suggested (see below - you did something similar before).</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">decoder_fn_train</span>(<span class=\"pl-smi\">encoder_state</span>):\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">decoder_fn</span>(<span class=\"pl-smi\">cell_state</span>, <span class=\"pl-smi\">cell_output</span>, <span class=\"pl-smi\">context_state</span>):\n    <span class=\"pl-k\">if</span> cell_state <span class=\"pl-k\">==</span> <span class=\"pl-c1\">None</span>: <span class=\"pl-c\"><span class=\"pl-c\">#</span> first call, return encoder_state</span>\n      <span class=\"pl-k\">return</span> (<span class=\"pl-c1\">None</span>, encoder_state, <span class=\"pl-c1\">None</span>, cell_output, context_state)\n    <span class=\"pl-k\">else</span>:\n      <span class=\"pl-k\">return</span> (<span class=\"pl-c1\">None</span>, cell_state, <span class=\"pl-c1\">None</span>, cell_output, <span class=\"pl-bu\">`context_state)</span>\n  <span class=\"pl-k\">return</span> decoder_fn  </pre></div>\n<p>I agree about the max_len at inference, which I think you can pass to the wrapper as below:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">def</span> <span class=\"pl-en\">decoder_fn_eval</span>(<span class=\"pl-smi\">encoder_state</span>, <span class=\"pl-smi\">embeddings</span>, <span class=\"pl-smi\">sos_id</span>, <span class=\"pl-smi\">eos_id</span>, <span class=\"pl-smi\">max_len</span>):\n  <span class=\"pl-k\">def</span> <span class=\"pl-en\">decoder_fn</span>(<span class=\"pl-smi\">time</span>, <span class=\"pl-smi\">cell_state</span>, <span class=\"pl-smi\">cell_output</span>, <span class=\"pl-smi\">context_state</span>):\n\n  <span class=\"pl-k\">return</span> decoder_fn  </pre></div>\n<p>Above I added back the <code>time</code> variable to decoder_fn (so that you can compare with max_len), which means we need to update the arguments for decoder_fn_train &amp; dynamic_decoder as well.</p>\n<p>Perhaps to keep things simple for now, let's not use output_fn &amp; worry about attention later.</p>\n<p>If these sound good, maybe you can update your commits so that <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1794715\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ebrevdo\">@ebrevdo</a> can check and I can test on real data.</p>\n<p>-Thang</p>", "body_text": "Hi @alrojo,\nThanks for the update! Let's use functions instead of classes as @ebrevdo suggested (see below - you did something similar before).\ndef decoder_fn_train(encoder_state):\n  def decoder_fn(cell_state, cell_output, context_state):\n    if cell_state == None: # first call, return encoder_state\n      return (None, encoder_state, None, cell_output, context_state)\n    else:\n      return (None, cell_state, None, cell_output, `context_state)\n  return decoder_fn  \nI agree about the max_len at inference, which I think you can pass to the wrapper as below:\ndef decoder_fn_eval(encoder_state, embeddings, sos_id, eos_id, max_len):\n  def decoder_fn(time, cell_state, cell_output, context_state):\n\n  return decoder_fn  \nAbove I added back the time variable to decoder_fn (so that you can compare with max_len), which means we need to update the arguments for decoder_fn_train & dynamic_decoder as well.\nPerhaps to keep things simple for now, let's not use output_fn & worry about attention later.\nIf these sound good, maybe you can update your commits so that @ebrevdo can check and I can test on real data.\n-Thang", "body": "Hi @alrojo,\n\nThanks for the update! Let's use functions instead of classes as @ebrevdo suggested (see below - you did something similar before).\n\n``` python\ndef decoder_fn_train(encoder_state):\n  def decoder_fn(cell_state, cell_output, context_state):\n    if cell_state == None: # first call, return encoder_state\n      return (None, encoder_state, None, cell_output, context_state)\n    else:\n      return (None, cell_state, None, cell_output, `context_state)\n  return decoder_fn  \n```\n\nI agree about the max_len at inference, which I think you can pass to the wrapper as below:\n\n``` python\ndef decoder_fn_eval(encoder_state, embeddings, sos_id, eos_id, max_len):\n  def decoder_fn(time, cell_state, cell_output, context_state):\n\n  return decoder_fn  \n```\n\nAbove I added back the `time` variable to decoder_fn (so that you can compare with max_len), which means we need to update the arguments for decoder_fn_train & dynamic_decoder as well. \n\nPerhaps to keep things simple for now, let's not use output_fn & worry about attention later.\n\nIf these sound good, maybe you can update your commits so that @ebrevdo can check and I can test on real data.\n\n-Thang\n"}