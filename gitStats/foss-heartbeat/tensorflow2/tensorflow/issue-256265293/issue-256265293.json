{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12911", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12911/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12911/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12911/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/12911", "id": 256265293, "node_id": "MDU6SXNzdWUyNTYyNjUyOTM=", "number": 12911, "title": "tf.gather with int32 indices yields wrong result on gpu", "user": {"login": "LukasDrude", "id": 1886882, "node_id": "MDQ6VXNlcjE4ODY4ODI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1886882?v=4", "gravatar_id": "", "url": "https://api.github.com/users/LukasDrude", "html_url": "https://github.com/LukasDrude", "followers_url": "https://api.github.com/users/LukasDrude/followers", "following_url": "https://api.github.com/users/LukasDrude/following{/other_user}", "gists_url": "https://api.github.com/users/LukasDrude/gists{/gist_id}", "starred_url": "https://api.github.com/users/LukasDrude/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/LukasDrude/subscriptions", "organizations_url": "https://api.github.com/users/LukasDrude/orgs", "repos_url": "https://api.github.com/users/LukasDrude/repos", "events_url": "https://api.github.com/users/LukasDrude/events{/privacy}", "received_events_url": "https://api.github.com/users/LukasDrude/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 8, "created_at": "2017-09-08T14:07:20Z", "updated_at": "2017-12-05T02:15:55Z", "closed_at": "2017-12-05T02:15:55Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\nyes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\n$ cat /etc/issue<br>\nUbuntu 16.04.2 LTS</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:<br>\nSource head</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n1.3</li>\n<li><strong>Python version</strong>:<br>\n3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>:<br>\nbazel release 0.4.5</li>\n<li><strong>CUDA/cuDNN version</strong>:<br>\n8.0, 7.0</li>\n<li><strong>GPU model and memory</strong>:<br>\nGeForce GTX 980</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<pre><code>import tensorflow as tf\n\ndef bug():\n  params = tf.convert_to_tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=tf.float32)\n  indices_32 = tf.convert_to_tensor([2, 0, 2, 4], dtype=tf.int32)\n  indices_64 = tf.convert_to_tensor([2, 0, 2, 4], dtype=tf.int64)\n  test_op_32 = tf.gather(params, indices_32)\n  test_op_64 = tf.gather(params, indices_64)\n  with tf.Session() as sess:\n      res = sess.run([test_op_32, test_op_64])\n  print('test_op_32', res[0], 'test_op_64', res[1])\n\nbug()\nwith tf.device('/cpu:0'):\n  bug()\nbug()\n</code></pre>\n<h3>Describe the problem</h3>\n<p>When using <code>int32</code> indices for <code>tf.gather</code> on GPU, wrong (random) numbers are returned.</p>\n<p>See code above. It does not occur if using <code>int64</code> or running on CPU.</p>\n<h3>Output</h3>\n<pre><code>2017-09-08 15:54:08.775830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties:\nname: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785\npciBusID: 0000:04:00.0\ntotalMemory: 3.94GiB freeMemory: 158.62MiB\n2017-09-08 15:54:08.775862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\ntest_op_32 [ 0.  0.  0.  0.] test_op_64 [ 2.  0.  2.  4.]\n2017-09-08 15:54:08.792745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\ntest_op_32 [ 2.  0.  2.  4.] test_op_64 [ 2.  0.  2.  4.]\n2017-09-08 15:54:08.800545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\ntest_op_32 [ 3.  0.  0.  0.] test_op_64 [ 2.  0.  2.  4.]\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\nyes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n$ cat /etc/issue\nUbuntu 16.04.2 LTS\nTensorFlow installed from (source or binary):\nSource head\nTensorFlow version (use command below):\n1.3\nPython version:\n3.6\nBazel version (if compiling from source):\nbazel release 0.4.5\nCUDA/cuDNN version:\n8.0, 7.0\nGPU model and memory:\nGeForce GTX 980\nExact command to reproduce:\n\nimport tensorflow as tf\n\ndef bug():\n  params = tf.convert_to_tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=tf.float32)\n  indices_32 = tf.convert_to_tensor([2, 0, 2, 4], dtype=tf.int32)\n  indices_64 = tf.convert_to_tensor([2, 0, 2, 4], dtype=tf.int64)\n  test_op_32 = tf.gather(params, indices_32)\n  test_op_64 = tf.gather(params, indices_64)\n  with tf.Session() as sess:\n      res = sess.run([test_op_32, test_op_64])\n  print('test_op_32', res[0], 'test_op_64', res[1])\n\nbug()\nwith tf.device('/cpu:0'):\n  bug()\nbug()\n\nDescribe the problem\nWhen using int32 indices for tf.gather on GPU, wrong (random) numbers are returned.\nSee code above. It does not occur if using int64 or running on CPU.\nOutput\n2017-09-08 15:54:08.775830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties:\nname: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785\npciBusID: 0000:04:00.0\ntotalMemory: 3.94GiB freeMemory: 158.62MiB\n2017-09-08 15:54:08.775862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\ntest_op_32 [ 0.  0.  0.  0.] test_op_64 [ 2.  0.  2.  4.]\n2017-09-08 15:54:08.792745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\ntest_op_32 [ 2.  0.  2.  4.] test_op_64 [ 2.  0.  2.  4.]\n2017-09-08 15:54:08.800545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\ntest_op_32 [ 3.  0.  0.  0.] test_op_64 [ 2.  0.  2.  4.]", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n$ cat /etc/issue\r\nUbuntu 16.04.2 LTS\r\n- **TensorFlow installed from (source or binary)**:\r\nSource head\r\n- **TensorFlow version (use command below)**:\r\n1.3\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\nbazel release 0.4.5\r\n- **CUDA/cuDNN version**:\r\n8.0, 7.0\r\n- **GPU model and memory**:\r\nGeForce GTX 980\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef bug():\r\n  params = tf.convert_to_tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=tf.float32)\r\n  indices_32 = tf.convert_to_tensor([2, 0, 2, 4], dtype=tf.int32)\r\n  indices_64 = tf.convert_to_tensor([2, 0, 2, 4], dtype=tf.int64)\r\n  test_op_32 = tf.gather(params, indices_32)\r\n  test_op_64 = tf.gather(params, indices_64)\r\n  with tf.Session() as sess:\r\n      res = sess.run([test_op_32, test_op_64])\r\n  print('test_op_32', res[0], 'test_op_64', res[1])\r\n\r\nbug()\r\nwith tf.device('/cpu:0'):\r\n  bug()\r\nbug()\r\n```\r\n\r\n### Describe the problem\r\nWhen using `int32` indices for `tf.gather` on GPU, wrong (random) numbers are returned.\r\n\r\nSee code above. It does not occur if using `int64` or running on CPU.\r\n\r\n### Output\r\n```\r\n2017-09-08 15:54:08.775830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties:\r\nname: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 3.94GiB freeMemory: 158.62MiB\r\n2017-09-08 15:54:08.775862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\ntest_op_32 [ 0.  0.  0.  0.] test_op_64 [ 2.  0.  2.  4.]\r\n2017-09-08 15:54:08.792745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\ntest_op_32 [ 2.  0.  2.  4.] test_op_64 [ 2.  0.  2.  4.]\r\n2017-09-08 15:54:08.800545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\ntest_op_32 [ 3.  0.  0.  0.] test_op_64 [ 2.  0.  2.  4.]\r\n```"}