{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11273", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11273/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11273/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/11273/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/11273", "id": 240435691, "node_id": "MDU6SXNzdWUyNDA0MzU2OTE=", "number": 11273, "title": "Memory leak when using `tf.layers`", "user": {"login": "drasmuss", "id": 1952220, "node_id": "MDQ6VXNlcjE5NTIyMjA=", "avatar_url": "https://avatars1.githubusercontent.com/u/1952220?v=4", "gravatar_id": "", "url": "https://api.github.com/users/drasmuss", "html_url": "https://github.com/drasmuss", "followers_url": "https://api.github.com/users/drasmuss/followers", "following_url": "https://api.github.com/users/drasmuss/following{/other_user}", "gists_url": "https://api.github.com/users/drasmuss/gists{/gist_id}", "starred_url": "https://api.github.com/users/drasmuss/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/drasmuss/subscriptions", "organizations_url": "https://api.github.com/users/drasmuss/orgs", "repos_url": "https://api.github.com/users/drasmuss/repos", "events_url": "https://api.github.com/users/drasmuss/events{/privacy}", "received_events_url": "https://api.github.com/users/drasmuss/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "martinwicke", "id": 577277, "node_id": "MDQ6VXNlcjU3NzI3Nw==", "avatar_url": "https://avatars2.githubusercontent.com/u/577277?v=4", "gravatar_id": "", "url": "https://api.github.com/users/martinwicke", "html_url": "https://github.com/martinwicke", "followers_url": "https://api.github.com/users/martinwicke/followers", "following_url": "https://api.github.com/users/martinwicke/following{/other_user}", "gists_url": "https://api.github.com/users/martinwicke/gists{/gist_id}", "starred_url": "https://api.github.com/users/martinwicke/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/martinwicke/subscriptions", "organizations_url": "https://api.github.com/users/martinwicke/orgs", "repos_url": "https://api.github.com/users/martinwicke/repos", "events_url": "https://api.github.com/users/martinwicke/events{/privacy}", "received_events_url": "https://api.github.com/users/martinwicke/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2017-07-04T14:24:07Z", "updated_at": "2017-07-06T17:11:18Z", "closed_at": "2017-07-06T17:11:18Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.2.1</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> os\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> matplotlib.pyplot <span class=\"pl-k\">as</span> plt\n<span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> psutil\n\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">memory</span>():\n    pid <span class=\"pl-k\">=</span> os.getpid()\n    py <span class=\"pl-k\">=</span> psutil.Process(pid)\n    memory_use <span class=\"pl-k\">=</span> py.memory_info()[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">/</span> <span class=\"pl-c1\">2</span>. <span class=\"pl-k\">**</span> <span class=\"pl-c1\">30</span>\n    <span class=\"pl-k\">return</span> memory_use\n\n\nmemory_usage <span class=\"pl-k\">=</span> []\n<span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n    memory_usage.append(memory())\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>iter<span class=\"pl-pds\">\"</span></span>, i, memory_usage[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>])\n\n    <span class=\"pl-k\">with</span> tf.Graph().as_default():\n        x <span class=\"pl-k\">=</span> tf.constant(np.ones((<span class=\"pl-c1\">100</span>, <span class=\"pl-c1\">1000</span>), <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>np.float32))\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> memory leak</span>\n        x <span class=\"pl-k\">=</span> tf.layers.dense(x, <span class=\"pl-v\">units</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1000</span>)\n\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> no memory leak</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> with tf.variable_scope(\"layer\", reuse=False):</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>     x = tf.matmul(x, tf.get_variable(</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>         \"w\", shape=(1000, 1000), dtype=tf.float32,</span>\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span>         initializer=tf.ones_initializer()))</span>\n\nplt.figure()\nplt.plot(memory_usage)\nplt.xlabel(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>iterations<span class=\"pl-pds\">\"</span></span>)\nplt.ylabel(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>memory usage<span class=\"pl-pds\">\"</span></span>)\nplt.show()</pre></div>\n<h3>Describe the problem</h3>\n<p>There is some kind of memory leak when repeatedly building graphs containing <code>tf.layers</code> elements.  The example above shows the memory usage comparing what I think should be roughly equivalent implementations, one using <code>tf.layers.dense</code> and the other using manually created kernels/matmul ops.  When using <code>tf.layers.dense</code> the memory usage continually increases, whereas the manual approach shows memory being periodically cleaned up by garbage collection.  So my guess would be that there is some internal reference to the <code>tf.layers</code> elements that is preventing them from being garbage collected.</p>\n<p>not using <code>tf.layers.dense</code>:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1952220/27835565-78f5628c-60a9-11e7-9134-971b5caba784.png\"><img src=\"https://user-images.githubusercontent.com/1952220/27835565-78f5628c-60a9-11e7-9134-971b5caba784.png\" alt=\"non_layer\" style=\"max-width:100%;\"></a></p>\n<p>using <code>tf.layers.dense</code>:<br>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://user-images.githubusercontent.com/1952220/27835536-570a2bda-60a9-11e7-8936-1631f67be3b0.png\"><img src=\"https://user-images.githubusercontent.com/1952220/27835536-570a2bda-60a9-11e7-8936-1631f67be3b0.png\" alt=\"with_layer\" style=\"max-width:100%;\"></a></p>", "body_text": "System information\n\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.2.1\nPython version: 3.5\nExact command to reproduce:\n\nimport os\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport psutil\n\n\ndef memory():\n    pid = os.getpid()\n    py = psutil.Process(pid)\n    memory_use = py.memory_info()[0] / 2. ** 30\n    return memory_use\n\n\nmemory_usage = []\nfor i in range(1000):\n    memory_usage.append(memory())\n    print(\"iter\", i, memory_usage[-1])\n\n    with tf.Graph().as_default():\n        x = tf.constant(np.ones((100, 1000), dtype=np.float32))\n\n        # memory leak\n        x = tf.layers.dense(x, units=1000)\n\n        # no memory leak\n        # with tf.variable_scope(\"layer\", reuse=False):\n        #     x = tf.matmul(x, tf.get_variable(\n        #         \"w\", shape=(1000, 1000), dtype=tf.float32,\n        #         initializer=tf.ones_initializer()))\n\nplt.figure()\nplt.plot(memory_usage)\nplt.xlabel(\"iterations\")\nplt.ylabel(\"memory usage\")\nplt.show()\nDescribe the problem\nThere is some kind of memory leak when repeatedly building graphs containing tf.layers elements.  The example above shows the memory usage comparing what I think should be roughly equivalent implementations, one using tf.layers.dense and the other using manually created kernels/matmul ops.  When using tf.layers.dense the memory usage continually increases, whereas the manual approach shows memory being periodically cleaned up by garbage collection.  So my guess would be that there is some internal reference to the tf.layers elements that is preventing them from being garbage collected.\nnot using tf.layers.dense:\n\nusing tf.layers.dense:", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 3.5\r\n- **Exact command to reproduce**:\r\n\r\n``` python\r\nimport os\r\n\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport psutil\r\n\r\n\r\ndef memory():\r\n    pid = os.getpid()\r\n    py = psutil.Process(pid)\r\n    memory_use = py.memory_info()[0] / 2. ** 30\r\n    return memory_use\r\n\r\n\r\nmemory_usage = []\r\nfor i in range(1000):\r\n    memory_usage.append(memory())\r\n    print(\"iter\", i, memory_usage[-1])\r\n\r\n    with tf.Graph().as_default():\r\n        x = tf.constant(np.ones((100, 1000), dtype=np.float32))\r\n\r\n        # memory leak\r\n        x = tf.layers.dense(x, units=1000)\r\n\r\n        # no memory leak\r\n        # with tf.variable_scope(\"layer\", reuse=False):\r\n        #     x = tf.matmul(x, tf.get_variable(\r\n        #         \"w\", shape=(1000, 1000), dtype=tf.float32,\r\n        #         initializer=tf.ones_initializer()))\r\n\r\nplt.figure()\r\nplt.plot(memory_usage)\r\nplt.xlabel(\"iterations\")\r\nplt.ylabel(\"memory usage\")\r\nplt.show()\r\n```\r\n\r\n### Describe the problem\r\nThere is some kind of memory leak when repeatedly building graphs containing `tf.layers` elements.  The example above shows the memory usage comparing what I think should be roughly equivalent implementations, one using `tf.layers.dense` and the other using manually created kernels/matmul ops.  When using `tf.layers.dense` the memory usage continually increases, whereas the manual approach shows memory being periodically cleaned up by garbage collection.  So my guess would be that there is some internal reference to the `tf.layers` elements that is preventing them from being garbage collected.\r\n\r\nnot using `tf.layers.dense`:\r\n![non_layer](https://user-images.githubusercontent.com/1952220/27835565-78f5628c-60a9-11e7-9134-971b5caba784.png)\r\n\r\n\r\nusing `tf.layers.dense`:\r\n![with_layer](https://user-images.githubusercontent.com/1952220/27835536-570a2bda-60a9-11e7-8936-1631f67be3b0.png)\r\n\r\n\r\n\r\n"}