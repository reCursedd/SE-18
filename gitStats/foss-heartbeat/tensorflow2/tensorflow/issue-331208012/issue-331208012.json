{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19909", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19909/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19909/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19909/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19909", "id": 331208012, "node_id": "MDU6SXNzdWUzMzEyMDgwMTI=", "number": 19909, "title": "Tensorflow C++ API Batch Inference", "user": {"login": "spivakoa", "id": 25300810, "node_id": "MDQ6VXNlcjI1MzAwODEw", "avatar_url": "https://avatars0.githubusercontent.com/u/25300810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/spivakoa", "html_url": "https://github.com/spivakoa", "followers_url": "https://api.github.com/users/spivakoa/followers", "following_url": "https://api.github.com/users/spivakoa/following{/other_user}", "gists_url": "https://api.github.com/users/spivakoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/spivakoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/spivakoa/subscriptions", "organizations_url": "https://api.github.com/users/spivakoa/orgs", "repos_url": "https://api.github.com/users/spivakoa/repos", "events_url": "https://api.github.com/users/spivakoa/events{/privacy}", "received_events_url": "https://api.github.com/users/spivakoa/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 284443156, "node_id": "MDU6TGFiZWwyODQ0NDMxNTY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:docs", "name": "type:docs", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "MarkDaoust", "id": 1414837, "node_id": "MDQ6VXNlcjE0MTQ4Mzc=", "avatar_url": "https://avatars1.githubusercontent.com/u/1414837?v=4", "gravatar_id": "", "url": "https://api.github.com/users/MarkDaoust", "html_url": "https://github.com/MarkDaoust", "followers_url": "https://api.github.com/users/MarkDaoust/followers", "following_url": "https://api.github.com/users/MarkDaoust/following{/other_user}", "gists_url": "https://api.github.com/users/MarkDaoust/gists{/gist_id}", "starred_url": "https://api.github.com/users/MarkDaoust/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/MarkDaoust/subscriptions", "organizations_url": "https://api.github.com/users/MarkDaoust/orgs", "repos_url": "https://api.github.com/users/MarkDaoust/repos", "events_url": "https://api.github.com/users/MarkDaoust/events{/privacy}", "received_events_url": "https://api.github.com/users/MarkDaoust/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 18, "created_at": "2018-06-11T14:15:49Z", "updated_at": "2018-08-24T11:49:09Z", "closed_at": "2018-08-24T11:49:09Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>My question is considering the inference in C++ API using batches. I'm trying to run SSD net based on Mobilenet. It works on a single image, but when I try to use multiple images inference, I can't understand how to get the multiple outputs. It seems like my program runs properly as a run time increased for a batch inference though.<br>\nHere is my sample code: I'm loading a batch of 32 images with OpenCV, transform them into a input tensor and run the Session. I need to understand what should I change in order to get 32 outputs.<br>\nThank you.</p>\n<pre><code>int main(int argc, char* argv[]) {\n\t//string image(argv[1]);\n\tint batchSize = 32;\n\tstring pathFilenameImg1 = \"Patch6.jpg\";\n\tstring pathFilenameImg2 = \"Patch1.jpg\";\n\tstring pathFilenameImg3 = \"Patch2.jpg\";\n\tstring pathFilenameImg4 = \"Patch3.jpg\";\n\tstring pathFilenameImg5 = \"Patch0.jpg\";\n\tstring pathFilenameImg6 = \"Patch1.jpg\";\n\tstring pathFilenameImg7 = \"Patch2.jpg\";\n\tstring pathFilenameImg8 = \"Patch3.jpg\";\n\tstring graph = \"ssd_mobilenet.pb\";\n\tstring labels = \"security_labels.txt\";\n\tint32 input_width = 512;\n\tint32 input_height = 512;\n\tint32 input_depth = 3;\n\tstring input_layer = \"image_tensor\";\n\tvector&lt;string&gt; output_layer = { \"detection_boxes:0\", \"detection_scores:0\", \"detection_classes:0\", \"num_detections:0\"};\n\n\tbool self_test = false;\n\tstring root_dir = \"\";\n\n\t// First we load and initialize the model.\n\tstd::unique_ptr&lt;tensorflow::Session&gt; session;\n\tstring graph_path = tensorflow::io::JoinPath(root_dir, graph);\n\tLOG(ERROR) &lt;&lt; \"graph_path:\" &lt;&lt; graph_path;\n\tStatus load_graph_status = LoadGraph(graph_path, &amp;session);\n\tif (!load_graph_status.ok()) {\n\t\tLOG(ERROR) &lt;&lt; \"LoadGraph ERROR!!!!\" &lt;&lt; load_graph_status;\n\t\treturn -1;\n\t}\n\n\n\t// Read and prepare images using OpenCV:\n\tstd::vector&lt;string&gt; imgPathArray= { pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, \n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\n\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1\n\t};\n\tstd::vector&lt;cv::Mat&gt; imgArray;\n\tfor (int i = 0; i &lt; batchSize; i++)\n\t\timgArray.push_back(cv::imread(imgPathArray.at(i)));\n\n\n\t// creating a Tensor for storing the data\n\tTensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\n\tauto input_tensor_mapped = input_tensor.tensor&lt;uchar, 4&gt;();\n\n\tfor (int bz = 0; bz &lt; batchSize; ++bz) {\n\t\tuchar *source_data;\n\t\tsource_data = imgArray.at(bz).data;\n\t\tfor (int y = 0; y &lt; input_height; ++y) {\n\t\t\tuchar* source_row = source_data + (y * input_width * input_depth);\n\t\t\tfor (int x = 0; x &lt; input_width; ++x) {\n\t\t\t\tuchar* source_pixel = source_row + (x * input_depth);\n\t\t\t\tuchar* source_B = source_pixel + 0;\n\t\t\t\tuchar* source_G = source_pixel + 1;\n\t\t\t\tuchar* source_R = source_pixel + 2;\n\t\t\t\tinput_tensor_mapped(bz, y, x, 0) = *source_R;\n\t\t\t\tinput_tensor_mapped(bz, y, x, 1) = *source_G;\n\t\t\t\tinput_tensor_mapped(bz, y, x, 2) = *source_B;\n\t\t\t}\n\t\t}\n\t}\n\n\n\t/*// Get the image from disk as a float array of numbers, resized and normalized\n\t// to the specifications the main graph expects.\n\tstd::vector&lt;Tensor&gt; resized_tensors;\n\tstring image_path = tensorflow::io::JoinPath(root_dir, image);\n\tStatus read_tensor_status = ReadTensorFromImageFile(image_path, input_height, input_width, input_mean, input_std, &amp;resized_tensors);\n\tif (!read_tensor_status.ok()) {\n\t\tLOG(ERROR) &lt;&lt; read_tensor_status;\n\t\treturn -1;\n\t}\n\tconst Tensor&amp; resized_tensor = resized_tensors[0];\n\n\tLOG(ERROR) &lt;&lt; \"image shape:\" &lt;&lt; resized_tensor.shape().DebugString() &lt;&lt; \",len:\" &lt;&lt; resized_tensors.size() &lt;&lt; \",tensor type:\" &lt;&lt; resized_tensor.dtype();*/\n\n\n\t// Actually run the image through the model.\n\tstd::vector&lt;Tensor&gt; outputs;\n\n\tstd::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\n\tStatus run_status = session-&gt;Run({ { input_layer, input_tensor} }, output_layer, {}, &amp;outputs);\n\tstd::chrono::steady_clock::time_point end = std::chrono::steady_clock::now();\tstd::cout &lt;&lt; \"Time difference (sec) = \" &lt;&lt; (std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(end - begin).count()) / 1000000.0 &lt;&lt; std::endl;\n\n\tif (!run_status.ok()) {\n\t\tLOG(ERROR) &lt;&lt; \"Running model failed: \" &lt;&lt; run_status;\n\t\treturn -1;\n\t}\n\n\t//int image_width = resized_tensor.dims();\n\t//int image_height = 0;\n\t//int image_height = resized_tensor.shape()[1];\n\n\t//LOG(ERROR) &lt;&lt; \"output size:\" &lt;&lt; outputs.size() &lt;&lt; \",image_width:\" &lt;&lt; image_width &lt;&lt; \",image_height:\" &lt;&lt; image_height &lt;&lt; endl;\n\n\tauto boxes = outputs[0].flat_outer_dims&lt;float, 3&gt;();\n\ttensorflow::TTypes&lt;float&gt;::Flat scores = outputs[1].flat&lt;float&gt;();\n\ttensorflow::TTypes&lt;float&gt;::Flat classes = outputs[2].flat&lt;float&gt;();\n\ttensorflow::TTypes&lt;float&gt;::Flat num_detections = outputs[3].flat&lt;float&gt;();\n\n\n\t//LOG(ERROR) &lt;&lt; \"num_detections:\" &lt;&lt; num_detections(0) &lt;&lt; \",\" &lt;&lt; outputs[0].shape().DebugString();\n\tint BarcodeCnt = 0;\n\tint GyoshCnt = 0;\n\tfor (size_t i = 0; i &lt; num_detections(0) &amp;&amp; i &lt; 20; ++i)\n\t{\n\t\tif (scores(i) &gt; 0.9)\n\t\t{\n\t\t\tLOG(ERROR) &lt;&lt;\"score:\" &lt;&lt; scores(i) &lt;&lt; \",class:\" &lt;&lt; classes(i) &lt;&lt; \",box:\" &lt;&lt; \",\" &lt;&lt; boxes(0, i, 0) &lt;&lt; \",\" &lt;&lt; boxes(0, i, 1) &lt;&lt; \",\" &lt;&lt; boxes(0, i, 2) &lt;&lt; \",\" &lt;&lt; boxes(0, i, 3);\n\t\t\tif(classes(i) == 1)\n\t\t\t\tBarcodeCnt++;\n\t\t\telse\n\t\t\t\tGyoshCnt ++;\n\t\t}\n\t}\n\tLOG(ERROR) &lt;&lt; \"Total number of Security Barcodes is :\" &lt;&lt; BarcodeCnt;\n\tLOG(ERROR) &lt;&lt; \"Total number of Security Gyoshes is :\" &lt;&lt; GyoshCnt;\n\n\t\n\n\n\treturn 0;\n}\n</code></pre>", "body_text": "Hello,\nMy question is considering the inference in C++ API using batches. I'm trying to run SSD net based on Mobilenet. It works on a single image, but when I try to use multiple images inference, I can't understand how to get the multiple outputs. It seems like my program runs properly as a run time increased for a batch inference though.\nHere is my sample code: I'm loading a batch of 32 images with OpenCV, transform them into a input tensor and run the Session. I need to understand what should I change in order to get 32 outputs.\nThank you.\nint main(int argc, char* argv[]) {\n\t//string image(argv[1]);\n\tint batchSize = 32;\n\tstring pathFilenameImg1 = \"Patch6.jpg\";\n\tstring pathFilenameImg2 = \"Patch1.jpg\";\n\tstring pathFilenameImg3 = \"Patch2.jpg\";\n\tstring pathFilenameImg4 = \"Patch3.jpg\";\n\tstring pathFilenameImg5 = \"Patch0.jpg\";\n\tstring pathFilenameImg6 = \"Patch1.jpg\";\n\tstring pathFilenameImg7 = \"Patch2.jpg\";\n\tstring pathFilenameImg8 = \"Patch3.jpg\";\n\tstring graph = \"ssd_mobilenet.pb\";\n\tstring labels = \"security_labels.txt\";\n\tint32 input_width = 512;\n\tint32 input_height = 512;\n\tint32 input_depth = 3;\n\tstring input_layer = \"image_tensor\";\n\tvector<string> output_layer = { \"detection_boxes:0\", \"detection_scores:0\", \"detection_classes:0\", \"num_detections:0\"};\n\n\tbool self_test = false;\n\tstring root_dir = \"\";\n\n\t// First we load and initialize the model.\n\tstd::unique_ptr<tensorflow::Session> session;\n\tstring graph_path = tensorflow::io::JoinPath(root_dir, graph);\n\tLOG(ERROR) << \"graph_path:\" << graph_path;\n\tStatus load_graph_status = LoadGraph(graph_path, &session);\n\tif (!load_graph_status.ok()) {\n\t\tLOG(ERROR) << \"LoadGraph ERROR!!!!\" << load_graph_status;\n\t\treturn -1;\n\t}\n\n\n\t// Read and prepare images using OpenCV:\n\tstd::vector<string> imgPathArray= { pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, \n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\n\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1\n\t};\n\tstd::vector<cv::Mat> imgArray;\n\tfor (int i = 0; i < batchSize; i++)\n\t\timgArray.push_back(cv::imread(imgPathArray.at(i)));\n\n\n\t// creating a Tensor for storing the data\n\tTensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\n\tauto input_tensor_mapped = input_tensor.tensor<uchar, 4>();\n\n\tfor (int bz = 0; bz < batchSize; ++bz) {\n\t\tuchar *source_data;\n\t\tsource_data = imgArray.at(bz).data;\n\t\tfor (int y = 0; y < input_height; ++y) {\n\t\t\tuchar* source_row = source_data + (y * input_width * input_depth);\n\t\t\tfor (int x = 0; x < input_width; ++x) {\n\t\t\t\tuchar* source_pixel = source_row + (x * input_depth);\n\t\t\t\tuchar* source_B = source_pixel + 0;\n\t\t\t\tuchar* source_G = source_pixel + 1;\n\t\t\t\tuchar* source_R = source_pixel + 2;\n\t\t\t\tinput_tensor_mapped(bz, y, x, 0) = *source_R;\n\t\t\t\tinput_tensor_mapped(bz, y, x, 1) = *source_G;\n\t\t\t\tinput_tensor_mapped(bz, y, x, 2) = *source_B;\n\t\t\t}\n\t\t}\n\t}\n\n\n\t/*// Get the image from disk as a float array of numbers, resized and normalized\n\t// to the specifications the main graph expects.\n\tstd::vector<Tensor> resized_tensors;\n\tstring image_path = tensorflow::io::JoinPath(root_dir, image);\n\tStatus read_tensor_status = ReadTensorFromImageFile(image_path, input_height, input_width, input_mean, input_std, &resized_tensors);\n\tif (!read_tensor_status.ok()) {\n\t\tLOG(ERROR) << read_tensor_status;\n\t\treturn -1;\n\t}\n\tconst Tensor& resized_tensor = resized_tensors[0];\n\n\tLOG(ERROR) << \"image shape:\" << resized_tensor.shape().DebugString() << \",len:\" << resized_tensors.size() << \",tensor type:\" << resized_tensor.dtype();*/\n\n\n\t// Actually run the image through the model.\n\tstd::vector<Tensor> outputs;\n\n\tstd::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\n\tStatus run_status = session->Run({ { input_layer, input_tensor} }, output_layer, {}, &outputs);\n\tstd::chrono::steady_clock::time_point end = std::chrono::steady_clock::now();\tstd::cout << \"Time difference (sec) = \" << (std::chrono::duration_cast<std::chrono::microseconds>(end - begin).count()) / 1000000.0 << std::endl;\n\n\tif (!run_status.ok()) {\n\t\tLOG(ERROR) << \"Running model failed: \" << run_status;\n\t\treturn -1;\n\t}\n\n\t//int image_width = resized_tensor.dims();\n\t//int image_height = 0;\n\t//int image_height = resized_tensor.shape()[1];\n\n\t//LOG(ERROR) << \"output size:\" << outputs.size() << \",image_width:\" << image_width << \",image_height:\" << image_height << endl;\n\n\tauto boxes = outputs[0].flat_outer_dims<float, 3>();\n\ttensorflow::TTypes<float>::Flat scores = outputs[1].flat<float>();\n\ttensorflow::TTypes<float>::Flat classes = outputs[2].flat<float>();\n\ttensorflow::TTypes<float>::Flat num_detections = outputs[3].flat<float>();\n\n\n\t//LOG(ERROR) << \"num_detections:\" << num_detections(0) << \",\" << outputs[0].shape().DebugString();\n\tint BarcodeCnt = 0;\n\tint GyoshCnt = 0;\n\tfor (size_t i = 0; i < num_detections(0) && i < 20; ++i)\n\t{\n\t\tif (scores(i) > 0.9)\n\t\t{\n\t\t\tLOG(ERROR) <<\"score:\" << scores(i) << \",class:\" << classes(i) << \",box:\" << \",\" << boxes(0, i, 0) << \",\" << boxes(0, i, 1) << \",\" << boxes(0, i, 2) << \",\" << boxes(0, i, 3);\n\t\t\tif(classes(i) == 1)\n\t\t\t\tBarcodeCnt++;\n\t\t\telse\n\t\t\t\tGyoshCnt ++;\n\t\t}\n\t}\n\tLOG(ERROR) << \"Total number of Security Barcodes is :\" << BarcodeCnt;\n\tLOG(ERROR) << \"Total number of Security Gyoshes is :\" << GyoshCnt;\n\n\t\n\n\n\treturn 0;\n}", "body": "Hello,\r\n\r\nMy question is considering the inference in C++ API using batches. I'm trying to run SSD net based on Mobilenet. It works on a single image, but when I try to use multiple images inference, I can't understand how to get the multiple outputs. It seems like my program runs properly as a run time increased for a batch inference though.\r\nHere is my sample code: I'm loading a batch of 32 images with OpenCV, transform them into a input tensor and run the Session. I need to understand what should I change in order to get 32 outputs. \r\nThank you.\r\n\r\n```\r\nint main(int argc, char* argv[]) {\r\n\t//string image(argv[1]);\r\n\tint batchSize = 32;\r\n\tstring pathFilenameImg1 = \"Patch6.jpg\";\r\n\tstring pathFilenameImg2 = \"Patch1.jpg\";\r\n\tstring pathFilenameImg3 = \"Patch2.jpg\";\r\n\tstring pathFilenameImg4 = \"Patch3.jpg\";\r\n\tstring pathFilenameImg5 = \"Patch0.jpg\";\r\n\tstring pathFilenameImg6 = \"Patch1.jpg\";\r\n\tstring pathFilenameImg7 = \"Patch2.jpg\";\r\n\tstring pathFilenameImg8 = \"Patch3.jpg\";\r\n\tstring graph = \"ssd_mobilenet.pb\";\r\n\tstring labels = \"security_labels.txt\";\r\n\tint32 input_width = 512;\r\n\tint32 input_height = 512;\r\n\tint32 input_depth = 3;\r\n\tstring input_layer = \"image_tensor\";\r\n\tvector<string> output_layer = { \"detection_boxes:0\", \"detection_scores:0\", \"detection_classes:0\", \"num_detections:0\"};\r\n\r\n\tbool self_test = false;\r\n\tstring root_dir = \"\";\r\n\r\n\t// First we load and initialize the model.\r\n\tstd::unique_ptr<tensorflow::Session> session;\r\n\tstring graph_path = tensorflow::io::JoinPath(root_dir, graph);\r\n\tLOG(ERROR) << \"graph_path:\" << graph_path;\r\n\tStatus load_graph_status = LoadGraph(graph_path, &session);\r\n\tif (!load_graph_status.ok()) {\r\n\t\tLOG(ERROR) << \"LoadGraph ERROR!!!!\" << load_graph_status;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\r\n\t// Read and prepare images using OpenCV:\r\n\tstd::vector<string> imgPathArray= { pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, \r\n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\r\n\t\t\t\t\t\t\t\t\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,\r\n\t\tpathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1\r\n\t};\r\n\tstd::vector<cv::Mat> imgArray;\r\n\tfor (int i = 0; i < batchSize; i++)\r\n\t\timgArray.push_back(cv::imread(imgPathArray.at(i)));\r\n\r\n\r\n\t// creating a Tensor for storing the data\r\n\tTensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\r\n\tauto input_tensor_mapped = input_tensor.tensor<uchar, 4>();\r\n\r\n\tfor (int bz = 0; bz < batchSize; ++bz) {\r\n\t\tuchar *source_data;\r\n\t\tsource_data = imgArray.at(bz).data;\r\n\t\tfor (int y = 0; y < input_height; ++y) {\r\n\t\t\tuchar* source_row = source_data + (y * input_width * input_depth);\r\n\t\t\tfor (int x = 0; x < input_width; ++x) {\r\n\t\t\t\tuchar* source_pixel = source_row + (x * input_depth);\r\n\t\t\t\tuchar* source_B = source_pixel + 0;\r\n\t\t\t\tuchar* source_G = source_pixel + 1;\r\n\t\t\t\tuchar* source_R = source_pixel + 2;\r\n\t\t\t\tinput_tensor_mapped(bz, y, x, 0) = *source_R;\r\n\t\t\t\tinput_tensor_mapped(bz, y, x, 1) = *source_G;\r\n\t\t\t\tinput_tensor_mapped(bz, y, x, 2) = *source_B;\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\r\n\t/*// Get the image from disk as a float array of numbers, resized and normalized\r\n\t// to the specifications the main graph expects.\r\n\tstd::vector<Tensor> resized_tensors;\r\n\tstring image_path = tensorflow::io::JoinPath(root_dir, image);\r\n\tStatus read_tensor_status = ReadTensorFromImageFile(image_path, input_height, input_width, input_mean, input_std, &resized_tensors);\r\n\tif (!read_tensor_status.ok()) {\r\n\t\tLOG(ERROR) << read_tensor_status;\r\n\t\treturn -1;\r\n\t}\r\n\tconst Tensor& resized_tensor = resized_tensors[0];\r\n\r\n\tLOG(ERROR) << \"image shape:\" << resized_tensor.shape().DebugString() << \",len:\" << resized_tensors.size() << \",tensor type:\" << resized_tensor.dtype();*/\r\n\r\n\r\n\t// Actually run the image through the model.\r\n\tstd::vector<Tensor> outputs;\r\n\r\n\tstd::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();\r\n\tStatus run_status = session->Run({ { input_layer, input_tensor} }, output_layer, {}, &outputs);\r\n\tstd::chrono::steady_clock::time_point end = std::chrono::steady_clock::now();\tstd::cout << \"Time difference (sec) = \" << (std::chrono::duration_cast<std::chrono::microseconds>(end - begin).count()) / 1000000.0 << std::endl;\r\n\r\n\tif (!run_status.ok()) {\r\n\t\tLOG(ERROR) << \"Running model failed: \" << run_status;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\t//int image_width = resized_tensor.dims();\r\n\t//int image_height = 0;\r\n\t//int image_height = resized_tensor.shape()[1];\r\n\r\n\t//LOG(ERROR) << \"output size:\" << outputs.size() << \",image_width:\" << image_width << \",image_height:\" << image_height << endl;\r\n\r\n\tauto boxes = outputs[0].flat_outer_dims<float, 3>();\r\n\ttensorflow::TTypes<float>::Flat scores = outputs[1].flat<float>();\r\n\ttensorflow::TTypes<float>::Flat classes = outputs[2].flat<float>();\r\n\ttensorflow::TTypes<float>::Flat num_detections = outputs[3].flat<float>();\r\n\r\n\r\n\t//LOG(ERROR) << \"num_detections:\" << num_detections(0) << \",\" << outputs[0].shape().DebugString();\r\n\tint BarcodeCnt = 0;\r\n\tint GyoshCnt = 0;\r\n\tfor (size_t i = 0; i < num_detections(0) && i < 20; ++i)\r\n\t{\r\n\t\tif (scores(i) > 0.9)\r\n\t\t{\r\n\t\t\tLOG(ERROR) <<\"score:\" << scores(i) << \",class:\" << classes(i) << \",box:\" << \",\" << boxes(0, i, 0) << \",\" << boxes(0, i, 1) << \",\" << boxes(0, i, 2) << \",\" << boxes(0, i, 3);\r\n\t\t\tif(classes(i) == 1)\r\n\t\t\t\tBarcodeCnt++;\r\n\t\t\telse\r\n\t\t\t\tGyoshCnt ++;\r\n\t\t}\r\n\t}\r\n\tLOG(ERROR) << \"Total number of Security Barcodes is :\" << BarcodeCnt;\r\n\tLOG(ERROR) << \"Total number of Security Gyoshes is :\" << GyoshCnt;\r\n\r\n\t\r\n\r\n\r\n\treturn 0;\r\n}\r\n```"}