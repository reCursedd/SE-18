{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/397048183", "html_url": "https://github.com/tensorflow/tensorflow/issues/19909#issuecomment-397048183", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19909", "id": 397048183, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NzA0ODE4Mw==", "user": {"login": "spivakoa", "id": 25300810, "node_id": "MDQ6VXNlcjI1MzAwODEw", "avatar_url": "https://avatars0.githubusercontent.com/u/25300810?v=4", "gravatar_id": "", "url": "https://api.github.com/users/spivakoa", "html_url": "https://github.com/spivakoa", "followers_url": "https://api.github.com/users/spivakoa/followers", "following_url": "https://api.github.com/users/spivakoa/following{/other_user}", "gists_url": "https://api.github.com/users/spivakoa/gists{/gist_id}", "starred_url": "https://api.github.com/users/spivakoa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/spivakoa/subscriptions", "organizations_url": "https://api.github.com/users/spivakoa/orgs", "repos_url": "https://api.github.com/users/spivakoa/repos", "events_url": "https://api.github.com/users/spivakoa/events{/privacy}", "received_events_url": "https://api.github.com/users/spivakoa/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-13T18:56:28Z", "updated_at": "2018-06-16T16:10:56Z", "author_association": "NONE", "body_html": "<p>It is in the name of the topic: How can I run inference on batch of images instead of a single one?<br>\nIn my code example above I showed how I \"fill\" an input 4-D Tensor with pixel values.<br>\nHere it is:</p>\n<div class=\"highlight highlight-source-c++\"><pre><span class=\"pl-c\"><span class=\"pl-c\">//</span> creating a Tensor for storing the data</span>\nTensor <span class=\"pl-en\">input_tensor</span>(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\n<span class=\"pl-k\">auto</span> input_tensor_mapped = input_tensor.tensor&lt;uchar, <span class=\"pl-c1\">4</span>&gt;();\n\n<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> bz = <span class=\"pl-c1\">0</span>; bz &lt; batchSize; ++bz) {\n\tuchar *source_data;\n\tsource_data = imgArray.<span class=\"pl-c1\">at</span>(bz).<span class=\"pl-smi\">data</span>;\n\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> y = <span class=\"pl-c1\">0</span>; y &lt; input_height; ++y) {\n\t\tuchar* source_row = source_data + (y * input_width * input_depth);\n\t\t<span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> x = <span class=\"pl-c1\">0</span>; x &lt; input_width; ++x) {\n\t\t\tuchar* source_pixel = source_row + (x * input_depth);\n\t\t\tuchar* source_B = source_pixel + <span class=\"pl-c1\">0</span>;\n\t\t\tuchar* source_G = source_pixel + <span class=\"pl-c1\">1</span>;\n\t\t\tuchar* source_R = source_pixel + <span class=\"pl-c1\">2</span>;\n\t\t\t<span class=\"pl-c1\">input_tensor_mapped</span>(bz, y, x, <span class=\"pl-c1\">0</span>) = *source_R;\n\t\t\t<span class=\"pl-c1\">input_tensor_mapped</span>(bz, y, x, <span class=\"pl-c1\">1</span>) = *source_G;\n\t\t\t<span class=\"pl-c1\">input_tensor_mapped</span>(bz, y, x, <span class=\"pl-c1\">2</span>) = *source_B;\n\t\t}\n\t}\n} </pre></div>\n<p>Then I run the Graph:</p>\n<div class=\"highlight highlight-source-c++\"><pre>Status run_status = session-&gt;<span class=\"pl-en\">Run</span>({ { input_layer, input_tensor} }, output_layer, {}, &amp;outputs);</pre></div>\n<p>However the outputs is vector of Tensors with size of 4, because the output layer is defined as follows:</p>\n<div class=\"highlight highlight-source-c++\"><pre>output_layer = { <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>detection_boxes:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>detection_scores:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>detection_classes:0<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>num_detections:0<span class=\"pl-pds\">\"</span></span>};</pre></div>\n<p>I need to understand how should I define the output to reveal 4xbatch size values.</p>\n<p>This what Tensorflow documentation lacks with. No explanation whatsoever of how to run multiple images using C++ API.</p>", "body_text": "It is in the name of the topic: How can I run inference on batch of images instead of a single one?\nIn my code example above I showed how I \"fill\" an input 4-D Tensor with pixel values.\nHere it is:\n// creating a Tensor for storing the data\nTensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\nauto input_tensor_mapped = input_tensor.tensor<uchar, 4>();\n\nfor (int bz = 0; bz < batchSize; ++bz) {\n\tuchar *source_data;\n\tsource_data = imgArray.at(bz).data;\n\tfor (int y = 0; y < input_height; ++y) {\n\t\tuchar* source_row = source_data + (y * input_width * input_depth);\n\t\tfor (int x = 0; x < input_width; ++x) {\n\t\t\tuchar* source_pixel = source_row + (x * input_depth);\n\t\t\tuchar* source_B = source_pixel + 0;\n\t\t\tuchar* source_G = source_pixel + 1;\n\t\t\tuchar* source_R = source_pixel + 2;\n\t\t\tinput_tensor_mapped(bz, y, x, 0) = *source_R;\n\t\t\tinput_tensor_mapped(bz, y, x, 1) = *source_G;\n\t\t\tinput_tensor_mapped(bz, y, x, 2) = *source_B;\n\t\t}\n\t}\n} \nThen I run the Graph:\nStatus run_status = session->Run({ { input_layer, input_tensor} }, output_layer, {}, &outputs);\nHowever the outputs is vector of Tensors with size of 4, because the output layer is defined as follows:\noutput_layer = { \"detection_boxes:0\", \"detection_scores:0\", \"detection_classes:0\", \"num_detections:0\"};\nI need to understand how should I define the output to reveal 4xbatch size values.\nThis what Tensorflow documentation lacks with. No explanation whatsoever of how to run multiple images using C++ API.", "body": "It is in the name of the topic: How can I run inference on batch of images instead of a single one?\r\nIn my code example above I showed how I \"fill\" an input 4-D Tensor with pixel values.\r\nHere it is:\r\n\r\n``` c++\r\n// creating a Tensor for storing the data\r\nTensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));\r\nauto input_tensor_mapped = input_tensor.tensor<uchar, 4>();\r\n\r\nfor (int bz = 0; bz < batchSize; ++bz) {\r\n\tuchar *source_data;\r\n\tsource_data = imgArray.at(bz).data;\r\n\tfor (int y = 0; y < input_height; ++y) {\r\n\t\tuchar* source_row = source_data + (y * input_width * input_depth);\r\n\t\tfor (int x = 0; x < input_width; ++x) {\r\n\t\t\tuchar* source_pixel = source_row + (x * input_depth);\r\n\t\t\tuchar* source_B = source_pixel + 0;\r\n\t\t\tuchar* source_G = source_pixel + 1;\r\n\t\t\tuchar* source_R = source_pixel + 2;\r\n\t\t\tinput_tensor_mapped(bz, y, x, 0) = *source_R;\r\n\t\t\tinput_tensor_mapped(bz, y, x, 1) = *source_G;\r\n\t\t\tinput_tensor_mapped(bz, y, x, 2) = *source_B;\r\n\t\t}\r\n\t}\r\n} \r\n```\r\n\r\nThen I run the Graph:\r\n\r\n```c++\r\nStatus run_status = session->Run({ { input_layer, input_tensor} }, output_layer, {}, &outputs);\r\n```\r\nHowever the outputs is vector of Tensors with size of 4, because the output layer is defined as follows:\r\n\r\n``` c++\r\noutput_layer = { \"detection_boxes:0\", \"detection_scores:0\", \"detection_classes:0\", \"num_detections:0\"};\r\n```\r\n\r\nI need to understand how should I define the output to reveal 4xbatch size values.\r\n\r\nThis what Tensorflow documentation lacks with. No explanation whatsoever of how to run multiple images using C++ API."}