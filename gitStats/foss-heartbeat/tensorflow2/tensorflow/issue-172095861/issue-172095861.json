{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3921", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3921/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3921/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3921/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3921", "id": 172095861, "node_id": "MDU6SXNzdWUxNzIwOTU4NjE=", "number": 3921, "title": "MemoryError in ubuntu, not mac", "user": {"login": "aimeida", "id": 1012110, "node_id": "MDQ6VXNlcjEwMTIxMTA=", "avatar_url": "https://avatars0.githubusercontent.com/u/1012110?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aimeida", "html_url": "https://github.com/aimeida", "followers_url": "https://api.github.com/users/aimeida/followers", "following_url": "https://api.github.com/users/aimeida/following{/other_user}", "gists_url": "https://api.github.com/users/aimeida/gists{/gist_id}", "starred_url": "https://api.github.com/users/aimeida/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aimeida/subscriptions", "organizations_url": "https://api.github.com/users/aimeida/orgs", "repos_url": "https://api.github.com/users/aimeida/repos", "events_url": "https://api.github.com/users/aimeida/events{/privacy}", "received_events_url": "https://api.github.com/users/aimeida/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-08-19T09:55:08Z", "updated_at": "2016-08-22T23:04:24Z", "closed_at": "2016-08-22T20:25:59Z", "author_association": "NONE", "body_html": "<p>Hello, my script gets killed by MemoryError, running in an aws EC2 instance, with 7.5G memory.<br>\nHowever, it has no problem running in my Mac (8g memory) !!! they use same TF, but numpy version is slightly different.</p>\n<p>Python 2.7.10 (default, Oct 23 2015, 19:19:21)<br>\n[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin<br>\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import numpy as np<br>\nnp.<strong>version</strong><br>\n'1.11.1'</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>Python 2.7.6 (default, Jun 22 2015, 17:58:13)<br>\n[GCC 4.8.2] on linux2<br>\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import numpy as np<br>\nnp.<strong>version</strong><br>\n'1.11.0'</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>I have absolutely no idea what happened... and my data is not likely to require that much memory either...  i did memory profiling in EC2, error occurs at line 290.</p>\n<h1>Line #    Mem usage    Increment   Line Contents</h1>\n<p>275  412.289 MiB    0.000 MiB       <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=19148526\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Profile\">@Profile</a><br>\n276                                 def test_naive(self, mx, yls, fn_model=None, W=None, b=None):<br>\n277                                     \"\"\"load variables and calculate acc\"\"\"<br>\n278 5117.520 MiB 4705.230 MiB           mx_array = mx.toarray()<br>\n279 5117.520 MiB    0.000 MiB           if fn_model is not None:<br>\n280                                         reader = tf.train.NewCheckpointReader(fn_model)<br>\n281                                         logger.info(\"loaded saved param from \" + fn_model)<br>\n282                                         W, b = reader.get_tensor(\"W\"), reader.get_tensor(\"b\")<br>\n283                                     else:<br>\n284 5117.520 MiB    0.000 MiB               assert (W is not None) and (b is not None)<br>\n285<br>\n286 5117.523 MiB    0.004 MiB           print 'read', type(W), type(b), mx_array.shape<br>\n287 5117.523 MiB    0.000 MiB           x, _ = self.init_placeholder()<br>\n288 5117.523 MiB    0.000 MiB           with tf.Session() as sess:<br>\n289 5117.523 MiB    0.000 MiB               tf.initialize_all_variables()<br>\n290 5130.176 MiB   12.652 MiB               y = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})</p>\n<p>File \"meshtags/model_bow.py\", line 290, in test_naive<br>\ny = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 372, in run<br>\nrun_metadata_ptr)<br>\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 619, in _run<br>\nnp_val = np.array(subfeed_val, dtype=subfeed_dtype)<br>\nMemoryError</p>\n<p>any comments are welcome ! thanks a lot.</p>", "body_text": "Hello, my script gets killed by MemoryError, running in an aws EC2 instance, with 7.5G memory.\nHowever, it has no problem running in my Mac (8g memory) !!! they use same TF, but numpy version is slightly different.\nPython 2.7.10 (default, Oct 23 2015, 19:19:21)\n[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nimport numpy as np\nnp.version\n'1.11.1'\n\n\n\nPython 2.7.6 (default, Jun 22 2015, 17:58:13)\n[GCC 4.8.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nimport numpy as np\nnp.version\n'1.11.0'\n\n\n\nI have absolutely no idea what happened... and my data is not likely to require that much memory either...  i did memory profiling in EC2, error occurs at line 290.\nLine #    Mem usage    Increment   Line Contents\n275  412.289 MiB    0.000 MiB       @Profile\n276                                 def test_naive(self, mx, yls, fn_model=None, W=None, b=None):\n277                                     \"\"\"load variables and calculate acc\"\"\"\n278 5117.520 MiB 4705.230 MiB           mx_array = mx.toarray()\n279 5117.520 MiB    0.000 MiB           if fn_model is not None:\n280                                         reader = tf.train.NewCheckpointReader(fn_model)\n281                                         logger.info(\"loaded saved param from \" + fn_model)\n282                                         W, b = reader.get_tensor(\"W\"), reader.get_tensor(\"b\")\n283                                     else:\n284 5117.520 MiB    0.000 MiB               assert (W is not None) and (b is not None)\n285\n286 5117.523 MiB    0.004 MiB           print 'read', type(W), type(b), mx_array.shape\n287 5117.523 MiB    0.000 MiB           x, _ = self.init_placeholder()\n288 5117.523 MiB    0.000 MiB           with tf.Session() as sess:\n289 5117.523 MiB    0.000 MiB               tf.initialize_all_variables()\n290 5130.176 MiB   12.652 MiB               y = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})\nFile \"meshtags/model_bow.py\", line 290, in test_naive\ny = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 372, in run\nrun_metadata_ptr)\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 619, in _run\nnp_val = np.array(subfeed_val, dtype=subfeed_dtype)\nMemoryError\nany comments are welcome ! thanks a lot.", "body": "Hello, my script gets killed by MemoryError, running in an aws EC2 instance, with 7.5G memory.\nHowever, it has no problem running in my Mac (8g memory) !!! they use same TF, but numpy version is slightly different.\n\nPython 2.7.10 (default, Oct 23 2015, 19:19:21) \n[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n> > > import numpy as np\n> > > np.**version**\n> > > '1.11.1'\n\nPython 2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n> > > import numpy as np\n> > > np.**version**\n> > > '1.11.0'\n\nI have absolutely no idea what happened... and my data is not likely to require that much memory either...  i did memory profiling in EC2, error occurs at line 290.\n# Line #    Mem usage    Increment   Line Contents\n\n   275  412.289 MiB    0.000 MiB       @profile\n   276                                 def test_naive(self, mx, yls, fn_model=None, W=None, b=None):\n   277                                     \"\"\"load variables and calculate acc\"\"\"\n   278 5117.520 MiB 4705.230 MiB           mx_array = mx.toarray()\n   279 5117.520 MiB    0.000 MiB           if fn_model is not None:\n   280                                         reader = tf.train.NewCheckpointReader(fn_model)\n   281                                         logger.info(\"loaded saved param from \" + fn_model)\n   282                                         W, b = reader.get_tensor(\"W\"), reader.get_tensor(\"b\")\n   283                                     else:\n   284 5117.520 MiB    0.000 MiB               assert (W is not None) and (b is not None)\n   285  \n   286 5117.523 MiB    0.004 MiB           print 'read', type(W), type(b), mx_array.shape\n   287 5117.523 MiB    0.000 MiB           x, _ = self.init_placeholder()\n   288 5117.523 MiB    0.000 MiB           with tf.Session() as sess:\n   289 5117.523 MiB    0.000 MiB               tf.initialize_all_variables()\n   290 5130.176 MiB   12.652 MiB               y = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})\n\n  File \"meshtags/model_bow.py\", line 290, in test_naive\n    y = sess.run(tf.nn.softmax(tf.matmul(x, W) + b), feed_dict={x: mx_array})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 372, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 619, in _run\n    np_val = np.array(subfeed_val, dtype=subfeed_dtype)\nMemoryError\n\nany comments are welcome ! thanks a lot.\n"}