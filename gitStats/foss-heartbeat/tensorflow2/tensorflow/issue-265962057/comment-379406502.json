{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/379406502", "html_url": "https://github.com/tensorflow/tensorflow/issues/13766#issuecomment-379406502", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13766", "id": 379406502, "node_id": "MDEyOklzc3VlQ29tbWVudDM3OTQwNjUwMg==", "user": {"login": "thomasquintana", "id": 1891840, "node_id": "MDQ6VXNlcjE4OTE4NDA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1891840?v=4", "gravatar_id": "", "url": "https://api.github.com/users/thomasquintana", "html_url": "https://github.com/thomasquintana", "followers_url": "https://api.github.com/users/thomasquintana/followers", "following_url": "https://api.github.com/users/thomasquintana/following{/other_user}", "gists_url": "https://api.github.com/users/thomasquintana/gists{/gist_id}", "starred_url": "https://api.github.com/users/thomasquintana/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/thomasquintana/subscriptions", "organizations_url": "https://api.github.com/users/thomasquintana/orgs", "repos_url": "https://api.github.com/users/thomasquintana/repos", "events_url": "https://api.github.com/users/thomasquintana/events{/privacy}", "received_events_url": "https://api.github.com/users/thomasquintana/received_events", "type": "User", "site_admin": false}, "created_at": "2018-04-06T23:03:06Z", "updated_at": "2018-04-06T23:07:24Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=192142\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/mrry\">@mrry</a> Any update on this? I have upgraded to version 1.7.0 and still encountering the same issue.</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">from</span> argparse <span class=\"pl-k\">import</span> ArgumentParser\n<span class=\"pl-k\">import</span> pickle\n\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">main</span>(<span class=\"pl-smi\">args</span>):\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Generate the complete source and meta paths.</span>\n    source <span class=\"pl-k\">=</span> args.source\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> source.endswith(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.tfrecords<span class=\"pl-pds\">'</span></span>):\n        source <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">{}</span>.tfrecords<span class=\"pl-pds\">'</span></span>.format(source)\n\n    meta <span class=\"pl-k\">=</span> args.source\n    <span class=\"pl-k\">if</span> <span class=\"pl-k\">not</span> source.endswith(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.tfrecords<span class=\"pl-pds\">'</span></span>):\n        meta <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">{}</span>.meta.pkl<span class=\"pl-pds\">'</span></span>.format(meta)\n    <span class=\"pl-k\">else</span>:\n        meta <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-c1\">{}</span>.meta.pkl<span class=\"pl-pds\">'</span></span>.format(meta.rsplit(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>.<span class=\"pl-pds\">'</span></span>, <span class=\"pl-c1\">1</span>)[<span class=\"pl-c1\">0</span>])\n    \n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Train the model.</span>\n    train(source, meta, args.destination)\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">parse</span>(<span class=\"pl-smi\">example_proto</span>):\n\n    features <span class=\"pl-k\">=</span> {\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>bucket<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>coefficients<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.string),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>coefficients_length<span class=\"pl-pds\">'</span></span>: tf.FixedLenFeature([], tf.int64),\n        <span class=\"pl-s\"><span class=\"pl-pds\">'</span>label<span class=\"pl-pds\">'</span></span>: tf.VarLenFeature(tf.int64)\n    }\n    parsed_features <span class=\"pl-k\">=</span> tf.parse_single_example(example_proto, features)\n\n    bucket <span class=\"pl-k\">=</span> tf.cast(parsed_features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>bucket<span class=\"pl-pds\">'</span></span>], tf.int32)\n    coefficients <span class=\"pl-k\">=</span> tf.decode_raw(parsed_features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>coefficients<span class=\"pl-pds\">'</span></span>], tf.float32)\n    coefficients_length <span class=\"pl-k\">=</span> tf.cast(parsed_features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>coefficients_length<span class=\"pl-pds\">'</span></span>], tf.int32)\n    label <span class=\"pl-k\">=</span> tf.cast(parsed_features[<span class=\"pl-s\"><span class=\"pl-pds\">'</span>label<span class=\"pl-pds\">'</span></span>], tf.int32)\n\n    <span class=\"pl-k\">return</span> bucket, coefficients, coefficients_length, label\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">train</span>(<span class=\"pl-smi\">source</span>, <span class=\"pl-smi\">meta</span>, <span class=\"pl-smi\">destination</span>, <span class=\"pl-smi\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>, <span class=\"pl-smi\">epochs</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1</span>):\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Load the training meta data.</span>\n    <span class=\"pl-v\">file</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">open</span>(meta, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>rb<span class=\"pl-pds\">'</span></span>)\n    meta <span class=\"pl-k\">=</span> pickle.load(<span class=\"pl-v\">file</span>)\n    <span class=\"pl-v\">file</span>.close()\n\n    <span class=\"pl-c\"><span class=\"pl-c\">#</span> Create a tf.data input pipe line.</span>\n    dataset <span class=\"pl-k\">=</span> tf.data.TFRecordDataset([source])\n    dataset <span class=\"pl-k\">=</span> dataset.map(parse)\n    dataset <span class=\"pl-k\">=</span> dataset.padded_batch(batch_size, <span class=\"pl-v\">padded_shapes</span><span class=\"pl-k\">=</span>(<span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">None</span>, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">None</span>))\n    dataset <span class=\"pl-k\">=</span> dataset.repeat(epochs) \n    iterator <span class=\"pl-k\">=</span> dataset.make_initializable_iterator()\n\n    bucket, coefficients, coefficients_length, label <span class=\"pl-k\">=</span> iterator.get_next()\n\n    <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> session:\n        \n        session.run(iterator.initializer)\n        \n        <span class=\"pl-c1\">print</span>(session.run([bucket, coefficients, coefficients_length, label]))\n\n<span class=\"pl-k\">if</span> <span class=\"pl-c1\">__name__</span> <span class=\"pl-k\">==</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>__main__<span class=\"pl-pds\">'</span></span>:\n    \n    <span class=\"pl-c1\">PARSER</span> <span class=\"pl-k\">=</span> ArgumentParser(<span class=\"pl-v\">description</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>Trains a model.<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">PARSER</span>.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--destination<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">required</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n    \t\t\t\t\t<span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>The path where the trained model should be stored.<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">PARSER</span>.add_argument(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>--source<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">required</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>, <span class=\"pl-v\">type</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">str</span>,\n    \t\t\t\t\t<span class=\"pl-v\">help</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>The path to the training data.<span class=\"pl-pds\">'</span></span>)\n    <span class=\"pl-c1\">ARGS</span> <span class=\"pl-k\">=</span> <span class=\"pl-c1\">PARSER</span>.parse_args()\n\n    main(<span class=\"pl-c1\">ARGS</span>)</pre></div>\n<p>Output:</p>\n<pre><code>Traceback (most recent call last):\n  File \"trainer.py\", line 70, in &lt;module&gt;\n    main(ARGS)\n  File \"trainer.py\", line 20, in main\n    train(source, meta, args.destination)\n  File \"trainer.py\", line 49, in train\n    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 821, in padded_batch\n    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1713, in __init__\n    \"Batching of padded sparse tensors is not currently supported\")\nTypeError: Batching of padded sparse tensors is not currently supported\n</code></pre>", "body_text": "@mrry Any update on this? I have upgraded to version 1.7.0 and still encountering the same issue.\nfrom argparse import ArgumentParser\nimport pickle\n\nimport tensorflow as tf\n\ndef main(args):\n\n    # Generate the complete source and meta paths.\n    source = args.source\n    if not source.endswith('.tfrecords'):\n        source = '{}.tfrecords'.format(source)\n\n    meta = args.source\n    if not source.endswith('.tfrecords'):\n        meta = '{}.meta.pkl'.format(meta)\n    else:\n        meta = '{}.meta.pkl'.format(meta.rsplit('.', 1)[0])\n    \n    # Train the model.\n    train(source, meta, args.destination)\n\ndef parse(example_proto):\n\n    features = {\n        'bucket': tf.FixedLenFeature([], tf.int64),\n        'coefficients': tf.FixedLenFeature([], tf.string),\n        'coefficients_length': tf.FixedLenFeature([], tf.int64),\n        'label': tf.VarLenFeature(tf.int64)\n    }\n    parsed_features = tf.parse_single_example(example_proto, features)\n\n    bucket = tf.cast(parsed_features['bucket'], tf.int32)\n    coefficients = tf.decode_raw(parsed_features['coefficients'], tf.float32)\n    coefficients_length = tf.cast(parsed_features['coefficients_length'], tf.int32)\n    label = tf.cast(parsed_features['label'], tf.int32)\n\n    return bucket, coefficients, coefficients_length, label\n\ndef train(source, meta, destination, batch_size=64, epochs=1):\n\n    # Load the training meta data.\n    file = open(meta, 'rb')\n    meta = pickle.load(file)\n    file.close()\n\n    # Create a tf.data input pipe line.\n    dataset = tf.data.TFRecordDataset([source])\n    dataset = dataset.map(parse)\n    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))\n    dataset = dataset.repeat(epochs) \n    iterator = dataset.make_initializable_iterator()\n\n    bucket, coefficients, coefficients_length, label = iterator.get_next()\n\n    with tf.Session() as session:\n        \n        session.run(iterator.initializer)\n        \n        print(session.run([bucket, coefficients, coefficients_length, label]))\n\nif __name__ == '__main__':\n    \n    PARSER = ArgumentParser(description='Trains a model.')\n    PARSER.add_argument('--destination', required=True, type=str,\n    \t\t\t\t\thelp='The path where the trained model should be stored.')\n    PARSER.add_argument('--source', required=True, type=str,\n    \t\t\t\t\thelp='The path to the training data.')\n    ARGS = PARSER.parse_args()\n\n    main(ARGS)\nOutput:\nTraceback (most recent call last):\n  File \"trainer.py\", line 70, in <module>\n    main(ARGS)\n  File \"trainer.py\", line 20, in main\n    train(source, meta, args.destination)\n  File \"trainer.py\", line 49, in train\n    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 821, in padded_batch\n    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1713, in __init__\n    \"Batching of padded sparse tensors is not currently supported\")\nTypeError: Batching of padded sparse tensors is not currently supported", "body": "@mrry Any update on this? I have upgraded to version 1.7.0 and still encountering the same issue.\r\n\r\n```python\r\nfrom argparse import ArgumentParser\r\nimport pickle\r\n\r\nimport tensorflow as tf\r\n\r\ndef main(args):\r\n\r\n    # Generate the complete source and meta paths.\r\n    source = args.source\r\n    if not source.endswith('.tfrecords'):\r\n        source = '{}.tfrecords'.format(source)\r\n\r\n    meta = args.source\r\n    if not source.endswith('.tfrecords'):\r\n        meta = '{}.meta.pkl'.format(meta)\r\n    else:\r\n        meta = '{}.meta.pkl'.format(meta.rsplit('.', 1)[0])\r\n    \r\n    # Train the model.\r\n    train(source, meta, args.destination)\r\n\r\ndef parse(example_proto):\r\n\r\n    features = {\r\n        'bucket': tf.FixedLenFeature([], tf.int64),\r\n        'coefficients': tf.FixedLenFeature([], tf.string),\r\n        'coefficients_length': tf.FixedLenFeature([], tf.int64),\r\n        'label': tf.VarLenFeature(tf.int64)\r\n    }\r\n    parsed_features = tf.parse_single_example(example_proto, features)\r\n\r\n    bucket = tf.cast(parsed_features['bucket'], tf.int32)\r\n    coefficients = tf.decode_raw(parsed_features['coefficients'], tf.float32)\r\n    coefficients_length = tf.cast(parsed_features['coefficients_length'], tf.int32)\r\n    label = tf.cast(parsed_features['label'], tf.int32)\r\n\r\n    return bucket, coefficients, coefficients_length, label\r\n\r\ndef train(source, meta, destination, batch_size=64, epochs=1):\r\n\r\n    # Load the training meta data.\r\n    file = open(meta, 'rb')\r\n    meta = pickle.load(file)\r\n    file.close()\r\n\r\n    # Create a tf.data input pipe line.\r\n    dataset = tf.data.TFRecordDataset([source])\r\n    dataset = dataset.map(parse)\r\n    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))\r\n    dataset = dataset.repeat(epochs) \r\n    iterator = dataset.make_initializable_iterator()\r\n\r\n    bucket, coefficients, coefficients_length, label = iterator.get_next()\r\n\r\n    with tf.Session() as session:\r\n        \r\n        session.run(iterator.initializer)\r\n        \r\n        print(session.run([bucket, coefficients, coefficients_length, label]))\r\n\r\nif __name__ == '__main__':\r\n    \r\n    PARSER = ArgumentParser(description='Trains a model.')\r\n    PARSER.add_argument('--destination', required=True, type=str,\r\n    \t\t\t\t\thelp='The path where the trained model should be stored.')\r\n    PARSER.add_argument('--source', required=True, type=str,\r\n    \t\t\t\t\thelp='The path to the training data.')\r\n    ARGS = PARSER.parse_args()\r\n\r\n    main(ARGS)\r\n```\r\n\r\nOutput:\r\n```\r\nTraceback (most recent call last):\r\n  File \"trainer.py\", line 70, in <module>\r\n    main(ARGS)\r\n  File \"trainer.py\", line 20, in main\r\n    train(source, meta, args.destination)\r\n  File \"trainer.py\", line 49, in train\r\n    dataset = dataset.padded_batch(batch_size, padded_shapes=(0, None, 0, None))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 821, in padded_batch\r\n    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1713, in __init__\r\n    \"Batching of padded sparse tensors is not currently supported\")\r\nTypeError: Batching of padded sparse tensors is not currently supported\r\n```"}