{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/350862890", "html_url": "https://github.com/tensorflow/tensorflow/issues/13766#issuecomment-350862890", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13766", "id": 350862890, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MDg2Mjg5MA==", "user": {"login": "svetlov", "id": 1593310, "node_id": "MDQ6VXNlcjE1OTMzMTA=", "avatar_url": "https://avatars3.githubusercontent.com/u/1593310?v=4", "gravatar_id": "", "url": "https://api.github.com/users/svetlov", "html_url": "https://github.com/svetlov", "followers_url": "https://api.github.com/users/svetlov/followers", "following_url": "https://api.github.com/users/svetlov/following{/other_user}", "gists_url": "https://api.github.com/users/svetlov/gists{/gist_id}", "starred_url": "https://api.github.com/users/svetlov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/svetlov/subscriptions", "organizations_url": "https://api.github.com/users/svetlov/orgs", "repos_url": "https://api.github.com/users/svetlov/repos", "events_url": "https://api.github.com/users/svetlov/events{/privacy}", "received_events_url": "https://api.github.com/users/svetlov/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-11T21:24:42Z", "updated_at": "2017-12-11T21:24:42Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=1072079\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/jsimsa\">@jsimsa</a>, I learn model to estimate video - text relevance, so from one side i have sequence of frames(var length), and by other side i have bag of words/ngrams. For this it's convinient to use old interface <code>tf.batch(..., dynamic_pad=True)</code>, cause i want padded video frames for lstm and sparse representation of bag of words/ngrams cause of <code>tf.contrib.layers.safe_embedding_lookup_sparse</code>.</p>", "body_text": "@jsimsa, I learn model to estimate video - text relevance, so from one side i have sequence of frames(var length), and by other side i have bag of words/ngrams. For this it's convinient to use old interface tf.batch(..., dynamic_pad=True), cause i want padded video frames for lstm and sparse representation of bag of words/ngrams cause of tf.contrib.layers.safe_embedding_lookup_sparse.", "body": "@jsimsa, I learn model to estimate video - text relevance, so from one side i have sequence of frames(var length), and by other side i have bag of words/ngrams. For this it's convinient to use old interface `tf.batch(..., dynamic_pad=True)`, cause i want padded video frames for lstm and sparse representation of bag of words/ngrams cause of `tf.contrib.layers.safe_embedding_lookup_sparse`. "}