{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/281546503", "html_url": "https://github.com/tensorflow/tensorflow/issues/7712#issuecomment-281546503", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7712", "id": 281546503, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MTU0NjUwMw==", "user": {"login": "fchollet", "id": 710255, "node_id": "MDQ6VXNlcjcxMDI1NQ==", "avatar_url": "https://avatars3.githubusercontent.com/u/710255?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fchollet", "html_url": "https://github.com/fchollet", "followers_url": "https://api.github.com/users/fchollet/followers", "following_url": "https://api.github.com/users/fchollet/following{/other_user}", "gists_url": "https://api.github.com/users/fchollet/gists{/gist_id}", "starred_url": "https://api.github.com/users/fchollet/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fchollet/subscriptions", "organizations_url": "https://api.github.com/users/fchollet/orgs", "repos_url": "https://api.github.com/users/fchollet/repos", "events_url": "https://api.github.com/users/fchollet/events{/privacy}", "received_events_url": "https://api.github.com/users/fchollet/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-22T02:12:17Z", "updated_at": "2017-02-22T02:14:46Z", "author_association": "MEMBER", "body_html": "<p>Anything that has a state (e.g. this function) should not be added as a function in <code>tf.nn</code> (which should only contain pure functions), but rather as a layer (<code>tf.layers</code>). This is precisely what layers are meant to cover. This is a <code>PELU</code> layer, not an activation function.</p>\n<p>However I would be wary of adding new core layers for each and every paper out there. At best this would be a candidate for contrib.</p>", "body_text": "Anything that has a state (e.g. this function) should not be added as a function in tf.nn (which should only contain pure functions), but rather as a layer (tf.layers). This is precisely what layers are meant to cover. This is a PELU layer, not an activation function.\nHowever I would be wary of adding new core layers for each and every paper out there. At best this would be a candidate for contrib.", "body": "Anything that has a state (e.g. this function) should not be added as a function in `tf.nn` (which should only contain pure functions), but rather as a layer (`tf.layers`). This is precisely what layers are meant to cover. This is a `PELU` layer, not an activation function.\r\n\r\nHowever I would be wary of adding new core layers for each and every paper out there. At best this would be a candidate for contrib."}