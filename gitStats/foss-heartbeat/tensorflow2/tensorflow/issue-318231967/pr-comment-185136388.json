{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/185136388", "pull_request_review_id": 116467985, "id": 185136388, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NTEzNjM4OA==", "diff_hunk": "@@ -45,25 +47,46 @@ TRTEngineOp::TRTEngineOp(OpKernelConstruction* context) : OpKernel(context) {\n   // from resourcemanager\n   // TODO(jie): cudaSetDevice make sure trt engine is allocated on the same\n   // gpu where the input/output is also located.\n-  int gpu_id = context->device()->tensorflow_gpu_device_info()->gpu_id;\n-  cudaSetDevice(gpu_id);\n-  int device;\n-  cudaGetDevice(&device);\n-  if (gpu_id != device) LOG(FATAL) << \"set device failed!\";\n+  // int gpu_id = context->device()->tensorflow_gpu_device_info()->gpu_id;\n+  // cudaSetDevice(gpu_id);\n+  // int device;\n+  // cudaGetDevice(&device);\n+  // if (gpu_id != device) LOG(FATAL) << \"set device failed!\";\n \n   // TODO(samikama) runtime should be taken from a resourcemanager as well.\n   // Only engine should be in the op and context and runtime should be taken\n   // from resourcemanager\n \n-  IRuntime* infer = nvinfer1::createInferRuntime(logger);\n-  trt_engine_ptr_.reset(infer->deserializeCudaEngine(\n-      serialized_engine.c_str(), serialized_engine.size(), nullptr));\n-  trt_execution_context_ptr_.reset(trt_engine_ptr_->createExecutionContext());\n+  // IRuntime* infer = nvinfer1::createInferRuntime(logger);\n+  // trt_engine_ptr_.reset(infer->deserializeCudaEngine(\n+  //     serialized_engine.c_str(), serialized_engine.size(), nullptr));\n+  // trt_execution_context_ptr_.reset(trt_engine_ptr_->createExecutionContext());\n   // Runtime is safe to delete after engine creation\n-  infer->destroy();\n+  // infer->destroy();\n }\n \n void TRTEngineOp::Compute(OpKernelContext* context) {\n+  if (!trt_execution_context_ptr_) {\n+    IRuntime* infer = nvinfer1::createInferRuntime(logger);\n+#if NV_TENSORRT_MAJOR > 3\n+    tensorflow::TfGpuId tf_gpu_id(\n+        context->device()->tensorflow_gpu_device_info()->gpu_id);\n+    tensorflow::GPUOptions gpuoptions;\n+    auto pm = tensorflow::ProcessState::singleton();\n+    auto dev_allocator = pm->GetGPUAllocator(gpuoptions, tf_gpu_id, 1);\n+    if (!dev_allocator) {\n+      LOG(FATAL) << \"Can't find device allocator for gpu device\" << tf_gpu_id;\n+    }\n+    allocator_ = std::make_shared<TRTDeviceAllocator>(dev_allocator);\n+    infer->setGpuAllocator(allocator_.get());\n+#endif", "path": "tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc", "position": null, "original_position": 67, "commit_id": "bf70368d36df3ee9a16f5285940d73fb54d911c0", "original_commit_id": "e276bf65e2f3ec452eb28d0a9d34849d65663788", "user": {"login": "samikama", "id": 10539540, "node_id": "MDQ6VXNlcjEwNTM5NTQw", "avatar_url": "https://avatars0.githubusercontent.com/u/10539540?v=4", "gravatar_id": "", "url": "https://api.github.com/users/samikama", "html_url": "https://github.com/samikama", "followers_url": "https://api.github.com/users/samikama/followers", "following_url": "https://api.github.com/users/samikama/following{/other_user}", "gists_url": "https://api.github.com/users/samikama/gists{/gist_id}", "starred_url": "https://api.github.com/users/samikama/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/samikama/subscriptions", "organizations_url": "https://api.github.com/users/samikama/orgs", "repos_url": "https://api.github.com/users/samikama/repos", "events_url": "https://api.github.com/users/samikama/events{/privacy}", "received_events_url": "https://api.github.com/users/samikama/received_events", "type": "User", "site_admin": false}, "body": "Isn't device already set on the current thread when the compute is called?", "created_at": "2018-04-30T23:17:01Z", "updated_at": "2018-05-02T21:46:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18909#discussion_r185136388", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18909", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/185136388"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18909#discussion_r185136388"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18909"}}, "body_html": "<p>Isn't device already set on the current thread when the compute is called?</p>", "body_text": "Isn't device already set on the current thread when the compute is called?", "in_reply_to_id": 185075890}