{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/185078265", "pull_request_review_id": 116108252, "id": 185078265, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDE4NTA3ODI2NQ==", "diff_hunk": "@@ -0,0 +1,236 @@\n+/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/contrib/tensorrt/convert/trt_optimization_pass.h\"\n+#include \"tensorflow/contrib/tensorrt/convert/convert_graph.h\"\n+#include \"tensorflow/core/grappler/clusters/cluster.h\"\n+#include \"tensorflow/core/grappler/grappler_item.h\"\n+#include \"tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.h\"\n+#include \"tensorflow/core/lib/strings/str_util.h\"\n+#include \"tensorflow/core/lib/strings/strcat.h\"\n+#include \"tensorflow/core/platform/logging.h\"\n+#include \"tensorflow/core/public/session_options.h\"\n+\n+using tensorflow::str_util::Uppercase;\n+using tensorflow::strings::StrAppend;\n+using tensorflow::strings::StrCat;\n+#if GOOGLE_CUDA\n+#if GOOGLE_TENSORRT\n+namespace tensorflow {\n+namespace tensorrt {\n+namespace convert {\n+// TODO(sami): Remove VLOG messages once the code matures\n+tensorflow::Status TRTOptimizationPass::Init(\n+    const tensorflow::RewriterConfig_CustomGraphOptimizer* config) {\n+  VLOG(1) << \"Called INIT for \" << m_name_ << \" with config = \" << config;\n+  if (config == nullptr) {\n+    maximum_workspace_size_ = 2 << 30;\n+    return tensorflow::Status::OK();\n+  }\n+  const auto params = config->parameter_map();\n+  if (params.count(\"minimum_segment_size\")) {\n+    minimum_segment_size_ = params.at(\"minimum_segment_size\").i();\n+  }\n+  if (params.count(\"max_batch_size\")) {\n+    maximum_batch_size_ = params.at(\"max_batch_size\").i();\n+  }\n+  if (params.count(\"max_workspace_size_bytes\"))\n+    maximum_workspace_size_ = params.at(\"max_workspace_size_bytes\").i();\n+  if (params.count(\"precision_mode\")) {\n+    string pm = Uppercase(params.at(\"precision_mode\").s());\n+    if (pm == \"FP32\") {\n+      precision_mode_ = 0;\n+    } else if (pm == \"FP16\") {\n+      precision_mode_ = 1;\n+    } else if (pm == \"INT8\") {\n+      precision_mode_ = 2;\n+    } else {\n+      LOG(ERROR) << \"Unknown precision mode '\" << pm << \"'\";\n+      return tensorflow::errors::InvalidArgument(\n+          \"Unknown precision mode argument\" + pm +\n+          \" Valid values are FP32, FP16, INT8\");\n+    }\n+  }\n+  return tensorflow::Status::OK();\n+};\n+\n+tensorflow::Status TRTOptimizationPass::Optimize(\n+    tensorflow::grappler::Cluster* cluster,\n+    const tensorflow::grappler::GrapplerItem& item, GraphDef* optimized_graph) {\n+  VLOG(1) << \"Called TRTOptimization Pass \" << m_name_;\n+  VLOG(1) << \"Cluster = \" << cluster;\n+  string offset(\"  \");\n+  string offset2 = StrCat(offset, offset);\n+  string offset3 = StrCat(offset2, offset);\n+  string offset4 = StrCat(offset2, offset2);\n+  if (cluster) {\n+    VLOG(1) << offset << \"type             = \" << cluster->type();\n+    VLOG(1) << offset << \"num warmup steps = \" << cluster->NumWarmupSteps();\n+    const auto devNames = cluster->GetDeviceNames();\n+    if (devNames.size()) {\n+      VLOG(1) << offset << \" Device names:\";\n+      for (const auto s : devNames) {\n+        VLOG(1) << offset2 << s;\n+      }\n+    }\n+    std::unordered_map<string, uint64> peak_mem;\n+    auto status = cluster->GetPeakMemoryUsage(&peak_mem);\n+    if (status == tensorflow::Status::OK()) {\n+      VLOG(1) << offset << \"Peak Memory Usage :\";\n+      for (auto s : peak_mem) {\n+        VLOG(1) << offset2 << s.first << \" = \" << s.second;\n+      }\n+    }\n+\n+    const auto dev_props = cluster->GetDevices();\n+    if (dev_props.size()) {\n+      VLOG(1) << offset << \"Device properties:\";\n+      for (auto k : dev_props) {\n+        VLOG(1) << offset2 << k.first;\n+        const auto& dt = k.second;\n+        VLOG(1) << offset3 << \"type          = \" << dt.type();\n+        VLOG(1) << offset3 << \"vendor        = \" << dt.vendor();\n+        VLOG(1) << offset3 << \"model         = \" << dt.model();\n+        VLOG(1) << offset3 << \"frequency     = \" << dt.frequency();\n+        VLOG(1) << offset3 << \"num cores     = \" << dt.num_cores();\n+        VLOG(1) << offset3 << \"num registers = \" << dt.num_registers();\n+        VLOG(1) << offset3 << \"L1 cache size = \" << dt.l1_cache_size();\n+        VLOG(1) << offset3 << \"L2 cache size = \" << dt.l2_cache_size();\n+        VLOG(1) << offset3 << \"L3 cache size = \" << dt.l3_cache_size();\n+        VLOG(1) << offset3 << \"SHMem per SMP = \"\n+                << dt.shared_memory_size_per_multiprocessor();\n+        VLOG(1) << offset3 << \"memory size   = \" << dt.memory_size();\n+        VLOG(1) << offset3 << \"bandwidth     = \" << dt.bandwidth();\n+        if (dt.environment_size()) {\n+          VLOG(1) << offset3 << \"environment   :\";\n+          for (const auto e : dt.environment()) {\n+            VLOG(1) << offset4 << e.first << \" = \" << e.second;\n+          }\n+        }\n+      }\n+    }\n+  }\n+  VLOG(1) << \"item: \" << item.id;\n+  int max_dim = -1;\n+  if (item.feed.size()) {\n+    VLOG(1) << offset << \"Feeds  :\";\n+    for (const auto& f : item.feed) {\n+      const auto& shape = f.second.shape();\n+      if (shape.dims() > 0) {\n+        if (shape.dim_size(0) > max_dim) max_dim = shape.dim_size(0);\n+      }\n+      VLOG(1) << offset2 << f.first << \" = shaped \"\n+              << f.second.shape().DebugString();\n+    }\n+  } else {\n+    VLOG(1) << offset << \"No Feeds\";\n+  }\n+  if (maximum_batch_size_ < 0) {  // automatic batch size from input\n+    if (max_dim > 0) {\n+      maximum_batch_size_ = max_dim;\n+      VLOG(1) << \"Setting maximum batch size to \" << max_dim;\n+    } else {\n+      maximum_batch_size_ = 128;\n+      LOG(WARNING) << \"Maximum batch size is not set\"\n+                      \" and can't be deduced from inputs setting it to\"\n+                   << maximum_batch_size_\n+                   << \". Suggest configuring it from configuration parameters\";\n+    }\n+  } else {\n+    if (max_dim > maximum_batch_size_) {\n+      LOG(WARNING) << \"Configured batch size \" << maximum_batch_size_\n+                   << \" is less than input batch size \" << max_dim\n+                   << \" adjusting maximum batch size to match input batch size\";\n+    }\n+  }\n+  if (item.fetch.size()) {\n+    VLOG(1) << offset << \"Fetches  :\";\n+    for (const auto& f : item.fetch) {\n+      VLOG(1) << offset2 << f;\n+    }\n+  } else {\n+    VLOG(1) << offset << \"No Fetches\";\n+  }\n+\n+  if (item.init_ops.size()) {\n+    VLOG(1) << offset << \"init ops  :\";\n+    for (const auto& f : item.init_ops) {\n+      VLOG(1) << offset2 << f;\n+    }\n+  } else {\n+    VLOG(1) << offset << \"No init ops\";\n+  }\n+  VLOG(1) << \"Save Op = \" << item.save_op;\n+  VLOG(1) << \"Restore Op = \" << item.restore_op;\n+  VLOG(1) << \"save_restore_loc_tensor = \" << item.save_restore_loc_tensor;\n+  if (item.keep_ops.size()) {\n+    VLOG(1) << offset << \"keep ops  :\";\n+    for (const auto& f : item.keep_ops) {\n+      VLOG(1) << offset2 << f;\n+    }\n+  } else {\n+    VLOG(1) << offset << \"No keep ops\";\n+  }\n+  VLOG(1) << item.graph.DebugString();\n+  tensorflow::grappler::GraphProperties static_graph_properties(item);\n+  TF_RETURN_IF_ERROR(static_graph_properties.InferStatically(true));\n+  for (const auto dev : cluster->GetDeviceSet()->devices()) {\n+    const auto& pname = dev->parsed_name();\n+    VLOG(1) << \"Device name= \" << dev->name()\n+            << \" parsedname job= \" << pname.job << \" id= \" << pname.id\n+            << \" has_id: \" << pname.has_id << \" has_job: \" << pname.has_job\n+            << \"has_type: \" << pname.has_type << \" type =\" << pname.type;\n+  }\n+  auto status = tensorflow::tensorrt::convert::ConvertAfterShapes(\n+      item.graph, item.fetch, maximum_batch_size_, maximum_workspace_size_,\n+      optimized_graph, precision_mode_, minimum_segment_size_,\n+      static_graph_properties, cluster);\n+  VLOG(2) << optimized_graph->DebugString();\n+  return status;\n+}\n+\n+void TRTOptimizationPass::Feedback(\n+    tensorflow::grappler::Cluster* cluster,\n+    const tensorflow::grappler::GrapplerItem& item,\n+    const GraphDef& optimized_graph, double result) {}\n+\n+using tensorflow::grappler::CustomGraphOptimizerRegistrar;\n+namespace {\n+\n+class samiReg : public CustomGraphOptimizerRegistrar {\n+ public:\n+  samiReg(const tensorflow::grappler::CustomGraphOptimizerRegistry::Creator& cr,\n+          const string& name)\n+      : CustomGraphOptimizerRegistrar(cr, name) {\n+    VLOG(1) << \"Constructing a CustomOptimizationPass registration object for \"\n+            << name;\n+  }\n+};\n+// static CustomGraphOptimizerRegistrar TRTOptimizationPass_Registrar([]() {", "path": "tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc", "position": null, "original_position": 220, "commit_id": "bf70368d36df3ee9a16f5285940d73fb54d911c0", "original_commit_id": "e276bf65e2f3ec452eb28d0a9d34849d65663788", "user": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "body": "Remove?", "created_at": "2018-04-30T19:02:09Z", "updated_at": "2018-05-02T21:46:24Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/18909#discussion_r185078265", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18909", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/185078265"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/18909#discussion_r185078265"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/18909"}}, "body_html": "<p>Remove?</p>", "body_text": "Remove?"}