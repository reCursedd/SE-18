{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/399194358", "html_url": "https://github.com/tensorflow/tensorflow/issues/19912#issuecomment-399194358", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19912", "id": 399194358, "node_id": "MDEyOklzc3VlQ29tbWVudDM5OTE5NDM1OA==", "user": {"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-21T18:08:34Z", "updated_at": "2018-06-21T18:08:34Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=25213730\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/sibyjackgrove\">@sibyjackgrove</a> You are seeing this issue because the model is not compatible with the input provided by the csv dataset iterator. Model expects input to be a tensor or a list or a dict with key as layer name of the layer that has placeholder. In your case {'InputLayer': Tensor(...)}.</p>\n<p>However, iterator from make_csv_dataset provided a dictionary where key is csv column header and value is row value. This is not compatible with the model. We do not have a way of knowing whether the dictionary is from csv or if user has generated the layer name and value pairs. The not very elegant workaround you can try is to match the name of input layer with csv column name. Sorry about that.</p>\n<p>We will make sure to add this information to our documentation and in the future see if we can improve support for this. Thank you!</p>", "body_text": "@sibyjackgrove You are seeing this issue because the model is not compatible with the input provided by the csv dataset iterator. Model expects input to be a tensor or a list or a dict with key as layer name of the layer that has placeholder. In your case {'InputLayer': Tensor(...)}.\nHowever, iterator from make_csv_dataset provided a dictionary where key is csv column header and value is row value. This is not compatible with the model. We do not have a way of knowing whether the dictionary is from csv or if user has generated the layer name and value pairs. The not very elegant workaround you can try is to match the name of input layer with csv column name. Sorry about that.\nWe will make sure to add this information to our documentation and in the future see if we can improve support for this. Thank you!", "body": "@sibyjackgrove You are seeing this issue because the model is not compatible with the input provided by the csv dataset iterator. Model expects input to be a tensor or a list or a dict with key as layer name of the layer that has placeholder. In your case {'InputLayer': Tensor(...)}.\r\n\r\nHowever, iterator from make_csv_dataset provided a dictionary where key is csv column header and value is row value. This is not compatible with the model. We do not have a way of knowing whether the dictionary is from csv or if user has generated the layer name and value pairs. The not very elegant workaround you can try is to match the name of input layer with csv column name. Sorry about that.\r\n\r\nWe will make sure to add this information to our documentation and in the future see if we can improve support for this. Thank you!"}