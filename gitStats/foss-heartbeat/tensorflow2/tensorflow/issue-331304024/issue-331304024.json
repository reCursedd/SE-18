{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19912", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19912/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19912/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19912/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19912", "id": 331304024, "node_id": "MDU6SXNzdWUzMzEzMDQwMjQ=", "number": 19912, "title": "tf dataset iterators producing Key error when used with tf.keras.Model fit method", "user": {"login": "sibyjackgrove", "id": 25213730, "node_id": "MDQ6VXNlcjI1MjEzNzMw", "avatar_url": "https://avatars0.githubusercontent.com/u/25213730?v=4", "gravatar_id": "", "url": "https://api.github.com/users/sibyjackgrove", "html_url": "https://github.com/sibyjackgrove", "followers_url": "https://api.github.com/users/sibyjackgrove/followers", "following_url": "https://api.github.com/users/sibyjackgrove/following{/other_user}", "gists_url": "https://api.github.com/users/sibyjackgrove/gists{/gist_id}", "starred_url": "https://api.github.com/users/sibyjackgrove/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/sibyjackgrove/subscriptions", "organizations_url": "https://api.github.com/users/sibyjackgrove/orgs", "repos_url": "https://api.github.com/users/sibyjackgrove/repos", "events_url": "https://api.github.com/users/sibyjackgrove/events{/privacy}", "received_events_url": "https://api.github.com/users/sibyjackgrove/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "pavithrasv", "id": 13326758, "node_id": "MDQ6VXNlcjEzMzI2NzU4", "avatar_url": "https://avatars0.githubusercontent.com/u/13326758?v=4", "gravatar_id": "", "url": "https://api.github.com/users/pavithrasv", "html_url": "https://github.com/pavithrasv", "followers_url": "https://api.github.com/users/pavithrasv/followers", "following_url": "https://api.github.com/users/pavithrasv/following{/other_user}", "gists_url": "https://api.github.com/users/pavithrasv/gists{/gist_id}", "starred_url": "https://api.github.com/users/pavithrasv/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/pavithrasv/subscriptions", "organizations_url": "https://api.github.com/users/pavithrasv/orgs", "repos_url": "https://api.github.com/users/pavithrasv/repos", "events_url": "https://api.github.com/users/pavithrasv/events{/privacy}", "received_events_url": "https://api.github.com/users/pavithrasv/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-06-11T18:41:36Z", "updated_at": "2018-10-13T17:33:44Z", "closed_at": "2018-06-21T18:10:05Z", "author_association": "CONTRIBUTOR", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Windows 10</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.9.0-rc0</li>\n<li><strong>Python version</strong>: 3.6</li>\n<li><strong>Bazel version (if compiling from source)</strong>: NA</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: NA</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>: model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>In the tf 1.9 rc0 release notes, it was mentioned that dataset iterator can work with Keras training and eval methods. However, the fit method is throwing the following error when used with an iterator.</p>\n<blockquote>\n<p>No data provided for \"InputLayer\". Need data for each key in: ['InputLayer']</p>\n</blockquote>\n<h3>Source code / logs</h3>\n<pre><code>X_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_0','Load_residential_multi_1'],shuffle=False)\nY_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_2'],shuffle=False)\ndataset = tf.data.Dataset.zip((X_dataset,Y_dataset))\ndataset = dataset.batch(2)\ndataset_iterator = dataset.make_one_shot_iterator()\n\nmodel = Sequential() \n#Input Layer\nmodel.add(InputLayer(input_shape=(1,),name='InputLayer'))#,input_tensor =dataset\n#Layer1 \nmodel.add(Dense(units=5,activation='relu',name='FeedForward1'))  #Add a feed forward layer\n#Layer2 \nmodel.add(Dense(units=5,activation='relu',name='FeedForward2'))  #Add a feed forward layer\n#Output layer \nmodel.add(Dense(units=2,name='OutputLayer'))\n#Specify loss function and optimizer\nmodel.compile(loss='mse',optimizer='adam',metrics=['mae'])\n#Summarize model\nmodel.summary()\n#Train model\nmodel.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\n</code></pre>\n<p>The error trace is given below:</p>\n<blockquote>\n<p>KeyError                                  Traceback (most recent call last)<br>\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)<br>\n125           if data[x].<strong>class</strong>.<strong>name</strong> == 'DataFrame' else data[x]<br>\n--&gt; 126           for x in names<br>\n127       ]</p>\n<p>~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in (.0)<br>\n125           if data[x].<strong>class</strong>.<strong>name</strong> == 'DataFrame' else data[x]<br>\n--&gt; 126           for x in names<br>\n127       ]</p>\n<p>KeyError: 'InputLayer'</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>ValueError                                Traceback (most recent call last)<br>\n in ()<br>\n----&gt; 1 model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)</p>\n<p>~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)<br>\n1256         steps_name='steps_per_epoch',<br>\n1257         steps=steps_per_epoch,<br>\n-&gt; 1258         validation_split=validation_split)<br>\n1259<br>\n1260     # Prepare validation data.</p>\n<p>~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)<br>\n867         feed_input_shapes,<br>\n868         check_batch_axis=False,  # Don't enforce the batch size.<br>\n--&gt; 869         exception_prefix='input')<br>\n870<br>\n871     if y is not None:</p>\n<p>~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)<br>\n128     except KeyError as e:<br>\n129       raise ValueError('No data provided for \"' + e.args[0] + '\". Need data '<br>\n--&gt; 130                        'for each key in: ' + str(names))<br>\n131   elif isinstance(data, list):<br>\n132     if isinstance(data[0], list):</p>\n<p>ValueError: No data provided for \"InputLayer\". Need data for each key in: ['InputLayer']</p>\n</blockquote>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): 1.9.0-rc0\nPython version: 3.6\nBazel version (if compiling from source): NA\nGCC/Compiler version (if compiling from source): NA\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce: model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\n\nDescribe the problem\nIn the tf 1.9 rc0 release notes, it was mentioned that dataset iterator can work with Keras training and eval methods. However, the fit method is throwing the following error when used with an iterator.\n\nNo data provided for \"InputLayer\". Need data for each key in: ['InputLayer']\n\nSource code / logs\nX_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_0','Load_residential_multi_1'],shuffle=False)\nY_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_2'],shuffle=False)\ndataset = tf.data.Dataset.zip((X_dataset,Y_dataset))\ndataset = dataset.batch(2)\ndataset_iterator = dataset.make_one_shot_iterator()\n\nmodel = Sequential() \n#Input Layer\nmodel.add(InputLayer(input_shape=(1,),name='InputLayer'))#,input_tensor =dataset\n#Layer1 \nmodel.add(Dense(units=5,activation='relu',name='FeedForward1'))  #Add a feed forward layer\n#Layer2 \nmodel.add(Dense(units=5,activation='relu',name='FeedForward2'))  #Add a feed forward layer\n#Output layer \nmodel.add(Dense(units=2,name='OutputLayer'))\n#Specify loss function and optimizer\nmodel.compile(loss='mse',optimizer='adam',metrics=['mae'])\n#Summarize model\nmodel.summary()\n#Train model\nmodel.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\n\nThe error trace is given below:\n\nKeyError                                  Traceback (most recent call last)\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\n125           if data[x].class.name == 'DataFrame' else data[x]\n--> 126           for x in names\n127       ]\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in (.0)\n125           if data[x].class.name == 'DataFrame' else data[x]\n--> 126           for x in names\n127       ]\nKeyError: 'InputLayer'\nDuring handling of the above exception, another exception occurred:\nValueError                                Traceback (most recent call last)\n in ()\n----> 1 model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n1256         steps_name='steps_per_epoch',\n1257         steps=steps_per_epoch,\n-> 1258         validation_split=validation_split)\n1259\n1260     # Prepare validation data.\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\n867         feed_input_shapes,\n868         check_batch_axis=False,  # Don't enforce the batch size.\n--> 869         exception_prefix='input')\n870\n871     if y is not None:\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\n128     except KeyError as e:\n129       raise ValueError('No data provided for \"' + e.args[0] + '\". Need data '\n--> 130                        'for each key in: ' + str(names))\n131   elif isinstance(data, list):\n132     if isinstance(data[0], list):\nValueError: No data provided for \"InputLayer\". Need data for each key in: ['InputLayer']", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.9.0-rc0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\r\n\r\n### Describe the problem\r\n In the tf 1.9 rc0 release notes, it was mentioned that dataset iterator can work with Keras training and eval methods. However, the fit method is throwing the following error when used with an iterator.\r\n\r\n> No data provided for \"InputLayer\". Need data for each key in: ['InputLayer']\r\n\r\n### Source code / logs\r\n\r\n```\r\nX_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_0','Load_residential_multi_1'],shuffle=False)\r\nY_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_2'],shuffle=False)\r\ndataset = tf.data.Dataset.zip((X_dataset,Y_dataset))\r\ndataset = dataset.batch(2)\r\ndataset_iterator = dataset.make_one_shot_iterator()\r\n\r\nmodel = Sequential() \r\n#Input Layer\r\nmodel.add(InputLayer(input_shape=(1,),name='InputLayer'))#,input_tensor =dataset\r\n#Layer1 \r\nmodel.add(Dense(units=5,activation='relu',name='FeedForward1'))  #Add a feed forward layer\r\n#Layer2 \r\nmodel.add(Dense(units=5,activation='relu',name='FeedForward2'))  #Add a feed forward layer\r\n#Output layer \r\nmodel.add(Dense(units=2,name='OutputLayer'))\r\n#Specify loss function and optimizer\r\nmodel.compile(loss='mse',optimizer='adam',metrics=['mae'])\r\n#Summarize model\r\nmodel.summary()\r\n#Train model\r\nmodel.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\r\n```\r\nThe error trace is given below:\r\n\r\n> KeyError                                  Traceback (most recent call last)\r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n>     125           if data[x].__class__.__name__ == 'DataFrame' else data[x]\r\n> --> 126           for x in names\r\n>     127       ]\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in <listcomp>(.0)\r\n>     125           if data[x].__class__.__name__ == 'DataFrame' else data[x]\r\n> --> 126           for x in names\r\n>     127       ]\r\n> \r\n> KeyError: 'InputLayer'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> ValueError                                Traceback (most recent call last)\r\n> <ipython-input-90-cd138934ce6f> in <module>()\r\n> ----> 1 model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n>    1256         steps_name='steps_per_epoch',\r\n>    1257         steps=steps_per_epoch,\r\n> -> 1258         validation_split=validation_split)\r\n>    1259 \r\n>    1260     # Prepare validation data.\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\r\n>     867         feed_input_shapes,\r\n>     868         check_batch_axis=False,  # Don't enforce the batch size.\r\n> --> 869         exception_prefix='input')\r\n>     870 \r\n>     871     if y is not None:\r\n> \r\n> ~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n>     128     except KeyError as e:\r\n>     129       raise ValueError('No data provided for \"' + e.args[0] + '\". Need data '\r\n> --> 130                        'for each key in: ' + str(names))\r\n>     131   elif isinstance(data, list):\r\n>     132     if isinstance(data[0], list):\r\n> \r\n> ValueError: No data provided for \"InputLayer\". Need data for each key in: ['InputLayer']"}