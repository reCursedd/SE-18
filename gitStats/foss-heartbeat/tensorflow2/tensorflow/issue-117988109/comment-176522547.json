{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/176522547", "html_url": "https://github.com/tensorflow/tensorflow/issues/305#issuecomment-176522547", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/305", "id": 176522547, "node_id": "MDEyOklzc3VlQ29tbWVudDE3NjUyMjU0Nw==", "user": {"login": "fpmchu", "id": 7635883, "node_id": "MDQ6VXNlcjc2MzU4ODM=", "avatar_url": "https://avatars0.githubusercontent.com/u/7635883?v=4", "gravatar_id": "", "url": "https://api.github.com/users/fpmchu", "html_url": "https://github.com/fpmchu", "followers_url": "https://api.github.com/users/fpmchu/followers", "following_url": "https://api.github.com/users/fpmchu/following{/other_user}", "gists_url": "https://api.github.com/users/fpmchu/gists{/gist_id}", "starred_url": "https://api.github.com/users/fpmchu/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/fpmchu/subscriptions", "organizations_url": "https://api.github.com/users/fpmchu/orgs", "repos_url": "https://api.github.com/users/fpmchu/repos", "events_url": "https://api.github.com/users/fpmchu/events{/privacy}", "received_events_url": "https://api.github.com/users/fpmchu/received_events", "type": "User", "site_admin": false}, "created_at": "2016-01-29T02:03:36Z", "updated_at": "2016-01-29T02:03:36Z", "author_association": "NONE", "body_html": "<p>Note that while this is progress, and you can theoretically remove the <code>with tf.device('/cpu:0')</code> line, it wouldn't work completely, because many underlying ops are still not GPU enabled (you can see this if you use <code>with tf.device('/gpu:0')</code> in <code>word2vec_basic.py</code>).  My guess is that because <code>scatter_sub</code> is an inline operation, if there's no GPU op, TF just fails; whereas for non-inline operations, TF just knows to copy data back and forth dynamically.  So for something like word2vec_basic.py where a lot of the underlying expensive ops don't have a GPU kernel, you end up using GPU for some and CPU for others, which doesn't speed things up AFAICT.</p>", "body_text": "Note that while this is progress, and you can theoretically remove the with tf.device('/cpu:0') line, it wouldn't work completely, because many underlying ops are still not GPU enabled (you can see this if you use with tf.device('/gpu:0') in word2vec_basic.py).  My guess is that because scatter_sub is an inline operation, if there's no GPU op, TF just fails; whereas for non-inline operations, TF just knows to copy data back and forth dynamically.  So for something like word2vec_basic.py where a lot of the underlying expensive ops don't have a GPU kernel, you end up using GPU for some and CPU for others, which doesn't speed things up AFAICT.", "body": "Note that while this is progress, and you can theoretically remove the `with tf.device('/cpu:0')` line, it wouldn't work completely, because many underlying ops are still not GPU enabled (you can see this if you use `with tf.device('/gpu:0')` in `word2vec_basic.py`).  My guess is that because `scatter_sub` is an inline operation, if there's no GPU op, TF just fails; whereas for non-inline operations, TF just knows to copy data back and forth dynamically.  So for something like word2vec_basic.py where a lot of the underlying expensive ops don't have a GPU kernel, you end up using GPU for some and CPU for others, which doesn't speed things up AFAICT.\n"}