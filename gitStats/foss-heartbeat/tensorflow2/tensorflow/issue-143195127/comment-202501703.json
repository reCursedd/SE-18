{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/202501703", "html_url": "https://github.com/tensorflow/tensorflow/issues/1619#issuecomment-202501703", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1619", "id": 202501703, "node_id": "MDEyOklzc3VlQ29tbWVudDIwMjUwMTcwMw==", "user": {"login": "andydavis1", "id": 15696327, "node_id": "MDQ6VXNlcjE1Njk2MzI3", "avatar_url": "https://avatars0.githubusercontent.com/u/15696327?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andydavis1", "html_url": "https://github.com/andydavis1", "followers_url": "https://api.github.com/users/andydavis1/followers", "following_url": "https://api.github.com/users/andydavis1/following{/other_user}", "gists_url": "https://api.github.com/users/andydavis1/gists{/gist_id}", "starred_url": "https://api.github.com/users/andydavis1/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andydavis1/subscriptions", "organizations_url": "https://api.github.com/users/andydavis1/orgs", "repos_url": "https://api.github.com/users/andydavis1/repos", "events_url": "https://api.github.com/users/andydavis1/events{/privacy}", "received_events_url": "https://api.github.com/users/andydavis1/received_events", "type": "User", "site_admin": false}, "created_at": "2016-03-28T17:40:22Z", "updated_at": "2016-03-28T17:40:22Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=8746710\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cuiguoxin\">@cuiguoxin</a> Thank you for your comments. I think that some of this confusion is due to this API being in an intermediate state (it currently just supports functions and not general graphs). As commented in the header file, this API is under construction, and will be changing frequently. Currently, the gradients passed in 'y_grad_node_outputs' are passed through to the input of the 'y_nodes', but these nodes are handled in a specialized way in the current implementation (i.e. function arg nodes). In a future version, the 'y_grad_node_outputs' will contain the gradient node outputs corresponding to the 'y_node_outputs', and will be propagated into the 'y_nodes' during backprop init.</p>", "body_text": "@cuiguoxin Thank you for your comments. I think that some of this confusion is due to this API being in an intermediate state (it currently just supports functions and not general graphs). As commented in the header file, this API is under construction, and will be changing frequently. Currently, the gradients passed in 'y_grad_node_outputs' are passed through to the input of the 'y_nodes', but these nodes are handled in a specialized way in the current implementation (i.e. function arg nodes). In a future version, the 'y_grad_node_outputs' will contain the gradient node outputs corresponding to the 'y_node_outputs', and will be propagated into the 'y_nodes' during backprop init.", "body": "@cuiguoxin Thank you for your comments. I think that some of this confusion is due to this API being in an intermediate state (it currently just supports functions and not general graphs). As commented in the header file, this API is under construction, and will be changing frequently. Currently, the gradients passed in 'y_grad_node_outputs' are passed through to the input of the 'y_nodes', but these nodes are handled in a specialized way in the current implementation (i.e. function arg nodes). In a future version, the 'y_grad_node_outputs' will contain the gradient node outputs corresponding to the 'y_node_outputs', and will be propagated into the 'y_nodes' during backprop init.\n"}