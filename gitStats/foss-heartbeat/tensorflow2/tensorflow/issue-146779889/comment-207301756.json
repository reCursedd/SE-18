{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/207301756", "html_url": "https://github.com/tensorflow/tensorflow/issues/1816#issuecomment-207301756", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/1816", "id": 207301756, "node_id": "MDEyOklzc3VlQ29tbWVudDIwNzMwMTc1Ng==", "user": {"login": "zhangjiajie", "id": 1018952, "node_id": "MDQ6VXNlcjEwMTg5NTI=", "avatar_url": "https://avatars1.githubusercontent.com/u/1018952?v=4", "gravatar_id": "", "url": "https://api.github.com/users/zhangjiajie", "html_url": "https://github.com/zhangjiajie", "followers_url": "https://api.github.com/users/zhangjiajie/followers", "following_url": "https://api.github.com/users/zhangjiajie/following{/other_user}", "gists_url": "https://api.github.com/users/zhangjiajie/gists{/gist_id}", "starred_url": "https://api.github.com/users/zhangjiajie/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/zhangjiajie/subscriptions", "organizations_url": "https://api.github.com/users/zhangjiajie/orgs", "repos_url": "https://api.github.com/users/zhangjiajie/repos", "events_url": "https://api.github.com/users/zhangjiajie/events{/privacy}", "received_events_url": "https://api.github.com/users/zhangjiajie/received_events", "type": "User", "site_admin": false}, "created_at": "2016-04-08T08:15:27Z", "updated_at": "2016-04-08T08:15:27Z", "author_association": "NONE", "body_html": "<p>For some reasons I am not allowed to post my code here, but the bug occurs when I try to stack multiple layers of BLSTM using dynamic_rnn() (see this related request: <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"145998256\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1779\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1779/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1779\">#1779</a>). For the backward pass, I first reversed the input using array_ops.reverse_sequence(), then reversed the output using the same function. I also used feed forward layers in between the BLSTMs.</p>\n<p>However, with one BLSTM layer, everything is fine.</p>\n<p>Thanks for all the help!</p>", "body_text": "For some reasons I am not allowed to post my code here, but the bug occurs when I try to stack multiple layers of BLSTM using dynamic_rnn() (see this related request: #1779). For the backward pass, I first reversed the input using array_ops.reverse_sequence(), then reversed the output using the same function. I also used feed forward layers in between the BLSTMs.\nHowever, with one BLSTM layer, everything is fine.\nThanks for all the help!", "body": "For some reasons I am not allowed to post my code here, but the bug occurs when I try to stack multiple layers of BLSTM using dynamic_rnn() (see this related request: https://github.com/tensorflow/tensorflow/issues/1779). For the backward pass, I first reversed the input using array_ops.reverse_sequence(), then reversed the output using the same function. I also used feed forward layers in between the BLSTMs. \n\nHowever, with one BLSTM layer, everything is fine.  \n\nThanks for all the help!\n"}