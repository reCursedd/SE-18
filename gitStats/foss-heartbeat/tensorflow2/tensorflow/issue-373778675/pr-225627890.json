{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23242", "id": 225627890, "node_id": "MDExOlB1bGxSZXF1ZXN0MjI1NjI3ODkw", "html_url": "https://github.com/tensorflow/tensorflow/pull/23242", "diff_url": "https://github.com/tensorflow/tensorflow/pull/23242.diff", "patch_url": "https://github.com/tensorflow/tensorflow/pull/23242.patch", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23242", "number": 23242, "state": "closed", "locked": false, "title": "[Features]mixed precision support enhancement using decorator", "user": {"login": "Dido0o0", "id": 16295526, "node_id": "MDQ6VXNlcjE2Mjk1NTI2", "avatar_url": "https://avatars2.githubusercontent.com/u/16295526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dido0o0", "html_url": "https://github.com/Dido0o0", "followers_url": "https://api.github.com/users/Dido0o0/followers", "following_url": "https://api.github.com/users/Dido0o0/following{/other_user}", "gists_url": "https://api.github.com/users/Dido0o0/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dido0o0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dido0o0/subscriptions", "organizations_url": "https://api.github.com/users/Dido0o0/orgs", "repos_url": "https://api.github.com/users/Dido0o0/repos", "events_url": "https://api.github.com/users/Dido0o0/events{/privacy}", "received_events_url": "https://api.github.com/users/Dido0o0/received_events", "type": "User", "site_admin": false}, "body": "This feature realize the automatic/constant loss scaling algorithm in Backprop, which can help preserve small gradient magnitudes ( ref to  https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html)\r\nMixed precision with loss scaling is already support by tf.contrib.mixed_precision.LossScaleOptimizer,  with the following usage:\r\n```python\r\nloss = loss_fn()\r\nopt = tf.AdamOptimizer(learning_rate=...)\r\n\r\n# Choose a loss scale manager which decides how to pick the right loss scale\r\n# throughout the training process.\r\nloss_scale_manger = tf.contrib.mixed_precision.FixedLossScaleManager(5000)\r\n\r\n# Wraps the original optimizer in a LossScaleOptimizer.\r\nloss_scale_optimizer = LossScaleOptimizer(opt, loss_scale_manager)\r\n\r\n# Call minimize() on the loss scale optimizer.\r\ntrain_op = loss_scale_optimizer.minimize(loss)\r\n```\r\n\r\nThe optimizer `LossScaleOptimizer` is actually a wrapper of other optimizers.  However, the usage using wrapper is too limited to support all cases.  For example,\r\n    + if the users  are using `tf.gradients()` to compute the gradients rather than `optimizer.compute_gradients()`/`optimizer.minimize()`,  the wrapper is no longer in user. \r\n    + the `LossScaleOptimizer` wrapper may have compatibility problem with other optimizer wrappers, e.g. `SyncReplicasOptimizer`\r\n    + the current implementation in `LossScaleOptimizer` did not take the colocation parameter into consideration. \r\n\r\nInstead, we implement loss scaling using a decorator on `gradients()`, which is the atom function to compute the backprop gradients. The usage is as following:\r\n```python\r\nloss = loss_fn()\r\nopt = tf.AdamOptimizer(learning_rate=...)\r\n# constant loss scaling with loss_scale=64\r\nwith tf.mixed_precision_scope(automatic_loss_scaling=False, loss_scale=64):\r\n      grad = tf.gradients()  # if using tf.gradients\r\n      var_and_grad =opt.minimize(loss) # if using optimizer\r\n\r\n# automatic loss scaling\r\nwith tf.mixed_precision_scope(automatic_loss_scaling=True):\r\n      grad = tf.gradients()  # if using tf.gradients\r\n      var_and_grad =opt.minimize(loss) # if using optimizer\r\n```\r\n\r\nThe implementation can handle all of the above problems encounter by `LossScaleOptimizer` .", "created_at": "2018-10-25T05:27:04Z", "updated_at": "2018-10-25T05:35:12Z", "closed_at": "2018-10-25T05:35:12Z", "merged_at": null, "merge_commit_sha": "8d6d9f7f1d3cf96c16ad3d24f19ecf787534fdb2", "assignee": null, "assignees": [], "requested_reviewers": [], "requested_teams": [], "labels": [{"id": 300136613, "node_id": "MDU6TGFiZWwzMDAxMzY2MTM=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/cla:%20no", "name": "cla: no", "color": "eb6420", "default": false}], "milestone": null, "commits_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23242/commits", "review_comments_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23242/comments", "review_comment_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments{/number}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23242/comments", "statuses_url": "https://api.github.com/repos/tensorflow/tensorflow/statuses/b9399df9bdf1c61b814bb0fb279a3dca0f9d8043", "head": {"label": "Dido0o0:mixed_precision", "ref": "mixed_precision", "sha": "b9399df9bdf1c61b814bb0fb279a3dca0f9d8043", "user": {"login": "Dido0o0", "id": 16295526, "node_id": "MDQ6VXNlcjE2Mjk1NTI2", "avatar_url": "https://avatars2.githubusercontent.com/u/16295526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dido0o0", "html_url": "https://github.com/Dido0o0", "followers_url": "https://api.github.com/users/Dido0o0/followers", "following_url": "https://api.github.com/users/Dido0o0/following{/other_user}", "gists_url": "https://api.github.com/users/Dido0o0/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dido0o0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dido0o0/subscriptions", "organizations_url": "https://api.github.com/users/Dido0o0/orgs", "repos_url": "https://api.github.com/users/Dido0o0/repos", "events_url": "https://api.github.com/users/Dido0o0/events{/privacy}", "received_events_url": "https://api.github.com/users/Dido0o0/received_events", "type": "User", "site_admin": false}, "repo": {"id": 146548386, "node_id": "MDEwOlJlcG9zaXRvcnkxNDY1NDgzODY=", "name": "tensorflow", "full_name": "Dido0o0/tensorflow", "private": false, "owner": {"login": "Dido0o0", "id": 16295526, "node_id": "MDQ6VXNlcjE2Mjk1NTI2", "avatar_url": "https://avatars2.githubusercontent.com/u/16295526?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Dido0o0", "html_url": "https://github.com/Dido0o0", "followers_url": "https://api.github.com/users/Dido0o0/followers", "following_url": "https://api.github.com/users/Dido0o0/following{/other_user}", "gists_url": "https://api.github.com/users/Dido0o0/gists{/gist_id}", "starred_url": "https://api.github.com/users/Dido0o0/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Dido0o0/subscriptions", "organizations_url": "https://api.github.com/users/Dido0o0/orgs", "repos_url": "https://api.github.com/users/Dido0o0/repos", "events_url": "https://api.github.com/users/Dido0o0/events{/privacy}", "received_events_url": "https://api.github.com/users/Dido0o0/received_events", "type": "User", "site_admin": false}, "html_url": "https://github.com/Dido0o0/tensorflow", "description": "Computation using data flow graphs for scalable machine learning", "fork": true, "url": "https://api.github.com/repos/Dido0o0/tensorflow", "forks_url": "https://api.github.com/repos/Dido0o0/tensorflow/forks", "keys_url": "https://api.github.com/repos/Dido0o0/tensorflow/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/Dido0o0/tensorflow/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/Dido0o0/tensorflow/teams", "hooks_url": "https://api.github.com/repos/Dido0o0/tensorflow/hooks", "issue_events_url": "https://api.github.com/repos/Dido0o0/tensorflow/issues/events{/number}", "events_url": "https://api.github.com/repos/Dido0o0/tensorflow/events", "assignees_url": "https://api.github.com/repos/Dido0o0/tensorflow/assignees{/user}", "branches_url": "https://api.github.com/repos/Dido0o0/tensorflow/branches{/branch}", "tags_url": "https://api.github.com/repos/Dido0o0/tensorflow/tags", "blobs_url": "https://api.github.com/repos/Dido0o0/tensorflow/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/Dido0o0/tensorflow/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/Dido0o0/tensorflow/git/refs{/sha}", "trees_url": "https://api.github.com/repos/Dido0o0/tensorflow/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/Dido0o0/tensorflow/statuses/{sha}", "languages_url": "https://api.github.com/repos/Dido0o0/tensorflow/languages", "stargazers_url": "https://api.github.com/repos/Dido0o0/tensorflow/stargazers", "contributors_url": "https://api.github.com/repos/Dido0o0/tensorflow/contributors", "subscribers_url": "https://api.github.com/repos/Dido0o0/tensorflow/subscribers", "subscription_url": "https://api.github.com/repos/Dido0o0/tensorflow/subscription", "commits_url": "https://api.github.com/repos/Dido0o0/tensorflow/commits{/sha}", "git_commits_url": "https://api.github.com/repos/Dido0o0/tensorflow/git/commits{/sha}", "comments_url": "https://api.github.com/repos/Dido0o0/tensorflow/comments{/number}", "issue_comment_url": "https://api.github.com/repos/Dido0o0/tensorflow/issues/comments{/number}", "contents_url": "https://api.github.com/repos/Dido0o0/tensorflow/contents/{+path}", "compare_url": "https://api.github.com/repos/Dido0o0/tensorflow/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/Dido0o0/tensorflow/merges", "archive_url": "https://api.github.com/repos/Dido0o0/tensorflow/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/Dido0o0/tensorflow/downloads", "issues_url": "https://api.github.com/repos/Dido0o0/tensorflow/issues{/number}", "pulls_url": "https://api.github.com/repos/Dido0o0/tensorflow/pulls{/number}", "milestones_url": "https://api.github.com/repos/Dido0o0/tensorflow/milestones{/number}", "notifications_url": "https://api.github.com/repos/Dido0o0/tensorflow/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/Dido0o0/tensorflow/labels{/name}", "releases_url": "https://api.github.com/repos/Dido0o0/tensorflow/releases{/id}", "deployments_url": "https://api.github.com/repos/Dido0o0/tensorflow/deployments", "created_at": "2018-08-29T05:12:47Z", "updated_at": "2018-08-29T05:13:32Z", "pushed_at": "2018-10-25T12:09:37Z", "git_url": "git://github.com/Dido0o0/tensorflow.git", "ssh_url": "git@github.com:Dido0o0/tensorflow.git", "clone_url": "https://github.com/Dido0o0/tensorflow.git", "svn_url": "https://github.com/Dido0o0/tensorflow", "homepage": "https://tensorflow.org", "size": 270410, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "forks_count": 0, "mirror_url": null, "archived": false, "open_issues_count": 0, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master"}}, "base": {"label": "tensorflow:master", "ref": "master", "sha": "822337e2b3377b89dad3b88cb5c4df7b369aa521", "user": {"login": "tensorflow", "id": 15658638, "node_id": "MDEyOk9yZ2FuaXphdGlvbjE1NjU4NjM4", "avatar_url": "https://avatars1.githubusercontent.com/u/15658638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorflow", "html_url": "https://github.com/tensorflow", "followers_url": "https://api.github.com/users/tensorflow/followers", "following_url": "https://api.github.com/users/tensorflow/following{/other_user}", "gists_url": "https://api.github.com/users/tensorflow/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorflow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorflow/subscriptions", "organizations_url": "https://api.github.com/users/tensorflow/orgs", "repos_url": "https://api.github.com/users/tensorflow/repos", "events_url": "https://api.github.com/users/tensorflow/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorflow/received_events", "type": "Organization", "site_admin": false}, "repo": {"id": 45717250, "node_id": "MDEwOlJlcG9zaXRvcnk0NTcxNzI1MA==", "name": "tensorflow", "full_name": "tensorflow/tensorflow", "private": false, "owner": {"login": "tensorflow", "id": 15658638, "node_id": "MDEyOk9yZ2FuaXphdGlvbjE1NjU4NjM4", "avatar_url": "https://avatars1.githubusercontent.com/u/15658638?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tensorflow", "html_url": "https://github.com/tensorflow", "followers_url": "https://api.github.com/users/tensorflow/followers", "following_url": "https://api.github.com/users/tensorflow/following{/other_user}", "gists_url": "https://api.github.com/users/tensorflow/gists{/gist_id}", "starred_url": "https://api.github.com/users/tensorflow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tensorflow/subscriptions", "organizations_url": "https://api.github.com/users/tensorflow/orgs", "repos_url": "https://api.github.com/users/tensorflow/repos", "events_url": "https://api.github.com/users/tensorflow/events{/privacy}", "received_events_url": "https://api.github.com/users/tensorflow/received_events", "type": "Organization", "site_admin": false}, "html_url": "https://github.com/tensorflow/tensorflow", "description": "An Open Source Machine Learning Framework for Everyone", "fork": false, "url": "https://api.github.com/repos/tensorflow/tensorflow", "forks_url": "https://api.github.com/repos/tensorflow/tensorflow/forks", "keys_url": "https://api.github.com/repos/tensorflow/tensorflow/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/tensorflow/tensorflow/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/tensorflow/tensorflow/teams", "hooks_url": "https://api.github.com/repos/tensorflow/tensorflow/hooks", "issue_events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/events{/number}", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/events", "assignees_url": "https://api.github.com/repos/tensorflow/tensorflow/assignees{/user}", "branches_url": "https://api.github.com/repos/tensorflow/tensorflow/branches{/branch}", "tags_url": "https://api.github.com/repos/tensorflow/tensorflow/tags", "blobs_url": "https://api.github.com/repos/tensorflow/tensorflow/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/tensorflow/tensorflow/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/tensorflow/tensorflow/git/refs{/sha}", "trees_url": "https://api.github.com/repos/tensorflow/tensorflow/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/tensorflow/tensorflow/statuses/{sha}", "languages_url": "https://api.github.com/repos/tensorflow/tensorflow/languages", "stargazers_url": "https://api.github.com/repos/tensorflow/tensorflow/stargazers", "contributors_url": "https://api.github.com/repos/tensorflow/tensorflow/contributors", "subscribers_url": "https://api.github.com/repos/tensorflow/tensorflow/subscribers", "subscription_url": "https://api.github.com/repos/tensorflow/tensorflow/subscription", "commits_url": "https://api.github.com/repos/tensorflow/tensorflow/commits{/sha}", "git_commits_url": "https://api.github.com/repos/tensorflow/tensorflow/git/commits{/sha}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/comments{/number}", "issue_comment_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments{/number}", "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/{+path}", "compare_url": "https://api.github.com/repos/tensorflow/tensorflow/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/tensorflow/tensorflow/merges", "archive_url": "https://api.github.com/repos/tensorflow/tensorflow/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/tensorflow/tensorflow/downloads", "issues_url": "https://api.github.com/repos/tensorflow/tensorflow/issues{/number}", "pulls_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls{/number}", "milestones_url": "https://api.github.com/repos/tensorflow/tensorflow/milestones{/number}", "notifications_url": "https://api.github.com/repos/tensorflow/tensorflow/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/labels{/name}", "releases_url": "https://api.github.com/repos/tensorflow/tensorflow/releases{/id}", "deployments_url": "https://api.github.com/repos/tensorflow/tensorflow/deployments", "created_at": "2015-11-07T01:19:20Z", "updated_at": "2018-11-24T19:34:08Z", "pushed_at": "2018-11-24T18:40:19Z", "git_url": "git://github.com/tensorflow/tensorflow.git", "ssh_url": "git@github.com:tensorflow/tensorflow.git", "clone_url": "https://github.com/tensorflow/tensorflow.git", "svn_url": "https://github.com/tensorflow/tensorflow", "homepage": "https://tensorflow.org", "size": 284546, "stargazers_count": 115176, "watchers_count": 115176, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "forks_count": 69944, "mirror_url": null, "archived": false, "open_issues_count": 1759, "license": {"key": "apache-2.0", "name": "Apache License 2.0", "spdx_id": "Apache-2.0", "url": "https://api.github.com/licenses/apache-2.0", "node_id": "MDc6TGljZW5zZTI="}, "forks": 69944, "open_issues": 1759, "watchers": 115176, "default_branch": "master"}}, "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23242"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/23242"}, "issue": {"href": "https://api.github.com/repos/tensorflow/tensorflow/issues/23242"}, "comments": {"href": "https://api.github.com/repos/tensorflow/tensorflow/issues/23242/comments"}, "review_comments": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23242/comments"}, "review_comment": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments{/number}"}, "commits": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/23242/commits"}, "statuses": {"href": "https://api.github.com/repos/tensorflow/tensorflow/statuses/b9399df9bdf1c61b814bb0fb279a3dca0f9d8043"}}, "author_association": "NONE", "body_html": "<p>This feature realize the automatic/constant loss scaling algorithm in Backprop, which can help preserve small gradient magnitudes ( ref to  <a href=\"https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\" rel=\"nofollow\">https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html</a>)<br>\nMixed precision with loss scaling is already support by tf.contrib.mixed_precision.LossScaleOptimizer,  with the following usage:</p>\n<div class=\"highlight highlight-source-python\"><pre>loss <span class=\"pl-k\">=</span> loss_fn()\nopt <span class=\"pl-k\">=</span> tf.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">...</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Choose a loss scale manager which decides how to pick the right loss scale</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> throughout the training process.</span>\nloss_scale_manger <span class=\"pl-k\">=</span> tf.contrib.mixed_precision.FixedLossScaleManager(<span class=\"pl-c1\">5000</span>)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Wraps the original optimizer in a LossScaleOptimizer.</span>\nloss_scale_optimizer <span class=\"pl-k\">=</span> LossScaleOptimizer(opt, loss_scale_manager)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Call minimize() on the loss scale optimizer.</span>\ntrain_op <span class=\"pl-k\">=</span> loss_scale_optimizer.minimize(loss)</pre></div>\n<p>The optimizer <code>LossScaleOptimizer</code> is actually a wrapper of other optimizers.  However, the usage using wrapper is too limited to support all cases.  For example,<br>\n+ if the users  are using <code>tf.gradients()</code> to compute the gradients rather than <code>optimizer.compute_gradients()</code>/<code>optimizer.minimize()</code>,  the wrapper is no longer in user.<br>\n+ the <code>LossScaleOptimizer</code> wrapper may have compatibility problem with other optimizer wrappers, e.g. <code>SyncReplicasOptimizer</code><br>\n+ the current implementation in <code>LossScaleOptimizer</code> did not take the colocation parameter into consideration.</p>\n<p>Instead, we implement loss scaling using a decorator on <code>gradients()</code>, which is the atom function to compute the backprop gradients. The usage is as following:</p>\n<div class=\"highlight highlight-source-python\"><pre>loss <span class=\"pl-k\">=</span> loss_fn()\nopt <span class=\"pl-k\">=</span> tf.AdamOptimizer(<span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">...</span>)\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> constant loss scaling with loss_scale=64</span>\n<span class=\"pl-k\">with</span> tf.mixed_precision_scope(<span class=\"pl-v\">automatic_loss_scaling</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>, <span class=\"pl-v\">loss_scale</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">64</span>):\n      grad <span class=\"pl-k\">=</span> tf.gradients()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> if using tf.gradients</span>\n      var_and_grad <span class=\"pl-k\">=</span>opt.minimize(loss) <span class=\"pl-c\"><span class=\"pl-c\">#</span> if using optimizer</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> automatic loss scaling</span>\n<span class=\"pl-k\">with</span> tf.mixed_precision_scope(<span class=\"pl-v\">automatic_loss_scaling</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">True</span>):\n      grad <span class=\"pl-k\">=</span> tf.gradients()  <span class=\"pl-c\"><span class=\"pl-c\">#</span> if using tf.gradients</span>\n      var_and_grad <span class=\"pl-k\">=</span>opt.minimize(loss) <span class=\"pl-c\"><span class=\"pl-c\">#</span> if using optimizer</span></pre></div>\n<p>The implementation can handle all of the above problems encounter by <code>LossScaleOptimizer</code> .</p>", "body_text": "This feature realize the automatic/constant loss scaling algorithm in Backprop, which can help preserve small gradient magnitudes ( ref to  https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html)\nMixed precision with loss scaling is already support by tf.contrib.mixed_precision.LossScaleOptimizer,  with the following usage:\nloss = loss_fn()\nopt = tf.AdamOptimizer(learning_rate=...)\n\n# Choose a loss scale manager which decides how to pick the right loss scale\n# throughout the training process.\nloss_scale_manger = tf.contrib.mixed_precision.FixedLossScaleManager(5000)\n\n# Wraps the original optimizer in a LossScaleOptimizer.\nloss_scale_optimizer = LossScaleOptimizer(opt, loss_scale_manager)\n\n# Call minimize() on the loss scale optimizer.\ntrain_op = loss_scale_optimizer.minimize(loss)\nThe optimizer LossScaleOptimizer is actually a wrapper of other optimizers.  However, the usage using wrapper is too limited to support all cases.  For example,\n+ if the users  are using tf.gradients() to compute the gradients rather than optimizer.compute_gradients()/optimizer.minimize(),  the wrapper is no longer in user.\n+ the LossScaleOptimizer wrapper may have compatibility problem with other optimizer wrappers, e.g. SyncReplicasOptimizer\n+ the current implementation in LossScaleOptimizer did not take the colocation parameter into consideration.\nInstead, we implement loss scaling using a decorator on gradients(), which is the atom function to compute the backprop gradients. The usage is as following:\nloss = loss_fn()\nopt = tf.AdamOptimizer(learning_rate=...)\n# constant loss scaling with loss_scale=64\nwith tf.mixed_precision_scope(automatic_loss_scaling=False, loss_scale=64):\n      grad = tf.gradients()  # if using tf.gradients\n      var_and_grad =opt.minimize(loss) # if using optimizer\n\n# automatic loss scaling\nwith tf.mixed_precision_scope(automatic_loss_scaling=True):\n      grad = tf.gradients()  # if using tf.gradients\n      var_and_grad =opt.minimize(loss) # if using optimizer\nThe implementation can handle all of the above problems encounter by LossScaleOptimizer .", "merged": false, "mergeable": null, "rebaseable": null, "mergeable_state": "unknown", "merged_by": null, "comments": 1, "review_comments": 0, "maintainer_can_modify": false, "commits": 1, "additions": 1678, "deletions": 0, "changed_files": 4}