{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/421694071", "html_url": "https://github.com/tensorflow/tensorflow/issues/22012#issuecomment-421694071", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/22012", "id": 421694071, "node_id": "MDEyOklzc3VlQ29tbWVudDQyMTY5NDA3MQ==", "user": {"login": "yanboliang", "id": 1962026, "node_id": "MDQ6VXNlcjE5NjIwMjY=", "avatar_url": "https://avatars1.githubusercontent.com/u/1962026?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yanboliang", "html_url": "https://github.com/yanboliang", "followers_url": "https://api.github.com/users/yanboliang/followers", "following_url": "https://api.github.com/users/yanboliang/following{/other_user}", "gists_url": "https://api.github.com/users/yanboliang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yanboliang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yanboliang/subscriptions", "organizations_url": "https://api.github.com/users/yanboliang/orgs", "repos_url": "https://api.github.com/users/yanboliang/repos", "events_url": "https://api.github.com/users/yanboliang/events{/privacy}", "received_events_url": "https://api.github.com/users/yanboliang/received_events", "type": "User", "site_admin": false}, "created_at": "2018-09-16T04:52:53Z", "updated_at": "2018-09-16T04:57:04Z", "author_association": "CONTRIBUTOR", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=7067992\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/naoto0804\">@naoto0804</a><br>\nKeras model training will update params in <code>model._collected_trainable_weights</code> which is produced at <code>model.compile</code>.<br>\nWhen you call <code>dis_model.trainable = False</code> to freeze <code>dis_model</code>, you don't compile <code>dis_model</code>, so two things happens:</p>\n<ul>\n<li><code>dis_model._collected_trainable_weights</code> still includes old trainable params.</li>\n<li><code>dis_model.trainable_weights</code> will return null, as you set all params non-trainable.</li>\n</ul>\n<p>When you call <code>dis_model.train_on_batch</code>, the params in <code>dis_model._collected_trainable_weights</code> will be updated according gradient descent, so it meets your requirements. But Keras found <code>dis_model._collected_trainable_weights</code> and <code>dis_model.trainable_weights</code> are inconsistent, so print warning in case this is not by design.</p>\n<p>When you call <code>combined_model.compile</code>, <code>combined_model._collected_trainable_weights</code> will be generated, and it doesn't includes the params in <code>dis_model</code> as they are marked as non-trainable.</p>\n<p>To sum up, this warning is to prevent misuse. In your case, you code makes sense. I think we just need to reduce log frequency in <code>tf.keras</code> to once only, to prevent it floods the screen. I sent <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"360600507\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/22296\" data-hovercard-type=\"pull_request\" data-hovercard-url=\"/tensorflow/tensorflow/pull/22296/hovercard\" href=\"https://github.com/tensorflow/tensorflow/pull/22296\">#22296</a> to fix it. Thanks.</p>", "body_text": "@naoto0804\nKeras model training will update params in model._collected_trainable_weights which is produced at model.compile.\nWhen you call dis_model.trainable = False to freeze dis_model, you don't compile dis_model, so two things happens:\n\ndis_model._collected_trainable_weights still includes old trainable params.\ndis_model.trainable_weights will return null, as you set all params non-trainable.\n\nWhen you call dis_model.train_on_batch, the params in dis_model._collected_trainable_weights will be updated according gradient descent, so it meets your requirements. But Keras found dis_model._collected_trainable_weights and dis_model.trainable_weights are inconsistent, so print warning in case this is not by design.\nWhen you call combined_model.compile, combined_model._collected_trainable_weights will be generated, and it doesn't includes the params in dis_model as they are marked as non-trainable.\nTo sum up, this warning is to prevent misuse. In your case, you code makes sense. I think we just need to reduce log frequency in tf.keras to once only, to prevent it floods the screen. I sent #22296 to fix it. Thanks.", "body": "@naoto0804 \r\nKeras model training will update params in ```model._collected_trainable_weights``` which is produced at ```model.compile```.\r\nWhen you call ```dis_model.trainable = False``` to freeze ```dis_model```, you don't compile ```dis_model```, so two things happens:\r\n* ```dis_model._collected_trainable_weights``` still includes old trainable params.\r\n* ```dis_model.trainable_weights``` will return null, as you set all params non-trainable.\r\n\r\nWhen you call ```dis_model.train_on_batch```, the params in ```dis_model._collected_trainable_weights``` will be updated according gradient descent, so it meets your requirements. But Keras found ```dis_model._collected_trainable_weights``` and ```dis_model.trainable_weights``` are inconsistent, so print warning in case this is not by design.\r\n\r\nWhen you call ```combined_model.compile```, ```combined_model._collected_trainable_weights``` will be generated, and it doesn't includes the params in ```dis_model``` as they are marked as non-trainable.\r\n\r\nTo sum up, this warning is to prevent misuse. In your case, you code makes sense. I think we just need to reduce log frequency in ```tf.keras``` to once only, to prevent it floods the screen. I sent #22296 to fix it. Thanks. "}