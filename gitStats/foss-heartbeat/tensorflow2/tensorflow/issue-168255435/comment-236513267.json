{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/236513267", "html_url": "https://github.com/tensorflow/tensorflow/issues/3560#issuecomment-236513267", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3560", "id": 236513267, "node_id": "MDEyOklzc3VlQ29tbWVudDIzNjUxMzI2Nw==", "user": {"login": "HadronCloud", "id": 13091475, "node_id": "MDEyOk9yZ2FuaXphdGlvbjEzMDkxNDc1", "avatar_url": "https://avatars0.githubusercontent.com/u/13091475?v=4", "gravatar_id": "", "url": "https://api.github.com/users/HadronCloud", "html_url": "https://github.com/HadronCloud", "followers_url": "https://api.github.com/users/HadronCloud/followers", "following_url": "https://api.github.com/users/HadronCloud/following{/other_user}", "gists_url": "https://api.github.com/users/HadronCloud/gists{/gist_id}", "starred_url": "https://api.github.com/users/HadronCloud/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/HadronCloud/subscriptions", "organizations_url": "https://api.github.com/users/HadronCloud/orgs", "repos_url": "https://api.github.com/users/HadronCloud/repos", "events_url": "https://api.github.com/users/HadronCloud/events{/privacy}", "received_events_url": "https://api.github.com/users/HadronCloud/received_events", "type": "Organization", "site_admin": false}, "created_at": "2016-08-01T07:55:59Z", "updated_at": "2016-08-01T07:55:59Z", "author_association": "NONE", "body_html": "<p>thanks <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=5376757\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/michaelisard\">@michaelisard</a>, upgrading to CUDA 8.0 Release Candidate and cuDNN 5 and building from source again with GPUs enabled has resolved this issue!</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=2800641\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/JohnAllen\">@JohnAllen</a>, thanks for your information, as well.  We've found that running the retrainer when built for GPUs takes about 0.1 seconds per image bottleneck; previously, on a 36-core machine, it would take around 3 seconds per bottleneck with all cores maxed out.  If your setup is still taking 3 seconds per image bottleneck, I'm happy to help debug your setup with you as it really should be 20-30x faster on the GTX 1080.  You might simply need to rebuild the trainer with CUDA enabled.</p>\n<p>The retrainer / transfer learning example does not seem to support multiple GPUs, unfortunately, even with the --num_gpus flag.  I can open up another issue for that if that's not by design nor a known issue.  Thanks again, you have literally saved us weeks of processing time.</p>", "body_text": "thanks @michaelisard, upgrading to CUDA 8.0 Release Candidate and cuDNN 5 and building from source again with GPUs enabled has resolved this issue!\n@JohnAllen, thanks for your information, as well.  We've found that running the retrainer when built for GPUs takes about 0.1 seconds per image bottleneck; previously, on a 36-core machine, it would take around 3 seconds per bottleneck with all cores maxed out.  If your setup is still taking 3 seconds per image bottleneck, I'm happy to help debug your setup with you as it really should be 20-30x faster on the GTX 1080.  You might simply need to rebuild the trainer with CUDA enabled.\nThe retrainer / transfer learning example does not seem to support multiple GPUs, unfortunately, even with the --num_gpus flag.  I can open up another issue for that if that's not by design nor a known issue.  Thanks again, you have literally saved us weeks of processing time.", "body": "thanks @michaelisard, upgrading to CUDA 8.0 Release Candidate and cuDNN 5 and building from source again with GPUs enabled has resolved this issue!\n\n@JohnAllen, thanks for your information, as well.  We've found that running the retrainer when built for GPUs takes about 0.1 seconds per image bottleneck; previously, on a 36-core machine, it would take around 3 seconds per bottleneck with all cores maxed out.  If your setup is still taking 3 seconds per image bottleneck, I'm happy to help debug your setup with you as it really should be 20-30x faster on the GTX 1080.  You might simply need to rebuild the trainer with CUDA enabled.\n\nThe retrainer / transfer learning example does not seem to support multiple GPUs, unfortunately, even with the --num_gpus flag.  I can open up another issue for that if that's not by design nor a known issue.  Thanks again, you have literally saved us weeks of processing time.\n"}