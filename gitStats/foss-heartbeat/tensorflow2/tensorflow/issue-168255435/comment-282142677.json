{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/282142677", "html_url": "https://github.com/tensorflow/tensorflow/issues/3560#issuecomment-282142677", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3560", "id": 282142677, "node_id": "MDEyOklzc3VlQ29tbWVudDI4MjE0MjY3Nw==", "user": {"login": "Adithya2015", "id": 16039994, "node_id": "MDQ6VXNlcjE2MDM5OTk0", "avatar_url": "https://avatars1.githubusercontent.com/u/16039994?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Adithya2015", "html_url": "https://github.com/Adithya2015", "followers_url": "https://api.github.com/users/Adithya2015/followers", "following_url": "https://api.github.com/users/Adithya2015/following{/other_user}", "gists_url": "https://api.github.com/users/Adithya2015/gists{/gist_id}", "starred_url": "https://api.github.com/users/Adithya2015/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Adithya2015/subscriptions", "organizations_url": "https://api.github.com/users/Adithya2015/orgs", "repos_url": "https://api.github.com/users/Adithya2015/repos", "events_url": "https://api.github.com/users/Adithya2015/events{/privacy}", "received_events_url": "https://api.github.com/users/Adithya2015/received_events", "type": "User", "site_admin": false}, "created_at": "2017-02-23T22:29:11Z", "updated_at": "2017-02-23T22:30:33Z", "author_association": "NONE", "body_html": "<p>Hello everyone. I'm having some issue regarding running the bottlenecks on GPU. Currently, it takes about 1s per bottleneck and when I check the GPU utilizaiton with nvidia-smi it appears that it is fluctuating between 0-20%.</p>\n<p>Also, I noticed that this gets printed to my screen everytime sess.run() is called<br>\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)<br>\nMaybe this is the cause of overhead? I also tried to check the device placement logs and here are the first few lines from the log file</p>\n<p>Device mapping:<br>\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GRID K520, pci bus id: 0000:00:03.0<br>\nCreating bottleneck at ./newmodel/bottleneck/baby_in_crib/1_136.jpg.txt<br>\nDecodeJpeg_1: (DecodeJpeg): /job:localhost/replica:0/task:0/cpu:0<br>\nShape: (Shape): /job:localhost/replica:0/task:0/cpu:0<br>\nDecodeJpeg: (DecodeJpeg): /job:localhost/replica:0/task:0/cpu:0<br>\nCast: (Cast): /job:localhost/replica:0/task:0/gpu:0<br>\nExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0<br>\nResizeBilinear: (ResizeBilinear): /job:localhost/replica:0/task:0/gpu:0<br>\nSub: (Sub): /job:localhost/replica:0/task:0/gpu:0<br>\nMul: (Mul): /job:localhost/replica:0/task:0/gpu:0<br>\nconv/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0<br>\nconv/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0<br>\nconv/CheckNumerics: (CheckNumerics): /job:localhost/replica:0/task:0/gpu:0<br>\nconv/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0<br>\nconv: (Relu): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_1/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_1/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_1/CheckNumerics: (CheckNumerics): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_1: (Relu): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_2/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0<br>\nconv_2/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0<br>\n...</p>\n<p>As I understand, the operations in the first few layers are being run in the cpu and the rest on gpu. IS the data transfer between cpu and gpu the cause for the slow execution? <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=39175213\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/theclifbar\">@theclifbar</a> did you have any such issues while running your model?<br>\nThis is my first post here and please let me know if I have to open another discussion for this. Any help is much appreciated. Thanks!</p>", "body_text": "Hello everyone. I'm having some issue regarding running the bottlenecks on GPU. Currently, it takes about 1s per bottleneck and when I check the GPU utilizaiton with nvidia-smi it appears that it is fluctuating between 0-20%.\nAlso, I noticed that this gets printed to my screen everytime sess.run() is called\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nMaybe this is the cause of overhead? I also tried to check the device placement logs and here are the first few lines from the log file\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0\nCreating bottleneck at ./newmodel/bottleneck/baby_in_crib/1_136.jpg.txt\nDecodeJpeg_1: (DecodeJpeg): /job:localhost/replica:0/task:0/cpu:0\nShape: (Shape): /job:localhost/replica:0/task:0/cpu:0\nDecodeJpeg: (DecodeJpeg): /job:localhost/replica:0/task:0/cpu:0\nCast: (Cast): /job:localhost/replica:0/task:0/gpu:0\nExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0\nResizeBilinear: (ResizeBilinear): /job:localhost/replica:0/task:0/gpu:0\nSub: (Sub): /job:localhost/replica:0/task:0/gpu:0\nMul: (Mul): /job:localhost/replica:0/task:0/gpu:0\nconv/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\nconv/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0\nconv/CheckNumerics: (CheckNumerics): /job:localhost/replica:0/task:0/gpu:0\nconv/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\nconv: (Relu): /job:localhost/replica:0/task:0/gpu:0\nconv_1/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\nconv_1/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0\nconv_1/CheckNumerics: (CheckNumerics): /job:localhost/replica:0/task:0/gpu:0\nconv_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\nconv_1: (Relu): /job:localhost/replica:0/task:0/gpu:0\nconv_2/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\nconv_2/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0\n...\nAs I understand, the operations in the first few layers are being run in the cpu and the rest on gpu. IS the data transfer between cpu and gpu the cause for the slow execution? @theclifbar did you have any such issues while running your model?\nThis is my first post here and please let me know if I have to open another discussion for this. Any help is much appreciated. Thanks!", "body": "Hello everyone. I'm having some issue regarding running the bottlenecks on GPU. Currently, it takes about 1s per bottleneck and when I check the GPU utilizaiton with nvidia-smi it appears that it is fluctuating between 0-20%.\r\n\r\nAlso, I noticed that this gets printed to my screen everytime sess.run() is called\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\r\nMaybe this is the cause of overhead? I also tried to check the device placement logs and here are the first few lines from the log file\r\n\r\n\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0\r\nCreating bottleneck at ./newmodel/bottleneck/baby_in_crib/1_136.jpg.txt\r\nDecodeJpeg_1: (DecodeJpeg): /job:localhost/replica:0/task:0/cpu:0\r\nShape: (Shape): /job:localhost/replica:0/task:0/cpu:0\r\nDecodeJpeg: (DecodeJpeg): /job:localhost/replica:0/task:0/cpu:0\r\nCast: (Cast): /job:localhost/replica:0/task:0/gpu:0\r\nExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0\r\nResizeBilinear: (ResizeBilinear): /job:localhost/replica:0/task:0/gpu:0\r\nSub: (Sub): /job:localhost/replica:0/task:0/gpu:0\r\nMul: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\nconv/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\r\nconv/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0\r\nconv/CheckNumerics: (CheckNumerics): /job:localhost/replica:0/task:0/gpu:0\r\nconv/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\nconv: (Relu): /job:localhost/replica:0/task:0/gpu:0\r\nconv_1/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\r\nconv_1/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0\r\nconv_1/CheckNumerics: (CheckNumerics): /job:localhost/replica:0/task:0/gpu:0\r\nconv_1/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\nconv_1: (Relu): /job:localhost/replica:0/task:0/gpu:0\r\nconv_2/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\r\nconv_2/batchnorm: (BatchNormWithGlobalNormalization): /job:localhost/replica:0/task:0/gpu:0\r\n...\r\n\r\n\r\nAs I understand, the operations in the first few layers are being run in the cpu and the rest on gpu. IS the data transfer between cpu and gpu the cause for the slow execution? @theclifbar did you have any such issues while running your model? \r\nThis is my first post here and please let me know if I have to open another discussion for this. Any help is much appreciated. Thanks!\r\n\r\n"}