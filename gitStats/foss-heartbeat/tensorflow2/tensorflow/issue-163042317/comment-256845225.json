{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/256845225", "html_url": "https://github.com/tensorflow/tensorflow/issues/3114#issuecomment-256845225", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3114", "id": 256845225, "node_id": "MDEyOklzc3VlQ29tbWVudDI1Njg0NTIyNQ==", "user": {"login": "jungle-cat", "id": 1538764, "node_id": "MDQ6VXNlcjE1Mzg3NjQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/1538764?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jungle-cat", "html_url": "https://github.com/jungle-cat", "followers_url": "https://api.github.com/users/jungle-cat/followers", "following_url": "https://api.github.com/users/jungle-cat/following{/other_user}", "gists_url": "https://api.github.com/users/jungle-cat/gists{/gist_id}", "starred_url": "https://api.github.com/users/jungle-cat/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jungle-cat/subscriptions", "organizations_url": "https://api.github.com/users/jungle-cat/orgs", "repos_url": "https://api.github.com/users/jungle-cat/repos", "events_url": "https://api.github.com/users/jungle-cat/events{/privacy}", "received_events_url": "https://api.github.com/users/jungle-cat/received_events", "type": "User", "site_admin": false}, "created_at": "2016-10-28T06:20:07Z", "updated_at": "2016-10-28T06:20:07Z", "author_association": "NONE", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=710255\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/fchollet\">@fchollet</a> I also get the same error when using dynamic_rnn, have you ever solved this problem?</p>\n<p>Here's my snippet</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> numpy <span class=\"pl-k\">as</span> np\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tflearn\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">retrieve_sequence_length</span>(<span class=\"pl-smi\">data</span>):\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>sequence_length<span class=\"pl-pds\">'</span></span>):\n        used <span class=\"pl-k\">=</span> tf.sign(tf.abs(data))\n        length <span class=\"pl-k\">=</span> tf.cast(tf.reduce_sum(used, <span class=\"pl-v\">reduction_indices</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">2</span>]), tf.int32)\n    <span class=\"pl-k\">return</span> length \n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">loss</span>(<span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>, <span class=\"pl-smi\">sequence_length</span>):\n    <span class=\"pl-k\">with</span> tf.name_scope(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>loss<span class=\"pl-pds\">'</span></span>):\n        n_states <span class=\"pl-k\">=</span> x.get_shape()[<span class=\"pl-k\">-</span><span class=\"pl-c1\">1</span>].value\n        transition_params <span class=\"pl-k\">=</span> tflearn.variable(<span class=\"pl-v\">name</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>transition_params<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[n_states, n_states], \n                                             <span class=\"pl-v\">initializer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>xavier<span class=\"pl-pds\">'</span></span>, <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\n        loss <span class=\"pl-k\">=</span> tf.contrib.crf.crf_log_norm(x, sequence_length, transition_params)\n        <span class=\"pl-c\"><span class=\"pl-c\">#</span> loss, _ = tf.contrib.crf.crf_log_likelihood(x, y, sequence_length, transition_params)</span>\n    <span class=\"pl-k\">return</span> tf.reduce_mean(loss)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Data settings.</span>\nnum_examples <span class=\"pl-k\">=</span> <span class=\"pl-c1\">10000</span>\nnum_words <span class=\"pl-k\">=</span> <span class=\"pl-c1\">20</span>\nnum_features <span class=\"pl-k\">=</span> <span class=\"pl-c1\">100</span>\nnum_tags <span class=\"pl-k\">=</span> <span class=\"pl-c1\">5</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Random features.</span>\nx <span class=\"pl-k\">=</span> np.random.uniform(<span class=\"pl-v\">low</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.1</span>, <span class=\"pl-v\">high</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">1.1</span>, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>(num_examples, num_words, num_features)).astype(np.float32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> Random tag indices representing the gold sequence.</span>\ny <span class=\"pl-k\">=</span> np.random.randint(num_tags, <span class=\"pl-v\">size</span><span class=\"pl-k\">=</span>[num_examples, num_words]).astype(np.int32)\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> All sequences in this example have the same length, but they can be variable in a real model.</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)</span>\n\n\ninput0 <span class=\"pl-k\">=</span> tflearn.input_data(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, num_words, num_features], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.float32)\nsequence_length <span class=\"pl-k\">=</span> retrieve_sequence_length(input0)\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>sequence_length: <span class=\"pl-pds\">'</span></span>, sequence_length\n\nunary_scores <span class=\"pl-k\">=</span> tflearn.time_distributed(input0, tflearn.fully_connected, [num_tags, <span class=\"pl-s\"><span class=\"pl-pds\">'</span>softmax<span class=\"pl-pds\">'</span></span>])\n<span class=\"pl-c1\">print</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>unary_score: <span class=\"pl-pds\">'</span></span>, unary_scores\n\nnet <span class=\"pl-k\">=</span> tflearn.regression(unary_scores,\n                         <span class=\"pl-v\">placeholder</span><span class=\"pl-k\">=</span>tf.placeholder(<span class=\"pl-v\">shape</span><span class=\"pl-k\">=</span>[<span class=\"pl-c1\">None</span>, num_words], <span class=\"pl-v\">dtype</span><span class=\"pl-k\">=</span>tf.int32),\n                         <span class=\"pl-v\">learning_rate</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">0.001</span>,\n                         <span class=\"pl-v\">optimizer</span><span class=\"pl-k\">=</span><span class=\"pl-s\"><span class=\"pl-pds\">'</span>sgd<span class=\"pl-pds\">'</span></span>,\n                         <span class=\"pl-v\">loss</span><span class=\"pl-k\">=</span><span class=\"pl-k\">lambda</span> <span class=\"pl-smi\">x</span>, <span class=\"pl-smi\">y</span>: loss(x, y, sequence_length),\n                         <span class=\"pl-v\">metric</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">None</span>,\n                         <span class=\"pl-v\">n_classes</span><span class=\"pl-k\">=</span>num_tags,\n                         <span class=\"pl-v\">to_one_hot</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">False</span>)\n\nmodel <span class=\"pl-k\">=</span> tflearn.DNN(net)\n\nmodel.fit(x, y, <span class=\"pl-v\">batch_size</span><span class=\"pl-k\">=</span><span class=\"pl-c1\">32</span>)</pre></div>\n<p>the stacktrace of the error:</p>\n<pre><code>--\nTraceback (most recent call last):\n  File \"c.py\", line 54, in &lt;module&gt;\n    model.fit(x, y, batch_size=32)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/models/dnn.py\", line 214, in fit\n    callbacks=callbacks)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 304, in fit\n    show_metric)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 762, in _train\n    feed_batch)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: All inputs to node SGD/gradients/loss/RNN/while/expand_dims_state_grad/Reshape/StackPush must be from the same frame.\n</code></pre>", "body_text": "@fchollet I also get the same error when using dynamic_rnn, have you ever solved this problem?\nHere's my snippet\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\ndef retrieve_sequence_length(data):\n    with tf.name_scope('sequence_length'):\n        used = tf.sign(tf.abs(data))\n        length = tf.cast(tf.reduce_sum(used, reduction_indices=[1, 2]), tf.int32)\n    return length \n\ndef loss(x, y, sequence_length):\n    with tf.name_scope('loss'):\n        n_states = x.get_shape()[-1].value\n        transition_params = tflearn.variable(name='transition_params', shape=[n_states, n_states], \n                                             initializer='xavier', dtype=tf.float32)\n        loss = tf.contrib.crf.crf_log_norm(x, sequence_length, transition_params)\n        # loss, _ = tf.contrib.crf.crf_log_likelihood(x, y, sequence_length, transition_params)\n    return tf.reduce_mean(loss)\n\n# Data settings.\nnum_examples = 10000\nnum_words = 20\nnum_features = 100\nnum_tags = 5\n\n# Random features.\nx = np.random.uniform(low=0.1, high=1.1, size=(num_examples, num_words, num_features)).astype(np.float32)\n\n# Random tag indices representing the gold sequence.\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\n\n# All sequences in this example have the same length, but they can be variable in a real model.\n# sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\n\n\ninput0 = tflearn.input_data(shape=[None, num_words, num_features], dtype=tf.float32)\nsequence_length = retrieve_sequence_length(input0)\nprint 'sequence_length: ', sequence_length\n\nunary_scores = tflearn.time_distributed(input0, tflearn.fully_connected, [num_tags, 'softmax'])\nprint 'unary_score: ', unary_scores\n\nnet = tflearn.regression(unary_scores,\n                         placeholder=tf.placeholder(shape=[None, num_words], dtype=tf.int32),\n                         learning_rate=0.001,\n                         optimizer='sgd',\n                         loss=lambda x, y: loss(x, y, sequence_length),\n                         metric=None,\n                         n_classes=num_tags,\n                         to_one_hot=False)\n\nmodel = tflearn.DNN(net)\n\nmodel.fit(x, y, batch_size=32)\nthe stacktrace of the error:\n--\nTraceback (most recent call last):\n  File \"c.py\", line 54, in <module>\n    model.fit(x, y, batch_size=32)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/models/dnn.py\", line 214, in fit\n    callbacks=callbacks)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 304, in fit\n    show_metric)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 762, in _train\n    feed_batch)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: All inputs to node SGD/gradients/loss/RNN/while/expand_dims_state_grad/Reshape/StackPush must be from the same frame.", "body": "@fchollet I also get the same error when using dynamic_rnn, have you ever solved this problem?\n\nHere's my snippet\n\n``` python\nimport numpy as np\nimport tensorflow as tf\nimport tflearn\n\ndef retrieve_sequence_length(data):\n    with tf.name_scope('sequence_length'):\n        used = tf.sign(tf.abs(data))\n        length = tf.cast(tf.reduce_sum(used, reduction_indices=[1, 2]), tf.int32)\n    return length \n\ndef loss(x, y, sequence_length):\n    with tf.name_scope('loss'):\n        n_states = x.get_shape()[-1].value\n        transition_params = tflearn.variable(name='transition_params', shape=[n_states, n_states], \n                                             initializer='xavier', dtype=tf.float32)\n        loss = tf.contrib.crf.crf_log_norm(x, sequence_length, transition_params)\n        # loss, _ = tf.contrib.crf.crf_log_likelihood(x, y, sequence_length, transition_params)\n    return tf.reduce_mean(loss)\n\n# Data settings.\nnum_examples = 10000\nnum_words = 20\nnum_features = 100\nnum_tags = 5\n\n# Random features.\nx = np.random.uniform(low=0.1, high=1.1, size=(num_examples, num_words, num_features)).astype(np.float32)\n\n# Random tag indices representing the gold sequence.\ny = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\n\n# All sequences in this example have the same length, but they can be variable in a real model.\n# sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\n\n\ninput0 = tflearn.input_data(shape=[None, num_words, num_features], dtype=tf.float32)\nsequence_length = retrieve_sequence_length(input0)\nprint 'sequence_length: ', sequence_length\n\nunary_scores = tflearn.time_distributed(input0, tflearn.fully_connected, [num_tags, 'softmax'])\nprint 'unary_score: ', unary_scores\n\nnet = tflearn.regression(unary_scores,\n                         placeholder=tf.placeholder(shape=[None, num_words], dtype=tf.int32),\n                         learning_rate=0.001,\n                         optimizer='sgd',\n                         loss=lambda x, y: loss(x, y, sequence_length),\n                         metric=None,\n                         n_classes=num_tags,\n                         to_one_hot=False)\n\nmodel = tflearn.DNN(net)\n\nmodel.fit(x, y, batch_size=32)\n```\n\nthe stacktrace of the error:\n\n```\n--\nTraceback (most recent call last):\n  File \"c.py\", line 54, in <module>\n    model.fit(x, y, batch_size=32)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/models/dnn.py\", line 214, in fit\n    callbacks=callbacks)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 304, in fit\n    show_metric)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tflearn/helpers/trainer.py\", line 762, in _train\n    feed_batch)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/weiguo.fwg/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: All inputs to node SGD/gradients/loss/RNN/while/expand_dims_state_grad/Reshape/StackPush must be from the same frame.\n```\n"}