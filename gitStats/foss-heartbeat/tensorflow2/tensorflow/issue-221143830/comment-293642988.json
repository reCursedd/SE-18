{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/293642988", "html_url": "https://github.com/tensorflow/tensorflow/issues/9154#issuecomment-293642988", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9154", "id": 293642988, "node_id": "MDEyOklzc3VlQ29tbWVudDI5MzY0Mjk4OA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-04-12T16:59:58Z", "updated_at": "2017-04-12T16:59:58Z", "author_association": "MEMBER", "body_html": "<p>Thanks for reducing the problem to a small reproducible code snippet in your edit, that helps a lot.</p>\n<p>This is probably not documented as clearly as it should, but <code>tf.global_variables_initializer()</code> adds an operation to the graph (with control dependencies), so as time goes by you see the graph getting larger and larger. Instead, you should call out <code>tf.global_variables_initializer()</code> once, using something like this:</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> time\n<span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n\na <span class=\"pl-k\">=</span> tf.Variable([<span class=\"pl-c1\">1</span>,<span class=\"pl-c1\">2</span>,<span class=\"pl-c1\">3</span>,<span class=\"pl-c1\">4</span>,<span class=\"pl-c1\">5</span>])\ninit_op <span class=\"pl-k\">=</span> tf.global_variables_initializer()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">test</span>():\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">1000</span>):\n        <span class=\"pl-k\">with</span> tf.Session() <span class=\"pl-k\">as</span> sess:\n            ot <span class=\"pl-k\">=</span> time.time()\n            sess.run(init_op)\n            nt <span class=\"pl-k\">=</span> time.time()\n            <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>test : <span class=\"pl-c1\">{<span class=\"pl-k\">:.3f</span>}</span><span class=\"pl-pds\">'</span></span>.format(nt<span class=\"pl-k\">-</span>ot))</pre></div>\n<p>Hope that helps.<br>\nClosing this out since it doesn't appear to be a bug. I'll look into improving the documentation.</p>", "body_text": "Thanks for reducing the problem to a small reproducible code snippet in your edit, that helps a lot.\nThis is probably not documented as clearly as it should, but tf.global_variables_initializer() adds an operation to the graph (with control dependencies), so as time goes by you see the graph getting larger and larger. Instead, you should call out tf.global_variables_initializer() once, using something like this:\nimport time\nimport tensorflow as tf\n\na = tf.Variable([1,2,3,4,5])\ninit_op = tf.global_variables_initializer()\n\ndef test():\n    for i in range(1000):\n        with tf.Session() as sess:\n            ot = time.time()\n            sess.run(init_op)\n            nt = time.time()\n            print('test : {:.3f}'.format(nt-ot))\nHope that helps.\nClosing this out since it doesn't appear to be a bug. I'll look into improving the documentation.", "body": "Thanks for reducing the problem to a small reproducible code snippet in your edit, that helps a lot.\r\n\r\nThis is probably not documented as clearly as it should, but `tf.global_variables_initializer()` adds an operation to the graph (with control dependencies), so as time goes by you see the graph getting larger and larger. Instead, you should call out `tf.global_variables_initializer()` once, using something like this:\r\n\r\n```python\r\nimport time\r\nimport tensorflow as tf\r\n\r\na = tf.Variable([1,2,3,4,5])\r\ninit_op = tf.global_variables_initializer()\r\n\r\ndef test():\r\n    for i in range(1000):\r\n        with tf.Session() as sess:\r\n            ot = time.time()\r\n            sess.run(init_op)\r\n            nt = time.time()\r\n            print('test : {:.3f}'.format(nt-ot))\r\n```\r\n\r\nHope that helps.\r\nClosing this out since it doesn't appear to be a bug. I'll look into improving the documentation."}