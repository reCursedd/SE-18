{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203814392", "pull_request_review_id": 138779622, "id": 203814392, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzgxNDM5Mg==", "diff_hunk": "@@ -0,0 +1,180 @@\n+# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for Rprop-\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import numpy as np\n+\n+from tensorflow.contrib.opt.python.training import rprop_minus\n+from tensorflow.python.eager import context\n+from tensorflow.python.framework import constant_op\n+from tensorflow.python.framework import dtypes\n+from tensorflow.python.ops import resource_variable_ops\n+from tensorflow.python.ops import variables\n+from tensorflow.python.platform import test\n+\n+\n+def rprop_update_numpy(params,\n+                       g_t,\n+                       old_g_t,\n+                       d_t,\n+                       eta_minus,\n+                       eta_plus,\n+                       delta_min,\n+                       delta_max):\n+\n+  for i, _ in enumerate(g_t):\n+\n+    current_g = g_t[i]\n+    mul_grad = g_t[i] * old_g_t[i]\n+\n+    if mul_grad > 0:\n+      d_t[i] = np.fmin(delta_max, d_t[i] * eta_plus)\n+    elif mul_grad < 0:\n+      d_t[i] = np.fmax(delta_min, d_t[i] * eta_minus)\n+\n+    params[i] -= np.sign(current_g) * d_t[i]\n+\n+  return params, d_t, g_t\n+\n+class RpropMinusTest(test.TestCase):\n+\n+  def _testDense(self,\n+                 use_resource=False,\n+                 eta_minus=0.5,\n+                 eta_plus=1.2,\n+                 delta_min=1e-6,\n+                 delta_max=50,\n+                 delta_zero=0.5):\n+    for dtype in [dtypes.half, dtypes.float32, dtypes.float64]:\n+      with self.test_session(use_gpu=True):\n+\n+        # Initialize variables for numpy implementation.\n+        var0_np = np.array([1.0, 2.0], dtype=dtype.as_numpy_dtype)\n+        grads0_np = np.array([0.1, 0.1], dtype=dtype.as_numpy_dtype)\n+        neg_grads0_np = np.negative(grads0_np)\n+        old_grads0 = np.array([0, 0], dtype=dtype.as_numpy_dtype)\n+        delta0 = np.array([delta_zero, delta_zero], dtype=dtype.as_numpy_dtype)\n+\n+        var1_np = np.array([3.0, 4.0], dtype=dtype.as_numpy_dtype)\n+        grads1_np = np.array([0.01, 0.01], dtype=dtype.as_numpy_dtype)\n+        neg_grads1_np = np.negative(grads1_np)\n+        old_grads1 = np.array([0, 0], dtype=dtype.as_numpy_dtype)\n+        delta1 = np.array([delta_zero, delta_zero], dtype=dtype.as_numpy_dtype)\n+\n+        if use_resource:\n+          var0 = resource_variable_ops.ResourceVariable(var0_np)\n+          var1 = resource_variable_ops.ResourceVariable(var1_np)\n+        else:\n+          var0 = variables.Variable(var0_np)\n+          var1 = variables.Variable(var1_np)\n+\n+        grads0 = constant_op.constant(grads0_np)\n+        grads1 = constant_op.constant(grads1_np)\n+\n+        opt = rprop_minus.RpropMinusOptimizer(eta_minus=eta_minus,\n+                                              eta_plus=eta_plus,\n+                                              delta_min=delta_min,\n+                                              delta_max=delta_max,\n+                                              delta_zero=delta_zero)\n+\n+        pos_update = opt.apply_gradients(zip([grads0, grads1], [var0, var1]))\n+        neg_update = opt.apply_gradients(zip([-grads0, -grads1], [var0, var1]))\n+        if not context.executing_eagerly():\n+          self.evaluate(variables.global_variables_initializer())\n+          # Fetch params to validate initial values\n+          self.assertAllClose([1.0, 2.0], self.evaluate(var0))\n+          self.assertAllClose([3.0, 4.0], self.evaluate(var1))\n+\n+        # Run 10 steps of rprop-\n+        # first 3 steps with positive gradient (same consecutive sign)\n+        # next 3 steps with negative gradient (first iteration only will have negative sign)\n+        # last 4 steps with alternate gradient (negative sign)\n+        for t in range(1, 10):\n+\n+          if t < 4:\n+            grads0_sign = grads0_np\n+            grads1_sign = grads1_np\n+            if not context.executing_eagerly():\n+              self.evaluate(pos_update)\n+            elif t > 1:\n+              opt.apply_gradients(zip([grads0, grads1], [var0, var1]))\n+          elif t < 7:\n+            grads0_sign = neg_grads0_np\n+            grads1_sign = neg_grads1_np\n+            if not context.executing_eagerly():\n+              self.evaluate(neg_update)\n+            else:\n+              opt.apply_gradients(zip([-grads0, -grads1], [var0, var1]))\n+          else:\n+            if t & 1 == 0:\n+              grads0_sign = neg_grads0_np\n+              grads1_sign = neg_grads1_np\n+              if not context.executing_eagerly():\n+                self.evaluate(neg_update)\n+              else:\n+                opt.apply_gradients(zip([-grads0, -grads1], [var0, var1]))\n+            else:\n+              grads0_sign = grads0_np\n+              grads1_sign = grads1_np\n+              if not context.executing_eagerly():\n+                self.evaluate(pos_update)\n+              else:\n+                opt.apply_gradients(zip([grads0, grads1], [var0, var1]))\n+\n+          var0_np, delta0, old_grads0 = rprop_update_numpy(\n+              var0_np,\n+              grads0_sign,\n+              old_grads0,\n+              delta0,\n+              eta_minus=eta_minus,\n+              eta_plus=eta_plus,\n+              delta_min=delta_min,\n+              delta_max=delta_max)\n+          var1_np, delta1, old_grads1 = rprop_update_numpy(\n+              var1_np,\n+              grads1_sign,\n+              old_grads1,\n+              delta1,\n+              eta_minus=eta_minus,\n+              eta_plus=eta_plus,\n+              delta_min=delta_min,\n+              delta_max=delta_max)\n+\n+          self.assertAllCloseAccordingToType(var0_np, self.evaluate(var0))\n+          self.assertAllCloseAccordingToType(var1_np, self.evaluate(var1))\n+\n+  def testDense(self):", "path": "tensorflow/contrib/opt/python/training/rprop_minus_test.py", "position": null, "original_position": 162, "commit_id": "7e1c185bb1d31eeac606f7300303718dab2e9c8f", "original_commit_id": "178e89fdfad1fee46bd19572e80a41efde31b40f", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "body": "Same comments as the other test", "created_at": "2018-07-19T17:44:41Z", "updated_at": "2018-08-07T16:48:46Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20918#discussion_r203814392", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20918", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203814392"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20918#discussion_r203814392"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20918"}}, "body_html": "<p>Same comments as the other test</p>", "body_text": "Same comments as the other test"}