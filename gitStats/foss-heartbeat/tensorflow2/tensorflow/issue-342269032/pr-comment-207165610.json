{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/207165610", "pull_request_review_id": 142719486, "id": 207165610, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwNzE2NTYxMA==", "diff_hunk": "@@ -0,0 +1,319 @@\n+# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Implementation of iRprop+\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import variable_scope\n+from tensorflow.python.training import optimizer\n+from tensorflow.python.training import training_ops\n+\n+\n+class IRpropPlusOptimizer(optimizer.Optimizer):\n+  \"\"\"Optimizer that implements the iRprop+ algorithm.\n+\n+  The Rprop (resilient backpropagation) algorithms are efficient gradient-based\n+  optimization algorithms. They require hardly any hyperparameter tuning.\n+\n+  In Rprop, the direction of each objective variable update is given by the sign\n+  of the partial derivative. The amount of the change is decoupled\n+  from the absolute value of the partial derivative. It is determined by a\n+  step-size parameter, which is individually adapted for each objective\n+  variable.\n+\n+  Rprop was originally proposed by Riedmiller and Braun in the article\n+  [A direct adaptive method for faster backpropagation learning:\n+  the RPROP algorithm](https://doi.org/10.1109/ICNN.1993.298623).\n+  The original Rprop algorithm uses weight-backtracking. It retracts the update\n+  of an objective variable if the update caused a change in sign of the\n+  corresponding partial derivative. The implememented Rprop variant, which is\n+  called iRprop+ and is described in the article\n+  [Empirical evaluation of the improved Rprop learning algorithms](https://doi.org/10.1016/S0925-2312(01)00700-7)\n+  only retracts an update if additionally the overall error increased.\n+  The TensorFlow implementation is described in the article\n+  [Resilient Backpropagation (Rprop) for Batch-learning in TensorFlow](https://openreview.net/forum?id=r1R0o7yDz).\n+\n+  **The Rprop algorithms are recommended for batch learning, _not_ for\n+  mini-batch learning.** The iRprop+ (improved Rprop with weight-backtracking)\n+  algorithm is empirically found to be faster and more robust than the\n+  [standard variant](RpropMinusOptimizer.md).\n+  See [Resilient Backpropagation (Rprop) for Batch-learning in\n+  TensorFlow](https://openreview.net/forum?id=r1R0o7yDz)\n+  for details and references.\n+  \"\"\"\n+\n+  # Values for gate_gradients, taken from base class.\n+  GATE_NONE = 0\n+  GATE_OP = 1\n+  GATE_GRAPH = 2\n+\n+  def __init__(self,\n+               eta_minus=0.5,\n+               eta_plus=1.2,\n+               delta_zero=0.5,\n+               delta_min=1e-6,\n+               delta_max=50,\n+               use_locking=False, name=\"IRpropPlusOptimizer\"):\n+    \"\"\"Constructs a new IRpropPlusOptimizer object.\n+\n+    The pseudocode of the algorithm can be found in the articles\n+    [Empirical evaluation of the improved Rprop learning algorithms](https://doi.org/10.1016/S0925-2312(01)00700-7)\n+    and [Resilient Backpropagation (Rprop) for Batch-learning in TensorFlow](https://openreview.net/forum?id=r1R0o7yDz).\n+\n+    Initialization:\n+\n+    ```\n+    old_grad <- 0 (Initialize the gradient from the previous iteration g{t-1})\n+    delta_update <- delta_zero (Initialize step-size)\n+    t <- 0 (Initialize iteration counter)\n+    ```\n+\n+    The following update rule is performed for each individual objective\n+    variable (e.g., weight), where `g{t}` denotes the partial derivative of the\n+    objective function with respect to the objective variable at iteration `t`:\n+\n+    ```\n+    t <- t + 1\n+    grad_sign <- sign(g{t} * g{t-1})\n+    if (grad_sign > 0)\n+      delta_update{t} <- min(eta_plus * delta_update{t-1}, delta_max)\n+      variable{t+1} <- variable{t} -sign(g{t}) * delta_update{t}\n+    else if (grad_sign < 0)\n+      delta_update{t} <- max(eta_minus * delta_update{t-1}, delta_min)\n+      if (error{t} > error{t-1})\n+        variable{t+1} <- variable{t-1}\n+      g{t} = 0\n+    else\n+      variable{t+1} <- variable{t} - sign(g{t}) * delta_update{t}\n+\n+    ```\n+\n+    Args:\n+      eta_minus: Step-size decrease factor.\n+      eta_plus: Step-size increase factor.\n+      delta_zero: Initial step-size.\n+      delta_min: Lower bound on step-size.\n+      delta_max: Upper bound on step-size.\n+      use_locking: If True, use locks for update operations.\n+      name: Optional name for the operations created when applying gradients.\n+         Defaults to \"IRpropPlusOptimizer\".\n+   \"\"\"\n+\n+    super(IRpropPlusOptimizer, self).__init__(use_locking, name)\n+\n+    # Init parameters\n+    self._eta_minus = eta_minus\n+    self._eta_plus = eta_plus\n+    self._delta_zero = delta_zero\n+    self._delta_min = delta_min\n+    self._delta_max = delta_max\n+\n+    # Tensor versions of the constructor arguments, created in _prepare().\n+    self._eta_minus_t = None\n+    self._eta_plus_t = None\n+    # self._delta_zero_t = None\n+    self._delta_min_t = None\n+    self._delta_max_t = None\n+\n+    # Error tensors\n+    self._error = variable_scope.variable(0.0,\n+                                          name=\"error\", trainable=False)\n+    self._old_error = variable_scope.variable(0.0,\n+                                              name=\"old_error\", trainable=False)\n+\n+  def _prepare(self):\n+    self._eta_minus_t = ops.convert_to_tensor(self._eta_minus, name=\"eta_minus\")\n+    self._eta_plus_t = ops.convert_to_tensor(self._eta_plus, name=\"eta_plus\")\n+    self._delta_min_t = ops.convert_to_tensor(self._delta_min, name=\"delta_min\")\n+    self._delta_max_t = ops.convert_to_tensor(self._delta_max, name=\"delta_max\")\n+\n+  def _create_slots(self, var_list):\n+    # Create slots for the gradient at (t-1) and\n+    # the step-size \"delta_update\".\n+    for v in var_list:\n+      # Gradient from the previous step\n+      self._zeros_slot(v, 'old_grad', self._name)\n+      # Init value for delta at step t = 0\n+      init_step = math_ops.add(array_ops.zeros(\n+          v.get_shape().as_list(), dtype=v.dtype.base_dtype), self._delta_zero)\n+      self._get_or_make_slot(v, init_step, \"delta_update\", self._name)\n+\n+  # Helper method to check if variable is scalar\n+  def _is_scalar(self, tensor):\n+    return tensor is not None and \\\n+            tensor.shape.ndims == 0\n+           #tensor.shape.ndims is not None\n+\n+  # Called by apply_gradients in Optimizer base class\n+  def _apply_dense(self, grad, var):\n+    old_grad = self.get_slot(var, 'old_grad')\n+    delta_update = self.get_slot(var, \"delta_update\")\n+\n+    eta_minus_t = math_ops.cast(self._eta_minus_t, var.dtype.base_dtype)\n+    eta_plus_t = math_ops.cast(self._eta_plus_t, var.dtype.base_dtype)\n+    delta_min_t = math_ops.cast(self._delta_min_t, var.dtype.base_dtype)\n+    delta_max_t = math_ops.cast(self._delta_max_t, var.dtype.base_dtype)\n+    # iRprop+ error tensors\n+    error_t = math_ops.cast(self._error, var.dtype.base_dtype)\n+    old_error_t = math_ops.cast(self._old_error, var.dtype.base_dtype)\n+\n+    return training_ops.apply_i_rprop_plus(\n+        var,\n+        old_grad,\n+        delta_update,\n+        eta_minus_t,\n+        eta_plus_t,\n+        delta_min_t,\n+        delta_max_t,\n+        error_t,\n+        old_error_t,\n+        grad, use_locking=self._use_locking).op\n+\n+  def _resource_apply_dense(self, grad, var):\n+    old_grad = self.get_slot(var, \"old_grad\")\n+    delta_update = self.get_slot(var, \"delta_update\")\n+\n+    eta_minus_t = math_ops.cast(self._eta_minus_t, var.dtype.base_dtype)\n+    eta_plus_t = math_ops.cast(self._eta_plus_t, var.dtype.base_dtype)\n+    delta_min_t = math_ops.cast(self._delta_min_t, var.dtype.base_dtype)\n+    delta_max_t = math_ops.cast(self._delta_max_t, var.dtype.base_dtype)\n+    error_t = math_ops.cast(self._error, var.dtype.base_dtype)\n+    old_error_t = math_ops.cast(self._old_error, var.dtype.base_dtype)\n+\n+    return training_ops.resource_apply_i_rprop_plus(\n+        var.handle,\n+        old_grad.handle,\n+        delta_update.handle,\n+        eta_minus_t,\n+        eta_plus_t,\n+        delta_min_t,\n+        delta_max_t,\n+        error_t,\n+        old_error_t,\n+        grad, use_locking=self._use_locking)\n+\n+\n+  def minimize(self, loss, global_step=None, var_list=None,\n+               gate_gradients=GATE_OP, aggregation_method=None,\n+               colocate_gradients_with_ops=False, name=None, grad_loss=None):\n+    \"\"\"Add operations to minimize `loss` by updating `var_list`.\n+    This method simply combines calls `compute_gradients()` and\n+    `apply_gradients()`. If you want to process the gradient before applying\n+    them call `compute_gradients()` and `apply_gradients()` explicitly instead\n+    of using this function. The loss argument has to be passed as a 0-D Tensor.\n+    Args:\n+      loss: A 0-D `Tensor` containing the value to minimize.\n+      global_step: Optional `Variable` to increment by one after the\n+        variables have been updated.\n+      var_list: Optional list or tuple of `Variable` objects to update to\n+        minimize `loss`.  Defaults to the list of variables collected in\n+        the graph under the key `GraphKeys.TRAINABLE_VARIABLES`.\n+      gate_gradients: How to gate the computation of gradients.  Can be\n+        `GATE_NONE`, `GATE_OP`, or  `GATE_GRAPH`.\n+      aggregation_method: Specifies the method used to combine gradient terms.\n+        Valid values are defined in the class `AggregationMethod`.\n+      colocate_gradients_with_ops: If True, try colocating gradients with\n+        the corresponding op.\n+      name: Optional name for the returned operation.\n+      grad_loss: Optional. A `Tensor` holding the gradient computed for `loss`.\n+    Returns:\n+      An Operation that updates the variables in `var_list`.  If `global_step`\n+      was not `None`, that operation also increments `global_step`.\n+    Raises:\n+      ValueError: If some of the variables are not `Variable` objects.\n+      ValueError: If the `loss` is not a 0-D tensor (scalar).\n+    @compatibility(eager)\n+    When eager execution is enabled, `loss` should be a Python function that\n+    takes elements of `var_list` as arguments and computes the value to be\n+    minimized. If `var_list` is `None`, `loss` should take no arguments.\n+    Minimization (and gradient computation) is done with respect to the\n+    elements of `var_list` if not `None`, else with respect to any trainable\n+    variables created during the execution of the `loss` function.\n+    `gate_gradients`, `aggregation_method`, `colocate_gradients_with_ops` and\n+    `grad_loss` are ignored when eager execution is enabled.\n+    @end_compatibility\n+    \"\"\"\n+    # Override method from base class\n+\n+    # Error E(t)\n+    if self._is_scalar(loss):\n+      self._error = loss\n+    else:\n+      raise ValueError(\n+          \"'loss' (%s) must be a 0-D tensor.\" % loss)\n+\n+    return super(IRpropPlusOptimizer, self).minimize(\n+        loss,\n+        global_step=global_step, var_list=var_list,\n+        gate_gradients=gate_gradients,\n+        aggregation_method=aggregation_method,\n+        colocate_gradients_with_ops=colocate_gradients_with_ops, name=name,\n+        grad_loss=grad_loss)\n+\n+  def _finish(self, update_ops, name_scope):\n+\n+    # Update the old error E(t-1) <- E(t)\n+    with ops.control_dependencies(update_ops):\n+      with ops.colocate_with(self._error):\n+        old_error_update = self._old_error.assign(\n+            self._error, use_locking=self._use_locking)\n+\n+    return control_flow_ops.group(*update_ops + [old_error_update],\n+                                  name=name_scope)\n+\n+  def apply_gradients(self, grads_and_vars, loss, global_step=None, name=None):", "path": "tensorflow/contrib/opt/python/training/irprop_plus.py", "position": null, "original_position": 282, "commit_id": "7e1c185bb1d31eeac606f7300303718dab2e9c8f", "original_commit_id": "178e89fdfad1fee46bd19572e80a41efde31b40f", "user": {"login": "ciprianflow", "id": 7080826, "node_id": "MDQ6VXNlcjcwODA4MjY=", "avatar_url": "https://avatars0.githubusercontent.com/u/7080826?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ciprianflow", "html_url": "https://github.com/ciprianflow", "followers_url": "https://api.github.com/users/ciprianflow/followers", "following_url": "https://api.github.com/users/ciprianflow/following{/other_user}", "gists_url": "https://api.github.com/users/ciprianflow/gists{/gist_id}", "starred_url": "https://api.github.com/users/ciprianflow/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ciprianflow/subscriptions", "organizations_url": "https://api.github.com/users/ciprianflow/orgs", "repos_url": "https://api.github.com/users/ciprianflow/repos", "events_url": "https://api.github.com/users/ciprianflow/events{/privacy}", "received_events_url": "https://api.github.com/users/ciprianflow/received_events", "type": "User", "site_admin": false}, "body": "Same comment as above.", "created_at": "2018-08-02T09:46:39Z", "updated_at": "2018-08-07T16:48:46Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20918#discussion_r207165610", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20918", "author_association": "NONE", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/207165610"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20918#discussion_r207165610"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20918"}}, "body_html": "<p>Same comment as above.</p>", "body_text": "Same comment as above.", "in_reply_to_id": 203813913}