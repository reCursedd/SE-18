{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203813188", "pull_request_review_id": 138779622, "id": 203813188, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIwMzgxMzE4OA==", "diff_hunk": "@@ -0,0 +1,319 @@\n+# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Implementation of iRprop+\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+from tensorflow.python.framework import ops\n+from tensorflow.python.ops import control_flow_ops\n+from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import math_ops\n+from tensorflow.python.ops import variable_scope\n+from tensorflow.python.training import optimizer\n+from tensorflow.python.training import training_ops\n+\n+\n+class IRpropPlusOptimizer(optimizer.Optimizer):\n+  \"\"\"Optimizer that implements the iRprop+ algorithm.\n+\n+  The Rprop (resilient backpropagation) algorithms are efficient gradient-based\n+  optimization algorithms. They require hardly any hyperparameter tuning.\n+\n+  In Rprop, the direction of each objective variable update is given by the sign\n+  of the partial derivative. The amount of the change is decoupled\n+  from the absolute value of the partial derivative. It is determined by a\n+  step-size parameter, which is individually adapted for each objective\n+  variable.\n+\n+  Rprop was originally proposed by Riedmiller and Braun in the article\n+  [A direct adaptive method for faster backpropagation learning:\n+  the RPROP algorithm](https://doi.org/10.1109/ICNN.1993.298623).\n+  The original Rprop algorithm uses weight-backtracking. It retracts the update\n+  of an objective variable if the update caused a change in sign of the\n+  corresponding partial derivative. The implememented Rprop variant, which is\n+  called iRprop+ and is described in the article\n+  [Empirical evaluation of the improved Rprop learning algorithms](https://doi.org/10.1016/S0925-2312(01)00700-7)\n+  only retracts an update if additionally the overall error increased.\n+  The TensorFlow implementation is described in the article\n+  [Resilient Backpropagation (Rprop) for Batch-learning in TensorFlow](https://openreview.net/forum?id=r1R0o7yDz).\n+\n+  **The Rprop algorithms are recommended for batch learning, _not_ for\n+  mini-batch learning.** The iRprop+ (improved Rprop with weight-backtracking)\n+  algorithm is empirically found to be faster and more robust than the\n+  [standard variant](RpropMinusOptimizer.md).\n+  See [Resilient Backpropagation (Rprop) for Batch-learning in\n+  TensorFlow](https://openreview.net/forum?id=r1R0o7yDz)\n+  for details and references.\n+  \"\"\"\n+\n+  # Values for gate_gradients, taken from base class.\n+  GATE_NONE = 0", "path": "tensorflow/contrib/opt/python/training/irprop_plus.py", "position": null, "original_position": 64, "commit_id": "7e1c185bb1d31eeac606f7300303718dab2e9c8f", "original_commit_id": "178e89fdfad1fee46bd19572e80a41efde31b40f", "user": {"login": "alextp", "id": 5061, "node_id": "MDQ6VXNlcjUwNjE=", "avatar_url": "https://avatars0.githubusercontent.com/u/5061?v=4", "gravatar_id": "", "url": "https://api.github.com/users/alextp", "html_url": "https://github.com/alextp", "followers_url": "https://api.github.com/users/alextp/followers", "following_url": "https://api.github.com/users/alextp/following{/other_user}", "gists_url": "https://api.github.com/users/alextp/gists{/gist_id}", "starred_url": "https://api.github.com/users/alextp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/alextp/subscriptions", "organizations_url": "https://api.github.com/users/alextp/orgs", "repos_url": "https://api.github.com/users/alextp/repos", "events_url": "https://api.github.com/users/alextp/events{/privacy}", "received_events_url": "https://api.github.com/users/alextp/received_events", "type": "User", "site_admin": false}, "body": "Don't repeat these, just reuse Optimizer.GATE etc", "created_at": "2018-07-19T17:40:54Z", "updated_at": "2018-08-07T16:48:46Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/20918#discussion_r203813188", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20918", "author_association": "MEMBER", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/203813188"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/20918#discussion_r203813188"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/20918"}}, "body_html": "<p>Don't repeat these, just reuse Optimizer.GATE etc</p>", "body_text": "Don't repeat these, just reuse Optimizer.GATE etc"}