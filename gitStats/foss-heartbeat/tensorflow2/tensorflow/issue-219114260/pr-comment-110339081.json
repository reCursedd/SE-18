{"url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/110339081", "pull_request_review_id": 31505215, "id": 110339081, "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDExMDMzOTA4MQ==", "diff_hunk": "@@ -0,0 +1,888 @@\n+/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdlib>\n+#include \"tensorflow/contrib/verbs/rdma.h\"\n+#include \"tensorflow/contrib/verbs/verbs_util.h\"\n+#include \"tensorflow/core/common_runtime/device_mgr.h\"\n+#include \"tensorflow/core/common_runtime/dma_helper.h\"\n+#include \"tensorflow/core/common_runtime/gpu/gpu_util.h\"\n+#include \"tensorflow/core/distributed_runtime/rendezvous_mgr_interface.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/rendezvous.h\"\n+#include \"tensorflow/core/lib/core/status.h\"\n+#include \"tensorflow/core/lib/core/stringpiece.h\"\n+#include \"tensorflow/core/lib/hash/hash.h\"\n+#include \"tensorflow/core/lib/random/random.h\"\n+\n+namespace tensorflow {\n+\n+namespace {\n+// hash name to 32-bit integer\n+uint32_t NameHash(const string& name) {\n+    return Hash32(name.data(), name.size(), 0x1234ABCD);\n+}\n+\n+// convenience function for printing message\n+string MessageTypeToString(RdmaMessageType rmt) {\n+  switch(rmt){\n+    case RDMA_MESSAGE_ACK:\n+      return \"RDMA_MESSAGE_ACK\";\n+      break;\n+    case RDMA_MESSAGE_BUFFER_IDLE:\n+      return \"RDMA_MESSAGE_BUFFER_IDLE\";\n+      break;\n+    case RDMA_MESSAGE_BUFFER_REQUEST:\n+      return \"RDMA_MESSAGE_BUFFER_REQUEST\";\n+      break;\n+    case RDMA_MESSAGE_BUFFER_RESPONSE:\n+      return \"RDMA_MESSAGE_BUFFER_RESPONSE\";\n+      break;\n+    case RDMA_MESSAGE_TENSOR_REQUEST:\n+      return \"RDMA_MESSAGE_TENSOR_REQUEST\";\n+      break;\n+    case RDMA_MESSAGE_TENSOR_WRITE:\n+      return \"RDMA_MESSAGE_TENSOR_WRITE\";\n+      break;\n+    default: \n+      return \"UNKNOWN MESSAGE\";\n+  }\n+}\n+}\n+\n+ibv_context* open_default_device() {\n+  ibv_device** dev_list;\n+  ibv_device* ib_dev;\n+  dev_list = ibv_get_device_list(NULL);\n+  CHECK(dev_list) << \"No InfiniBand device found\";\n+  ib_dev = dev_list[0];\n+  CHECK(ib_dev) << \"No InfiniBand device found\";\n+  ibv_context* context = ibv_open_device(ib_dev);\n+  CHECK(context) << \"Open context failed for \" << ibv_get_device_name(ib_dev);\n+  return context;\n+}\n+\n+ibv_pd* alloc_protection_domain(ibv_context* context) {\n+  ibv_pd* pd = ibv_alloc_pd(context);\n+  CHECK(pd) << \"Failed to allocate protection domain\";\n+  return pd;\n+}\n+\n+RdmaAdapter::RdmaAdapter(const WorkerEnv* worker_env)\n+    : context_(open_default_device()),\n+      pd_(alloc_protection_domain(context_)),\n+      worker_env_(worker_env) {\n+  event_channel_ = ibv_create_comp_channel(context_);\n+  CHECK(event_channel_) << \"Failed to create completion channel\";\n+  cq_ = ibv_create_cq(context_, MAX_CONCURRENT_WRITES * 2, NULL, event_channel_, 0);\n+  CHECK(cq_) << \"Failed to create completion queue\";\n+  CHECK(!ibv_req_notify_cq(cq_, 0)) << \"Failed to request CQ notification\";\n+  polling_thread_.reset(Env::Default()->StartThread(\n+                            ThreadOptions(), \"RdmaAdapterCQThread\",\n+                            [this] {Process_CQ(); }));\n+  VLOG(2) << \"Start RdmaAdapter: \" << name(); \n+}\n+\n+RdmaAdapter::~RdmaAdapter() {\n+  polling_thread_.reset();\n+  CHECK(!ibv_destroy_cq(cq_)) << \"Failed to destroy CQ\";\n+  CHECK(!ibv_destroy_comp_channel(event_channel_)) << \"Failed to destroy channel\";\n+  CHECK(!ibv_dealloc_pd(pd_)) << \"Failed to deallocate PD\";\n+  CHECK(!ibv_close_device(context_)) << \"Failed to release context\";\n+}\n+\n+string RdmaAdapter::name() const {\n+  return string(context_->device->name);\n+}\n+\n+// Function to process incoming messages\n+// There are two types of messages: \n+// 1. IBV_WC_RECV_RDMA_WITH_IMM (receive)\n+// 2. IBV_WC_RDMA_WRITE (send))\n+void RdmaAdapter::Process_CQ() {\n+  while (true) {\n+    ibv_cq* cq;\n+    void* cq_context;\n+    CHECK(!ibv_get_cq_event(event_channel_, &cq, &cq_context));\n+    CHECK(cq == cq_);\n+    ibv_ack_cq_events(cq, 1);\n+    CHECK(!ibv_req_notify_cq(cq_, 0));\n+\n+    int ne = ibv_poll_cq(cq_, MAX_CONCURRENT_WRITES * 2,\n+      static_cast<ibv_wc*>(wc_));\n+    CHECK_GE(ne, 0);\n+    for (int i = 0; i < ne; ++i) {\n+      CHECK(wc_[i].status == IBV_WC_SUCCESS) << \"Failed status \\n\"\n+                                             << ibv_wc_status_str(wc_[i].status)\n+                                             << \" \" << wc_[i].status << \" \"\n+                                             << static_cast<int>(wc_[i].wr_id)\n+                                             << \" \"<< wc_[i].vendor_err;\n+      if (wc_[i].opcode == IBV_WC_RECV_RDMA_WITH_IMM) {\n+        RdmaChannel* rc = reinterpret_cast<RdmaChannel*>(wc_[i].wr_id);\n+        // put back a recv wr.\n+        rc->Recv();\n+        // imm_data is the index of RX buffer in the buffer table.\n+        uint32_t imm_data = wc_[i].imm_data;\n+        RdmaBuffer* rb = rc->FindBuffer(imm_data);\n+        RdmaMessage rm;\n+        RdmaMessage::ParseMessage(rm, rb->buffer_);\n+        VLOG(2) << \"recv RDMA message: \" << MessageTypeToString(rm.type_);\n+        \n+        if (rm.type_ == RDMA_MESSAGE_ACK) { \n+          // receive an ack to a message\n+          rb = rc->tx_message_buffer_;\n+          rb->SetBufferStatus(remote, idle);\n+          rb->SendNextItem();\n+        } else if (rm.type_ == RDMA_MESSAGE_TENSOR_REQUEST) {\n+          // received a request-for-tensor message\n+          // send ack to release remote tx message buffer\n+          RdmaBuffer* ab = rc->tx_ack_buffer_;\n+          ab->SendNextItem();\n+          // find or create buffer\n+          RdmaBuffer* tb = rc->FindOrCreateBuffer(rm.name_);\n+          string key_with_step_id = \n+                  VerbsUtil::AppendStepidToKey(rm.name_, rm.step_id_);\n+          tb->EnqueueItem(key_with_step_id);\n+          // send the next tensor\n+          worker_env_->compute_pool->Schedule([tb](){tb->SendNextItem();});\n+        } else if (rm.type_ == RDMA_MESSAGE_BUFFER_IDLE) { \n+          // receive tensor-buffer-ready message\n+          // send ack to release remote tx message buffer\n+          RdmaBuffer* ab = rc->tx_ack_buffer_;\n+          ab->SendNextItem();\n+          // find buffer\n+          RdmaBuffer* tb = rc->FindBuffer(rm.name_);\n+          tb->SetBufferStatus(remote, idle);\n+          worker_env_->compute_pool->Schedule([tb](){tb->SendNextItem();});\n+        } else if (rm.type_ == RDMA_MESSAGE_BUFFER_REQUEST) {\n+          // remote host requests to create a tensor buffer;\n+          // send ack to release remote tx message buffer\n+          RdmaBuffer* ab = rc->tx_ack_buffer_;\n+          ab->SendNextItem();\n+          // find or create the buffer\n+          RdmaBuffer* tb = rc->FindOrCreateBuffer(rm.name_, TENSOR);\n+          RemoteMR rmr;\n+          rmr.remote_addr = rm.remote_addr_;\n+          rmr.rkey = rm.rkey_;\n+          tb->SetRemoteMR(rmr, true);\n+          tb->CreateCPUBuffer(rm.buffer_size_);\n+          // create RDMA_MESSAGE_BUFFER_RESPONSE message\n+          RdmaMessage br;\n+          br.type_ = RDMA_MESSAGE_BUFFER_RESPONSE;\n+          br.name_size_ = rm.name_.size();\n+          br.name_ = rm.name_;\n+          br.buffer_size_ = rm.buffer_size_;\n+          br.remote_addr_ = reinterpret_cast<uint64_t>(tb->buffer_);\n+          br.rkey_ = tb->self_->rkey;\n+          string message = RdmaMessage::CreateMessage(br);\n+          RdmaBuffer* mb = rc->tx_message_buffer_;\n+          mb->EnqueueItem(message);\n+          mb->SendNextItem();\n+        } else if (rm.type_ == RDMA_MESSAGE_BUFFER_RESPONSE) {\n+          // remote creates a buffer and responds \n+          // send ack to release remote tx message buffer\n+          RdmaBuffer* ab = rc->tx_ack_buffer_;\n+          ab->SendNextItem();\n+          // find buffer\n+          RdmaBuffer* tb = rc->FindBuffer(rm.name_);\n+          CHECK(rm.buffer_size_ == tb->size_) \n+                  << \"rm.buffer_size = \" << rm.buffer_size_\n+                  << \"tb->size_ = \" << tb->size_ \n+                  << \"rm.name_ = \" << rm.name_;\n+          RemoteMR rmr;\n+          rmr.remote_addr = rm.remote_addr_;\n+          rmr.rkey = rm.rkey_;\n+          tb->SetRemoteMR(rmr, true);\n+          tb->SetBufferStatus(local, idle);\n+          tb->SetBufferStatus(remote, idle);\n+          worker_env_->compute_pool->Schedule([tb](){tb->SendNextItem();});\n+        } else if (rm.type_ == RDMA_MESSAGE_TENSOR_WRITE) {\n+          // tensor RDMA write completed\n+          worker_env_->compute_pool->Schedule([rm, rc](){\n+            string key_with_step_id = \n+                  VerbsUtil::AppendStepidToKey(rm.name_, rm.step_id_);\n+            rc->RunRecvCallback(key_with_step_id);\n+          });          \n+        }         \n+      } else if (wc_[i].opcode == IBV_WC_RDMA_WRITE) {\n+        RdmaBuffer* rb = reinterpret_cast<RdmaBuffer*>(wc_[i].wr_id);\n+        rb->SetBufferStatus(local, idle);\n+        RdmaMessage rm;\n+        RdmaMessage::ParseMessage(rm, rb->buffer_);\n+        VLOG(2) << \"sent RDMA message: \" << MessageTypeToString(rm.type_);\n+        if (rm.type_ != RDMA_MESSAGE_ACK) {\n+          worker_env_->compute_pool->Schedule([rb](){rb->SendNextItem();});\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+RdmaChannel::RdmaChannel(const RdmaAdapter* adapter, const string local_name,\n+                         const string remote_name)\n+    : adapter_(adapter), \n+      local_name_(local_name), \n+      remote_name_(remote_name) {\n+  // Create queue pair\n+  {\n+    struct ibv_qp_init_attr attr;\n+    memset(&attr, 0, sizeof(ibv_qp_init_attr));\n+    attr.send_cq = adapter_->cq_;\n+    attr.recv_cq = adapter_->cq_;\n+    attr.cap.max_send_wr = RdmaAdapter::MAX_CONCURRENT_WRITES;\n+    attr.cap.max_recv_wr = RdmaAdapter::MAX_CONCURRENT_WRITES;\n+    attr.cap.max_send_sge = 1;\n+    attr.cap.max_recv_sge = 1;\n+    attr.qp_type = IBV_QPT_RC;\n+\n+    qp_ = ibv_create_qp(adapter_->pd_, &attr);\n+    CHECK(qp_) << \"Failed to create queue pair\";\n+  }\n+\n+  // Init queue pair\n+  {\n+    struct ibv_qp_attr attr;\n+    memset(&attr, 0, sizeof(ibv_qp_attr));\n+    attr.qp_state = IBV_QPS_INIT;\n+    attr.pkey_index = 0;\n+    attr.port_num = 1;\n+    attr.qp_access_flags = IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE;\n+\n+    int mask = IBV_QP_STATE | IBV_QP_PKEY_INDEX | IBV_QP_PORT\n+        | IBV_QP_ACCESS_FLAGS;\n+    CHECK(!ibv_modify_qp(qp_, &attr, mask)) << \"Failed to set QP to INIT\";\n+  }\n+\n+  // Local address\n+  {\n+    struct ibv_port_attr attr;\n+    CHECK(!ibv_query_port(adapter_->context_, (uint8_t) 1, &attr))\n+        << \"Query port\";\n+    self_.lid = attr.lid;\n+    self_.qpn = qp_->qp_num;\n+    self_.psn = static_cast<uint32_t>(random::New64()) & 0xffffff;\n+  }\n+  \n+  // create message and ack buffers, then initialize the tables.\n+  {\n+    const string buffer_names[] = {\"tx_message_buffer\", \"rx_message_buffer\",\n+                                   \"tx_ack_buffer\", \"rx_ack_buffer\"};\n+    tx_message_buffer_ = new RdmaMessageBuffer(this, buffer_names[0]);\n+    rx_message_buffer_ = new RdmaMessageBuffer(this, buffer_names[1]);\n+    tx_ack_buffer_ = new RdmaAckBuffer(this, buffer_names[2]);\n+    rx_ack_buffer_ = new RdmaAckBuffer(this, buffer_names[3]);\n+    message_buffers_.reserve(kNumMessageBuffers);\n+    message_buffers_.push_back(tx_message_buffer_);\n+    message_buffers_.push_back(rx_message_buffer_);\n+    message_buffers_.push_back(tx_ack_buffer_);\n+    message_buffers_.push_back(rx_ack_buffer_);\n+    // create buffer on host\n+    tx_message_buffer_->CreateCPUBuffer(RdmaMessage::kRdmaMessageBufferSize);\n+    rx_message_buffer_->CreateCPUBuffer(RdmaMessage::kRdmaMessageBufferSize);\n+    tx_ack_buffer_->CreateCPUBuffer(RdmaMessage::kRdmaAckBufferSize);\n+    rx_ack_buffer_->CreateCPUBuffer(RdmaMessage::kRdmaAckBufferSize);\n+    // bt_mu_.lock() is not used in constructor.\n+    for (int i = 0; i < kNumMessageBuffers; i++) {\n+      uint32_t index = NameHash(buffer_names[i]);\n+      buffer_table_.insert({index, message_buffers_[i]});\n+      buffer_index_name_table_.insert({index, buffer_names[i]});\n+      buffer_name_index_table_.insert({buffer_names[i], index});\n+    }\n+    \n+    // Initiate recv\n+    for (int i = 0; i < 100; i++) {\n+      Recv();\n+    }\n+  }\n+}\n+\n+RdmaChannel::~RdmaChannel() {\n+  CHECK(!ibv_destroy_qp(qp_)) << \"Failed to destroy QP\";\n+  delete tx_message_buffer_;\n+  delete rx_message_buffer_;\n+  delete tx_ack_buffer_;\n+  delete rx_ack_buffer_;\n+}\n+\n+void RdmaChannel::SetRemoteAddress(RdmaAddress ra, bool override) {\n+    mu_.lock();\n+    if ((override) || (!remote_set_)) { \n+      remote_.lid = ra.lid;\n+      remote_.qpn = ra.qpn;\n+      remote_.psn = ra.psn;\n+      remote_set_ = true;\n+    } else {\n+      CHECK(remote_.lid == ra.lid);\n+      CHECK(remote_.qpn == ra.qpn);\n+      CHECK(remote_.psn == ra.psn);   \n+    }\n+    mu_.unlock();\n+}\n+\n+// Adding tokens to the completion queue\n+// Tokens are needed to process future messages.\n+void RdmaChannel::Recv() {\n+  struct ibv_recv_wr wr;\n+  memset(&wr, 0, sizeof(wr));\n+  wr.wr_id = (uint64_t) this;\n+  struct ibv_recv_wr* bad_wr;\n+  CHECK(!ibv_post_recv(qp_, &wr, &bad_wr)) << \"Failed to post recv\";\n+}\n+\n+// Lookup 32-bit buffer index from buffer name\n+// Args:\n+//   buffer_name: name of the buffer\n+// Returns:\n+//   32-bit index     \n+uint32_t RdmaChannel::LookupBufferIndex(const string& buffer_name){\n+  bt_mu_.lock();\n+  BufferNameIndexTable::iterator iter = buffer_name_index_table_.find(\n+          buffer_name);\n+  CHECK(iter != buffer_name_index_table_.end());\n+  bt_mu_.unlock();\n+  return iter->second;\n+}\n+\n+// Find a buffer by its 32-bit index\n+// Args:\n+//   index: 32-bit hash code of the tensor buffer name\n+// Returns:\n+//   name of the tensor buffer\n+RdmaBuffer* RdmaChannel::FindBuffer(const uint32_t index) {\n+  bt_mu_.lock();\n+  BufferTable::iterator iter = buffer_table_.find(index);\n+  CHECK(iter != buffer_table_.end());\n+  bt_mu_.unlock();\n+  return iter->second;\n+}\n+\n+// Find a buffer by its name\n+// Args:\n+//   name: name of the buffer\n+// Returns:\n+//   the named rdma buffer\n+RdmaBuffer* RdmaChannel::FindBuffer(const string& name) {\n+  uint32_t index = LookupBufferIndex(name);\n+  return FindBuffer(index);\n+}\n+\n+// Find a buffer if it exists, otherwise create one.\n+// The memory inside the created buffer is not allocated. \n+// Args: \n+//   name: the name of the buffer\n+//   buffer_type: TENSOR, MESSAGE or ACK.\n+// Returns:\n+//   the named buffer\n+RdmaBuffer* RdmaChannel::FindOrCreateBuffer(const string& name, \n+                                BufferType buffer_type) {\n+  RdmaBuffer* rb;\n+  bt_mu_.lock();\n+  // find index\n+  BufferNameIndexTable::iterator iter = buffer_name_index_table_.find(name);\n+  if (iter != buffer_name_index_table_.end()) {\n+    uint32_t index = iter->second;\n+    // find buffer\n+    BufferTable::iterator iter = buffer_table_.find(index);\n+    CHECK(iter != buffer_table_.end());\n+    rb = iter->second;\n+  } else {\n+    uint32_t index = NameHash(name);\n+    if (buffer_type == TENSOR) {\n+      rb = new RdmaTensorBuffer(this, name);\n+    } else if (buffer_type == MESSAGE) {\n+      rb = new RdmaMessageBuffer(this, name);\n+    } else if (buffer_type == ACK) {\n+      rb = new RdmaAckBuffer(this, name); \n+    }\n+    buffer_name_index_table_.insert({name, index});\n+    buffer_index_name_table_.insert({index, name});\n+    buffer_table_.insert({index, rb});\n+  }\n+  bt_mu_.unlock();\n+  return rb;\n+}\n+\n+// Insert callback to the callback_table.\n+// The callback is activated when the corresponding tensor is received.\n+// Arg: \n+//   key: the name of the tensor\n+//   recv_done: the callback associated with the tensor.\n+// Returns:\n+//   None\n+void RdmaChannel::InsertRecvCallback(string& key, \n+        std::function<void()> recv_done) {\n+  ct_mu_.lock();\n+  callback_table_.insert({key, recv_done});\n+  ct_mu_.unlock();\n+}\n+\n+// Remove callback from the callback_table.\n+// Arg: \n+//   key: the name of the tensor\n+// Returns:\n+//   None\n+void RdmaChannel::RemoveRecvCallback(const string& key) {\n+  ct_mu_.lock();\n+  callback_table_.erase(key);\n+  ct_mu_.unlock();\n+}\n+\n+// Run named callback in the callback_table.\n+// Arg: \n+//   key: the name of the tensor\n+// Returns:\n+//   None\n+void RdmaChannel::RunRecvCallback(const string& key) {\n+  ct_mu_.lock();\n+  CallbackTable::iterator iter = callback_table_.find(key);\n+  CHECK(iter != callback_table_.end());\n+  std::function<void()> recv_done = iter->second;\n+  ct_mu_.unlock();\n+  recv_done();\n+}\n+\n+void RdmaChannel::Connect() {\n+    mu_.lock();\n+    CHECK(remote_set_) << \"remote channel is not set\";\n+    mu_.unlock();\n+    Connect(remote_);\n+}\n+\n+// Setup channel to a remote node\n+// Args:\n+//   remoteAddr: the rdma address of a remote channel.\n+// Returns:\n+//   None\n+void RdmaChannel::Connect(RdmaAddress& remoteAddr) {\n+  mu_.lock();\n+  if (!connected_) {\n+    struct ibv_qp_attr attr;\n+    memset(&attr, 0, sizeof(ibv_qp_attr));\n+    attr.qp_state = IBV_QPS_RTR;\n+    attr.path_mtu = IBV_MTU_4096;\n+    attr.dest_qp_num = remoteAddr.qpn;\n+    attr.rq_psn = remoteAddr.psn;\n+    attr.max_dest_rd_atomic = 1;\n+    attr.min_rnr_timer = 12;\n+    attr.ah_attr.is_global = 0;\n+    attr.ah_attr.dlid = remoteAddr.lid;\n+    attr.ah_attr.sl = 0;\n+    attr.ah_attr.src_path_bits = 0;\n+    attr.ah_attr.port_num = 1;\n+  \n+    int r;\n+    CHECK(!(r = ibv_modify_qp(qp_, &attr,\n+                IBV_QP_STATE |\n+                IBV_QP_AV |\n+                IBV_QP_PATH_MTU |\n+                IBV_QP_DEST_QPN |\n+                IBV_QP_RQ_PSN |\n+                IBV_QP_MAX_DEST_RD_ATOMIC |\n+                IBV_QP_MIN_RNR_TIMER))) << \"QP to Ready to Receive \" << r;\n+  \n+    memset(&attr, 0, sizeof(ibv_qp_attr));\n+    attr.qp_state = IBV_QPS_RTS;\n+    attr.sq_psn = self_.psn;\n+    attr.timeout = 14;\n+    attr.retry_cnt = 7;\n+    attr.rnr_retry = 7; /* infinite */\n+    attr.max_rd_atomic = 1;\n+  \n+    CHECK(!(r = ibv_modify_qp(qp_, &attr,\n+                IBV_QP_STATE |\n+                IBV_QP_TIMEOUT |\n+                IBV_QP_RETRY_CNT |\n+                IBV_QP_RNR_RETRY |\n+                IBV_QP_SQ_PSN |\n+                IBV_QP_MAX_QP_RD_ATOMIC))) << \"QP to Ready to Send \" << r;\n+    \n+    connected_ = true;\n+  } else {\n+    LOG(INFO) << \"channel already connected\";\n+  }\n+  mu_.unlock();\n+}\n+\n+RdmaBuffer::RdmaBuffer(RdmaChannel* channel, string name)\n+           : channel_(channel), name_(name) {}\n+\n+RdmaBuffer::~RdmaBuffer() {\n+  CHECK(!ibv_dereg_mr(self_)) << \"ibv_dereg_mr failed\";\n+  FreeBuffer();\n+}\n+\n+void RdmaBuffer::FreeBuffer() {\n+  if ((buffer_ != nullptr) && buffer_on_host_) {\n+    free(buffer_);\n+  } \n+  // TODO\n+  // release buffer if it is on device. \n+  // We don't support RDMABuffer on device at this moment.\n+}\n+\n+// Allocate CPU memory for the Rdma buffer\n+// Args:\n+//   size: to-be-allocated memory size\n+//   lock: whether or not mutex_lock the process to protect concurrency.\n+// Returns:\n+//   None\n+void RdmaBuffer::CreateCPUBuffer(size_t size, bool lock) {\n+  CHECK(size > 0);\n+  if (lock) {\n+    mu_.lock();\n+  }\n+  if (local_status_ != none) {\n+    // delete existing buffer\n+    CHECK(!ibv_dereg_mr(self_)) << \"ibv_dereg_mr failed\";\n+    FreeBuffer();    \n+  }\n+  size_ = size;\n+  buffer_ = malloc(size_);\n+  self_ = ibv_reg_mr(channel_->adapter_->pd_, \n+            buffer_, size_,\n+            IBV_ACCESS_LOCAL_WRITE | \n+            IBV_ACCESS_REMOTE_WRITE);\n+  CHECK(self_) << \"Failed to register memory region\";\n+  buffer_on_host_ = true;\n+  local_status_ = idle;\n+  if (lock) {\n+    mu_.unlock();\n+  }\n+}\n+\n+// Set address of remote memory region\n+// Args:\n+//   rmr: address of remote memory region\n+//   override: whether override existing information\n+// Returns:\n+//   None\n+void RdmaBuffer::SetRemoteMR(RemoteMR rmr, bool override) {\n+  mu_.lock();\n+  if ((override) || (remote_status_ == none)) { \n+    remote_.remote_addr = rmr.remote_addr;\n+    remote_.rkey = rmr.rkey;\n+    remote_status_ = idle;\n+  } else {\n+    CHECK(remote_.remote_addr == rmr.remote_addr);\n+    CHECK(remote_.rkey == rmr.rkey);  \n+  }\n+  mu_.unlock();  \n+}\n+\n+// Put a task in the buffer's job queue\n+void RdmaBuffer::EnqueueItem(string item){\n+  mu_.lock();\n+  queue_.push(item);\n+  mu_.unlock();\n+}\n+\n+// Rdma-Write the content of the buffer\n+void RdmaBuffer::Write(uint32_t imm_data, size_t buffer_size) {\n+  \n+  struct ibv_sge list;\n+  list.addr = (uint64_t) buffer_;\n+  list.length = buffer_size;\n+  list.lkey = self_->lkey;\n+\n+  struct ibv_send_wr wr;\n+  memset(&wr, 0, sizeof(wr));\n+  wr.wr_id = (uint64_t) this;\n+  wr.sg_list = &list;\n+  wr.num_sge = 1;\n+  wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;\n+  wr.send_flags = IBV_SEND_SIGNALED;\n+  wr.imm_data = imm_data;\n+  wr.wr.rdma.remote_addr = (uint64_t) remote_.remote_addr;\n+  wr.wr.rdma.rkey = remote_.rkey;\n+\n+  struct ibv_send_wr *bad_wr;\n+  CHECK(!ibv_post_send(channel_->qp_, &wr, &bad_wr)) << \"Failed to post send\";\n+}\n+\n+RdmaAckBuffer::RdmaAckBuffer(RdmaChannel* channel, string name)\n+           : RdmaBuffer(channel, name) {}\n+    \n+RdmaMessageBuffer::RdmaMessageBuffer(RdmaChannel* channel, string name)\n+           : RdmaBuffer(channel, name) {}\n+\n+RdmaTensorBuffer::RdmaTensorBuffer(RdmaChannel* channel, string name)\n+           : RdmaBuffer(channel, name) {}\n+\n+// Send the next ack from the buffer's job queue.\n+void RdmaAckBuffer::SendNextItem() {\n+  uint32_t imm_data = LookupBufferIndex(\"rx_ack_buffer\");\n+  RdmaMessage rm;\n+  rm.name_ = \"rx_ack_buffer\";\n+  rm.type_ = RDMA_MESSAGE_ACK;\n+  rm.name_size_ = rm.name_.size();\n+  string message = RdmaMessage::CreateMessage(rm);\n+  memcpy(buffer_, message.data(), message.size());\n+  Write(imm_data, message.size());\n+}\n+\n+// Send the next message from the buffer's job queue.\n+void RdmaMessageBuffer::SendNextItem() {\n+  uint32_t imm_data = LookupBufferIndex(\"rx_message_buffer\");\n+  mu_.lock();\n+  if (!queue_.empty() && (local_status_ == idle) \n+          && (remote_status_ == idle)) {\n+    local_status_ = busy;\n+    remote_status_= busy;    \n+    string message = queue_.front();\n+    queue_.pop();\n+    // local/remote_status_ won't be set back to idle \n+    // unitl Write() is successful\n+    mu_.unlock();\n+    memcpy(buffer_, message.data(), message.size());\n+    Write(imm_data, message.size());\n+  } else {\n+    mu_.unlock();\n+  }\n+}\n+\n+// Send the next tensor from the buffer's job queue.\n+void RdmaTensorBuffer::SendNextItem() {\n+  // get the key\n+  string key_with_step_id = \"\";\n+  mu_.lock();\n+  if (!queue_.empty()) {\n+    key_with_step_id = queue_.front();\n+    queue_.pop();\n+  }\n+  mu_.unlock();\n+  // send the tensor if a key is acquired.\n+  if (key_with_step_id != \"\") {\n+    VLOG(2) << \"try to send tensor: \" << key_with_step_id; \n+    string key;\n+    int64 step_id;\n+    VerbsUtil::GetKeyAndStepId(key_with_step_id, key, step_id);\n+    CHECK(key.compare(name_) == 0);\n+    Rendezvous::ParsedKey parsed;\n+    Rendezvous::ParseKey(key, &parsed);\n+    Rendezvous::DoneCallback cb = [this, key_with_step_id, key, \n+      step_id, parsed](const Status& status,\n+                       const Rendezvous::Args& send_args,\n+                       const Rendezvous::Args& recv_args,\n+                       const Tensor& in, bool is_dead) {\n+      CHECK(status.ok()) << \"RecvLocalAsync was not ok, key\"\n+              << key_with_step_id\n+              << \" error message: \" << status.error_message();\n+      size_t buffer_size = RdmaMessage::kMessageTotalBytes;\n+      size_t tensor_bytes = 0;\n+      TensorProto proto;\n+      // Figures out which device the tensor is hosted on.\n+      Device* src_dev = nullptr;\n+      Status s = \n+        channel_->adapter_->worker_env_->\n+              device_mgr->LookupDevice(parsed.src_device, &src_dev);\n+      CHECK(s.ok()) << \"src device not found\";\n+      // Does the device have the right incarnation number we expect?\n+      CHECK(src_dev->attributes().incarnation() == \n+              parsed.src_incarnation)\n+            << \"RecvTensor expects a different device incarnation: \"\n+            <<  parsed.src_incarnation\n+            << \" vs. \"\n+            << src_dev->attributes().incarnation()\n+            << \". Your worker job was probably restarted. Check your \"\n+            << \"worker job for the reason why it was restarted.\";  \n+      Device* dst_dev = nullptr;\n+      // destination is on CPU.\n+      s = channel_->adapter_->worker_env_->\n+              device_mgr->LookupDevice(\"CPU:0\", &dst_dev);\n+      CHECK(s.ok())<< \"dst device not found\";\n+      AllocatorAttributes dst_alloc_attr;\n+      dst_alloc_attr.set_on_host(true);\n+      // string tensor needs to be serialized\n+      if (src_dev->tensorflow_gpu_device_info() && \n+              (!send_args.alloc_attrs.on_host())) {\n+        CHECK(send_args.device_context)\n+            << \"send dev name: \" << src_dev->name()\n+            << \" gpu_info: \" << src_dev->tensorflow_gpu_device_info();\n+        // \"val\" is on a GPU. Uses GPUUtil to fill the proto.\n+        s = VerbsUtil::SetProtoFromGPUSync(in, src_dev, ", "path": "tensorflow/contrib/verbs/rdma.cc", "position": 715, "original_position": 714, "commit_id": "b5581b2ffb75b98561f64fc6d0a72d40680d8723", "original_commit_id": "ed6a8d6cd51fd5b97a95b1682b805b2d63564126", "user": {"login": "junshi15", "id": 12075848, "node_id": "MDQ6VXNlcjEyMDc1ODQ4", "avatar_url": "https://avatars3.githubusercontent.com/u/12075848?v=4", "gravatar_id": "", "url": "https://api.github.com/users/junshi15", "html_url": "https://github.com/junshi15", "followers_url": "https://api.github.com/users/junshi15/followers", "following_url": "https://api.github.com/users/junshi15/following{/other_user}", "gists_url": "https://api.github.com/users/junshi15/gists{/gist_id}", "starred_url": "https://api.github.com/users/junshi15/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/junshi15/subscriptions", "organizations_url": "https://api.github.com/users/junshi15/orgs", "repos_url": "https://api.github.com/users/junshi15/repos", "events_url": "https://api.github.com/users/junshi15/events{/privacy}", "received_events_url": "https://api.github.com/users/junshi15/received_events", "type": "User", "site_admin": false}, "body": "In theory, it can. will optimize in a future revision.", "created_at": "2017-04-07T08:20:36Z", "updated_at": "2017-04-10T19:22:04Z", "html_url": "https://github.com/tensorflow/tensorflow/pull/8943#discussion_r110339081", "pull_request_url": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8943", "author_association": "CONTRIBUTOR", "_links": {"self": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/comments/110339081"}, "html": {"href": "https://github.com/tensorflow/tensorflow/pull/8943#discussion_r110339081"}, "pull_request": {"href": "https://api.github.com/repos/tensorflow/tensorflow/pulls/8943"}}, "body_html": "<p>In theory, it can. will optimize in a future revision.</p>", "body_text": "In theory, it can. will optimize in a future revision.", "in_reply_to_id": 110012002}