{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20068", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20068/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20068/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20068/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20068", "id": 332917844, "node_id": "MDU6SXNzdWUzMzI5MTc4NDQ=", "number": 20068, "title": "streaming data from google cloud storage to tensorflow input pipeline is slow", "user": {"login": "hbi-tianyi", "id": 33295291, "node_id": "MDQ6VXNlcjMzMjk1Mjkx", "avatar_url": "https://avatars2.githubusercontent.com/u/33295291?v=4", "gravatar_id": "", "url": "https://api.github.com/users/hbi-tianyi", "html_url": "https://github.com/hbi-tianyi", "followers_url": "https://api.github.com/users/hbi-tianyi/followers", "following_url": "https://api.github.com/users/hbi-tianyi/following{/other_user}", "gists_url": "https://api.github.com/users/hbi-tianyi/gists{/gist_id}", "starred_url": "https://api.github.com/users/hbi-tianyi/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/hbi-tianyi/subscriptions", "organizations_url": "https://api.github.com/users/hbi-tianyi/orgs", "repos_url": "https://api.github.com/users/hbi-tianyi/repos", "events_url": "https://api.github.com/users/hbi-tianyi/events{/privacy}", "received_events_url": "https://api.github.com/users/hbi-tianyi/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "saeta", "id": 1284535, "node_id": "MDQ6VXNlcjEyODQ1MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1284535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saeta", "html_url": "https://github.com/saeta", "followers_url": "https://api.github.com/users/saeta/followers", "following_url": "https://api.github.com/users/saeta/following{/other_user}", "gists_url": "https://api.github.com/users/saeta/gists{/gist_id}", "starred_url": "https://api.github.com/users/saeta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saeta/subscriptions", "organizations_url": "https://api.github.com/users/saeta/orgs", "repos_url": "https://api.github.com/users/saeta/repos", "events_url": "https://api.github.com/users/saeta/events{/privacy}", "received_events_url": "https://api.github.com/users/saeta/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "saeta", "id": 1284535, "node_id": "MDQ6VXNlcjEyODQ1MzU=", "avatar_url": "https://avatars1.githubusercontent.com/u/1284535?v=4", "gravatar_id": "", "url": "https://api.github.com/users/saeta", "html_url": "https://github.com/saeta", "followers_url": "https://api.github.com/users/saeta/followers", "following_url": "https://api.github.com/users/saeta/following{/other_user}", "gists_url": "https://api.github.com/users/saeta/gists{/gist_id}", "starred_url": "https://api.github.com/users/saeta/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/saeta/subscriptions", "organizations_url": "https://api.github.com/users/saeta/orgs", "repos_url": "https://api.github.com/users/saeta/repos", "events_url": "https://api.github.com/users/saeta/events{/privacy}", "received_events_url": "https://api.github.com/users/saeta/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 4, "created_at": "2018-06-15T21:22:26Z", "updated_at": "2018-10-03T21:26:18Z", "closed_at": "2018-10-03T16:37:57Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:<br>\nUbuntu 16.04 and MacOS High Sierra 10.13.4</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: docker and virtualenv</li>\n<li><strong>TensorFlow version (use command below)</strong>: v1.8.0-0-g93bc2e2072</li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>: N/A</li>\n</ul>\n<p>Describe the problem:<br>\nMy data is stored on google cloud storage (millions of small audios); my tensorflow input pipeline sample code is below.</p>\n<p>tf.data.Dataset.from_generator(generator_filename_func).<br>\nmap(signal_processing_func, num_parallel_calls=CPU_NUM).<br>\nbatch(100).<br>\nmake_one_shot_iterator()</p>\n<p>The pipeline starts with a generator (a generator that generates audio filenames from google cloud storage); then run signal processing with map function and multithread.</p>\n<p>The input pipeline is fast when reading data from local disk (download audios to cloud compute engine VM), however, reading data from mounted folder (mount google cloud storage to the folder with gcsfuse command) is slow (about 5-10 times slower). I know google cloud supports using python multithread to read data, but it does not seem to be compatible with tensorflow input pipeline. I also tried google.cloud.storage to stream data, it's also very slow for small files. How should I stream data from google cloud storage to tensorflow input pipeline with low latency? What tools/library is recommended and compatible with tensorflow input pipeline?</p>\n<p>The other weird thing is that the pipeline speed does not change much as I add more CPU and SSD. I believe the bottleneck is reading files, how can I optimize reading many small files in the tensorflow input pipeline?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nUbuntu 16.04 and MacOS High Sierra 10.13.4\nTensorFlow installed from (source or binary): docker and virtualenv\nTensorFlow version (use command below): v1.8.0-0-g93bc2e2072\nPython version: 2.7.12\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce: N/A\n\nDescribe the problem:\nMy data is stored on google cloud storage (millions of small audios); my tensorflow input pipeline sample code is below.\ntf.data.Dataset.from_generator(generator_filename_func).\nmap(signal_processing_func, num_parallel_calls=CPU_NUM).\nbatch(100).\nmake_one_shot_iterator()\nThe pipeline starts with a generator (a generator that generates audio filenames from google cloud storage); then run signal processing with map function and multithread.\nThe input pipeline is fast when reading data from local disk (download audios to cloud compute engine VM), however, reading data from mounted folder (mount google cloud storage to the folder with gcsfuse command) is slow (about 5-10 times slower). I know google cloud supports using python multithread to read data, but it does not seem to be compatible with tensorflow input pipeline. I also tried google.cloud.storage to stream data, it's also very slow for small files. How should I stream data from google cloud storage to tensorflow input pipeline with low latency? What tools/library is recommended and compatible with tensorflow input pipeline?\nThe other weird thing is that the pipeline speed does not change much as I add more CPU and SSD. I believe the bottleneck is reading files, how can I optimize reading many small files in the tensorflow input pipeline?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04 and MacOS High Sierra 10.13.4\r\n- **TensorFlow installed from (source or binary)**: docker and virtualenv\r\n- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: N/A\r\n\r\nDescribe the problem:\r\nMy data is stored on google cloud storage (millions of small audios); my tensorflow input pipeline sample code is below.\r\n \r\ntf.data.Dataset.from_generator(generator_filename_func).\\\r\nmap(signal_processing_func, num_parallel_calls=CPU_NUM).\\\r\nbatch(100).\\\r\nmake_one_shot_iterator()\r\n\r\nThe pipeline starts with a generator (a generator that generates audio filenames from google cloud storage); then run signal processing with map function and multithread. \r\n\r\nThe input pipeline is fast when reading data from local disk (download audios to cloud compute engine VM), however, reading data from mounted folder (mount google cloud storage to the folder with gcsfuse command) is slow (about 5-10 times slower). I know google cloud supports using python multithread to read data, but it does not seem to be compatible with tensorflow input pipeline. I also tried google.cloud.storage to stream data, it's also very slow for small files. How should I stream data from google cloud storage to tensorflow input pipeline with low latency? What tools/library is recommended and compatible with tensorflow input pipeline?\r\n\r\nThe other weird thing is that the pipeline speed does not change much as I add more CPU and SSD. I believe the bottleneck is reading files, how can I optimize reading many small files in the tensorflow input pipeline?\r\n\r\n"}