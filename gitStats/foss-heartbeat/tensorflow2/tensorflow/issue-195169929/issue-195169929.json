{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6274", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6274/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6274/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/6274/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/6274", "id": 195169929, "node_id": "MDU6SXNzdWUxOTUxNjk5Mjk=", "number": 6274, "title": "seq2seq checkpoints not working", "user": {"login": "jrthom18", "id": 9363452, "node_id": "MDQ6VXNlcjkzNjM0NTI=", "avatar_url": "https://avatars0.githubusercontent.com/u/9363452?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jrthom18", "html_url": "https://github.com/jrthom18", "followers_url": "https://api.github.com/users/jrthom18/followers", "following_url": "https://api.github.com/users/jrthom18/following{/other_user}", "gists_url": "https://api.github.com/users/jrthom18/gists{/gist_id}", "starred_url": "https://api.github.com/users/jrthom18/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jrthom18/subscriptions", "organizations_url": "https://api.github.com/users/jrthom18/orgs", "repos_url": "https://api.github.com/users/jrthom18/repos", "events_url": "https://api.github.com/users/jrthom18/events{/privacy}", "received_events_url": "https://api.github.com/users/jrthom18/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 1, "created_at": "2016-12-13T06:05:46Z", "updated_at": "2016-12-14T01:33:51Z", "closed_at": "2016-12-14T01:33:51Z", "author_association": "NONE", "body_html": "<p>I am seeing abnormal behavior when I train seq2seq...there are 3 checkpoint files being generated at each checkpoint i.e.:</p>\n<ul>\n<li>seq2seq.ckpt-300.data-00000-of-00001</li>\n<li>seq2seq.ckpt-300.index</li>\n<li>seq2seq.ckpt-300.meta</li>\n</ul>\n<p>Training seems to progress normally with no errors but when I pause training and try to resume or test from the last checkpoint, a model with fresh parameters is created and my training is rendered useless.</p>\n<p>UPDATE:<br>\nInitializing tf.train.Saver() with write_version=1 to revert back to the deprecated version appears to have fixed the problem. Now I see that only two files are created at each checkpoint i.e.:</p>\n<ul>\n<li>seq2seq.ckpt-300</li>\n<li>seq2seq.ckpt-300.meta</li>\n</ul>\n<p>Obviously this would suggest something is going on with the new write version...any ideas?</p>\n<p><strong>UPDATE:</strong><br>\nThe problem is referenced and solved here: <a href=\"http://stackoverflow.com/questions/40469553/tensorflow-loading-model-with-saver-v2\" rel=\"nofollow\">http://stackoverflow.com/questions/40469553/tensorflow-loading-model-with-saver-v2</a></p>", "body_text": "I am seeing abnormal behavior when I train seq2seq...there are 3 checkpoint files being generated at each checkpoint i.e.:\n\nseq2seq.ckpt-300.data-00000-of-00001\nseq2seq.ckpt-300.index\nseq2seq.ckpt-300.meta\n\nTraining seems to progress normally with no errors but when I pause training and try to resume or test from the last checkpoint, a model with fresh parameters is created and my training is rendered useless.\nUPDATE:\nInitializing tf.train.Saver() with write_version=1 to revert back to the deprecated version appears to have fixed the problem. Now I see that only two files are created at each checkpoint i.e.:\n\nseq2seq.ckpt-300\nseq2seq.ckpt-300.meta\n\nObviously this would suggest something is going on with the new write version...any ideas?\nUPDATE:\nThe problem is referenced and solved here: http://stackoverflow.com/questions/40469553/tensorflow-loading-model-with-saver-v2", "body": "I am seeing abnormal behavior when I train seq2seq...there are 3 checkpoint files being generated at each checkpoint i.e.:\r\n- seq2seq.ckpt-300.data-00000-of-00001 \r\n- seq2seq.ckpt-300.index\r\n- seq2seq.ckpt-300.meta\r\n\r\nTraining seems to progress normally with no errors but when I pause training and try to resume or test from the last checkpoint, a model with fresh parameters is created and my training is rendered useless. \r\n\r\nUPDATE:\r\nInitializing tf.train.Saver() with write_version=1 to revert back to the deprecated version appears to have fixed the problem. Now I see that only two files are created at each checkpoint i.e.:\r\n- seq2seq.ckpt-300\r\n- seq2seq.ckpt-300.meta\r\n\r\nObviously this would suggest something is going on with the new write version...any ideas?\r\n\r\n**UPDATE:**\r\nThe problem is referenced and solved here: http://stackoverflow.com/questions/40469553/tensorflow-loading-model-with-saver-v2"}