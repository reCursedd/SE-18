{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/322596468", "html_url": "https://github.com/tensorflow/tensorflow/issues/12186#issuecomment-322596468", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12186", "id": 322596468, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjU5NjQ2OA==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-15T21:34:58Z", "updated_at": "2017-08-15T21:34:58Z", "author_association": "MEMBER", "body_html": "<p>You can tell becuase you see the configs information.  _User settings:</p>\n<p>KMP_AFFINITY=granularity=fine,verbose,compact,1,0<br>\nKMP_BLOCKTIME=30<br>\nKMP_SETTINGS=1<br>\nOMP_NUM_THREADS=288</p>\n<p>You should try multiple settings.  The Errors and Warning are fine.  So if I am not mistaken you have<br>\n1 Xeon Phi with 72 cores.  (You said 288 logical which is why I guessed you had 2 cards for 144 cores and 288 logical)</p>\n<p>Given your number of cores you need to back down the number of threads.  For inception3 you should be doing, I am not sure why you set the BLOCK_TIME=2 but it ended up being set to 30 and should be 0 for inception3:</p>\n<p><code>KMP_SETTINGS=1 KMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 OMP_NUM_THREADS=72 python tf_cnn_benchmarks.py --model=inception3 --batch_size=128 --num_inter_threads=1 --num_intra_threads=72 --device=cpu --variable_update=parameter_server --local_parameter_device=cpu</code></p>\n<p>And if you are training real data you might back the threads down to ~60.  I have not tested on PHi but that is the advice in the article Intel wrong and you can see the same in setenv.</p>\n<p>For reference I get <strong>21 images/sec</strong> batch_size=32 running a similar script training inception3 on<br>\n2x Intel Xeon E5-2686 v4 on AWS r4.16xlarge, which would be 36 physical cores total if I remember correctly and not really comparable to the PHi.</p>\n<p>If you are not seeing the KMP_BLOCKTIME you set showing up in the debug info then you may want to check how you typed it or consider just commenting out this line in the script as you are setting these on your own.  <a href=\"https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks_MKL.py#L1318\">https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks_MKL.py#L1318</a></p>", "body_text": "You can tell becuase you see the configs information.  _User settings:\nKMP_AFFINITY=granularity=fine,verbose,compact,1,0\nKMP_BLOCKTIME=30\nKMP_SETTINGS=1\nOMP_NUM_THREADS=288\nYou should try multiple settings.  The Errors and Warning are fine.  So if I am not mistaken you have\n1 Xeon Phi with 72 cores.  (You said 288 logical which is why I guessed you had 2 cards for 144 cores and 288 logical)\nGiven your number of cores you need to back down the number of threads.  For inception3 you should be doing, I am not sure why you set the BLOCK_TIME=2 but it ended up being set to 30 and should be 0 for inception3:\nKMP_SETTINGS=1 KMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 OMP_NUM_THREADS=72 python tf_cnn_benchmarks.py --model=inception3 --batch_size=128 --num_inter_threads=1 --num_intra_threads=72 --device=cpu --variable_update=parameter_server --local_parameter_device=cpu\nAnd if you are training real data you might back the threads down to ~60.  I have not tested on PHi but that is the advice in the article Intel wrong and you can see the same in setenv.\nFor reference I get 21 images/sec batch_size=32 running a similar script training inception3 on\n2x Intel Xeon E5-2686 v4 on AWS r4.16xlarge, which would be 36 physical cores total if I remember correctly and not really comparable to the PHi.\nIf you are not seeing the KMP_BLOCKTIME you set showing up in the debug info then you may want to check how you typed it or consider just commenting out this line in the script as you are setting these on your own.  https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks_MKL.py#L1318", "body": "You can tell becuase you see the configs information.  _User settings:\r\n\r\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\r\n   KMP_BLOCKTIME=30\r\n   KMP_SETTINGS=1\r\n   OMP_NUM_THREADS=288\r\n\r\nYou should try multiple settings.  The Errors and Warning are fine.  So if I am not mistaken you have \r\n1 Xeon Phi with 72 cores.  (You said 288 logical which is why I guessed you had 2 cards for 144 cores and 288 logical)\r\n\r\nGiven your number of cores you need to back down the number of threads.  For inception3 you should be doing, I am not sure why you set the BLOCK_TIME=2 but it ended up being set to 30 and should be 0 for inception3:\r\n\r\n`KMP_SETTINGS=1 KMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 OMP_NUM_THREADS=72 python tf_cnn_benchmarks.py --model=inception3 --batch_size=128 --num_inter_threads=1 --num_intra_threads=72 --device=cpu --variable_update=parameter_server --local_parameter_device=cpu`\r\n\r\nAnd if you are training real data you might back the threads down to ~60.  I have not tested on PHi but that is the advice in the article Intel wrong and you can see the same in setenv.\r\n\r\nFor reference I get **21 images/sec** batch_size=32 running a similar script training inception3 on \r\n2x Intel Xeon E5-2686 v4 on AWS r4.16xlarge, which would be 36 physical cores total if I remember correctly and not really comparable to the PHi.\r\n\r\nIf you are not seeing the KMP_BLOCKTIME you set showing up in the debug info then you may want to check how you typed it or consider just commenting out this line in the script as you are setting these on your own.  https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks_MKL.py#L1318\r\n\r\n\r\n\r\n\r\n"}