{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/322538396", "html_url": "https://github.com/tensorflow/tensorflow/issues/12186#issuecomment-322538396", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12186", "id": 322538396, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjUzODM5Ng==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-15T17:48:20Z", "updated_at": "2017-08-15T17:48:20Z", "author_association": "MEMBER", "body_html": "<p>The MKL script is in my personal repo.  I am trying to make time to add some of the Flags to the main benchmark code.  To answer your question in a few ways:</p>\n<p>On the <a href=\"https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture\" rel=\"nofollow\">Intel blog</a> they list out the settings that they used.  I have only tested on Xeon Broadwell as I do not have access to Phi, but between their article and my testing I am confident I can get you in the right direction:</p>\n<ul>\n<li>For Xeon Phi you will want to set inter_op = the number of Physical CPUs (likely 1 or 2) and set intra_op = either the number physical or logical cores in your case 144 or 288.  Their testing showed the best option depends on the model.  You can also use this <a href=\"https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/setenvs.py\">document</a> for reference.  In their scrit 'knl' referse to knights landing and they tested with 68 physical cores.</li>\n</ul>\n<p>You want to set the intra_op = to whatever you use for the OMP_NUM_THREADS.</p>\n<p>So for example if you want to test with tf_cnn_benchmarks.py and test resnet50 you would run this command assuming you are using 2 Xeon Phis with 72 physical cores each for a total of 288 logical cores and 144 physical.  I am typing this from memory so you may need to fix some typos:</p>\n<p><code>KMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 OMP_NUM_THREADS=288 python tf_cnn_benchmarks.py --model=resnet50 --batch_size=128 --num_inter_threads=2 --num_intra_threads=288 --device=cpu --variable_update=parameter_server --local_parameter_device=cpu</code></p>\n<p>All of those fields may not be needed but I like to be specific and avoid the defaults so when I share the command line there is less ambiguity.</p>\n<p>If you are using real data Intel suggested OMP_NUM_THREADS= 50 for 68 physical cores.  In your setup you could try 144 (total physical cores) or something slightly smaller to match what Intel was testing and use 120 or so and see what happens.  What I like to do is setup a script and run the test for 100 steps 5 times for a variety of options to get a feel for the pros and cons of each settings.</p>\n<p>Let me know your results and if you get something similar to Intel's.</p>", "body_text": "The MKL script is in my personal repo.  I am trying to make time to add some of the Flags to the main benchmark code.  To answer your question in a few ways:\nOn the Intel blog they list out the settings that they used.  I have only tested on Xeon Broadwell as I do not have access to Phi, but between their article and my testing I am confident I can get you in the right direction:\n\nFor Xeon Phi you will want to set inter_op = the number of Physical CPUs (likely 1 or 2) and set intra_op = either the number physical or logical cores in your case 144 or 288.  Their testing showed the best option depends on the model.  You can also use this document for reference.  In their scrit 'knl' referse to knights landing and they tested with 68 physical cores.\n\nYou want to set the intra_op = to whatever you use for the OMP_NUM_THREADS.\nSo for example if you want to test with tf_cnn_benchmarks.py and test resnet50 you would run this command assuming you are using 2 Xeon Phis with 72 physical cores each for a total of 288 logical cores and 144 physical.  I am typing this from memory so you may need to fix some typos:\nKMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 OMP_NUM_THREADS=288 python tf_cnn_benchmarks.py --model=resnet50 --batch_size=128 --num_inter_threads=2 --num_intra_threads=288 --device=cpu --variable_update=parameter_server --local_parameter_device=cpu\nAll of those fields may not be needed but I like to be specific and avoid the defaults so when I share the command line there is less ambiguity.\nIf you are using real data Intel suggested OMP_NUM_THREADS= 50 for 68 physical cores.  In your setup you could try 144 (total physical cores) or something slightly smaller to match what Intel was testing and use 120 or so and see what happens.  What I like to do is setup a script and run the test for 100 steps 5 times for a variety of options to get a feel for the pros and cons of each settings.\nLet me know your results and if you get something similar to Intel's.", "body": "The MKL script is in my personal repo.  I am trying to make time to add some of the Flags to the main benchmark code.  To answer your question in a few ways:\r\n\r\nOn the [Intel blog](https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture) they list out the settings that they used.  I have only tested on Xeon Broadwell as I do not have access to Phi, but between their article and my testing I am confident I can get you in the right direction:\r\n-  For Xeon Phi you will want to set inter_op = the number of Physical CPUs (likely 1 or 2) and set intra_op = either the number physical or logical cores in your case 144 or 288.  Their testing showed the best option depends on the model.  You can also use this [document](https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/setenvs.py) for reference.  In their scrit 'knl' referse to knights landing and they tested with 68 physical cores.  \r\n\r\nYou want to set the intra_op = to whatever you use for the OMP_NUM_THREADS. \r\n\r\nSo for example if you want to test with tf_cnn_benchmarks.py and test resnet50 you would run this command assuming you are using 2 Xeon Phis with 72 physical cores each for a total of 288 logical cores and 144 physical.  I am typing this from memory so you may need to fix some typos:\r\n\r\n`KMP_BLOCKTIME=0 KMP_AFFINITY=granularity=fine,verbose,compact,1,0 OMP_NUM_THREADS=288 python tf_cnn_benchmarks.py --model=resnet50 --batch_size=128 --num_inter_threads=2 --num_intra_threads=288 --device=cpu --variable_update=parameter_server --local_parameter_device=cpu`\r\n\r\nAll of those fields may not be needed but I like to be specific and avoid the defaults so when I share the command line there is less ambiguity.  \r\n\r\nIf you are using real data Intel suggested OMP_NUM_THREADS= 50 for 68 physical cores.  In your setup you could try 144 (total physical cores) or something slightly smaller to match what Intel was testing and use 120 or so and see what happens.  What I like to do is setup a script and run the test for 100 steps 5 times for a variety of options to get a feel for the pros and cons of each settings.  \r\n\r\nLet me know your results and if you get something similar to Intel's.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"}