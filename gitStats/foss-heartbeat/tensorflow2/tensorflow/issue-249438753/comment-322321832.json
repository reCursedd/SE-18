{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/322321832", "html_url": "https://github.com/tensorflow/tensorflow/issues/12186#issuecomment-322321832", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/12186", "id": 322321832, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMjMyMTgzMg==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-14T22:00:29Z", "updated_at": "2017-08-14T22:00:29Z", "author_association": "MEMBER", "body_html": "<p>This may be the same person as on tensorflow-discuss, which is great and I am pasting the same response.</p>\n<p>A few things to help get you started.</p>\n<ul>\n<li>You will want to compile with the MKL to get the most our ot Xeon Phi</li>\n<li>You will need to set the MKL env flags</li>\n<li>You will need to set the num_inter_threads and num_intra_threads flags on the tf_cnn_benchmark.</li>\n<li>For MKL you want to use data_format=NCHW (which will not work if MKL is not compiled in).</li>\n</ul>\n<p>I will try to followup with you again but if I do not here is an example:</p>\n<ul>\n<li><a href=\"https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks_MKL.py\">tf_cnn_benchmarks.py </a> with some code changes to be slightly more optimized for the MKL  (I have PR to make it easier to set MKL env vars in our script but have not had time to get it approved and this link is better than nothing)</li>\n<li>This file sets the ENV vars for common models: <a href=\"https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/setenvs.py\">https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/setenvs.py</a></li>\n</ul>\n<p>To compile MKL from head I believe you now you only need to do <code>blaze --config=mkl</code>.  We have been working to simplify it but I believe that now works.  Previously (1.2.1) you had to answer a few questions in ./configure.  If you want to just try a pre-compiled version here is a link to a binary I created.  I make ZERO promises in regard to the binary.</p>\n<p><a href=\"https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.2.0.tag.12f033d.MKL_NOGPU-cp27-cp27mu-linux_x86_64.whl\" rel=\"nofollow\">https://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.2.0.tag.12f033d.MKL_NOGPU-cp27-cp27mu-linux_x86_64.whl</a></p>\n<p>That should get you started.  Intel published some <a href=\"https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture\" rel=\"nofollow\">benchmark numbers</a> that you can use to see if you are on the right track.</p>\n<p>Sorry for the sloppy response, I felt giving you the information in a non-professional structure was better than not responding.  Good luck and ping this thread if you have questions.</p>", "body_text": "This may be the same person as on tensorflow-discuss, which is great and I am pasting the same response.\nA few things to help get you started.\n\nYou will want to compile with the MKL to get the most our ot Xeon Phi\nYou will need to set the MKL env flags\nYou will need to set the num_inter_threads and num_intra_threads flags on the tf_cnn_benchmark.\nFor MKL you want to use data_format=NCHW (which will not work if MKL is not compiled in).\n\nI will try to followup with you again but if I do not here is an example:\n\ntf_cnn_benchmarks.py  with some code changes to be slightly more optimized for the MKL  (I have PR to make it easier to set MKL env vars in our script but have not had time to get it approved and this link is better than nothing)\nThis file sets the ENV vars for common models: https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/setenvs.py\n\nTo compile MKL from head I believe you now you only need to do blaze --config=mkl.  We have been working to simplify it but I believe that now works.  Previously (1.2.1) you had to answer a few questions in ./configure.  If you want to just try a pre-compiled version here is a link to a binary I created.  I make ZERO promises in regard to the binary.\nhttps://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.2.0.tag.12f033d.MKL_NOGPU-cp27-cp27mu-linux_x86_64.whl\nThat should get you started.  Intel published some benchmark numbers that you can use to see if you are on the right track.\nSorry for the sloppy response, I felt giving you the information in a non-professional structure was better than not responding.  Good luck and ping this thread if you have questions.", "body": "This may be the same person as on tensorflow-discuss, which is great and I am pasting the same response.\r\n\r\nA few things to help get you started.\r\n\r\n- You will want to compile with the MKL to get the most our ot Xeon Phi\r\n- You will need to set the MKL env flags\r\n- You will need to set the num_inter_threads and num_intra_threads flags on the tf_cnn_benchmark.\r\n- For MKL you want to use data_format=NCHW (which will not work if MKL is not compiled in).\r\n\r\nI will try to followup with you again but if I do not here is an example:\r\n\r\n- [tf_cnn_benchmarks.py ](https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks_MKL.py) with some code changes to be slightly more optimized for the MKL  (I have PR to make it easier to set MKL env vars in our script but have not had time to get it approved and this link is better than nothing)\r\n- This file sets the ENV vars for common models: https://github.com/tfboyd/benchmarks/blob/mkl/scripts/tf_cnn_benchmarks/setenvs.py\r\n\r\nTo compile MKL from head I believe you now you only need to do `blaze --config=mkl`.  We have been working to simplify it but I believe that now works.  Previously (1.2.1) you had to answer a few questions in ./configure.  If you want to just try a pre-compiled version here is a link to a binary I created.  I make ZERO promises in regard to the binary.  \r\n\r\nhttps://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.2.0.tag.12f033d.MKL_NOGPU-cp27-cp27mu-linux_x86_64.whl\r\n\r\nThat should get you started.  Intel published some [benchmark numbers](https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture) that you can use to see if you are on the right track. \r\n\r\nSorry for the sloppy response, I felt giving you the information in a non-professional structure was better than not responding.  Good luck and ping this thread if you have questions."}