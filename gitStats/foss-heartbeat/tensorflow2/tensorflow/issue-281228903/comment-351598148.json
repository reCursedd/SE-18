{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/351598148", "html_url": "https://github.com/tensorflow/tensorflow/issues/15288#issuecomment-351598148", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/15288", "id": 351598148, "node_id": "MDEyOklzc3VlQ29tbWVudDM1MTU5ODE0OA==", "user": {"login": "asimshankar", "id": 16018, "node_id": "MDQ6VXNlcjE2MDE4", "avatar_url": "https://avatars2.githubusercontent.com/u/16018?v=4", "gravatar_id": "", "url": "https://api.github.com/users/asimshankar", "html_url": "https://github.com/asimshankar", "followers_url": "https://api.github.com/users/asimshankar/followers", "following_url": "https://api.github.com/users/asimshankar/following{/other_user}", "gists_url": "https://api.github.com/users/asimshankar/gists{/gist_id}", "starred_url": "https://api.github.com/users/asimshankar/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/asimshankar/subscriptions", "organizations_url": "https://api.github.com/users/asimshankar/orgs", "repos_url": "https://api.github.com/users/asimshankar/repos", "events_url": "https://api.github.com/users/asimshankar/events{/privacy}", "received_events_url": "https://api.github.com/users/asimshankar/received_events", "type": "User", "site_admin": false}, "created_at": "2017-12-14T03:28:38Z", "updated_at": "2017-12-14T03:29:08Z", "author_association": "MEMBER", "body_html": "<p>Thanks for sharing the code, this helps.</p>\n<p>I noticed one big issue with the code you provided - the inputs are numpy arrays (which are necessarily in host memory) and so in each call to <code>tf.matmul</code> (with eager execution enabled) you're including the cost of (synchronously and serially) copying the input tensors from CPU to GPU memory. That cost is likely dominating (and increases with size). I'm not entirely sure about the variance, but the absolute numbers seem really high for all cases.</p>\n<p>Here is a simpler benchmark which I think is doing what you're trying to, along with results on my machine (which appears to have the same Titan X Pascal GPU):</p>\n<div class=\"highlight highlight-source-python\"><pre><span class=\"pl-k\">import</span> tensorflow <span class=\"pl-k\">as</span> tf\n<span class=\"pl-k\">import</span> tensorflow.contrib.eager <span class=\"pl-k\">as</span> tfe\n<span class=\"pl-k\">import</span> time\n\ntfe.enable_eager_execution()\n\n<span class=\"pl-k\">def</span> <span class=\"pl-en\">run</span>(<span class=\"pl-smi\">size</span>):\n  <span class=\"pl-k\">with</span> tf.device(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/gpu:0<span class=\"pl-pds\">'</span></span>):\n    a <span class=\"pl-k\">=</span> tf.random_uniform([size, size])\n    b <span class=\"pl-k\">=</span> tf.random_uniform([size, size])\n    <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Size: <span class=\"pl-pds\">'</span></span>, a.shape)\n    <span class=\"pl-k\">for</span> i <span class=\"pl-k\">in</span> <span class=\"pl-c1\">range</span>(<span class=\"pl-c1\">5</span>):\n      start <span class=\"pl-k\">=</span> time.time() \n      tf.matmul(a, b)\n      <span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>Runtime is <span class=\"pl-c1\">%2.5f</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">%</span> (time.time() <span class=\"pl-k\">-</span> start))\n\n<span class=\"pl-c1\">print</span>(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>One warmup run to account for GPU initialization<span class=\"pl-pds\">'</span></span>)\nrun(<span class=\"pl-c1\">10</span>)\n<span class=\"pl-k\">for</span> p <span class=\"pl-k\">in</span> [<span class=\"pl-c1\">500</span>, <span class=\"pl-c1\">1000</span>, <span class=\"pl-c1\">2000</span>, <span class=\"pl-c1\">5000</span>, <span class=\"pl-c1\">10000</span>]:\n  run(p)</pre></div>\n<p>Which results in:</p>\n<pre><code>One warmup run to account for GPU initialization\n2017-12-14 03:11:39.311967: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-12-14 03:11:39.619956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-12-14 03:11:39.620511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 0 with properties: \nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\npciBusID: 0000:02:00.0\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\n2017-12-14 03:11:39.799633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-12-14 03:11:39.800043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 1 with properties: \nname: Quadro K620 major: 5 minor: 0 memoryClockRate(GHz): 1.124\npciBusID: 0000:03:00.0\ntotalMemory: 1.94GiB freeMemory: 1.12GiB\n2017-12-14 03:11:39.800099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] Device peer to peer matrix\n2017-12-14 03:11:39.800140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1124] DMA: 0 1 \n2017-12-14 03:11:39.800172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 0:   Y N \n2017-12-14 03:11:39.800211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 1:   N Y \n2017-12-14 03:11:39.800275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1193] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\n2017-12-14 03:11:39.800330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Ignoring gpu device (device: 1, name: Quadro K620, pci bus id: 0000:03:00.0, compute capability: 5.0) with Cuda multiprocessor count: 3. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n('Size: ', TensorShape([Dimension(10), Dimension(10)]))\nRuntime is 0.10812\nRuntime is 0.00008\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(500), Dimension(500)]))\nRuntime is 0.00005\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(1000), Dimension(1000)]))\nRuntime is 0.00005\nRuntime is 0.00005\nRuntime is 0.00005\nRuntime is 0.00007\nRuntime is 0.00005\n('Size: ', TensorShape([Dimension(2000), Dimension(2000)]))\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00005\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(5000), Dimension(5000)]))\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00006\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(10000), Dimension(10000)]))\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00005\nRuntime is 0.00004\n</code></pre>\n<p>Do let us know if these results above are reproducible on your setup and if the explanation makes sense.</p>", "body_text": "Thanks for sharing the code, this helps.\nI noticed one big issue with the code you provided - the inputs are numpy arrays (which are necessarily in host memory) and so in each call to tf.matmul (with eager execution enabled) you're including the cost of (synchronously and serially) copying the input tensors from CPU to GPU memory. That cost is likely dominating (and increases with size). I'm not entirely sure about the variance, but the absolute numbers seem really high for all cases.\nHere is a simpler benchmark which I think is doing what you're trying to, along with results on my machine (which appears to have the same Titan X Pascal GPU):\nimport tensorflow as tf\nimport tensorflow.contrib.eager as tfe\nimport time\n\ntfe.enable_eager_execution()\n\ndef run(size):\n  with tf.device('/gpu:0'):\n    a = tf.random_uniform([size, size])\n    b = tf.random_uniform([size, size])\n    print('Size: ', a.shape)\n    for i in range(5):\n      start = time.time() \n      tf.matmul(a, b)\n      print('Runtime is %2.5f' % (time.time() - start))\n\nprint('One warmup run to account for GPU initialization')\nrun(10)\nfor p in [500, 1000, 2000, 5000, 10000]:\n  run(p)\nWhich results in:\nOne warmup run to account for GPU initialization\n2017-12-14 03:11:39.311967: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-12-14 03:11:39.619956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-12-14 03:11:39.620511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 0 with properties: \nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\npciBusID: 0000:02:00.0\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\n2017-12-14 03:11:39.799633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-12-14 03:11:39.800043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 1 with properties: \nname: Quadro K620 major: 5 minor: 0 memoryClockRate(GHz): 1.124\npciBusID: 0000:03:00.0\ntotalMemory: 1.94GiB freeMemory: 1.12GiB\n2017-12-14 03:11:39.800099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] Device peer to peer matrix\n2017-12-14 03:11:39.800140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1124] DMA: 0 1 \n2017-12-14 03:11:39.800172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 0:   Y N \n2017-12-14 03:11:39.800211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 1:   N Y \n2017-12-14 03:11:39.800275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1193] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\n2017-12-14 03:11:39.800330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Ignoring gpu device (device: 1, name: Quadro K620, pci bus id: 0000:03:00.0, compute capability: 5.0) with Cuda multiprocessor count: 3. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n('Size: ', TensorShape([Dimension(10), Dimension(10)]))\nRuntime is 0.10812\nRuntime is 0.00008\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(500), Dimension(500)]))\nRuntime is 0.00005\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(1000), Dimension(1000)]))\nRuntime is 0.00005\nRuntime is 0.00005\nRuntime is 0.00005\nRuntime is 0.00007\nRuntime is 0.00005\n('Size: ', TensorShape([Dimension(2000), Dimension(2000)]))\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00005\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(5000), Dimension(5000)]))\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00006\nRuntime is 0.00004\n('Size: ', TensorShape([Dimension(10000), Dimension(10000)]))\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00004\nRuntime is 0.00005\nRuntime is 0.00004\n\nDo let us know if these results above are reproducible on your setup and if the explanation makes sense.", "body": "Thanks for sharing the code, this helps.\r\n\r\nI noticed one big issue with the code you provided - the inputs are numpy arrays (which are necessarily in host memory) and so in each call to `tf.matmul` (with eager execution enabled) you're including the cost of (synchronously and serially) copying the input tensors from CPU to GPU memory. That cost is likely dominating (and increases with size). I'm not entirely sure about the variance, but the absolute numbers seem really high for all cases.\r\n\r\nHere is a simpler benchmark which I think is doing what you're trying to, along with results on my machine (which appears to have the same Titan X Pascal GPU):\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport time\r\n\r\ntfe.enable_eager_execution()\r\n\r\ndef run(size):\r\n  with tf.device('/gpu:0'):\r\n    a = tf.random_uniform([size, size])\r\n    b = tf.random_uniform([size, size])\r\n    print('Size: ', a.shape)\r\n    for i in range(5):\r\n      start = time.time() \r\n      tf.matmul(a, b)\r\n      print('Runtime is %2.5f' % (time.time() - start))\r\n\r\nprint('One warmup run to account for GPU initialization')\r\nrun(10)\r\nfor p in [500, 1000, 2000, 5000, 10000]:\r\n  run(p)\r\n```\r\n\r\nWhich results in:\r\n\r\n```\r\nOne warmup run to account for GPU initialization\r\n2017-12-14 03:11:39.311967: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-14 03:11:39.619956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-12-14 03:11:39.620511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 0 with properties: \r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\r\n2017-12-14 03:11:39.799633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-12-14 03:11:39.800043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 1 with properties: \r\nname: Quadro K620 major: 5 minor: 0 memoryClockRate(GHz): 1.124\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 1.94GiB freeMemory: 1.12GiB\r\n2017-12-14 03:11:39.800099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] Device peer to peer matrix\r\n2017-12-14 03:11:39.800140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1124] DMA: 0 1 \r\n2017-12-14 03:11:39.800172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 0:   Y N \r\n2017-12-14 03:11:39.800211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 1:   N Y \r\n2017-12-14 03:11:39.800275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1193] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2017-12-14 03:11:39.800330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Ignoring gpu device (device: 1, name: Quadro K620, pci bus id: 0000:03:00.0, compute capability: 5.0) with Cuda multiprocessor count: 3. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\r\n('Size: ', TensorShape([Dimension(10), Dimension(10)]))\r\nRuntime is 0.10812\r\nRuntime is 0.00008\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(500), Dimension(500)]))\r\nRuntime is 0.00005\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(1000), Dimension(1000)]))\r\nRuntime is 0.00005\r\nRuntime is 0.00005\r\nRuntime is 0.00005\r\nRuntime is 0.00007\r\nRuntime is 0.00005\r\n('Size: ', TensorShape([Dimension(2000), Dimension(2000)]))\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00005\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(5000), Dimension(5000)]))\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00006\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(10000), Dimension(10000)]))\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00005\r\nRuntime is 0.00004\r\n```\r\n\r\nDo let us know if these results above are reproducible on your setup and if the explanation makes sense."}