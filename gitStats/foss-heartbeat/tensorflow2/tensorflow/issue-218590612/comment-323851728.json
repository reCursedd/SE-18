{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/323851728", "html_url": "https://github.com/tensorflow/tensorflow/issues/8879#issuecomment-323851728", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/8879", "id": 323851728, "node_id": "MDEyOklzc3VlQ29tbWVudDMyMzg1MTcyOA==", "user": {"login": "delton137", "id": 7319436, "node_id": "MDQ6VXNlcjczMTk0MzY=", "avatar_url": "https://avatars2.githubusercontent.com/u/7319436?v=4", "gravatar_id": "", "url": "https://api.github.com/users/delton137", "html_url": "https://github.com/delton137", "followers_url": "https://api.github.com/users/delton137/followers", "following_url": "https://api.github.com/users/delton137/following{/other_user}", "gists_url": "https://api.github.com/users/delton137/gists{/gist_id}", "starred_url": "https://api.github.com/users/delton137/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/delton137/subscriptions", "organizations_url": "https://api.github.com/users/delton137/orgs", "repos_url": "https://api.github.com/users/delton137/repos", "events_url": "https://api.github.com/users/delton137/events{/privacy}", "received_events_url": "https://api.github.com/users/delton137/received_events", "type": "User", "site_admin": false}, "created_at": "2017-08-21T21:00:17Z", "updated_at": "2017-08-21T21:00:50Z", "author_association": "NONE", "body_html": "<p>I am having the same issue :</p>\n<p>Linux Mint 18.1 Serena<br>\nCUDA 8.0<br>\nlibcudnn 5.1<br>\ntensorflow-gpu            1.3.0<br>\nkeras  (using tf as a backend)</p>\n<pre><code> E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n2017-08-21 16:53:38.788947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\n2017-08-21 16:53:38.788956: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo&lt;T&gt;(), &amp;algorithms) \n</code></pre>\n<p>Per another thread, this appears to be an issue with the GPU running out of memory. I have tried to use this code snippet</p>\n<pre><code>    from keras.backend.tensorflow_backend import set_session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.1\n    set_session(tf.Session(config=config))\n\n</code></pre>\n<p>but no luck. I have been checking nvidia-smi. I get the following :</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:02:00.0  On |                  N/A |\n| 20%   30C    P8     9W / 250W |    427MiB / 11169MiB |      4%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1383    G   /usr/lib/xorg/Xorg                             271MiB |\n|    0      1991    G   compton                                          3MiB |\n|    0      2143    G   ...el-token=3B20FA9DA27556BEE46CF45A65B73A9B   107MiB |\n|    0      8279    G   ...s-passed-by-fd --v8-snapshot-passed-by-fd    42MiB |\n+-----------------------------------------------------------------------------+\n</code></pre>", "body_text": "I am having the same issue :\nLinux Mint 18.1 Serena\nCUDA 8.0\nlibcudnn 5.1\ntensorflow-gpu            1.3.0\nkeras  (using tf as a backend)\n E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n2017-08-21 16:53:38.788947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\n2017-08-21 16:53:38.788956: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \n\nPer another thread, this appears to be an issue with the GPU running out of memory. I have tried to use this code snippet\n    from keras.backend.tensorflow_backend import set_session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.1\n    set_session(tf.Session(config=config))\n\n\nbut no luck. I have been checking nvidia-smi. I get the following :\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 108...  Off  | 00000000:02:00.0  On |                  N/A |\n| 20%   30C    P8     9W / 250W |    427MiB / 11169MiB |      4%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1383    G   /usr/lib/xorg/Xorg                             271MiB |\n|    0      1991    G   compton                                          3MiB |\n|    0      2143    G   ...el-token=3B20FA9DA27556BEE46CF45A65B73A9B   107MiB |\n|    0      8279    G   ...s-passed-by-fd --v8-snapshot-passed-by-fd    42MiB |\n+-----------------------------------------------------------------------------+", "body": "I am having the same issue : \r\n\r\nLinux Mint 18.1 Serena\r\nCUDA 8.0\r\nlibcudnn 5.1\r\ntensorflow-gpu            1.3.0 \r\nkeras  (using tf as a backend)\r\n\r\n```\r\n E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2017-08-21 16:53:38.788947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\n2017-08-21 16:53:38.788956: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\n```\r\n\r\nPer another thread, this appears to be an issue with the GPU running out of memory. I have tried to use this code snippet \r\n\r\n```\r\n    from keras.backend.tensorflow_backend import set_session\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    config.gpu_options.per_process_gpu_memory_fraction = 0.1\r\n    set_session(tf.Session(config=config))\r\n\r\n```\r\n\r\nbut no luck. I have been checking nvidia-smi. I get the following : \r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:02:00.0  On |                  N/A |\r\n| 20%   30C    P8     9W / 250W |    427MiB / 11169MiB |      4%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1383    G   /usr/lib/xorg/Xorg                             271MiB |\r\n|    0      1991    G   compton                                          3MiB |\r\n|    0      2143    G   ...el-token=3B20FA9DA27556BEE46CF45A65B73A9B   107MiB |\r\n|    0      8279    G   ...s-passed-by-fd --v8-snapshot-passed-by-fd    42MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n"}