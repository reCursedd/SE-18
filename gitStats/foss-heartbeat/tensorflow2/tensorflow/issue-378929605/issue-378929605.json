{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23609", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23609/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23609/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23609/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23609", "id": 378929605, "node_id": "MDU6SXNzdWUzNzg5Mjk2MDU=", "number": 23609, "title": "[Cloud TPU] Various issues with uint8 data type", "user": {"login": "Keno", "id": 1291671, "node_id": "MDQ6VXNlcjEyOTE2NzE=", "avatar_url": "https://avatars1.githubusercontent.com/u/1291671?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Keno", "html_url": "https://github.com/Keno", "followers_url": "https://api.github.com/users/Keno/followers", "following_url": "https://api.github.com/users/Keno/following{/other_user}", "gists_url": "https://api.github.com/users/Keno/gists{/gist_id}", "starred_url": "https://api.github.com/users/Keno/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Keno/subscriptions", "organizations_url": "https://api.github.com/users/Keno/orgs", "repos_url": "https://api.github.com/users/Keno/repos", "events_url": "https://api.github.com/users/Keno/events{/privacy}", "received_events_url": "https://api.github.com/users/Keno/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 1097541661, "node_id": "MDU6TGFiZWwxMDk3NTQxNjYx", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:tpus", "name": "comp:tpus", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "froystig", "id": 123903, "node_id": "MDQ6VXNlcjEyMzkwMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/123903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/froystig", "html_url": "https://github.com/froystig", "followers_url": "https://api.github.com/users/froystig/followers", "following_url": "https://api.github.com/users/froystig/following{/other_user}", "gists_url": "https://api.github.com/users/froystig/gists{/gist_id}", "starred_url": "https://api.github.com/users/froystig/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/froystig/subscriptions", "organizations_url": "https://api.github.com/users/froystig/orgs", "repos_url": "https://api.github.com/users/froystig/repos", "events_url": "https://api.github.com/users/froystig/events{/privacy}", "received_events_url": "https://api.github.com/users/froystig/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "froystig", "id": 123903, "node_id": "MDQ6VXNlcjEyMzkwMw==", "avatar_url": "https://avatars3.githubusercontent.com/u/123903?v=4", "gravatar_id": "", "url": "https://api.github.com/users/froystig", "html_url": "https://github.com/froystig", "followers_url": "https://api.github.com/users/froystig/followers", "following_url": "https://api.github.com/users/froystig/following{/other_user}", "gists_url": "https://api.github.com/users/froystig/gists{/gist_id}", "starred_url": "https://api.github.com/users/froystig/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/froystig/subscriptions", "organizations_url": "https://api.github.com/users/froystig/orgs", "repos_url": "https://api.github.com/users/froystig/repos", "events_url": "https://api.github.com/users/froystig/events{/privacy}", "received_events_url": "https://api.github.com/users/froystig/received_events", "type": "User", "site_admin": false}, {"login": "jekbradbury", "id": 11729078, "node_id": "MDQ6VXNlcjExNzI5MDc4", "avatar_url": "https://avatars2.githubusercontent.com/u/11729078?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jekbradbury", "html_url": "https://github.com/jekbradbury", "followers_url": "https://api.github.com/users/jekbradbury/followers", "following_url": "https://api.github.com/users/jekbradbury/following{/other_user}", "gists_url": "https://api.github.com/users/jekbradbury/gists{/gist_id}", "starred_url": "https://api.github.com/users/jekbradbury/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jekbradbury/subscriptions", "organizations_url": "https://api.github.com/users/jekbradbury/orgs", "repos_url": "https://api.github.com/users/jekbradbury/repos", "events_url": "https://api.github.com/users/jekbradbury/events{/privacy}", "received_events_url": "https://api.github.com/users/jekbradbury/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2018-11-08T21:44:39Z", "updated_at": "2018-11-19T16:49:25Z", "closed_at": null, "author_association": "CONTRIBUTOR", "body_html": "<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A</li>\n<li>TensorFlow installed from (source or binary): GCP</li>\n<li>TensorFlow version (use command below): 1.11+</li>\n<li>Python version: N/A</li>\n<li>Bazel version (if compiling from source): N/A</li>\n<li>GCC/Compiler version (if compiling from source): N/A</li>\n<li>CUDA/cuDNN version: N/A</li>\n<li>GPU model and memory: TPUv2</li>\n</ul>\n<p><strong>Describe the current behavior</strong></p>\n<p>There's three issues here:</p>\n<ol>\n<li>Missing propagation of error messages, crashing the TPU host</li>\n<li>It not compiling for shapes other than <code>u8[1024]</code> or multiples thereof</li>\n<li>It crashing on infeed even for <code>u8[1024]</code></li>\n</ol>\n<p>At the moment, compiling (via XRTCompile) crashes the TPU host for anything that uses UInt8 datatypes, unless it's one dimensional and the size is a multiple of 1024. Using the julia frontend:</p>\n<pre><code>julia&gt; @async @tpu (()-&gt;XLA.HloInfeed(Tuple{XRTArray{UInt8, (256,), 1}})(XLA.HloAfterAll()())[1][1])()\nERROR: Tensorflow error: Status: Socket closed\n\n</code></pre>\n<pre><code>julia&gt; @async @tpu (()-&gt;XLA.HloInfeed(Tuple{XRTArray{UInt8, (1024,1024), 2}})(XLA.HloAfterAll()())[1][1])()\nERROR: Tensorflow error: Status: Socket closed\n</code></pre>\n<p>And though compiling succeeds for one dimensional UInt8 vectors of size 1024, trying to infeed crashes:</p>\n<pre><code>julia&gt; @async @tpu (()-&gt;XLA.HloInfeed(Tuple{XRTArray{UInt8, (1024,), 1}})(XLA.HloAfterAll()())[1][1])()\nTask (runnable) @0x00007fae07199120\n\njulia&gt; infeed((zeros(UInt8, 1024),))\nERROR: Tensorflow error: Status: Socket closed\n</code></pre>\n<p><strong>Describe the expected behavior</strong><br>\nIdeally all of these would work. If that takes longer to do, at least exposing the error message to the client, rather than crashing would be desired.</p>\n<p><strong>Code to reproduce the issue</strong><br>\nSee above (should be reproducible with any frontend that uses xrt to talk to Cloud TPUs though).</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\nTensorFlow installed from (source or binary): GCP\nTensorFlow version (use command below): 1.11+\nPython version: N/A\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: N/A\nGPU model and memory: TPUv2\n\nDescribe the current behavior\nThere's three issues here:\n\nMissing propagation of error messages, crashing the TPU host\nIt not compiling for shapes other than u8[1024] or multiples thereof\nIt crashing on infeed even for u8[1024]\n\nAt the moment, compiling (via XRTCompile) crashes the TPU host for anything that uses UInt8 datatypes, unless it's one dimensional and the size is a multiple of 1024. Using the julia frontend:\njulia> @async @tpu (()->XLA.HloInfeed(Tuple{XRTArray{UInt8, (256,), 1}})(XLA.HloAfterAll()())[1][1])()\nERROR: Tensorflow error: Status: Socket closed\n\n\njulia> @async @tpu (()->XLA.HloInfeed(Tuple{XRTArray{UInt8, (1024,1024), 2}})(XLA.HloAfterAll()())[1][1])()\nERROR: Tensorflow error: Status: Socket closed\n\nAnd though compiling succeeds for one dimensional UInt8 vectors of size 1024, trying to infeed crashes:\njulia> @async @tpu (()->XLA.HloInfeed(Tuple{XRTArray{UInt8, (1024,), 1}})(XLA.HloAfterAll()())[1][1])()\nTask (runnable) @0x00007fae07199120\n\njulia> infeed((zeros(UInt8, 1024),))\nERROR: Tensorflow error: Status: Socket closed\n\nDescribe the expected behavior\nIdeally all of these would work. If that takes longer to do, at least exposing the error message to the client, rather than crashing would be desired.\nCode to reproduce the issue\nSee above (should be reproducible with any frontend that uses xrt to talk to Cloud TPUs though).", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): GCP\r\n- TensorFlow version (use command below): 1.11+\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: TPUv2\r\n\r\n**Describe the current behavior**\r\n\r\nThere's three issues here:\r\n1. Missing propagation of error messages, crashing the TPU host\r\n2. It not compiling for shapes other than `u8[1024]` or multiples thereof\r\n3. It crashing on infeed even for `u8[1024]`\r\n\r\nAt the moment, compiling (via XRTCompile) crashes the TPU host for anything that uses UInt8 datatypes, unless it's one dimensional and the size is a multiple of 1024. Using the julia frontend:\r\n\r\n```\r\njulia> @async @tpu (()->XLA.HloInfeed(Tuple{XRTArray{UInt8, (256,), 1}})(XLA.HloAfterAll()())[1][1])()\r\nERROR: Tensorflow error: Status: Socket closed\r\n\r\n```\r\n\r\n```\r\njulia> @async @tpu (()->XLA.HloInfeed(Tuple{XRTArray{UInt8, (1024,1024), 2}})(XLA.HloAfterAll()())[1][1])()\r\nERROR: Tensorflow error: Status: Socket closed\r\n```\r\n\r\nAnd though compiling succeeds for one dimensional UInt8 vectors of size 1024, trying to infeed crashes:\r\n```\r\njulia> @async @tpu (()->XLA.HloInfeed(Tuple{XRTArray{UInt8, (1024,), 1}})(XLA.HloAfterAll()())[1][1])()\r\nTask (runnable) @0x00007fae07199120\r\n\r\njulia> infeed((zeros(UInt8, 1024),))\r\nERROR: Tensorflow error: Status: Socket closed\r\n```\r\n\r\n**Describe the expected behavior**\r\nIdeally all of these would work. If that takes longer to do, at least exposing the error message to the client, rather than crashing would be desired.\r\n\r\n**Code to reproduce the issue**\r\nSee above (should be reproducible with any frontend that uses xrt to talk to Cloud TPUs though)."}