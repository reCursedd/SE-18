{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5883", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5883/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5883/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/5883/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/5883", "id": 191862299, "node_id": "MDU6SXNzdWUxOTE4NjIyOTk=", "number": 5883, "title": "Android TF Error: Not found: Op type not registered 'Const'", "user": {"login": "es007", "id": 4059304, "node_id": "MDQ6VXNlcjQwNTkzMDQ=", "avatar_url": "https://avatars0.githubusercontent.com/u/4059304?v=4", "gravatar_id": "", "url": "https://api.github.com/users/es007", "html_url": "https://github.com/es007", "followers_url": "https://api.github.com/users/es007/followers", "following_url": "https://api.github.com/users/es007/following{/other_user}", "gists_url": "https://api.github.com/users/es007/gists{/gist_id}", "starred_url": "https://api.github.com/users/es007/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/es007/subscriptions", "organizations_url": "https://api.github.com/users/es007/orgs", "repos_url": "https://api.github.com/users/es007/repos", "events_url": "https://api.github.com/users/es007/events{/privacy}", "received_events_url": "https://api.github.com/users/es007/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "petewarden", "id": 161459, "node_id": "MDQ6VXNlcjE2MTQ1OQ==", "avatar_url": "https://avatars0.githubusercontent.com/u/161459?v=4", "gravatar_id": "", "url": "https://api.github.com/users/petewarden", "html_url": "https://github.com/petewarden", "followers_url": "https://api.github.com/users/petewarden/followers", "following_url": "https://api.github.com/users/petewarden/following{/other_user}", "gists_url": "https://api.github.com/users/petewarden/gists{/gist_id}", "starred_url": "https://api.github.com/users/petewarden/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/petewarden/subscriptions", "organizations_url": "https://api.github.com/users/petewarden/orgs", "repos_url": "https://api.github.com/users/petewarden/repos", "events_url": "https://api.github.com/users/petewarden/events{/privacy}", "received_events_url": "https://api.github.com/users/petewarden/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 2, "created_at": "2016-11-27T13:47:29Z", "updated_at": "2017-01-16T03:07:46Z", "closed_at": "2017-01-16T03:07:46Z", "author_association": "NONE", "body_html": "<p>Hello,</p>\n<p>I'm trying to run a dummy inference model I built in TF with python.<br>\nThe model takes an input vector (size 3x200) and multiply (component-wise) it with a variable vector of the same size whose values were randomized. so output_node = input_node * variable_node<br>\nThen there is a reduce_sum to a final value.<br>\nThe model was generated with this procedure:<br>\n`<br>\ncheckpoint_prefix = \"mygraph.ckpt\"<br>\ncheckpoint_state_name = \"mygraph.ckpt\"<br>\ninput_graph_name = \"input_graph.pb\"<br>\noutput_graph_name = \"output_graph.pb\"</p>\n<pre><code>def dummy_model(input):\n    with tf.Graph().as_default():\n        sess = tf.Session()\n        with sess.as_default():\n\n        variable_node = tf.Variable(tf.random_normal([3, 200], stddev=0.35), name=\"variable_node\")\n        input_node = tf.Variable(input, name=\"input_node\")\n        output_node = tf.reduce_sum(tf.mul(variable_node, input_node, name=\"output_node\"), axis=1)\n        init_op = tf.global_variables_initializer()\n\n        #init = tf.global_variables_initializer()\n        sess.run(init_op)\n\n        saver = tf.train.Saver(write_version=2)\n        checkpoint_path = saver.save(sess, checkpoint_prefix, global_step=0, latest_filename=checkpoint_state_name)\n        tf.train.write_graph(sess.graph, \"./\", input_graph_name)`\n</code></pre>\n<p>After generating the model files (and renaming them) I made the process of freezing and optimizing the graph for inference on android using the script in the python\\tools folder (freeze_graph.py, optimize_for_inference.py, print_selective_registration_header.py). In the end of this process I get the optimized graph 'my_optimized_graph.pb' and the ops_to_register.h' header which is used to tell tensorflow (bazel) what kernels to register when you add the \"SELECTIVE_REGISTRATION\" flag to the build rule.</p>\n<p>My problem is, when I load the model in android I get the following errors occurred after the session-&gt;create() call:</p>\n<blockquote>\n<p>E/native: op_kernel.cc:925 OpKernel ('op: \"_Send\" device_type: \"GPU\"') for unknown op: _Send<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Recv\" device_type: \"GPU\"') for unknown op: _Recv<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Send\" device_type: \"CPU\"') for unknown op: _Send<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"NoOp\" device_type: \"GPU\"') for unknown op: NoOp<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Recv\" device_type: \"CPU\"') for unknown op: _Recv<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"NoOp\" device_type: \"CPU\"') for unknown op: NoOp<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"Placeholder\" device_type: \"GPU\"') for unknown op: Placeholder<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"Placeholder\" device_type: \"CPU\"') for unknown op: Placeholder<br>\nE/native: op_kernel.cc:925 OpKernel ('op: \"Const\" device_type: \"CPU\"') for unknown op: Const<br>\nE/native: tensorflow_inference_jni.cc:138 Could not create Tensorflow Graph: Not found: Op type not registered 'Const'</p>\n</blockquote>\n<p>It seems like the kernels did registered but the ops are unknown.<br>\nI searched a lot the forum and couldn't find solution for this issue.</p>\n<h3>Did anyone succeed in compiling TF on Android with SELECTIVE_REGISTRATION and running a custom graph model other than the \"inception\" model which used in the demo?</h3>", "body_text": "Hello,\nI'm trying to run a dummy inference model I built in TF with python.\nThe model takes an input vector (size 3x200) and multiply (component-wise) it with a variable vector of the same size whose values were randomized. so output_node = input_node * variable_node\nThen there is a reduce_sum to a final value.\nThe model was generated with this procedure:\n`\ncheckpoint_prefix = \"mygraph.ckpt\"\ncheckpoint_state_name = \"mygraph.ckpt\"\ninput_graph_name = \"input_graph.pb\"\noutput_graph_name = \"output_graph.pb\"\ndef dummy_model(input):\n    with tf.Graph().as_default():\n        sess = tf.Session()\n        with sess.as_default():\n\n        variable_node = tf.Variable(tf.random_normal([3, 200], stddev=0.35), name=\"variable_node\")\n        input_node = tf.Variable(input, name=\"input_node\")\n        output_node = tf.reduce_sum(tf.mul(variable_node, input_node, name=\"output_node\"), axis=1)\n        init_op = tf.global_variables_initializer()\n\n        #init = tf.global_variables_initializer()\n        sess.run(init_op)\n\n        saver = tf.train.Saver(write_version=2)\n        checkpoint_path = saver.save(sess, checkpoint_prefix, global_step=0, latest_filename=checkpoint_state_name)\n        tf.train.write_graph(sess.graph, \"./\", input_graph_name)`\n\nAfter generating the model files (and renaming them) I made the process of freezing and optimizing the graph for inference on android using the script in the python\\tools folder (freeze_graph.py, optimize_for_inference.py, print_selective_registration_header.py). In the end of this process I get the optimized graph 'my_optimized_graph.pb' and the ops_to_register.h' header which is used to tell tensorflow (bazel) what kernels to register when you add the \"SELECTIVE_REGISTRATION\" flag to the build rule.\nMy problem is, when I load the model in android I get the following errors occurred after the session->create() call:\n\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Send\" device_type: \"GPU\"') for unknown op: _Send\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Recv\" device_type: \"GPU\"') for unknown op: _Recv\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Send\" device_type: \"CPU\"') for unknown op: _Send\nE/native: op_kernel.cc:925 OpKernel ('op: \"NoOp\" device_type: \"GPU\"') for unknown op: NoOp\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Recv\" device_type: \"CPU\"') for unknown op: _Recv\nE/native: op_kernel.cc:925 OpKernel ('op: \"NoOp\" device_type: \"CPU\"') for unknown op: NoOp\nE/native: op_kernel.cc:925 OpKernel ('op: \"Placeholder\" device_type: \"GPU\"') for unknown op: Placeholder\nE/native: op_kernel.cc:925 OpKernel ('op: \"Placeholder\" device_type: \"CPU\"') for unknown op: Placeholder\nE/native: op_kernel.cc:925 OpKernel ('op: \"Const\" device_type: \"CPU\"') for unknown op: Const\nE/native: tensorflow_inference_jni.cc:138 Could not create Tensorflow Graph: Not found: Op type not registered 'Const'\n\nIt seems like the kernels did registered but the ops are unknown.\nI searched a lot the forum and couldn't find solution for this issue.\nDid anyone succeed in compiling TF on Android with SELECTIVE_REGISTRATION and running a custom graph model other than the \"inception\" model which used in the demo?", "body": "Hello,\r\n\r\nI'm trying to run a dummy inference model I built in TF with python.\r\nThe model takes an input vector (size 3x200) and multiply (component-wise) it with a variable vector of the same size whose values were randomized. so output_node = input_node * variable_node\r\nThen there is a reduce_sum to a final value.\r\nThe model was generated with this procedure:\r\n`  \r\n    checkpoint_prefix = \"mygraph.ckpt\"\r\n    checkpoint_state_name = \"mygraph.ckpt\"\r\n    input_graph_name = \"input_graph.pb\"\r\n    output_graph_name = \"output_graph.pb\"\r\n\r\n    def dummy_model(input):\r\n        with tf.Graph().as_default():\r\n            sess = tf.Session()\r\n            with sess.as_default():\r\n\r\n            variable_node = tf.Variable(tf.random_normal([3, 200], stddev=0.35), name=\"variable_node\")\r\n            input_node = tf.Variable(input, name=\"input_node\")\r\n            output_node = tf.reduce_sum(tf.mul(variable_node, input_node, name=\"output_node\"), axis=1)\r\n            init_op = tf.global_variables_initializer()\r\n\r\n            #init = tf.global_variables_initializer()\r\n            sess.run(init_op)\r\n \r\n            saver = tf.train.Saver(write_version=2)\r\n            checkpoint_path = saver.save(sess, checkpoint_prefix, global_step=0, latest_filename=checkpoint_state_name)\r\n            tf.train.write_graph(sess.graph, \"./\", input_graph_name)`\r\n   \r\n\r\nAfter generating the model files (and renaming them) I made the process of freezing and optimizing the graph for inference on android using the script in the python\\tools folder (freeze_graph.py, optimize_for_inference.py, print_selective_registration_header.py). In the end of this process I get the optimized graph 'my_optimized_graph.pb' and the ops_to_register.h' header which is used to tell tensorflow (bazel) what kernels to register when you add the \"SELECTIVE_REGISTRATION\" flag to the build rule.\r\n\r\nMy problem is, when I load the model in android I get the following errors occurred after the session->create() call:\r\n\r\n> E/native: op_kernel.cc:925 OpKernel ('op: \"_Send\" device_type: \"GPU\"') for unknown op: _Send\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Recv\" device_type: \"GPU\"') for unknown op: _Recv\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Send\" device_type: \"CPU\"') for unknown op: _Send\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"NoOp\" device_type: \"GPU\"') for unknown op: NoOp\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"_Recv\" device_type: \"CPU\"') for unknown op: _Recv\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"NoOp\" device_type: \"CPU\"') for unknown op: NoOp\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"Placeholder\" device_type: \"GPU\"') for unknown op: Placeholder\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"Placeholder\" device_type: \"CPU\"') for unknown op: Placeholder\r\nE/native: op_kernel.cc:925 OpKernel ('op: \"Const\" device_type: \"CPU\"') for unknown op: Const\r\nE/native: tensorflow_inference_jni.cc:138 Could not create Tensorflow Graph: Not found: Op type not registered 'Const'\r\n\r\nIt seems like the kernels did registered but the ops are unknown.\r\nI searched a lot the forum and couldn't find solution for this issue.\r\n### Did anyone succeed in compiling TF on Android with SELECTIVE_REGISTRATION and running a custom graph model other than the \"inception\" model which used in the demo?"}