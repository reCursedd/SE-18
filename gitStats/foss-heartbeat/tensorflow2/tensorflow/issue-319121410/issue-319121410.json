{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18995", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18995/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18995/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/18995/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/18995", "id": 319121410, "node_id": "MDU6SXNzdWUzMTkxMjE0MTA=", "number": 18995, "title": "compiling c++ code with TFLite library gives error with cstring", "user": {"login": "timedilation", "id": 14119417, "node_id": "MDQ6VXNlcjE0MTE5NDE3", "avatar_url": "https://avatars1.githubusercontent.com/u/14119417?v=4", "gravatar_id": "", "url": "https://api.github.com/users/timedilation", "html_url": "https://github.com/timedilation", "followers_url": "https://api.github.com/users/timedilation/followers", "following_url": "https://api.github.com/users/timedilation/following{/other_user}", "gists_url": "https://api.github.com/users/timedilation/gists{/gist_id}", "starred_url": "https://api.github.com/users/timedilation/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/timedilation/subscriptions", "organizations_url": "https://api.github.com/users/timedilation/orgs", "repos_url": "https://api.github.com/users/timedilation/repos", "events_url": "https://api.github.com/users/timedilation/events{/privacy}", "received_events_url": "https://api.github.com/users/timedilation/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "andrehentz", "id": 25754898, "node_id": "MDQ6VXNlcjI1NzU0ODk4", "avatar_url": "https://avatars3.githubusercontent.com/u/25754898?v=4", "gravatar_id": "", "url": "https://api.github.com/users/andrehentz", "html_url": "https://github.com/andrehentz", "followers_url": "https://api.github.com/users/andrehentz/followers", "following_url": "https://api.github.com/users/andrehentz/following{/other_user}", "gists_url": "https://api.github.com/users/andrehentz/gists{/gist_id}", "starred_url": "https://api.github.com/users/andrehentz/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/andrehentz/subscriptions", "organizations_url": "https://api.github.com/users/andrehentz/orgs", "repos_url": "https://api.github.com/users/andrehentz/repos", "events_url": "https://api.github.com/users/andrehentz/events{/privacy}", "received_events_url": "https://api.github.com/users/andrehentz/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2018-05-01T05:38:46Z", "updated_at": "2018-10-18T19:47:47Z", "closed_at": "2018-06-22T10:41:37Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: N/A (using only source files)</li>\n<li><strong>TensorFlow version (use command below)</strong>: N/A</li>\n<li><strong>Python version</strong>: 2.7.12</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.13.0</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: g++ 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: N/A</li>\n<li><strong>GPU model and memory</strong>: N/A</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.</p>\n<p>I'm trying to compile custom c++ code with command<br>\n<code>g++ -std=c++11 -Itensorflow/contrib/lite -I. -Lbazel-bin/tensorflow/contrib/lite -tflite test.cpp -o test</code></p>\n<p>and it gives some error that some functions in cstring cannot be found.</p>\n<p>When I delete line <code>#include &lt;cstring&gt;</code> from flatbuffers/base.h, errors from cstring disappear but others remain. Including cstring in flatbuffers.h also gives same errors.<br>\nI'm using flatbuffers cloned from git google flatbuffers repository. Is this can be a problem?</p>\n<p>I've made c++ tensorflow lite library with command<br>\n<code>bagel build //tensorflow/contrib/lite:framework</code><br>\nwith lite/BUILD including<br>\n<code>cc_binary( name = \"libtflite.so\", deps = [ \":framework\", \"//tensorflow/contrib/lite/kernels:builtin_ops\"], ] ) </code></p>\n<p>Thanks.</p>\n<h3>Source code / logs</h3>\n<p>Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.</p>\n<h4>C++ Code</h4>\n<pre><code>  1 #include &lt;stdio.h&gt;\n  2 \n  3 #include \"tensorflow/contrib/lite/kernels/register.h\"\n  4 #include \"tensorflow/contrib/lite/model.h\"\n  5 #include \"tensorflow/contrib/lite/string_util.h\"\n  6 #include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"\n  7 \n  8 \n  9 \n 10 int main(){\n 11     const char* graph_path = \"xorGate.lite\";\n 12     const int num_threads = 1;\n 13     std::string input_layer_type = \"float\";\n 14     float x,y;\n 15 \n 16     std::unique_ptr&lt;tflite::FlatBufferModel&gt; model(\n 17         tflite::FlatBufferModel::BuildFromFile(graph_path));\n 18 \n 19     if(!model){\n 20         printf(\"Failed to mmap model\\n\");\n 21         exit(0);\n 22     }\n 23 \n 24     tflite::ops::builtin::BuiltinOpResolver resolver;\n 25     std::unique_ptr&lt;tflite::Interpreter&gt; interpreter;\n 26     tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);\n 27 \n 28     if(!interpreter){\n 29         printf(\"Failed to construct interpreter\\n\");\n 30         exit(0);\n 31     }\n 32 \n 33     if(num_threads != 1){\n 34         interpreter-&gt;SetNumThreads(num_threads);\n 35     }\n 36 \n 37     float* input = interpreter-&gt;typed_input_tensor&lt;float&gt;(0);\n 38 \n 39     if(interpreter-&gt;AllocateTensors() != kTfLiteOk){\n 40         printf(\"Failed to allocate tensors\\n\");\n 41         exit(0);\n 42     }\n 43 \n 44     //read two numbers\n 45     std::printf(\"Type two float numbers : \");\n 46     std::scanf(\"%f %f\", &amp;x, &amp;y);\n 47     input[0] = x;\n 48     input[1] = y;\n 49 \n 50     if(interpreter-&gt;Invoke() != kTfLiteOk){\n 51         std::printf(\"Failed to invoke!\\n\");\n 52         exit(0);\n 53     }\n 54     float* output = interpreter-&gt;typed_output_tensor&lt;float&gt;(0);\n 55     printf(\"output = %f\\n\", output[0]);\n 56     return 0;\n 57 }\n</code></pre>\n<h4>Log</h4>\n<pre><code>In file included from ./flatbuffers/base.h:2:0,\n                 from ./flatbuffers/flatbuffers.h:18,\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n/usr/include/c++/5/cstring:75:11: error: \u2018::memchr\u2019 has not been declared\n   using ::memchr;\n/usr/include/c++/5/cstring:76:11: error: \u2018::memcmp\u2019 has not been declared\n   using ::memcmp;\n/usr/include/c++/5/cstring:77:11: error: \u2018::memcpy\u2019 has not been declared\n   using ::memcpy;\n/usr/include/c++/5/cstring:78:11: error: \u2018::memmove\u2019 has not been declared\n   using ::memmove;\n/usr/include/c++/5/cstring:79:11: error: \u2018::memset\u2019 has not been declared\n   using ::memset;\n/usr/include/c++/5/cstring:80:11: error: \u2018::strcat\u2019 has not been declared\n   using ::strcat;\n\n...\nsame error from different functions\n...\n   \nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::String::operator&lt;(const flatbuffers::String&amp;) const\u2019:\n./flatbuffers/flatbuffers.h:346:12: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\n     return std::strcmp(c_str(), o.c_str()) &lt; 0;\n            ^\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::Allocator::memcpy_downward(uint8_t*, size_t, uint8_t*, size_t, size_t, size_t)\u2019:\n./flatbuffers/flatbuffers.h:387:23: error: \u2018memcpy\u2019 was not declared in this scope\n            in_use_back);\n                       ^\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::push(const uint8_t*, size_t)\u2019:\n./flatbuffers/flatbuffers.h:628:39: error: \u2018memcpy\u2019 was not declared in this scope\n     memcpy(make_space(num), bytes, num);\n                                       ^\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::fill_big(size_t)\u2019:\n./flatbuffers/flatbuffers.h:652:57: error: \u2018memset\u2019 was not declared in this scope\n     memset(make_space(zero_pad_bytes), 0, zero_pad_bytes);\n                                                         ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::uoffset_t flatbuffers::FlatBufferBuilder::EndTable(flatbuffers::uoffset_t)\u2019:\n./flatbuffers/flatbuffers.h:982:62: error: \u2018memcmp\u2019 was not declared in this scope\n         if (vt1_size != vt2_size || memcmp(vt2, vt1, vt1_size)) continue;\n                                                              ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset&lt;flatbuffers::String&gt; flatbuffers::FlatBufferBuilder::CreateString(const char*)\u2019:\n./flatbuffers/flatbuffers.h:1061:40: error: \u2018strlen\u2019 was not declared in this scope\n     return CreateString(str, strlen(str));\n                                        ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset&lt;flatbuffers::String&gt; flatbuffers::FlatBufferBuilder::CreateString(char*)\u2019:\n./flatbuffers/flatbuffers.h:1068:40: error: \u2018strlen\u2019 was not declared in this scope\n     return CreateString(str, strlen(str));\n                                        ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset&lt;flatbuffers::String&gt; flatbuffers::FlatBufferBuilder::CreateSharedString(const char*)\u2019:\n./flatbuffers/flatbuffers.h:1124:46: error: \u2018strlen\u2019 was not declared in this scope\n     return CreateSharedString(str, strlen(str));\n                                              ^\nIn file included from ./flatbuffers/base.h:12:0,\n                 from ./flatbuffers/flatbuffers.h:18,\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::FlatBufferBuilder::Finish(flatbuffers::uoffset_t, const char*, bool)\u2019:\n./flatbuffers/flatbuffers.h:1563:48: error: \u2018strlen\u2019 was not declared in this scope\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\n                                                ^\n./flatbuffers/flatbuffers.h:1563:7: note: in expansion of macro \u2018FLATBUFFERS_ASSERT\u2019\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\n       ^\nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::FlatBufferBuilder::StringOffsetCompare::operator()(const flatbuffers::Offset&lt;flatbuffers::String&gt;&amp;, const flatbuffers::Offset&lt;flatbuffers::String&gt;&amp;) const\u2019:\n./flatbuffers/flatbuffers.h:1604:64: error: \u2018strncmp\u2019 was not declared in this scope\n                      (std::min)(stra-&gt;size(), strb-&gt;size()) + 1) &lt; 0;\n                                                                ^\n./flatbuffers/flatbuffers.h: In function \u2018bool flatbuffers::BufferHasIdentifier(const void*, const char*, bool)\u2019:\n./flatbuffers/flatbuffers.h:1676:58: error: \u2018strncmp\u2019 was not declared in this scope\n                  FlatBufferBuilder::kFileIdentifierLength) == 0;\n                                                          ^\n./flatbuffers/flatbuffers.h: In function \u2018int flatbuffers::LookupEnum(const char**, const char*)\u2019:\n./flatbuffers/flatbuffers.h:2119:10: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\n     if (!std::strcmp(*p, name)) return static_cast&lt;int&gt;(p - names);\n</code></pre>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\nTensorFlow installed from (source or binary): N/A (using only source files)\nTensorFlow version (use command below): N/A\nPython version: 2.7.12\nBazel version (if compiling from source): 0.13.0\nGCC/Compiler version (if compiling from source): g++ 5.4.0\nCUDA/cuDNN version: N/A\nGPU model and memory: N/A\nExact command to reproduce:\n\nDescribe the problem\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\nI'm trying to compile custom c++ code with command\ng++ -std=c++11 -Itensorflow/contrib/lite -I. -Lbazel-bin/tensorflow/contrib/lite -tflite test.cpp -o test\nand it gives some error that some functions in cstring cannot be found.\nWhen I delete line #include <cstring> from flatbuffers/base.h, errors from cstring disappear but others remain. Including cstring in flatbuffers.h also gives same errors.\nI'm using flatbuffers cloned from git google flatbuffers repository. Is this can be a problem?\nI've made c++ tensorflow lite library with command\nbagel build //tensorflow/contrib/lite:framework\nwith lite/BUILD including\ncc_binary( name = \"libtflite.so\", deps = [ \":framework\", \"//tensorflow/contrib/lite/kernels:builtin_ops\"], ] ) \nThanks.\nSource code / logs\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\nC++ Code\n  1 #include <stdio.h>\n  2 \n  3 #include \"tensorflow/contrib/lite/kernels/register.h\"\n  4 #include \"tensorflow/contrib/lite/model.h\"\n  5 #include \"tensorflow/contrib/lite/string_util.h\"\n  6 #include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"\n  7 \n  8 \n  9 \n 10 int main(){\n 11     const char* graph_path = \"xorGate.lite\";\n 12     const int num_threads = 1;\n 13     std::string input_layer_type = \"float\";\n 14     float x,y;\n 15 \n 16     std::unique_ptr<tflite::FlatBufferModel> model(\n 17         tflite::FlatBufferModel::BuildFromFile(graph_path));\n 18 \n 19     if(!model){\n 20         printf(\"Failed to mmap model\\n\");\n 21         exit(0);\n 22     }\n 23 \n 24     tflite::ops::builtin::BuiltinOpResolver resolver;\n 25     std::unique_ptr<tflite::Interpreter> interpreter;\n 26     tflite::InterpreterBuilder(*model, resolver)(&interpreter);\n 27 \n 28     if(!interpreter){\n 29         printf(\"Failed to construct interpreter\\n\");\n 30         exit(0);\n 31     }\n 32 \n 33     if(num_threads != 1){\n 34         interpreter->SetNumThreads(num_threads);\n 35     }\n 36 \n 37     float* input = interpreter->typed_input_tensor<float>(0);\n 38 \n 39     if(interpreter->AllocateTensors() != kTfLiteOk){\n 40         printf(\"Failed to allocate tensors\\n\");\n 41         exit(0);\n 42     }\n 43 \n 44     //read two numbers\n 45     std::printf(\"Type two float numbers : \");\n 46     std::scanf(\"%f %f\", &x, &y);\n 47     input[0] = x;\n 48     input[1] = y;\n 49 \n 50     if(interpreter->Invoke() != kTfLiteOk){\n 51         std::printf(\"Failed to invoke!\\n\");\n 52         exit(0);\n 53     }\n 54     float* output = interpreter->typed_output_tensor<float>(0);\n 55     printf(\"output = %f\\n\", output[0]);\n 56     return 0;\n 57 }\n\nLog\nIn file included from ./flatbuffers/base.h:2:0,\n                 from ./flatbuffers/flatbuffers.h:18,\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n/usr/include/c++/5/cstring:75:11: error: \u2018::memchr\u2019 has not been declared\n   using ::memchr;\n/usr/include/c++/5/cstring:76:11: error: \u2018::memcmp\u2019 has not been declared\n   using ::memcmp;\n/usr/include/c++/5/cstring:77:11: error: \u2018::memcpy\u2019 has not been declared\n   using ::memcpy;\n/usr/include/c++/5/cstring:78:11: error: \u2018::memmove\u2019 has not been declared\n   using ::memmove;\n/usr/include/c++/5/cstring:79:11: error: \u2018::memset\u2019 has not been declared\n   using ::memset;\n/usr/include/c++/5/cstring:80:11: error: \u2018::strcat\u2019 has not been declared\n   using ::strcat;\n\n...\nsame error from different functions\n...\n   \nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::String::operator<(const flatbuffers::String&) const\u2019:\n./flatbuffers/flatbuffers.h:346:12: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\n     return std::strcmp(c_str(), o.c_str()) < 0;\n            ^\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::Allocator::memcpy_downward(uint8_t*, size_t, uint8_t*, size_t, size_t, size_t)\u2019:\n./flatbuffers/flatbuffers.h:387:23: error: \u2018memcpy\u2019 was not declared in this scope\n            in_use_back);\n                       ^\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::push(const uint8_t*, size_t)\u2019:\n./flatbuffers/flatbuffers.h:628:39: error: \u2018memcpy\u2019 was not declared in this scope\n     memcpy(make_space(num), bytes, num);\n                                       ^\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::fill_big(size_t)\u2019:\n./flatbuffers/flatbuffers.h:652:57: error: \u2018memset\u2019 was not declared in this scope\n     memset(make_space(zero_pad_bytes), 0, zero_pad_bytes);\n                                                         ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::uoffset_t flatbuffers::FlatBufferBuilder::EndTable(flatbuffers::uoffset_t)\u2019:\n./flatbuffers/flatbuffers.h:982:62: error: \u2018memcmp\u2019 was not declared in this scope\n         if (vt1_size != vt2_size || memcmp(vt2, vt1, vt1_size)) continue;\n                                                              ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateString(const char*)\u2019:\n./flatbuffers/flatbuffers.h:1061:40: error: \u2018strlen\u2019 was not declared in this scope\n     return CreateString(str, strlen(str));\n                                        ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateString(char*)\u2019:\n./flatbuffers/flatbuffers.h:1068:40: error: \u2018strlen\u2019 was not declared in this scope\n     return CreateString(str, strlen(str));\n                                        ^\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateSharedString(const char*)\u2019:\n./flatbuffers/flatbuffers.h:1124:46: error: \u2018strlen\u2019 was not declared in this scope\n     return CreateSharedString(str, strlen(str));\n                                              ^\nIn file included from ./flatbuffers/base.h:12:0,\n                 from ./flatbuffers/flatbuffers.h:18,\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::FlatBufferBuilder::Finish(flatbuffers::uoffset_t, const char*, bool)\u2019:\n./flatbuffers/flatbuffers.h:1563:48: error: \u2018strlen\u2019 was not declared in this scope\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\n                                                ^\n./flatbuffers/flatbuffers.h:1563:7: note: in expansion of macro \u2018FLATBUFFERS_ASSERT\u2019\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\n       ^\nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\n                 from ./tensorflow/contrib/lite/model.h:40,\n                 from tensorflow/contrib/lite/kernels/register.h:20,\n                 from test.cpp:1:\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::FlatBufferBuilder::StringOffsetCompare::operator()(const flatbuffers::Offset<flatbuffers::String>&, const flatbuffers::Offset<flatbuffers::String>&) const\u2019:\n./flatbuffers/flatbuffers.h:1604:64: error: \u2018strncmp\u2019 was not declared in this scope\n                      (std::min)(stra->size(), strb->size()) + 1) < 0;\n                                                                ^\n./flatbuffers/flatbuffers.h: In function \u2018bool flatbuffers::BufferHasIdentifier(const void*, const char*, bool)\u2019:\n./flatbuffers/flatbuffers.h:1676:58: error: \u2018strncmp\u2019 was not declared in this scope\n                  FlatBufferBuilder::kFileIdentifierLength) == 0;\n                                                          ^\n./flatbuffers/flatbuffers.h: In function \u2018int flatbuffers::LookupEnum(const char**, const char*)\u2019:\n./flatbuffers/flatbuffers.h:2119:10: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\n     if (!std::strcmp(*p, name)) return static_cast<int>(p - names);", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: N/A (using only source files)\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.13.0\r\n- **GCC/Compiler version (if compiling from source)**: g++ 5.4.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI'm trying to compile custom c++ code with command\r\n`g++ -std=c++11 -Itensorflow/contrib/lite -I. -Lbazel-bin/tensorflow/contrib/lite -tflite test.cpp -o test`\r\n\r\nand it gives some error that some functions in cstring cannot be found.\r\n\r\nWhen I delete line `#include <cstring>` from flatbuffers/base.h, errors from cstring disappear but others remain. Including cstring in flatbuffers.h also gives same errors.\r\nI'm using flatbuffers cloned from git google flatbuffers repository. Is this can be a problem?\r\n\r\n\r\nI've made c++ tensorflow lite library with command\r\n`bagel build //tensorflow/contrib/lite:framework`\r\nwith lite/BUILD including\r\n`cc_binary(\r\n    name = \"libtflite.so\",\r\n    deps = [\r\n        \":framework\",\r\n        \"//tensorflow/contrib/lite/kernels:builtin_ops\"],\r\n    ]\r\n)\r\n`\r\n\r\n\r\nThanks.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n#### C++ Code\r\n```\r\n  1 #include <stdio.h>\r\n  2 \r\n  3 #include \"tensorflow/contrib/lite/kernels/register.h\"\r\n  4 #include \"tensorflow/contrib/lite/model.h\"\r\n  5 #include \"tensorflow/contrib/lite/string_util.h\"\r\n  6 #include \"tensorflow/contrib/lite/tools/mutable_op_resolver.h\"\r\n  7 \r\n  8 \r\n  9 \r\n 10 int main(){\r\n 11     const char* graph_path = \"xorGate.lite\";\r\n 12     const int num_threads = 1;\r\n 13     std::string input_layer_type = \"float\";\r\n 14     float x,y;\r\n 15 \r\n 16     std::unique_ptr<tflite::FlatBufferModel> model(\r\n 17         tflite::FlatBufferModel::BuildFromFile(graph_path));\r\n 18 \r\n 19     if(!model){\r\n 20         printf(\"Failed to mmap model\\n\");\r\n 21         exit(0);\r\n 22     }\r\n 23 \r\n 24     tflite::ops::builtin::BuiltinOpResolver resolver;\r\n 25     std::unique_ptr<tflite::Interpreter> interpreter;\r\n 26     tflite::InterpreterBuilder(*model, resolver)(&interpreter);\r\n 27 \r\n 28     if(!interpreter){\r\n 29         printf(\"Failed to construct interpreter\\n\");\r\n 30         exit(0);\r\n 31     }\r\n 32 \r\n 33     if(num_threads != 1){\r\n 34         interpreter->SetNumThreads(num_threads);\r\n 35     }\r\n 36 \r\n 37     float* input = interpreter->typed_input_tensor<float>(0);\r\n 38 \r\n 39     if(interpreter->AllocateTensors() != kTfLiteOk){\r\n 40         printf(\"Failed to allocate tensors\\n\");\r\n 41         exit(0);\r\n 42     }\r\n 43 \r\n 44     //read two numbers\r\n 45     std::printf(\"Type two float numbers : \");\r\n 46     std::scanf(\"%f %f\", &x, &y);\r\n 47     input[0] = x;\r\n 48     input[1] = y;\r\n 49 \r\n 50     if(interpreter->Invoke() != kTfLiteOk){\r\n 51         std::printf(\"Failed to invoke!\\n\");\r\n 52         exit(0);\r\n 53     }\r\n 54     float* output = interpreter->typed_output_tensor<float>(0);\r\n 55     printf(\"output = %f\\n\", output[0]);\r\n 56     return 0;\r\n 57 }\r\n```\r\n\r\n#### Log\r\n```\r\nIn file included from ./flatbuffers/base.h:2:0,\r\n                 from ./flatbuffers/flatbuffers.h:18,\r\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n/usr/include/c++/5/cstring:75:11: error: \u2018::memchr\u2019 has not been declared\r\n   using ::memchr;\r\n/usr/include/c++/5/cstring:76:11: error: \u2018::memcmp\u2019 has not been declared\r\n   using ::memcmp;\r\n/usr/include/c++/5/cstring:77:11: error: \u2018::memcpy\u2019 has not been declared\r\n   using ::memcpy;\r\n/usr/include/c++/5/cstring:78:11: error: \u2018::memmove\u2019 has not been declared\r\n   using ::memmove;\r\n/usr/include/c++/5/cstring:79:11: error: \u2018::memset\u2019 has not been declared\r\n   using ::memset;\r\n/usr/include/c++/5/cstring:80:11: error: \u2018::strcat\u2019 has not been declared\r\n   using ::strcat;\r\n\r\n...\r\nsame error from different functions\r\n...\r\n   \r\nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::String::operator<(const flatbuffers::String&) const\u2019:\r\n./flatbuffers/flatbuffers.h:346:12: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\r\n     return std::strcmp(c_str(), o.c_str()) < 0;\r\n            ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::Allocator::memcpy_downward(uint8_t*, size_t, uint8_t*, size_t, size_t, size_t)\u2019:\r\n./flatbuffers/flatbuffers.h:387:23: error: \u2018memcpy\u2019 was not declared in this scope\r\n            in_use_back);\r\n                       ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::push(const uint8_t*, size_t)\u2019:\r\n./flatbuffers/flatbuffers.h:628:39: error: \u2018memcpy\u2019 was not declared in this scope\r\n     memcpy(make_space(num), bytes, num);\r\n                                       ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::vector_downward::fill_big(size_t)\u2019:\r\n./flatbuffers/flatbuffers.h:652:57: error: \u2018memset\u2019 was not declared in this scope\r\n     memset(make_space(zero_pad_bytes), 0, zero_pad_bytes);\r\n                                                         ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::uoffset_t flatbuffers::FlatBufferBuilder::EndTable(flatbuffers::uoffset_t)\u2019:\r\n./flatbuffers/flatbuffers.h:982:62: error: \u2018memcmp\u2019 was not declared in this scope\r\n         if (vt1_size != vt2_size || memcmp(vt2, vt1, vt1_size)) continue;\r\n                                                              ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateString(const char*)\u2019:\r\n./flatbuffers/flatbuffers.h:1061:40: error: \u2018strlen\u2019 was not declared in this scope\r\n     return CreateString(str, strlen(str));\r\n                                        ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateString(char*)\u2019:\r\n./flatbuffers/flatbuffers.h:1068:40: error: \u2018strlen\u2019 was not declared in this scope\r\n     return CreateString(str, strlen(str));\r\n                                        ^\r\n./flatbuffers/flatbuffers.h: In member function \u2018flatbuffers::Offset<flatbuffers::String> flatbuffers::FlatBufferBuilder::CreateSharedString(const char*)\u2019:\r\n./flatbuffers/flatbuffers.h:1124:46: error: \u2018strlen\u2019 was not declared in this scope\r\n     return CreateSharedString(str, strlen(str));\r\n                                              ^\r\nIn file included from ./flatbuffers/base.h:12:0,\r\n                 from ./flatbuffers/flatbuffers.h:18,\r\n                 from ./tensorflow/contrib/lite/schema/schema_generated.h:21,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n./flatbuffers/flatbuffers.h: In member function \u2018void flatbuffers::FlatBufferBuilder::Finish(flatbuffers::uoffset_t, const char*, bool)\u2019:\r\n./flatbuffers/flatbuffers.h:1563:48: error: \u2018strlen\u2019 was not declared in this scope\r\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\r\n                                                ^\r\n./flatbuffers/flatbuffers.h:1563:7: note: in expansion of macro \u2018FLATBUFFERS_ASSERT\u2019\r\n       FLATBUFFERS_ASSERT(strlen(file_identifier) == kFileIdentifierLength);\r\n       ^\r\nIn file included from ./tensorflow/contrib/lite/schema/schema_generated.h:21:0,\r\n                 from ./tensorflow/contrib/lite/model.h:40,\r\n                 from tensorflow/contrib/lite/kernels/register.h:20,\r\n                 from test.cpp:1:\r\n./flatbuffers/flatbuffers.h: In member function \u2018bool flatbuffers::FlatBufferBuilder::StringOffsetCompare::operator()(const flatbuffers::Offset<flatbuffers::String>&, const flatbuffers::Offset<flatbuffers::String>&) const\u2019:\r\n./flatbuffers/flatbuffers.h:1604:64: error: \u2018strncmp\u2019 was not declared in this scope\r\n                      (std::min)(stra->size(), strb->size()) + 1) < 0;\r\n                                                                ^\r\n./flatbuffers/flatbuffers.h: In function \u2018bool flatbuffers::BufferHasIdentifier(const void*, const char*, bool)\u2019:\r\n./flatbuffers/flatbuffers.h:1676:58: error: \u2018strncmp\u2019 was not declared in this scope\r\n                  FlatBufferBuilder::kFileIdentifierLength) == 0;\r\n                                                          ^\r\n./flatbuffers/flatbuffers.h: In function \u2018int flatbuffers::LookupEnum(const char**, const char*)\u2019:\r\n./flatbuffers/flatbuffers.h:2119:10: error: \u2018strcmp\u2019 is not a member of \u2018std\u2019\r\n     if (!std::strcmp(*p, name)) return static_cast<int>(p - names);\r\n```"}