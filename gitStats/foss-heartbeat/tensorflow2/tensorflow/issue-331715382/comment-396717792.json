{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/396717792", "html_url": "https://github.com/tensorflow/tensorflow/issues/19952#issuecomment-396717792", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19952", "id": 396717792, "node_id": "MDEyOklzc3VlQ29tbWVudDM5NjcxNzc5Mg==", "user": {"login": "terrykong", "id": 7576060, "node_id": "MDQ6VXNlcjc1NzYwNjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7576060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/terrykong", "html_url": "https://github.com/terrykong", "followers_url": "https://api.github.com/users/terrykong/followers", "following_url": "https://api.github.com/users/terrykong/following{/other_user}", "gists_url": "https://api.github.com/users/terrykong/gists{/gist_id}", "starred_url": "https://api.github.com/users/terrykong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/terrykong/subscriptions", "organizations_url": "https://api.github.com/users/terrykong/orgs", "repos_url": "https://api.github.com/users/terrykong/repos", "events_url": "https://api.github.com/users/terrykong/events{/privacy}", "received_events_url": "https://api.github.com/users/terrykong/received_events", "type": "User", "site_admin": false}, "created_at": "2018-06-12T20:11:45Z", "updated_at": "2018-06-12T20:11:45Z", "author_association": "NONE", "body_html": "<p>I've thought of using Dataset.batch (and even Dataset.padded_batch), to batch num_workers and then tf.contrib.data.unbatch() them, but the shapes don't match, i.e., [batch_size, max_seq_len_1] and [batch_size, max_seq_len_2], not to mention it is a lot of extra work to batch() -&gt; unbatch -&gt; rebatch().</p>", "body_text": "I've thought of using Dataset.batch (and even Dataset.padded_batch), to batch num_workers and then tf.contrib.data.unbatch() them, but the shapes don't match, i.e., [batch_size, max_seq_len_1] and [batch_size, max_seq_len_2], not to mention it is a lot of extra work to batch() -> unbatch -> rebatch().", "body": "I've thought of using Dataset.batch (and even Dataset.padded_batch), to batch num_workers and then tf.contrib.data.unbatch() them, but the shapes don't match, i.e., [batch_size, max_seq_len_1] and [batch_size, max_seq_len_2], not to mention it is a lot of extra work to batch() -> unbatch -> rebatch()."}