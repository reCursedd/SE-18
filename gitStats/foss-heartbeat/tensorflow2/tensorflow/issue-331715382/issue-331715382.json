{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19952", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19952/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19952/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19952/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/19952", "id": 331715382, "node_id": "MDU6SXNzdWUzMzE3MTUzODI=", "number": 19952, "title": "tf.data.Dataset.shard_and_drop_remainder?", "user": {"login": "terrykong", "id": 7576060, "node_id": "MDQ6VXNlcjc1NzYwNjA=", "avatar_url": "https://avatars3.githubusercontent.com/u/7576060?v=4", "gravatar_id": "", "url": "https://api.github.com/users/terrykong", "html_url": "https://github.com/terrykong", "followers_url": "https://api.github.com/users/terrykong/followers", "following_url": "https://api.github.com/users/terrykong/following{/other_user}", "gists_url": "https://api.github.com/users/terrykong/gists{/gist_id}", "starred_url": "https://api.github.com/users/terrykong/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/terrykong/subscriptions", "organizations_url": "https://api.github.com/users/terrykong/orgs", "repos_url": "https://api.github.com/users/terrykong/repos", "events_url": "https://api.github.com/users/terrykong/events{/privacy}", "received_events_url": "https://api.github.com/users/terrykong/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473173272, "node_id": "MDU6TGFiZWw0NzMxNzMyNzI=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:feature", "name": "type:feature", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "jsimsa", "id": 1072079, "node_id": "MDQ6VXNlcjEwNzIwNzk=", "avatar_url": "https://avatars2.githubusercontent.com/u/1072079?v=4", "gravatar_id": "", "url": "https://api.github.com/users/jsimsa", "html_url": "https://github.com/jsimsa", "followers_url": "https://api.github.com/users/jsimsa/followers", "following_url": "https://api.github.com/users/jsimsa/following{/other_user}", "gists_url": "https://api.github.com/users/jsimsa/gists{/gist_id}", "starred_url": "https://api.github.com/users/jsimsa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/jsimsa/subscriptions", "organizations_url": "https://api.github.com/users/jsimsa/orgs", "repos_url": "https://api.github.com/users/jsimsa/repos", "events_url": "https://api.github.com/users/jsimsa/events{/privacy}", "received_events_url": "https://api.github.com/users/jsimsa/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 7, "created_at": "2018-06-12T19:07:47Z", "updated_at": "2018-11-15T00:49:19Z", "closed_at": "2018-11-15T00:49:19Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>:<br>\n- yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>:</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>:</li>\n<li><strong>TensorFlow version (use command below)</strong>:<br>\n- v.1.8.0</li>\n<li><strong>Python version</strong>:</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I'm curious if there's anyway to accomplish a function like Dataset.shard_and_drop_remainder(num_shards, index) with the current machinery? If not, then I guess this is a feature request. The use case I have is, I'm training an RNN model with horovod and I've decided to bucket my variable length sequences, then batch them, and then shard to the number of workers, but I have no idea if there are enough batches at all my workers to perform an allreduce, which results in horovod complaining and failing in the allreduce. Ideally I would like the dataset to take \"num_shards\" and use that to check whether I have enough elements in the dataset to carry out another global step.</p>\n<p>The solution I've come up with now is to iterate once to count the number of batches and then use Dataset.take((num_batches//num_workers)*num_workers) to ensure the number of batches is divisible by the number of workers.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\n- yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\nTensorFlow installed from (source or binary):\nTensorFlow version (use command below):\n- v.1.8.0\nPython version:\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce:\n\nDescribe the problem\nI'm curious if there's anyway to accomplish a function like Dataset.shard_and_drop_remainder(num_shards, index) with the current machinery? If not, then I guess this is a feature request. The use case I have is, I'm training an RNN model with horovod and I've decided to bucket my variable length sequences, then batch them, and then shard to the number of workers, but I have no idea if there are enough batches at all my workers to perform an allreduce, which results in horovod complaining and failing in the allreduce. Ideally I would like the dataset to take \"num_shards\" and use that to check whether I have enough elements in the dataset to carry out another global step.\nThe solution I've come up with now is to iterate once to count the number of batches and then use Dataset.take((num_batches//num_workers)*num_workers) to ensure the number of batches is divisible by the number of workers.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n      - yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n       - v.1.8.0\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm curious if there's anyway to accomplish a function like Dataset.shard_and_drop_remainder(num_shards, index) with the current machinery? If not, then I guess this is a feature request. The use case I have is, I'm training an RNN model with horovod and I've decided to bucket my variable length sequences, then batch them, and then shard to the number of workers, but I have no idea if there are enough batches at all my workers to perform an allreduce, which results in horovod complaining and failing in the allreduce. Ideally I would like the dataset to take \"num_shards\" and use that to check whether I have enough elements in the dataset to carry out another global step.\r\n\r\nThe solution I've come up with now is to iterate once to count the number of batches and then use Dataset.take((num_batches//num_workers)*num_workers) to ensure the number of batches is divisible by the number of workers. \r\n"}