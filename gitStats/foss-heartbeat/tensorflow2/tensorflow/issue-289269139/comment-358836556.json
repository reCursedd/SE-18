{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/358836556", "html_url": "https://github.com/tensorflow/tensorflow/issues/16193#issuecomment-358836556", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16193", "id": 358836556, "node_id": "MDEyOklzc3VlQ29tbWVudDM1ODgzNjU1Ng==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-19T01:18:18Z", "updated_at": "2018-01-19T04:24:17Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=31006614\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Pelups\">@Pelups</a> :  Could you either share the exact graph file you used and/or test with the graph I used below?  I am getting contradictory results and while I try different setups it would help if I was testing the exact same setup.  Also what CPU setup are you using, the CPU model code is the easiest way to share that.</p>\n<p>I am still investigating and it is possible I am running the test incorrectly, there are a lot of results from the script and I believe I am interpreting them correctly but maybe not.  On an AWS m4.4xlarge 16 vCPUs at 2.3 Ghz (broadwell) I am seeing different results and I want to keep looking as I find it odd my results are so different.  If you have the exact graph you were using that would help.   Here is the test that I ran.</p>\n<p>I used the following graphs:</p>\n<ul>\n<li><a href=\"http://download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz\" rel=\"nofollow\">mobilenetv1</a></li>\n<li><a href=\"https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\" rel=\"nofollow\">inception</a></li>\n</ul>\n<p>I ran mobilenet with:</p>\n<div class=\"highlight highlight-source-shell\"><pre>./benchmark_model --graph=/data/mobilenet_v1_1_224/mobilenet_v1_1.0_224/frozen_graph.pb --input_layer=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>input<span class=\"pl-pds\">\"</span></span> --output_layer=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MobilenetV1/Predictions/Reshape_1<span class=\"pl-pds\">\"</span></span></pre></div>\n<p><strong>For Inception</strong> there was no difference between 1.4.1 and 1.5RC1</p>\n<ul>\n<li>1.4.1: <strong>32.7ms</strong>  2018-01-18 22:30:25.591497: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=450 first=32455 curr=32522 min=30880 max=36377 avg=32680.5 std=703</li>\n<li>1.5RC1: <strong>32.5ms</strong>   2018-01-18 22:43:14.819298: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=451 first=33216 curr=33187 min=31072 max=37290 avg=32510 std=768</li>\n</ul>\n<p><strong>For mobilenetv1</strong> the results were perplexing and I am digging in.  1.5RC1 was faster.  I double checked that I did not compile in AVX by looking at the logs.</p>\n<p><strong>All Threads (16)</strong></p>\n<ul>\n<li>1.4.1: <strong>32.4ms</strong> 2018-01-19 00:01:13.230477: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=308 first=34539 curr=32567 min=30796 max=34958 avg=32374.9 std=650</li>\n<li>1.5RC1: <strong>24.9ms</strong>  2018-01-18 23:57:49.456252: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=400 first=24113 curr=24401 min=23805 max=26506 avg=24910.6 std=524</li>\n<li>1.5.RC1  <strong>17.8ms</strong> AVX2 compiled with broadwell running on the Docker.  Weird and repeated as outside Docker AVX2 is consistent 21ms.</li>\n</ul>\n<p><strong>1 Thread</strong></p>\n<ul>\n<li>1.4.1: <strong>179ms</strong>  2018-01-19 00:42:10.455322: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=56 first=179066 curr=178621 min=177166 max=180046 avg=178665 std=574</li>\n<li>1.5RC1: <strong>106ms</strong>  2018-01-19 00:12:49.710419: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=94 first=106362 curr=106541 min=105246 max=108088 avg=106450 std=356</li>\n<li>1.5.RC1  <strong>52ms</strong> AVX2 compiled with broadwell running on the Docker.</li>\n</ul>\n<p>Testing outside docker (still testing)<br>\nmobilenetv1:<br>\nAll Threads (16):</p>\n<ul>\n<li>1.5.RC1  <strong>21ms</strong> AVX2 compiled with broadwell (consistent)</li>\n<li>1.4.1 <strong>31ms</strong> SSE3</li>\n</ul>\n<p>One Thread:</p>\n<ul>\n<li>1.5.RC1  <strong>56.3ms</strong> AVX2 compiled with broadwell</li>\n<li>1.4.1 <strong>178ms</strong> SSE3</li>\n</ul>\n<p><strong>Extra info for tracking:</strong></p>\n<ul>\n<li>I used Bazel 0.5.4 for 1.4.1 and Bazel 0.9 for 1.5RC1.  I doubt the version of bazel matters</li>\n<li>I built for CPU only in a Docker.  bazel --config=opt</li>\n<li>I have the log files so I have everything that was output</li>\n<li>I ran the tests a few times and did not average them I just confirmed the results were not jumping around and took one.  Not 100% scientific.</li>\n</ul>\n<p>We are currently holding the 1.5 build as we investigate further.</p>", "body_text": "@Pelups :  Could you either share the exact graph file you used and/or test with the graph I used below?  I am getting contradictory results and while I try different setups it would help if I was testing the exact same setup.  Also what CPU setup are you using, the CPU model code is the easiest way to share that.\nI am still investigating and it is possible I am running the test incorrectly, there are a lot of results from the script and I believe I am interpreting them correctly but maybe not.  On an AWS m4.4xlarge 16 vCPUs at 2.3 Ghz (broadwell) I am seeing different results and I want to keep looking as I find it odd my results are so different.  If you have the exact graph you were using that would help.   Here is the test that I ran.\nI used the following graphs:\n\nmobilenetv1\ninception\n\nI ran mobilenet with:\n./benchmark_model --graph=/data/mobilenet_v1_1_224/mobilenet_v1_1.0_224/frozen_graph.pb --input_layer=\"input\" --output_layer=\"MobilenetV1/Predictions/Reshape_1\"\nFor Inception there was no difference between 1.4.1 and 1.5RC1\n\n1.4.1: 32.7ms  2018-01-18 22:30:25.591497: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=450 first=32455 curr=32522 min=30880 max=36377 avg=32680.5 std=703\n1.5RC1: 32.5ms   2018-01-18 22:43:14.819298: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=451 first=33216 curr=33187 min=31072 max=37290 avg=32510 std=768\n\nFor mobilenetv1 the results were perplexing and I am digging in.  1.5RC1 was faster.  I double checked that I did not compile in AVX by looking at the logs.\nAll Threads (16)\n\n1.4.1: 32.4ms 2018-01-19 00:01:13.230477: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=308 first=34539 curr=32567 min=30796 max=34958 avg=32374.9 std=650\n1.5RC1: 24.9ms  2018-01-18 23:57:49.456252: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=400 first=24113 curr=24401 min=23805 max=26506 avg=24910.6 std=524\n1.5.RC1  17.8ms AVX2 compiled with broadwell running on the Docker.  Weird and repeated as outside Docker AVX2 is consistent 21ms.\n\n1 Thread\n\n1.4.1: 179ms  2018-01-19 00:42:10.455322: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=56 first=179066 curr=178621 min=177166 max=180046 avg=178665 std=574\n1.5RC1: 106ms  2018-01-19 00:12:49.710419: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=94 first=106362 curr=106541 min=105246 max=108088 avg=106450 std=356\n1.5.RC1  52ms AVX2 compiled with broadwell running on the Docker.\n\nTesting outside docker (still testing)\nmobilenetv1:\nAll Threads (16):\n\n1.5.RC1  21ms AVX2 compiled with broadwell (consistent)\n1.4.1 31ms SSE3\n\nOne Thread:\n\n1.5.RC1  56.3ms AVX2 compiled with broadwell\n1.4.1 178ms SSE3\n\nExtra info for tracking:\n\nI used Bazel 0.5.4 for 1.4.1 and Bazel 0.9 for 1.5RC1.  I doubt the version of bazel matters\nI built for CPU only in a Docker.  bazel --config=opt\nI have the log files so I have everything that was output\nI ran the tests a few times and did not average them I just confirmed the results were not jumping around and took one.  Not 100% scientific.\n\nWe are currently holding the 1.5 build as we investigate further.", "body": "@Pelups :  Could you either share the exact graph file you used and/or test with the graph I used below?  I am getting contradictory results and while I try different setups it would help if I was testing the exact same setup.  Also what CPU setup are you using, the CPU model code is the easiest way to share that.\r\n\r\nI am still investigating and it is possible I am running the test incorrectly, there are a lot of results from the script and I believe I am interpreting them correctly but maybe not.  On an AWS m4.4xlarge 16 vCPUs at 2.3 Ghz (broadwell) I am seeing different results and I want to keep looking as I find it odd my results are so different.  If you have the exact graph you were using that would help.   Here is the test that I ran.\r\n\r\nI used the following graphs:\r\n- [mobilenetv1](http://download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz) \r\n- [inception](https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip)\r\n\r\nI ran mobilenet with:  \r\n```bash\r\n./benchmark_model --graph=/data/mobilenet_v1_1_224/mobilenet_v1_1.0_224/frozen_graph.pb --input_layer=\"input\" --output_layer=\"MobilenetV1/Predictions/Reshape_1\"\r\n```\r\n**For Inception** there was no difference between 1.4.1 and 1.5RC1\r\n\r\n- 1.4.1: **32.7ms**  2018-01-18 22:30:25.591497: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=450 first=32455 curr=32522 min=30880 max=36377 avg=32680.5 std=703\r\n- 1.5RC1: **32.5ms**   2018-01-18 22:43:14.819298: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=451 first=33216 curr=33187 min=31072 max=37290 avg=32510 std=768\r\n\r\n\r\n**For mobilenetv1** the results were perplexing and I am digging in.  1.5RC1 was faster.  I double checked that I did not compile in AVX by looking at the logs.\r\n\r\n**All Threads (16)**\r\n\r\n- 1.4.1: **32.4ms** 2018-01-19 00:01:13.230477: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=308 first=34539 curr=32567 min=30796 max=34958 avg=32374.9 std=650\r\n- 1.5RC1: **24.9ms**  2018-01-18 23:57:49.456252: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=400 first=24113 curr=24401 min=23805 max=26506 avg=24910.6 std=524\r\n- 1.5.RC1  **17.8ms** AVX2 compiled with broadwell running on the Docker.  Weird and repeated as outside Docker AVX2 is consistent 21ms.\r\n\r\n**1 Thread**\r\n\r\n- 1.4.1: **179ms**  2018-01-19 00:42:10.455322: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=56 first=179066 curr=178621 min=177166 max=180046 avg=178665 std=574\r\n- 1.5RC1: **106ms**  2018-01-19 00:12:49.710419: I tensorflow/core/util/stat_summarizer.cc:468] Timings (microseconds): count=94 first=106362 curr=106541 min=105246 max=108088 avg=106450 std=356\r\n- 1.5.RC1  **52ms** AVX2 compiled with broadwell running on the Docker. \r\n\r\nTesting outside docker (still testing)\r\nmobilenetv1:\r\nAll Threads (16):\r\n- 1.5.RC1  **21ms** AVX2 compiled with broadwell (consistent)\r\n- 1.4.1 **31ms** SSE3\r\n\r\nOne Thread:\r\n- 1.5.RC1  **56.3ms** AVX2 compiled with broadwell\r\n- 1.4.1 **178ms** SSE3\r\n\r\n\r\n**Extra info for tracking:**\r\n- I used Bazel 0.5.4 for 1.4.1 and Bazel 0.9 for 1.5RC1.  I doubt the version of bazel matters\r\n- I built for CPU only in a Docker.  bazel --config=opt\r\n- I have the log files so I have everything that was output\r\n- I ran the tests a few times and did not average them I just confirmed the results were not jumping around and took one.  Not 100% scientific.  \r\n\r\nWe are currently holding the 1.5 build as we investigate further.  \r\n"}