{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16193", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16193/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16193/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/16193/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/16193", "id": 289269139, "node_id": "MDU6SXNzdWUyODkyNjkxMzk=", "number": 16193, "title": "Performance issues with TF1.5 on CPU", "user": {"login": "Pelups", "id": 31006614, "node_id": "MDQ6VXNlcjMxMDA2NjE0", "avatar_url": "https://avatars0.githubusercontent.com/u/31006614?v=4", "gravatar_id": "", "url": "https://api.github.com/users/Pelups", "html_url": "https://github.com/Pelups", "followers_url": "https://api.github.com/users/Pelups/followers", "following_url": "https://api.github.com/users/Pelups/following{/other_user}", "gists_url": "https://api.github.com/users/Pelups/gists{/gist_id}", "starred_url": "https://api.github.com/users/Pelups/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/Pelups/subscriptions", "organizations_url": "https://api.github.com/users/Pelups/orgs", "repos_url": "https://api.github.com/users/Pelups/repos", "events_url": "https://api.github.com/users/Pelups/events{/privacy}", "received_events_url": "https://api.github.com/users/Pelups/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 473172988, "node_id": "MDU6TGFiZWw0NzMxNzI5ODg=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:bug/performance", "name": "type:bug/performance", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 8, "created_at": "2018-01-17T13:39:19Z", "updated_at": "2018-01-22T16:34:30Z", "closed_at": "2018-01-22T09:01:17Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: source</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.5.0-rc1</li>\n<li><strong>Python version</strong>: 2.7</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.4</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>: 5.4.0</li>\n<li><strong>CUDA/cuDNN version</strong>: NA</li>\n<li><strong>GPU model and memory</strong>: NA</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>Hello,<br>\nI'm facing performance issues with the last releases of TF using a CPU.<br>\nI'm using the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/benchmark/benchmark_model.cc\">benchmark tool</a> to calculate mean inference time of a model.</p>\n<p>For example, in order to evaluate mobilenet (trained on a custom dataset), I'm using this command :<br>\n<code>bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=\"path to mobilenet graph\" --input_layer=\"input\" --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"MobilenetV1/Predictions/Reshape_1\"</code><br>\nAfter setting CUDA_VISIBLE_DEVICES to \"\" in order to run on CPU.</p>\n<p>With TF 1.4.1, I obtain a mean inference time equals to 26ms (13ms if I compile with optimization flags).<br>\nUsing tf 1.5.*, I obtain a mean inference time equals to 51ms (45ms if I compile with optimization flags).</p>\n<p>The loss is very important, so I'm wondering if it's a known issue and how I can improve this.</p>\n<p>I tried with tags/v1.5.0-rc0, tags/v1.5.0-rc1 and master, and the problem is the same.</p>\n<p>Thank you</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): source\nTensorFlow version (use command below): 1.5.0-rc1\nPython version: 2.7\nBazel version (if compiling from source): 0.5.4\nGCC/Compiler version (if compiling from source): 5.4.0\nCUDA/cuDNN version: NA\nGPU model and memory: NA\nExact command to reproduce:\n\nHello,\nI'm facing performance issues with the last releases of TF using a CPU.\nI'm using the benchmark tool to calculate mean inference time of a model.\nFor example, in order to evaluate mobilenet (trained on a custom dataset), I'm using this command :\nbazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=\"path to mobilenet graph\" --input_layer=\"input\" --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"MobilenetV1/Predictions/Reshape_1\"\nAfter setting CUDA_VISIBLE_DEVICES to \"\" in order to run on CPU.\nWith TF 1.4.1, I obtain a mean inference time equals to 26ms (13ms if I compile with optimization flags).\nUsing tf 1.5.*, I obtain a mean inference time equals to 51ms (45ms if I compile with optimization flags).\nThe loss is very important, so I'm wondering if it's a known issue and how I can improve this.\nI tried with tags/v1.5.0-rc0, tags/v1.5.0-rc1 and master, and the problem is the same.\nThank you", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.5.0-rc1\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n\r\nHello,\r\nI'm facing performance issues with the last releases of TF using a CPU.\r\nI'm using the [benchmark tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/benchmark/benchmark_model.cc) to calculate mean inference time of a model.\r\n\r\nFor example, in order to evaluate mobilenet (trained on a custom dataset), I'm using this command :\r\n`bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=\"path to mobilenet graph\" --input_layer=\"input\" --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"MobilenetV1/Predictions/Reshape_1\"`\r\nAfter setting CUDA_VISIBLE_DEVICES to \"\" in order to run on CPU.\r\n\r\nWith TF 1.4.1, I obtain a mean inference time equals to 26ms (13ms if I compile with optimization flags).\r\nUsing tf 1.5.*, I obtain a mean inference time equals to 51ms (45ms if I compile with optimization flags).\r\n\r\nThe loss is very important, so I'm wondering if it's a known issue and how I can improve this.\r\n\r\nI tried with tags/v1.5.0-rc0, tags/v1.5.0-rc1 and master, and the problem is the same.\r\n\r\nThank you"}