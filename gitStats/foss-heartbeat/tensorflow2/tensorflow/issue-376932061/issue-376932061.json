{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23463", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23463/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23463/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/23463/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/23463", "id": 376932061, "node_id": "MDU6SXNzdWUzNzY5MzIwNjE=", "number": 23463, "title": "[Bug] TensorRT converted graph gives wrong output", "user": {"login": "mike199515", "id": 6950999, "node_id": "MDQ6VXNlcjY5NTA5OTk=", "avatar_url": "https://avatars3.githubusercontent.com/u/6950999?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mike199515", "html_url": "https://github.com/mike199515", "followers_url": "https://api.github.com/users/mike199515/followers", "following_url": "https://api.github.com/users/mike199515/following{/other_user}", "gists_url": "https://api.github.com/users/mike199515/gists{/gist_id}", "starred_url": "https://api.github.com/users/mike199515/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mike199515/subscriptions", "organizations_url": "https://api.github.com/users/mike199515/orgs", "repos_url": "https://api.github.com/users/mike199515/repos", "events_url": "https://api.github.com/users/mike199515/events{/privacy}", "received_events_url": "https://api.github.com/users/mike199515/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "open", "locked": false, "assignee": {"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "aaroey", "id": 31743510, "node_id": "MDQ6VXNlcjMxNzQzNTEw", "avatar_url": "https://avatars0.githubusercontent.com/u/31743510?v=4", "gravatar_id": "", "url": "https://api.github.com/users/aaroey", "html_url": "https://github.com/aaroey", "followers_url": "https://api.github.com/users/aaroey/followers", "following_url": "https://api.github.com/users/aaroey/following{/other_user}", "gists_url": "https://api.github.com/users/aaroey/gists{/gist_id}", "starred_url": "https://api.github.com/users/aaroey/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/aaroey/subscriptions", "organizations_url": "https://api.github.com/users/aaroey/orgs", "repos_url": "https://api.github.com/users/aaroey/repos", "events_url": "https://api.github.com/users/aaroey/events{/privacy}", "received_events_url": "https://api.github.com/users/aaroey/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 1, "created_at": "2018-11-02T19:02:03Z", "updated_at": "2018-11-22T18:51:02Z", "closed_at": null, "author_association": "NONE", "body_html": "<p><em>Please make sure that this is a bug. As per our <a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em></p>\n<p><strong>System information</strong></p>\n<ul>\n<li>Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes</li>\n<li>OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04</li>\n<li>Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No</li>\n<li>TensorFlow installed from (source or binary): binary</li>\n<li>TensorFlow version (use command below): 1.11.0</li>\n<li>Python version: 2.7.12</li>\n<li>Bazel version (if compiling from source): N/A</li>\n<li>GCC/Compiler version (if compiling from source): N/A</li>\n<li>CUDA/cuDNN version: 9.0/7</li>\n<li>GPU model and memory: GTX 1080, 8GB</li>\n</ul>\n<p>env.txt:</p>\n<pre><code>\n== cat /etc/issue ===============================================\nLinux yiwei-desktop 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux yiwei-desktop 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy                              1.15.2                \nprotobuf                           3.6.0                 \ntensorflow-gpu                     1.11.0                \ntensorflow-tensorboard             0.1.8                 \n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.11.0\ntf.GIT_VERSION = v1.11.0-0-gc19e29306c\ntf.COMPILER_VERSION = v1.11.0-0-gc19e29306c\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nThu Nov  1 18:42:17 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\n| 29%   46C    P2    42W / 180W |   1391MiB /  8112MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      2190      G   /usr/lib/xorg/Xorg                           582MiB |\n|    0      5166      G   compiz                                       493MiB |\n|    0      6354      G   ...-token=6EB0A193120E130143DC89992F94A977   196MiB |\n|    0      7163      C   /usr/lib/libreoffice/program/soffice.bin     107MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.252\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n</code></pre>\n<p><strong>Describe the current behavior</strong><br>\nWhen using TensorRT to convert a graph that contains a specific structure, the output of the graph would be wrong compare to the output of from the original graph with same input. Sometimes the output can be as large as infinity or some very big numbers.</p>\n<p><strong>Describe the expected behavior</strong><br>\nWe expect the two graph to output similiarly (Normally, we get absolute error &lt; 1e-5)</p>\n<p><strong>Code to reproduce the issue</strong></p>\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import tensorrt as trt\n\n\n# Set to False would not trigger the bug.\nBUGGED_VERSION = True\n\n\ndef build_graph_from_def(graph_def, input_nodes, output_nodes):\n    \"\"\"\n    build the actual graph from definition\n    \"\"\"\n    tf.reset_default_graph()\n    graph = tf.Graph()\n    with graph.as_default():\n        return_tensors = [operation_name +\n                          \":0\" for operation_name in input_nodes + output_nodes]\n        tensors = tf.import_graph_def(graph_def=graph_def, name=\"\",\n                                      return_elements=return_tensors)\n        input_tensor_list = tensors[:len(input_nodes)]\n        output_tensor_list = tensors[len(input_nodes):]\n\n    return graph, input_tensor_list, output_tensor_list\n\n\ndef conv(inp, name):\n    # Seems to be data-format irrelevant. Tested with both NCHW and NHWC.\n    # However, when bias is zero (as initialized by tf.layers.conv2d by default)\n    # The bug would trigger.\n    if BUGGED_VERSION:\n        return tf.layers.conv2d(inp, filters=16, kernel_size=(3, 3), name=name)\n    else:\n        return tf.layers.conv2d(inp, filters=16, kernel_size=(3, 3),\n                                bias_initializer=tf.variance_scaling_initializer(), name=name)\n\n\ndef main():\n    with tf.variable_scope(\"Net\"):\n        inp = tf.placeholder(tf.float32, shape=(1, 28, 28, 3), name=\"input\")\n        conv_shared = conv(inp, \"conv_shared\")\n        conv1_1 = conv(conv_shared, \"conv1_1\")\n        conv1_2 = conv(conv1_1, \"conv1_2\")\n        conv2_1 = conv(conv_shared, \"conv2_1\")\n        conv2_2 = conv(conv2_1, \"conv2_2\")\n    input_nodes = [\"Net/input\"]\n\n    # We need to output both to trigger the error.\n    # Also note that if we includes \"Net/conv_shared/BiasAdd\" to output_nodes, the bug\n    # disappears.\n    output_nodes = [\"Net/conv1_2/BiasAdd\", \"Net/conv2_2/BiasAdd\"]\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        const_graph_def = tf.graph_util.convert_variables_to_constants(\n            sess, sess.graph.as_graph_def(), output_nodes)\n\n    optimized_graph_def = trt.create_inference_graph(\n        input_graph_def=const_graph_def,\n        outputs=output_nodes,\n        max_batch_size=1,\n        max_workspace_size_bytes=1 &lt;&lt; 25)\n\n    graph, input_tensors, output_tensors = build_graph_from_def(\n        optimized_graph_def, input_nodes, output_nodes)\n\n    # Seems to be input-value irrelevant, also tested with np.ones and random\n    input_value = np.zeros((1, 28, 28, 3))\n    with tf.Session(graph=graph) as sess:\n        converted_output = sess.run(output_tensors[0], feed_dict={\n                                    input_tensors[0]: input_value})\n\n    graph, input_tensors, output_tensors = build_graph_from_def(\n        const_graph_def, input_nodes, output_nodes)\n    with tf.Session(graph=graph) as sess:\n        original_output = sess.run(output_tensors[0], feed_dict={\n            input_tensors[0]: input_value})\n\n    deltas = np.abs(converted_output - original_output)\n\n    # Output would be random and varies each time (maybe correct by accident),\n    # indicating being memory or graph-weight specific issue.\n    print(\"min={}\".format(np.min(deltas)))\n    print(\"max={}\".format(np.max(deltas)))\n    print(\"median={}\".format(np.median(deltas)))\n    print(\"mean={}\".format(np.mean(deltas)))\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>\n<p><strong>Other info / logs</strong><br>\nThis may be Nvidia's bug as well, yet not able to test that directly. Thoughts about the problem has been included in the sample code. A typical output looks like the following:</p>\n<pre><code>2018-11-02 11:51:59.336625: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-11-02 11:51:59.401658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-11-02 11:51:59.402192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 6.11GiB\n2018-11-02 11:51:59.402205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:51:59.676511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:51:59.676541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:51:59.676547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:51:59.676703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-02 11:51:59.778756: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count &gt;= 8): 1\n2018-11-02 11:51:59.778802: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n2018-11-02 11:51:59.778973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:51:59.778987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:51:59.778992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:51:59.778996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:51:59.779084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-02 11:51:59.787791: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'Net/', converted to graph\n2018-11-02 11:51:59.787804: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:418] Can't find a device placement for the op!\n2018-11-02 11:52:01.472421: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine Net/my_trt_op_0 creation for segment 0, composed of 13 nodes succeeded.\n2018-11-02 11:52:01.475092: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\n2018-11-02 11:52:01.475574: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\n2018-11-02 11:52:01.476125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: tf_graph\n2018-11-02 11:52:01.476138: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 21 nodes (-10), 20 edges (-10), time = 1.141ms.\n2018-11-02 11:52:01.476143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 26 nodes (5), 26 edges (6), time = 0.54ms.\n2018-11-02 11:52:01.476147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (-12), 14 edges (-12), time = 1685.31897ms.\n2018-11-02 11:52:01.476151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 14 edges (0), time = 0.442ms.\n2018-11-02 11:52:01.476155: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 14 edges (0), time = 0.576ms.\n2018-11-02 11:52:01.476159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: Net/my_trt_op_0_native_segment\n2018-11-02 11:52:01.476163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 13 edges (0), time = 0.537ms.\n2018-11-02 11:52:01.476167: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 14 nodes (0), 13 edges (0), time = 0.339ms.\n2018-11-02 11:52:01.476171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 13 edges (0), time = 0.071ms.\n2018-11-02 11:52:01.476175: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 13 edges (0), time = 0.405ms.\n2018-11-02 11:52:01.476180: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 13 edges (0), time = 0.066ms.\n2018-11-02 11:52:01.505052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:52:01.505082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:52:01.505088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:52:01.505092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:52:01.505183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-02 11:52:01.527376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:52:01.527397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:52:01.527403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:52:01.527407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:52:01.527486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\nmin=4.95342129678e+29\nmax=2.45457421171e+31\nmedian=6.9235024529e+30\nmean=8.45157562195e+30\n\n</code></pre>", "body_text": "Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\nTensorFlow installed from (source or binary): binary\nTensorFlow version (use command below): 1.11.0\nPython version: 2.7.12\nBazel version (if compiling from source): N/A\nGCC/Compiler version (if compiling from source): N/A\nCUDA/cuDNN version: 9.0/7\nGPU model and memory: GTX 1080, 8GB\n\nenv.txt:\n\n== cat /etc/issue ===============================================\nLinux yiwei-desktop 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\nVERSION_ID=\"16.04\"\nVERSION_CODENAME=xenial\n\n== are we in docker =============================================\nNo\n\n== compiler =====================================================\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n== uname -a =====================================================\nLinux yiwei-desktop 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\n\n== check pips ===================================================\nnumpy                              1.15.2                \nprotobuf                           3.6.0                 \ntensorflow-gpu                     1.11.0                \ntensorflow-tensorboard             0.1.8                 \n\n== check for virtualenv =========================================\nFalse\n\n== tensorflow import ============================================\ntf.VERSION = 1.11.0\ntf.GIT_VERSION = v1.11.0-0-gc19e29306c\ntf.COMPILER_VERSION = v1.11.0-0-gc19e29306c\nSanity check: array([1], dtype=int32)\n\n== env ==========================================================\nLD_LIBRARY_PATH is unset\nDYLD_LIBRARY_PATH is unset\n\n== nvidia-smi ===================================================\nThu Nov  1 18:42:17 2018       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\n| 29%   46C    P2    42W / 180W |   1391MiB /  8112MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0      2190      G   /usr/lib/xorg/Xorg                           582MiB |\n|    0      5166      G   compiz                                       493MiB |\n|    0      6354      G   ...-token=6EB0A193120E130143DC89992F94A977   196MiB |\n|    0      7163      C   /usr/lib/libreoffice/program/soffice.bin     107MiB |\n+-----------------------------------------------------------------------------+\n\n== cuda libs  ===================================================\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.252\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\n\nDescribe the current behavior\nWhen using TensorRT to convert a graph that contains a specific structure, the output of the graph would be wrong compare to the output of from the original graph with same input. Sometimes the output can be as large as infinity or some very big numbers.\nDescribe the expected behavior\nWe expect the two graph to output similiarly (Normally, we get absolute error < 1e-5)\nCode to reproduce the issue\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.contrib import tensorrt as trt\n\n\n# Set to False would not trigger the bug.\nBUGGED_VERSION = True\n\n\ndef build_graph_from_def(graph_def, input_nodes, output_nodes):\n    \"\"\"\n    build the actual graph from definition\n    \"\"\"\n    tf.reset_default_graph()\n    graph = tf.Graph()\n    with graph.as_default():\n        return_tensors = [operation_name +\n                          \":0\" for operation_name in input_nodes + output_nodes]\n        tensors = tf.import_graph_def(graph_def=graph_def, name=\"\",\n                                      return_elements=return_tensors)\n        input_tensor_list = tensors[:len(input_nodes)]\n        output_tensor_list = tensors[len(input_nodes):]\n\n    return graph, input_tensor_list, output_tensor_list\n\n\ndef conv(inp, name):\n    # Seems to be data-format irrelevant. Tested with both NCHW and NHWC.\n    # However, when bias is zero (as initialized by tf.layers.conv2d by default)\n    # The bug would trigger.\n    if BUGGED_VERSION:\n        return tf.layers.conv2d(inp, filters=16, kernel_size=(3, 3), name=name)\n    else:\n        return tf.layers.conv2d(inp, filters=16, kernel_size=(3, 3),\n                                bias_initializer=tf.variance_scaling_initializer(), name=name)\n\n\ndef main():\n    with tf.variable_scope(\"Net\"):\n        inp = tf.placeholder(tf.float32, shape=(1, 28, 28, 3), name=\"input\")\n        conv_shared = conv(inp, \"conv_shared\")\n        conv1_1 = conv(conv_shared, \"conv1_1\")\n        conv1_2 = conv(conv1_1, \"conv1_2\")\n        conv2_1 = conv(conv_shared, \"conv2_1\")\n        conv2_2 = conv(conv2_1, \"conv2_2\")\n    input_nodes = [\"Net/input\"]\n\n    # We need to output both to trigger the error.\n    # Also note that if we includes \"Net/conv_shared/BiasAdd\" to output_nodes, the bug\n    # disappears.\n    output_nodes = [\"Net/conv1_2/BiasAdd\", \"Net/conv2_2/BiasAdd\"]\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        const_graph_def = tf.graph_util.convert_variables_to_constants(\n            sess, sess.graph.as_graph_def(), output_nodes)\n\n    optimized_graph_def = trt.create_inference_graph(\n        input_graph_def=const_graph_def,\n        outputs=output_nodes,\n        max_batch_size=1,\n        max_workspace_size_bytes=1 << 25)\n\n    graph, input_tensors, output_tensors = build_graph_from_def(\n        optimized_graph_def, input_nodes, output_nodes)\n\n    # Seems to be input-value irrelevant, also tested with np.ones and random\n    input_value = np.zeros((1, 28, 28, 3))\n    with tf.Session(graph=graph) as sess:\n        converted_output = sess.run(output_tensors[0], feed_dict={\n                                    input_tensors[0]: input_value})\n\n    graph, input_tensors, output_tensors = build_graph_from_def(\n        const_graph_def, input_nodes, output_nodes)\n    with tf.Session(graph=graph) as sess:\n        original_output = sess.run(output_tensors[0], feed_dict={\n            input_tensors[0]: input_value})\n\n    deltas = np.abs(converted_output - original_output)\n\n    # Output would be random and varies each time (maybe correct by accident),\n    # indicating being memory or graph-weight specific issue.\n    print(\"min={}\".format(np.min(deltas)))\n    print(\"max={}\".format(np.max(deltas)))\n    print(\"median={}\".format(np.median(deltas)))\n    print(\"mean={}\".format(np.mean(deltas)))\n\nif __name__ == \"__main__\":\n    main()\n\nOther info / logs\nThis may be Nvidia's bug as well, yet not able to test that directly. Thoughts about the problem has been included in the sample code. A typical output looks like the following:\n2018-11-02 11:51:59.336625: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2018-11-02 11:51:59.401658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2018-11-02 11:51:59.402192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 6.11GiB\n2018-11-02 11:51:59.402205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:51:59.676511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:51:59.676541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:51:59.676547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:51:59.676703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-02 11:51:59.778756: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\n2018-11-02 11:51:59.778802: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n2018-11-02 11:51:59.778973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:51:59.778987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:51:59.778992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:51:59.778996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:51:59.779084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-02 11:51:59.787791: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'Net/', converted to graph\n2018-11-02 11:51:59.787804: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:418] Can't find a device placement for the op!\n2018-11-02 11:52:01.472421: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine Net/my_trt_op_0 creation for segment 0, composed of 13 nodes succeeded.\n2018-11-02 11:52:01.475092: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\n2018-11-02 11:52:01.475574: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\n2018-11-02 11:52:01.476125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: tf_graph\n2018-11-02 11:52:01.476138: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 21 nodes (-10), 20 edges (-10), time = 1.141ms.\n2018-11-02 11:52:01.476143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 26 nodes (5), 26 edges (6), time = 0.54ms.\n2018-11-02 11:52:01.476147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (-12), 14 edges (-12), time = 1685.31897ms.\n2018-11-02 11:52:01.476151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 14 edges (0), time = 0.442ms.\n2018-11-02 11:52:01.476155: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 14 edges (0), time = 0.576ms.\n2018-11-02 11:52:01.476159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: Net/my_trt_op_0_native_segment\n2018-11-02 11:52:01.476163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 13 edges (0), time = 0.537ms.\n2018-11-02 11:52:01.476167: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 14 nodes (0), 13 edges (0), time = 0.339ms.\n2018-11-02 11:52:01.476171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 13 edges (0), time = 0.071ms.\n2018-11-02 11:52:01.476175: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 13 edges (0), time = 0.405ms.\n2018-11-02 11:52:01.476180: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 13 edges (0), time = 0.066ms.\n2018-11-02 11:52:01.505052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:52:01.505082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:52:01.505088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:52:01.505092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:52:01.505183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n2018-11-02 11:52:01.527376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n2018-11-02 11:52:01.527397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n2018-11-02 11:52:01.527403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n2018-11-02 11:52:01.527407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n2018-11-02 11:52:01.527486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\nmin=4.95342129678e+29\nmax=2.45457421171e+31\nmedian=6.9235024529e+30\nmean=8.45157562195e+30", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: 2.7.12\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 9.0/7\r\n- GPU model and memory: GTX 1080, 8GB\r\n\r\nenv.txt:\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux yiwei-desktop 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux yiwei-desktop 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                              1.15.2                \r\nprotobuf                           3.6.0                 \r\ntensorflow-gpu                     1.11.0                \r\ntensorflow-tensorboard             0.1.8                 \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.11.0\r\ntf.GIT_VERSION = v1.11.0-0-gc19e29306c\r\ntf.COMPILER_VERSION = v1.11.0-0-gc19e29306c\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nThu Nov  1 18:42:17 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\r\n| 29%   46C    P2    42W / 180W |   1391MiB /  8112MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      2190      G   /usr/lib/xorg/Xorg                           582MiB |\r\n|    0      5166      G   compiz                                       493MiB |\r\n|    0      6354      G   ...-token=6EB0A193120E130143DC89992F94A977   196MiB |\r\n|    0      7163      C   /usr/lib/libreoffice/program/soffice.bin     107MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.252\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n```\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nWhen using TensorRT to convert a graph that contains a specific structure, the output of the graph would be wrong compare to the output of from the original graph with same input. Sometimes the output can be as large as infinity or some very big numbers.\r\n\r\n**Describe the expected behavior**\r\nWe expect the two graph to output similiarly (Normally, we get absolute error < 1e-5)\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import tensorrt as trt\r\n\r\n\r\n# Set to False would not trigger the bug.\r\nBUGGED_VERSION = True\r\n\r\n\r\ndef build_graph_from_def(graph_def, input_nodes, output_nodes):\r\n    \"\"\"\r\n    build the actual graph from definition\r\n    \"\"\"\r\n    tf.reset_default_graph()\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        return_tensors = [operation_name +\r\n                          \":0\" for operation_name in input_nodes + output_nodes]\r\n        tensors = tf.import_graph_def(graph_def=graph_def, name=\"\",\r\n                                      return_elements=return_tensors)\r\n        input_tensor_list = tensors[:len(input_nodes)]\r\n        output_tensor_list = tensors[len(input_nodes):]\r\n\r\n    return graph, input_tensor_list, output_tensor_list\r\n\r\n\r\ndef conv(inp, name):\r\n    # Seems to be data-format irrelevant. Tested with both NCHW and NHWC.\r\n    # However, when bias is zero (as initialized by tf.layers.conv2d by default)\r\n    # The bug would trigger.\r\n    if BUGGED_VERSION:\r\n        return tf.layers.conv2d(inp, filters=16, kernel_size=(3, 3), name=name)\r\n    else:\r\n        return tf.layers.conv2d(inp, filters=16, kernel_size=(3, 3),\r\n                                bias_initializer=tf.variance_scaling_initializer(), name=name)\r\n\r\n\r\ndef main():\r\n    with tf.variable_scope(\"Net\"):\r\n        inp = tf.placeholder(tf.float32, shape=(1, 28, 28, 3), name=\"input\")\r\n        conv_shared = conv(inp, \"conv_shared\")\r\n        conv1_1 = conv(conv_shared, \"conv1_1\")\r\n        conv1_2 = conv(conv1_1, \"conv1_2\")\r\n        conv2_1 = conv(conv_shared, \"conv2_1\")\r\n        conv2_2 = conv(conv2_1, \"conv2_2\")\r\n    input_nodes = [\"Net/input\"]\r\n\r\n    # We need to output both to trigger the error.\r\n    # Also note that if we includes \"Net/conv_shared/BiasAdd\" to output_nodes, the bug\r\n    # disappears.\r\n    output_nodes = [\"Net/conv1_2/BiasAdd\", \"Net/conv2_2/BiasAdd\"]\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        const_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess, sess.graph.as_graph_def(), output_nodes)\r\n\r\n    optimized_graph_def = trt.create_inference_graph(\r\n        input_graph_def=const_graph_def,\r\n        outputs=output_nodes,\r\n        max_batch_size=1,\r\n        max_workspace_size_bytes=1 << 25)\r\n\r\n    graph, input_tensors, output_tensors = build_graph_from_def(\r\n        optimized_graph_def, input_nodes, output_nodes)\r\n\r\n    # Seems to be input-value irrelevant, also tested with np.ones and random\r\n    input_value = np.zeros((1, 28, 28, 3))\r\n    with tf.Session(graph=graph) as sess:\r\n        converted_output = sess.run(output_tensors[0], feed_dict={\r\n                                    input_tensors[0]: input_value})\r\n\r\n    graph, input_tensors, output_tensors = build_graph_from_def(\r\n        const_graph_def, input_nodes, output_nodes)\r\n    with tf.Session(graph=graph) as sess:\r\n        original_output = sess.run(output_tensors[0], feed_dict={\r\n            input_tensors[0]: input_value})\r\n\r\n    deltas = np.abs(converted_output - original_output)\r\n\r\n    # Output would be random and varies each time (maybe correct by accident),\r\n    # indicating being memory or graph-weight specific issue.\r\n    print(\"min={}\".format(np.min(deltas)))\r\n    print(\"max={}\".format(np.max(deltas)))\r\n    print(\"median={}\".format(np.median(deltas)))\r\n    print(\"mean={}\".format(np.mean(deltas)))\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\n**Other info / logs**\r\nThis may be Nvidia's bug as well, yet not able to test that directly. Thoughts about the problem has been included in the sample code. A typical output looks like the following:\r\n```\r\n2018-11-02 11:51:59.336625: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-11-02 11:51:59.401658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-11-02 11:51:59.402192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 6.11GiB\r\n2018-11-02 11:51:59.402205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-11-02 11:51:59.676511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-02 11:51:59.676541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-11-02 11:51:59.676547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-11-02 11:51:59.676703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-11-02 11:51:59.778756: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 1\r\n2018-11-02 11:51:59.778802: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2018-11-02 11:51:59.778973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-11-02 11:51:59.778987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-02 11:51:59.778992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-11-02 11:51:59.778996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-11-02 11:51:59.779084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-11-02 11:51:59.787791: I tensorflow/contrib/tensorrt/convert/convert_nodes.cc:2952] Segment @scope 'Net/', converted to graph\r\n2018-11-02 11:51:59.787804: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:418] Can't find a device placement for the op!\r\n2018-11-02 11:52:01.472421: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:952] Engine Net/my_trt_op_0 creation for segment 0, composed of 13 nodes succeeded.\r\n2018-11-02 11:52:01.475092: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-11-02 11:52:01.475574: W tensorflow/contrib/tensorrt/convert/trt_optimization_pass.cc:185] TensorRTOptimizer is probably called on funcdef! This optimizer must *NOT* be called on function objects.\r\n2018-11-02 11:52:01.476125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: tf_graph\r\n2018-11-02 11:52:01.476138: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 21 nodes (-10), 20 edges (-10), time = 1.141ms.\r\n2018-11-02 11:52:01.476143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 26 nodes (5), 26 edges (6), time = 0.54ms.\r\n2018-11-02 11:52:01.476147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (-12), 14 edges (-12), time = 1685.31897ms.\r\n2018-11-02 11:52:01.476151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 14 edges (0), time = 0.442ms.\r\n2018-11-02 11:52:01.476155: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 14 edges (0), time = 0.576ms.\r\n2018-11-02 11:52:01.476159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:404] Optimization results for grappler item: Net/my_trt_op_0_native_segment\r\n2018-11-02 11:52:01.476163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 13 edges (0), time = 0.537ms.\r\n2018-11-02 11:52:01.476167: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   layout: Graph size after: 14 nodes (0), 13 edges (0), time = 0.339ms.\r\n2018-11-02 11:52:01.476171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 13 edges (0), time = 0.071ms.\r\n2018-11-02 11:52:01.476175: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   constant folding: Graph size after: 14 nodes (0), 13 edges (0), time = 0.405ms.\r\n2018-11-02 11:52:01.476180: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:406]   TensorRTOptimizer: Graph size after: 14 nodes (0), 13 edges (0), time = 0.066ms.\r\n2018-11-02 11:52:01.505052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-11-02 11:52:01.505082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-02 11:52:01.505088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-11-02 11:52:01.505092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-11-02 11:52:01.505183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-11-02 11:52:01.527376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n2018-11-02 11:52:01.527397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-02 11:52:01.527403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n2018-11-02 11:52:01.527407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n2018-11-02 11:52:01.527486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5857 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nmin=4.95342129678e+29\r\nmax=2.45457421171e+31\r\nmedian=6.9235024529e+30\r\nmean=8.45157562195e+30\r\n\r\n```\r\n"}