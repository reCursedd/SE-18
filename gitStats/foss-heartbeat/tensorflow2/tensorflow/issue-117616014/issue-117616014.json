{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/272", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/272/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/272/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/272/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/272", "id": 117616014, "node_id": "MDU6SXNzdWUxMTc2MTYwMTQ=", "number": 272, "title": "softmax_cross_entropy_with_logits to take integer labels / avoid giant dense one-hot matrix", "user": {"login": "mjwillson", "id": 4502, "node_id": "MDQ6VXNlcjQ1MDI=", "avatar_url": "https://avatars0.githubusercontent.com/u/4502?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mjwillson", "html_url": "https://github.com/mjwillson", "followers_url": "https://api.github.com/users/mjwillson/followers", "following_url": "https://api.github.com/users/mjwillson/following{/other_user}", "gists_url": "https://api.github.com/users/mjwillson/gists{/gist_id}", "starred_url": "https://api.github.com/users/mjwillson/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mjwillson/subscriptions", "organizations_url": "https://api.github.com/users/mjwillson/orgs", "repos_url": "https://api.github.com/users/mjwillson/repos", "events_url": "https://api.github.com/users/mjwillson/events{/privacy}", "received_events_url": "https://api.github.com/users/mjwillson/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "rajatmonga", "id": 15679194, "node_id": "MDQ6VXNlcjE1Njc5MTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/15679194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajatmonga", "html_url": "https://github.com/rajatmonga", "followers_url": "https://api.github.com/users/rajatmonga/followers", "following_url": "https://api.github.com/users/rajatmonga/following{/other_user}", "gists_url": "https://api.github.com/users/rajatmonga/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajatmonga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajatmonga/subscriptions", "organizations_url": "https://api.github.com/users/rajatmonga/orgs", "repos_url": "https://api.github.com/users/rajatmonga/repos", "events_url": "https://api.github.com/users/rajatmonga/events{/privacy}", "received_events_url": "https://api.github.com/users/rajatmonga/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rajatmonga", "id": 15679194, "node_id": "MDQ6VXNlcjE1Njc5MTk0", "avatar_url": "https://avatars0.githubusercontent.com/u/15679194?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rajatmonga", "html_url": "https://github.com/rajatmonga", "followers_url": "https://api.github.com/users/rajatmonga/followers", "following_url": "https://api.github.com/users/rajatmonga/following{/other_user}", "gists_url": "https://api.github.com/users/rajatmonga/gists{/gist_id}", "starred_url": "https://api.github.com/users/rajatmonga/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rajatmonga/subscriptions", "organizations_url": "https://api.github.com/users/rajatmonga/orgs", "repos_url": "https://api.github.com/users/rajatmonga/repos", "events_url": "https://api.github.com/users/rajatmonga/events{/privacy}", "received_events_url": "https://api.github.com/users/rajatmonga/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 5, "created_at": "2015-11-18T15:50:32Z", "updated_at": "2016-02-28T16:11:59Z", "closed_at": "2016-02-28T16:11:59Z", "author_association": "NONE", "body_html": "<p>Currently to compute this loss for a classifier you need to generate a big dense matrix of one-hot vectors to pass to softmax_cross_entropy_with_logits, as in the example at <a href=\"http://tensorflow.org/tutorials/mnist/tf/index.html#loss\" rel=\"nofollow\">http://tensorflow.org/tutorials/mnist/tf/index.html#loss</a></p>\n<p>This is kinda fiddly to do, but also rather wasteful of memory especially in the case of a larger multiclass softmax. Could we have a version of this function which accepts a list of indices, e.g. like Theano's: <a href=\"http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.categorical_crossentropy\" rel=\"nofollow\">http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.categorical_crossentropy</a> ?</p>", "body_text": "Currently to compute this loss for a classifier you need to generate a big dense matrix of one-hot vectors to pass to softmax_cross_entropy_with_logits, as in the example at http://tensorflow.org/tutorials/mnist/tf/index.html#loss\nThis is kinda fiddly to do, but also rather wasteful of memory especially in the case of a larger multiclass softmax. Could we have a version of this function which accepts a list of indices, e.g. like Theano's: http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.categorical_crossentropy ?", "body": "Currently to compute this loss for a classifier you need to generate a big dense matrix of one-hot vectors to pass to softmax_cross_entropy_with_logits, as in the example at http://tensorflow.org/tutorials/mnist/tf/index.html#loss\n\nThis is kinda fiddly to do, but also rather wasteful of memory especially in the case of a larger multiclass softmax. Could we have a version of this function which accepts a list of indices, e.g. like Theano's: http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.categorical_crossentropy ?\n"}