{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3372", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3372/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3372/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/3372/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/3372", "id": 166179810, "node_id": "MDU6SXNzdWUxNjYxNzk4MTA=", "number": 3372, "title": "Multi-GPU for LSTM", "user": {"login": "yajiemiao", "id": 15018842, "node_id": "MDQ6VXNlcjE1MDE4ODQy", "avatar_url": "https://avatars2.githubusercontent.com/u/15018842?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yajiemiao", "html_url": "https://github.com/yajiemiao", "followers_url": "https://api.github.com/users/yajiemiao/followers", "following_url": "https://api.github.com/users/yajiemiao/following{/other_user}", "gists_url": "https://api.github.com/users/yajiemiao/gists{/gist_id}", "starred_url": "https://api.github.com/users/yajiemiao/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yajiemiao/subscriptions", "organizations_url": "https://api.github.com/users/yajiemiao/orgs", "repos_url": "https://api.github.com/users/yajiemiao/repos", "events_url": "https://api.github.com/users/yajiemiao/events{/privacy}", "received_events_url": "https://api.github.com/users/yajiemiao/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2016-07-18T19:59:54Z", "updated_at": "2016-07-28T16:13:20Z", "closed_at": "2016-07-28T16:13:20Z", "author_association": "NONE", "body_html": "<p>I am experimenting with multi-gpu feedforwarding for LSTM models, by feeding two batches of sequences through a LSTM model. Here are two cases I am testing:</p>\n<p><strong>Single-GPU</strong>: simply pass the two batches sequentially on 1 GPU<br>\n<strong>Two-GPU</strong>: 2 parallel GPUs where each GPU takes care of one batch. <strong>My code is in the attached file</strong> (.txt --&gt; .py).</p>\n<p>However, instead of being 2X faster, the two-GPU case runs even slightly slower than the single-GPU case. It seems that even if I am initiating 2 GPU threads, the 2 batches are processed still sequentially, rather than in a parallel manner.</p>\n<p>Does anyone see anything wrong with my code, or give any insight on how to do debugging? Your help would be highly appreciated.</p>\n<p><a href=\"https://github.com/tensorflow/tensorflow/files/370021/lstm_multi_gpu.txt\">lstm_multi_gpu.txt</a></p>", "body_text": "I am experimenting with multi-gpu feedforwarding for LSTM models, by feeding two batches of sequences through a LSTM model. Here are two cases I am testing:\nSingle-GPU: simply pass the two batches sequentially on 1 GPU\nTwo-GPU: 2 parallel GPUs where each GPU takes care of one batch. My code is in the attached file (.txt --> .py).\nHowever, instead of being 2X faster, the two-GPU case runs even slightly slower than the single-GPU case. It seems that even if I am initiating 2 GPU threads, the 2 batches are processed still sequentially, rather than in a parallel manner.\nDoes anyone see anything wrong with my code, or give any insight on how to do debugging? Your help would be highly appreciated.\nlstm_multi_gpu.txt", "body": "I am experimenting with multi-gpu feedforwarding for LSTM models, by feeding two batches of sequences through a LSTM model. Here are two cases I am testing:\n\n**Single-GPU**: simply pass the two batches sequentially on 1 GPU\n**Two-GPU**: 2 parallel GPUs where each GPU takes care of one batch. **My code is in the attached file** (.txt --> .py).\n\nHowever, instead of being 2X faster, the two-GPU case runs even slightly slower than the single-GPU case. It seems that even if I am initiating 2 GPU threads, the 2 batches are processed still sequentially, rather than in a parallel manner. \n\nDoes anyone see anything wrong with my code, or give any insight on how to do debugging? Your help would be highly appreciated.\n\n[lstm_multi_gpu.txt](https://github.com/tensorflow/tensorflow/files/370021/lstm_multi_gpu.txt)\n"}