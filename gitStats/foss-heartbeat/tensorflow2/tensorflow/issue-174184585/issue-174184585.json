{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4118", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4118/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4118/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/4118/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/4118", "id": 174184585, "node_id": "MDU6SXNzdWUxNzQxODQ1ODU=", "number": 4118, "title": "Undefined Symbols When Compiling User Op for GPU", "user": {"login": "woodshop", "id": 4654379, "node_id": "MDQ6VXNlcjQ2NTQzNzk=", "avatar_url": "https://avatars3.githubusercontent.com/u/4654379?v=4", "gravatar_id": "", "url": "https://api.github.com/users/woodshop", "html_url": "https://github.com/woodshop", "followers_url": "https://api.github.com/users/woodshop/followers", "following_url": "https://api.github.com/users/woodshop/following{/other_user}", "gists_url": "https://api.github.com/users/woodshop/gists{/gist_id}", "starred_url": "https://api.github.com/users/woodshop/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/woodshop/subscriptions", "organizations_url": "https://api.github.com/users/woodshop/orgs", "repos_url": "https://api.github.com/users/woodshop/repos", "events_url": "https://api.github.com/users/woodshop/events{/privacy}", "received_events_url": "https://api.github.com/users/woodshop/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 4, "created_at": "2016-08-31T04:58:06Z", "updated_at": "2017-05-03T15:41:20Z", "closed_at": "2016-08-31T05:05:01Z", "author_association": "NONE", "body_html": "<h2>Summary</h2>\n<p>I can compile, but not load, a user-defined TF shared library using CUDA. The library is based off of the TF <a href=\"https://www.tensorflow.org/versions/master/how_tos/adding_an_op/index.html#adding-a-new-op\" rel=\"nofollow\"><code>zero_out</code></a> example. I've modified the example to support CPU and GPU devices. Upon loading the shared library I get the following error: <code>tensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi</code>.</p>\n<p>I suspect that the problem has something to do with my particular combination of compiler and OS environment. However after trying many ideas I've hit a wall.</p>\n<h2>Similar Issues</h2>\n<p><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"150907853\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/2097\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/2097/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/2097\">#2097</a>: My problem looks similat to this one.<br>\n<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"142371940\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1569\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1569/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1569\">#1569</a>: There are two suggestions made in this issue:</p>\n<ol>\n<li>Try a <code>gcc-4.*</code> compiler</li>\n<li>Use the compiler variable <code>D_GLIBCXX_USE_CXX11_ABI=0</code></li>\n</ol>\n<p>Neither of these suggestions are working for me.</p>\n<h2>Detailed Explanation</h2>\n<p>I give details below about my environment, the source code, the steps I've taken to compile, and the error.</p>\n<h3>Environment</h3>\n<p>OS: Ubuntu 16.04 LTS<br>\nKernel : 4.4.0-34-generic<br>\nCompiler: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609<br>\nCuda: 7.5<br>\nCudnn:  5.1.3</p>\n<p>My problem exists whether I use a TF binary or compile my own version from source. Note that in order to successfully compile TF from source I must add the following three lines to <code>CROSSTOOL.tpl</code>:</p>\n<pre><code>cxx_flag: \"-D_MWAITXINTRIN_H_INCLUDED\"\ncxx_flag: \"-D_FORCE_INLINES\"\ncxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\"\n</code></pre>\n<h3>Source Code</h3>\n<p>I have three source files and a Makefile:</p>\n<h4><code>zero_out.h</code></h4>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">ifndef</span> TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\n#<span class=\"pl-k\">define</span> <span class=\"pl-en\">TENSORFLOW_KERNELS_ZERO_OUT_OP_H_</span>\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\">tensorflow</span> {\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\">functor</span> {\n\n<span class=\"pl-c\"><span class=\"pl-c\">//</span> Generic helper functor for the ZeroOut Op.</span>\n<span class=\"pl-k\">template </span>&lt;<span class=\"pl-k\">typename</span> Device&gt;\n<span class=\"pl-k\">struct</span> <span class=\"pl-en\">ZeroOutFunctor</span>;\n\n}  <span class=\"pl-c\"><span class=\"pl-c\">//</span> namespace functor</span>\n}  <span class=\"pl-c\"><span class=\"pl-c\">//</span> namespace tensorflow</span>\n\n#<span class=\"pl-k\">endif</span>  <span class=\"pl-c\"><span class=\"pl-c\">//</span> TENSORFLOW_KERNELS_ZERO_OUT_OP_H_</span></pre></div>\n<h4><code>zero_out.cc</code></h4>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">define</span> <span class=\"pl-en\">EIGEN_USE_THREADS</span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>zero_out.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/op_kernel.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/tensor.h<span class=\"pl-pds\">\"</span></span>\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\">tensorflow</span> {\n\n<span class=\"pl-en\">REGISTER_OP</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ZeroOut<span class=\"pl-pds\">\"</span></span>)\n.Input(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>to_zero: float<span class=\"pl-pds\">\"</span></span>)\n.Output(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>zeroed: float<span class=\"pl-pds\">\"</span></span>)\n.Doc(<span class=\"pl-s\"><span class=\"pl-pds\">R\"doc(</span></span>\n<span class=\"pl-s\">Zeros all elements of the tensor except the first.</span>\n<span class=\"pl-s\">zeroed: A Tensor.</span>\n<span class=\"pl-s\">  output[0] = input[0]</span>\n<span class=\"pl-s\">  output[1:N] = 0</span>\n<span class=\"pl-s\"><span class=\"pl-pds\">)doc\"</span></span>);;\n\n<span class=\"pl-k\">typedef</span> Eigen::ThreadPoolDevice CPUDevice;\n<span class=\"pl-k\">typedef</span> Eigen::GpuDevice GPUDevice;\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\">functor</span> {\n\n<span class=\"pl-k\">template </span>&lt;<span class=\"pl-k\">typename</span> Device&gt;\n<span class=\"pl-k\">struct</span> <span class=\"pl-en\">ZeroOutFunctor</span> {\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">operator</span>()(<span class=\"pl-k\">const</span> Device&amp; d,\n          <span class=\"pl-k\">typename</span> TTypes&lt;<span class=\"pl-k\">float</span>&gt;::ConstFlat input,\n          <span class=\"pl-k\">typename</span> TTypes&lt;<span class=\"pl-k\">float</span>&gt;::Flat output,\n          <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N);\n};\n\n<span class=\"pl-k\">template </span>&lt;&gt;\n<span class=\"pl-k\">struct</span> <span class=\"pl-en\">ZeroOutFunctor</span>&lt;CPUDevice&gt; {\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">operator</span>()(<span class=\"pl-k\">const</span> CPUDevice&amp; d,\n          <span class=\"pl-k\">typename</span> TTypes&lt;<span class=\"pl-k\">float</span>&gt;::ConstFlat input,\n          <span class=\"pl-k\">typename</span> TTypes&lt;<span class=\"pl-k\">float</span>&gt;::Flat output,\n          <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N) {\n    <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = <span class=\"pl-c1\">1</span>; i &lt; N; i++) {\n      <span class=\"pl-c1\">output</span>(i) = <span class=\"pl-c1\">0</span>;\n    }\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Preserve the first input value if possible.</span>\n    <span class=\"pl-k\">if</span> (N &gt; <span class=\"pl-c1\">0</span>) <span class=\"pl-c1\">output</span>(<span class=\"pl-c1\">0</span>) = <span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>);\n  }\n};\n} <span class=\"pl-c\"><span class=\"pl-c\">//</span> namespace functor    </span>\n\n<span class=\"pl-k\">template </span>&lt;<span class=\"pl-k\">typename</span> Device&gt;\n<span class=\"pl-k\">class</span> <span class=\"pl-en\">ZeroOutOp</span> : <span class=\"pl-k\">public</span> <span class=\"pl-en\">OpKernel</span> {\n<span class=\"pl-k\">public:</span>\n  <span class=\"pl-k\">explicit</span> <span class=\"pl-en\">ZeroOutOp</span>(OpKernelConstruction* context) : OpKernel(context) {}\n\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">Compute</span>(OpKernelContext* context) <span class=\"pl-k\">override</span> {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Grab the input tensor</span>\n    <span class=\"pl-k\">const</span> Tensor&amp; input_tensor = context-&gt;<span class=\"pl-c1\">input</span>(<span class=\"pl-c1\">0</span>);\n    <span class=\"pl-k\">auto</span> input = input_tensor.<span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">float</span>&gt;();\n\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> Create an output tensor</span>\n    Tensor* output_tensor = <span class=\"pl-c1\">NULL</span>;\n    <span class=\"pl-c1\">OP_REQUIRES_OK</span>(context, context-&gt;<span class=\"pl-c1\">allocate_output</span>(<span class=\"pl-c1\">0</span>, input_tensor.<span class=\"pl-c1\">shape</span>(),\n                             &amp;output_tensor));\n\n    <span class=\"pl-k\">auto</span> output = output_tensor-&gt;<span class=\"pl-k\">template</span> <span class=\"pl-smi\">flat</span>&lt;<span class=\"pl-k\">float</span>&gt;();\n    <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N = input.<span class=\"pl-c1\">size</span>();\n    functor::ZeroOutFunctor&lt;Device&gt;()(context-&gt;<span class=\"pl-smi\">eigen_device</span>&lt;Device&gt;(),\n                      input, output, N);\n  }\n};\n\n<span class=\"pl-en\">REGISTER_KERNEL_BUILDER</span>(Name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ZeroOut<span class=\"pl-pds\">\"</span></span>)                 \\\n            .Device(DEVICE_CPU),        \\\n            ZeroOutOp&lt;CPUDevice&gt;);\n\n#<span class=\"pl-k\">if</span> GOOGLE_CUDA\n<span class=\"pl-en\">REGISTER_KERNEL_BUILDER</span>(Name(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>ZeroOut<span class=\"pl-pds\">\"</span></span>)                 \\\n            .Device(DEVICE_GPU),        \\\n            ZeroOutOp&lt;GPUDevice&gt;);\n#<span class=\"pl-k\">endif</span> <span class=\"pl-c\"><span class=\"pl-c\">//</span> GOOGLE_CUDA</span>\n} <span class=\"pl-c\"><span class=\"pl-c\">//</span> namespace tensoroflow</span>\n</pre></div>\n<h4><code>zero_out_gpu.cu.cc</code></h4>\n<div class=\"highlight highlight-source-c++\"><pre>#<span class=\"pl-k\">if</span> GOOGLE_CUDA\n\n#<span class=\"pl-k\">define</span> <span class=\"pl-en\">EIGEN_USE_GPU</span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>zero_out.h<span class=\"pl-pds\">\"</span></span>\n\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>third_party/eigen3/unsupported/Eigen/CXX11/Tensor<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/tensor.h<span class=\"pl-pds\">\"</span></span>\n#<span class=\"pl-k\">include</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>tensorflow/core/framework/tensor_types.h<span class=\"pl-pds\">\"</span></span>\n\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\">tensorflow</span> {\n\n<span class=\"pl-k\">namespace</span> <span class=\"pl-en\">functor</span> {\n\n<span class=\"pl-k\">using</span> GPUDevice = Eigen::GpuDevice;\n\n__global__ <span class=\"pl-k\">void</span> <span class=\"pl-en\">ZeroOutKernel</span>(<span class=\"pl-k\">const</span> <span class=\"pl-k\">float</span>* in, <span class=\"pl-k\">float</span>* out, <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N) {\n  <span class=\"pl-k\">for</span> (<span class=\"pl-k\">int</span> i = blockIdx.<span class=\"pl-smi\">x</span> * blockDim.<span class=\"pl-smi\">x</span> + threadIdx.<span class=\"pl-smi\">x</span>; i &lt; N;\n       i += blockDim.<span class=\"pl-smi\">x</span> * gridDim.<span class=\"pl-smi\">x</span>) {\n    <span class=\"pl-k\">if</span> (i == <span class=\"pl-c1\">0</span>) {\n      out[i] = in[i];\n    } <span class=\"pl-k\">else</span> {\n      out[i] = <span class=\"pl-c1\">0</span>;\n    }\n  }\n}\n\n<span class=\"pl-k\">template </span>&lt;&gt;\n<span class=\"pl-k\">struct</span> <span class=\"pl-en\">ZeroOutFunctor</span>&lt;GPUDevice&gt; {\n  <span class=\"pl-k\">void</span> <span class=\"pl-en\">operator</span>()(<span class=\"pl-k\">const</span> GPUDevice&amp; d,\n          <span class=\"pl-k\">typename</span> TTypes&lt;<span class=\"pl-k\">float</span>&gt;::ConstFlat input,\n          <span class=\"pl-k\">typename</span> TTypes&lt;<span class=\"pl-k\">float</span>&gt;::Flat output,\n          <span class=\"pl-k\">const</span> <span class=\"pl-k\">int</span> N) {\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> How to compute the optimal block count and threads per block?</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> tensorflow/core/util/cuda_kernel_helper.h isn;t included in the binary</span>\n    <span class=\"pl-c\"><span class=\"pl-c\">//</span> distribution</span>\n    ZeroOutKernel&lt;&lt;&lt;<span class=\"pl-c1\">32</span>, <span class=\"pl-c1\">256</span>, <span class=\"pl-c1\">0</span>, d.<span class=\"pl-c1\">stream</span>()&gt;&gt;&gt;(input.<span class=\"pl-c1\">data</span>(), output.<span class=\"pl-c1\">data</span>(), N);\n  }\n};\n\n<span class=\"pl-k\">template </span><span class=\"pl-k\">struct</span> <span class=\"pl-en\">ZeroOutFunctor</span>&lt;GPUDevice&gt;;  \n} <span class=\"pl-c\"><span class=\"pl-c\">//</span> namespace functor </span>\n} <span class=\"pl-c\"><span class=\"pl-c\">//</span> namespace tensorflow</span>\n#<span class=\"pl-k\">endif</span> <span class=\"pl-c\"><span class=\"pl-c\">//</span> GOOGLE_CUDA</span></pre></div>\n<h4><code>Makefile</code></h4>\n<div class=\"highlight highlight-source-makefile\"><pre><span class=\"pl-smi\">INCLUDE</span> += -I /usr/local/cuda-7.5/include\n<span class=\"pl-smi\">INCLUDE</span> += -I <span class=\"pl-s\">$(<span class=\"pl-c1\">shell</span> python -c \\</span>\n<span class=\"pl-s\">    'import tensorflow as tf; print(tf.sysconfig.get_include()</span>)')\n\n<span class=\"pl-smi\">CXX</span> = gcc -std=c++11\n<span class=\"pl-smi\">CXXFLAGS</span> =                          <span class=\"pl-cce\">\\</span>\n    -D_MWAITXINTRIN_H_INCLUDED  <span class=\"pl-cce\">\\</span>\n    -D_FORCE_INLINES            <span class=\"pl-cce\">\\</span>\n    <span class=\"pl-s\">$(<span class=\"pl-smi\">INCLUDE</span>)</span> -fPIC -lcudart   <span class=\"pl-cce\">\\</span>\n\n<span class=\"pl-smi\">NVCC</span> = nvcc -std=c++11 -c\n<span class=\"pl-smi\">NVCCFLAGS</span> =                         <span class=\"pl-cce\">\\</span>\n    -D_MWAITXINTRIN_H_INCLUDED  <span class=\"pl-cce\">\\</span>\n    -D_FORCE_INLINES            <span class=\"pl-cce\">\\</span>\n    <span class=\"pl-s\">$(<span class=\"pl-smi\">INCLUDE</span>)</span> -x cu -Xcompiler -fPIC\n\n<span class=\"pl-smi\">LDFLAGS</span> = -shared\n<span class=\"pl-smi\">CUDA_SRCS</span> = zero_out_gpu.cu.cc\n<span class=\"pl-smi\">SRCS</span> = zero_out.cc\n<span class=\"pl-smi\">RM</span> = rm -f\n<span class=\"pl-smi\">TARGET_LIB</span> = zero_out.so\n<span class=\"pl-smi\">CUDA_OBJ</span> = zero_out.cu.o\n\n<span class=\"pl-en\">all</span>: <span class=\"pl-s\">$(<span class=\"pl-smi\">TARGET_LIB</span>)</span>\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> This target (CPU and GPU) does not find the right symbols</span>\n<span class=\"pl-en\"><span class=\"pl-s\">$(<span class=\"pl-smi\">TARGET_LIB</span>)</span></span>: <span class=\"pl-s\">$(<span class=\"pl-smi\">SRCS</span>)</span> <span class=\"pl-s\">$(<span class=\"pl-smi\">CUDA_OBJ</span>)</span> \n    $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=1\n\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> This target (CPU only) is fine</span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span> $(TARGET_LIB): $(SRCS) </span>\n<span class=\"pl-c\"><span class=\"pl-c\">#</span>   $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=0</span>\n\n<span class=\"pl-en\"><span class=\"pl-s\">$(<span class=\"pl-smi\">CUDA_OBJ</span>)</span></span>: <span class=\"pl-s\">$(<span class=\"pl-smi\">CUDA_SRCS</span>)</span>\n    $(NVCC) -o $@ $^ $(NVCCFLAGS) -DGOOGLE_CUDA=1\n\n<span class=\"pl-c1\">.PHONY</span>: clean\n<span class=\"pl-en\">clean</span>:\n    -$(RM) $(TARGET_LIB)\n    -$(RM) *~\n    -$(RM) *.o</pre></div>\n<h3>Compilation</h3>\n<p>Compilation runs without errors:</p>\n<div class=\"highlight highlight-source-shell\"><pre>$ make\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nnvcc -std=c++11 -c -o zero_out.cu.o zero_out_gpu.cu.cc -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -x cu -Xcompiler -fPIC -DGOOGLE_CUDA=1\n/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing <span class=\"pl-k\">return</span> statement at end of non-void <span class=\"pl-k\">function</span> <span class=\"pl-en\">\"tensorflow::Allocator::RequestedSize\"</span>\n\n/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing <span class=\"pl-k\">return</span> statement at end of non-void <span class=\"pl-k\">function</span> <span class=\"pl-en\">\"tensorflow::Allocator::RequestedSize\"</span>\n\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\ngcc -std=c++11 -shared -o zero_out.so zero_out.cc zero_out.cu.o -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -fPIC -lcudart  -DGOOGLE_CUDA=1</pre></div>\n<h2>Error When Loading the Library:</h2>\n<div class=\"highlight highlight-source-shell\"><pre>$ python -c <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>import tensorflow as tf; tf.load_op_library('zero_out.so')t.so')<span class=\"pl-pds\">\"</span></span>\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nTraceback (most recent call last):\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>&lt;string&gt;<span class=\"pl-pds\">\"</span></span>, line 1, <span class=\"pl-k\">in</span> <span class=\"pl-k\">&lt;</span>module<span class=\"pl-k\">&gt;</span>\n  File <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py<span class=\"pl-pds\">\"</span></span>, line 75, <span class=\"pl-k\">in</span> load_op_library\n    raise errors._make_specific_exception(None, None, error_msg, error_code)\ntensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi</pre></div>\n<h2>Notes and Some Things I've Tried</h2>\n<ol>\n<li>I have no difficulties compiling and loading a shared library for CPU-only. (See the commented target in the Makefile.)</li>\n<li>My problem persists whether using a TF bleeding-edge source (with <code>bazel</code>) or TF binary installation (with <code>make</code>)</li>\n<li>I've tried compiling the shared library with <code>g++</code>, as well as using some earlier <code>gcc-4.*</code> compilers</li>\n<li>I've tried mimicking the nvcc and gcc options provided in <code>CROSSTOOL.tpl</code></li>\n<li>I don't have immediate access to an earlier Linux distro, otherwise I would have tried it</li>\n</ol>\n<p>Any help is greatly appreciated!</p>", "body_text": "Summary\nI can compile, but not load, a user-defined TF shared library using CUDA. The library is based off of the TF zero_out example. I've modified the example to support CPU and GPU devices. Upon loading the shared library I get the following error: tensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi.\nI suspect that the problem has something to do with my particular combination of compiler and OS environment. However after trying many ideas I've hit a wall.\nSimilar Issues\n#2097: My problem looks similat to this one.\n#1569: There are two suggestions made in this issue:\n\nTry a gcc-4.* compiler\nUse the compiler variable D_GLIBCXX_USE_CXX11_ABI=0\n\nNeither of these suggestions are working for me.\nDetailed Explanation\nI give details below about my environment, the source code, the steps I've taken to compile, and the error.\nEnvironment\nOS: Ubuntu 16.04 LTS\nKernel : 4.4.0-34-generic\nCompiler: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609\nCuda: 7.5\nCudnn:  5.1.3\nMy problem exists whether I use a TF binary or compile my own version from source. Note that in order to successfully compile TF from source I must add the following three lines to CROSSTOOL.tpl:\ncxx_flag: \"-D_MWAITXINTRIN_H_INCLUDED\"\ncxx_flag: \"-D_FORCE_INLINES\"\ncxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\"\n\nSource Code\nI have three source files and a Makefile:\nzero_out.h\n#ifndef TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\n#define TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\n\nnamespace tensorflow {\n\nnamespace functor {\n\n// Generic helper functor for the ZeroOut Op.\ntemplate <typename Device>\nstruct ZeroOutFunctor;\n\n}  // namespace functor\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\nzero_out.cc\n#define EIGEN_USE_THREADS\n#include \"zero_out.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n\nnamespace tensorflow {\n\nREGISTER_OP(\"ZeroOut\")\n.Input(\"to_zero: float\")\n.Output(\"zeroed: float\")\n.Doc(R\"doc(\nZeros all elements of the tensor except the first.\nzeroed: A Tensor.\n  output[0] = input[0]\n  output[1:N] = 0\n)doc\");;\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\nnamespace functor {\n\ntemplate <typename Device>\nstruct ZeroOutFunctor {\n  void operator()(const Device& d,\n          typename TTypes<float>::ConstFlat input,\n          typename TTypes<float>::Flat output,\n          const int N);\n};\n\ntemplate <>\nstruct ZeroOutFunctor<CPUDevice> {\n  void operator()(const CPUDevice& d,\n          typename TTypes<float>::ConstFlat input,\n          typename TTypes<float>::Flat output,\n          const int N) {\n    for (int i = 1; i < N; i++) {\n      output(i) = 0;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output(0) = input(0);\n  }\n};\n} // namespace functor    \n\ntemplate <typename Device>\nclass ZeroOutOp : public OpKernel {\npublic:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<float>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                             &output_tensor));\n\n    auto output = output_tensor->template flat<float>();\n    const int N = input.size();\n    functor::ZeroOutFunctor<Device>()(context->eigen_device<Device>(),\n                      input, output, N);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\")                 \\\n            .Device(DEVICE_CPU),        \\\n            ZeroOutOp<CPUDevice>);\n\n#if GOOGLE_CUDA\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\")                 \\\n            .Device(DEVICE_GPU),        \\\n            ZeroOutOp<GPUDevice>);\n#endif // GOOGLE_CUDA\n} // namespace tensoroflow\n\nzero_out_gpu.cu.cc\n#if GOOGLE_CUDA\n\n#define EIGEN_USE_GPU\n\n#include \"zero_out.h\"\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n\n\nnamespace tensorflow {\n\nnamespace functor {\n\nusing GPUDevice = Eigen::GpuDevice;\n\n__global__ void ZeroOutKernel(const float* in, float* out, const int N) {\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N;\n       i += blockDim.x * gridDim.x) {\n    if (i == 0) {\n      out[i] = in[i];\n    } else {\n      out[i] = 0;\n    }\n  }\n}\n\ntemplate <>\nstruct ZeroOutFunctor<GPUDevice> {\n  void operator()(const GPUDevice& d,\n          typename TTypes<float>::ConstFlat input,\n          typename TTypes<float>::Flat output,\n          const int N) {\n    // How to compute the optimal block count and threads per block?\n    // tensorflow/core/util/cuda_kernel_helper.h isn;t included in the binary\n    // distribution\n    ZeroOutKernel<<<32, 256, 0, d.stream()>>>(input.data(), output.data(), N);\n  }\n};\n\ntemplate struct ZeroOutFunctor<GPUDevice>;  \n} // namespace functor \n} // namespace tensorflow\n#endif // GOOGLE_CUDA\nMakefile\nINCLUDE += -I /usr/local/cuda-7.5/include\nINCLUDE += -I $(shell python -c \\\n    'import tensorflow as tf; print(tf.sysconfig.get_include())')\n\nCXX = gcc -std=c++11\nCXXFLAGS =                          \\\n    -D_MWAITXINTRIN_H_INCLUDED  \\\n    -D_FORCE_INLINES            \\\n    $(INCLUDE) -fPIC -lcudart   \\\n\nNVCC = nvcc -std=c++11 -c\nNVCCFLAGS =                         \\\n    -D_MWAITXINTRIN_H_INCLUDED  \\\n    -D_FORCE_INLINES            \\\n    $(INCLUDE) -x cu -Xcompiler -fPIC\n\nLDFLAGS = -shared\nCUDA_SRCS = zero_out_gpu.cu.cc\nSRCS = zero_out.cc\nRM = rm -f\nTARGET_LIB = zero_out.so\nCUDA_OBJ = zero_out.cu.o\n\nall: $(TARGET_LIB)\n\n# This target (CPU and GPU) does not find the right symbols\n$(TARGET_LIB): $(SRCS) $(CUDA_OBJ) \n    $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=1\n\n# This target (CPU only) is fine\n# $(TARGET_LIB): $(SRCS) \n#   $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=0\n\n$(CUDA_OBJ): $(CUDA_SRCS)\n    $(NVCC) -o $@ $^ $(NVCCFLAGS) -DGOOGLE_CUDA=1\n\n.PHONY: clean\nclean:\n    -$(RM) $(TARGET_LIB)\n    -$(RM) *~\n    -$(RM) *.o\nCompilation\nCompilation runs without errors:\n$ make\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nnvcc -std=c++11 -c -o zero_out.cu.o zero_out_gpu.cu.cc -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -x cu -Xcompiler -fPIC -DGOOGLE_CUDA=1\n/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing return statement at end of non-void function \"tensorflow::Allocator::RequestedSize\"\n\n/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing return statement at end of non-void function \"tensorflow::Allocator::RequestedSize\"\n\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\ngcc -std=c++11 -shared -o zero_out.so zero_out.cc zero_out.cu.o -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -fPIC -lcudart  -DGOOGLE_CUDA=1\nError When Loading the Library:\n$ python -c \"import tensorflow as tf; tf.load_op_library('zero_out.so')t.so')\"\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py\", line 75, in load_op_library\n    raise errors._make_specific_exception(None, None, error_msg, error_code)\ntensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi\nNotes and Some Things I've Tried\n\nI have no difficulties compiling and loading a shared library for CPU-only. (See the commented target in the Makefile.)\nMy problem persists whether using a TF bleeding-edge source (with bazel) or TF binary installation (with make)\nI've tried compiling the shared library with g++, as well as using some earlier gcc-4.* compilers\nI've tried mimicking the nvcc and gcc options provided in CROSSTOOL.tpl\nI don't have immediate access to an earlier Linux distro, otherwise I would have tried it\n\nAny help is greatly appreciated!", "body": "## Summary\n\nI can compile, but not load, a user-defined TF shared library using CUDA. The library is based off of the TF [`zero_out`](https://www.tensorflow.org/versions/master/how_tos/adding_an_op/index.html#adding-a-new-op) example. I've modified the example to support CPU and GPU devices. Upon loading the shared library I get the following error: `tensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi`.\n\nI suspect that the problem has something to do with my particular combination of compiler and OS environment. However after trying many ideas I've hit a wall.\n## Similar Issues\n\nhttps://github.com/tensorflow/tensorflow/issues/2097: My problem looks similat to this one.\nhttps://github.com/tensorflow/tensorflow/issues/1569: There are two suggestions made in this issue:\n1. Try a `gcc-4.*` compiler\n2. Use the compiler variable `D_GLIBCXX_USE_CXX11_ABI=0`\n\nNeither of these suggestions are working for me.\n## Detailed Explanation\n\nI give details below about my environment, the source code, the steps I've taken to compile, and the error.\n### Environment\n\nOS: Ubuntu 16.04 LTS\nKernel : 4.4.0-34-generic\nCompiler: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609\nCuda: 7.5\nCudnn:  5.1.3\n\nMy problem exists whether I use a TF binary or compile my own version from source. Note that in order to successfully compile TF from source I must add the following three lines to `CROSSTOOL.tpl`:\n\n```\ncxx_flag: \"-D_MWAITXINTRIN_H_INCLUDED\"\ncxx_flag: \"-D_FORCE_INLINES\"\ncxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\"\n```\n### Source Code\n\nI have three source files and a Makefile:\n#### `zero_out.h`\n\n``` c++\n#ifndef TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\n#define TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\n\nnamespace tensorflow {\n\nnamespace functor {\n\n// Generic helper functor for the ZeroOut Op.\ntemplate <typename Device>\nstruct ZeroOutFunctor;\n\n}  // namespace functor\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_KERNELS_ZERO_OUT_OP_H_\n```\n#### `zero_out.cc`\n\n``` c++\n#define EIGEN_USE_THREADS\n#include \"zero_out.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n\nnamespace tensorflow {\n\nREGISTER_OP(\"ZeroOut\")\n.Input(\"to_zero: float\")\n.Output(\"zeroed: float\")\n.Doc(R\"doc(\nZeros all elements of the tensor except the first.\nzeroed: A Tensor.\n  output[0] = input[0]\n  output[1:N] = 0\n)doc\");;\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\nnamespace functor {\n\ntemplate <typename Device>\nstruct ZeroOutFunctor {\n  void operator()(const Device& d,\n          typename TTypes<float>::ConstFlat input,\n          typename TTypes<float>::Flat output,\n          const int N);\n};\n\ntemplate <>\nstruct ZeroOutFunctor<CPUDevice> {\n  void operator()(const CPUDevice& d,\n          typename TTypes<float>::ConstFlat input,\n          typename TTypes<float>::Flat output,\n          const int N) {\n    for (int i = 1; i < N; i++) {\n      output(i) = 0;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output(0) = input(0);\n  }\n};\n} // namespace functor    \n\ntemplate <typename Device>\nclass ZeroOutOp : public OpKernel {\npublic:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<float>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                             &output_tensor));\n\n    auto output = output_tensor->template flat<float>();\n    const int N = input.size();\n    functor::ZeroOutFunctor<Device>()(context->eigen_device<Device>(),\n                      input, output, N);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\")                 \\\n            .Device(DEVICE_CPU),        \\\n            ZeroOutOp<CPUDevice>);\n\n#if GOOGLE_CUDA\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\")                 \\\n            .Device(DEVICE_GPU),        \\\n            ZeroOutOp<GPUDevice>);\n#endif // GOOGLE_CUDA\n} // namespace tensoroflow\n\n```\n#### `zero_out_gpu.cu.cc`\n\n``` c++\n#if GOOGLE_CUDA\n\n#define EIGEN_USE_GPU\n\n#include \"zero_out.h\"\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n\n\nnamespace tensorflow {\n\nnamespace functor {\n\nusing GPUDevice = Eigen::GpuDevice;\n\n__global__ void ZeroOutKernel(const float* in, float* out, const int N) {\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N;\n       i += blockDim.x * gridDim.x) {\n    if (i == 0) {\n      out[i] = in[i];\n    } else {\n      out[i] = 0;\n    }\n  }\n}\n\ntemplate <>\nstruct ZeroOutFunctor<GPUDevice> {\n  void operator()(const GPUDevice& d,\n          typename TTypes<float>::ConstFlat input,\n          typename TTypes<float>::Flat output,\n          const int N) {\n    // How to compute the optimal block count and threads per block?\n    // tensorflow/core/util/cuda_kernel_helper.h isn;t included in the binary\n    // distribution\n    ZeroOutKernel<<<32, 256, 0, d.stream()>>>(input.data(), output.data(), N);\n  }\n};\n\ntemplate struct ZeroOutFunctor<GPUDevice>;  \n} // namespace functor \n} // namespace tensorflow\n#endif // GOOGLE_CUDA\n```\n#### `Makefile`\n\n``` make\nINCLUDE += -I /usr/local/cuda-7.5/include\nINCLUDE += -I $(shell python -c \\\n    'import tensorflow as tf; print(tf.sysconfig.get_include())')\n\nCXX = gcc -std=c++11\nCXXFLAGS =                          \\\n    -D_MWAITXINTRIN_H_INCLUDED  \\\n    -D_FORCE_INLINES            \\\n    $(INCLUDE) -fPIC -lcudart   \\\n\nNVCC = nvcc -std=c++11 -c\nNVCCFLAGS =                         \\\n    -D_MWAITXINTRIN_H_INCLUDED  \\\n    -D_FORCE_INLINES            \\\n    $(INCLUDE) -x cu -Xcompiler -fPIC\n\nLDFLAGS = -shared\nCUDA_SRCS = zero_out_gpu.cu.cc\nSRCS = zero_out.cc\nRM = rm -f\nTARGET_LIB = zero_out.so\nCUDA_OBJ = zero_out.cu.o\n\nall: $(TARGET_LIB)\n\n# This target (CPU and GPU) does not find the right symbols\n$(TARGET_LIB): $(SRCS) $(CUDA_OBJ) \n    $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=1\n\n# This target (CPU only) is fine\n# $(TARGET_LIB): $(SRCS) \n#   $(CXX) $(LDFLAGS) -o $@ $^ $(CXXFLAGS) -DGOOGLE_CUDA=0\n\n$(CUDA_OBJ): $(CUDA_SRCS)\n    $(NVCC) -o $@ $^ $(NVCCFLAGS) -DGOOGLE_CUDA=1\n\n.PHONY: clean\nclean:\n    -$(RM) $(TARGET_LIB)\n    -$(RM) *~\n    -$(RM) *.o\n```\n### Compilation\n\nCompilation runs without errors:\n\n``` bash\n$ make\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nnvcc -std=c++11 -c -o zero_out.cu.o zero_out_gpu.cu.cc -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -x cu -Xcompiler -fPIC -DGOOGLE_CUDA=1\n/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing return statement at end of non-void function \"tensorflow::Allocator::RequestedSize\"\n\n/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/framework/allocator.h(155): warning: missing return statement at end of non-void function \"tensorflow::Allocator::RequestedSize\"\n\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\ngcc -std=c++11 -shared -o zero_out.so zero_out.cc zero_out.cu.o -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES -I /usr/local/cuda-7.5/include -I /home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/include -fPIC -lcudart  -DGOOGLE_CUDA=1\n```\n## Error When Loading the Library:\n\n``` bash\n$ python -c \"import tensorflow as tf; tf.load_op_library('zero_out.so')t.so')\"\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/home/sarroff/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py\", line 75, in load_op_library\n    raise errors._make_specific_exception(None, None, error_msg, error_code)\ntensorflow.python.framework.errors.NotFoundError: zero_out.so: undefined symbol: _ZN10tensorflow7functor14ZeroOutFunctorIN5Eigen9GpuDeviceEEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi1ELi1ElEELi16EEENS7_INS8_IfLi1ELi1ElEELi16EEEi\n```\n## Notes and Some Things I've Tried\n1. I have no difficulties compiling and loading a shared library for CPU-only. (See the commented target in the Makefile.)\n2. My problem persists whether using a TF bleeding-edge source (with `bazel`) or TF binary installation (with `make`)\n3. I've tried compiling the shared library with `g++`, as well as using some earlier `gcc-4.*` compilers\n4. I've tried mimicking the nvcc and gcc options provided in `CROSSTOOL.tpl`\n5. I don't have immediate access to an earlier Linux distro, otherwise I would have tried it\n\nAny help is greatly appreciated!\n"}