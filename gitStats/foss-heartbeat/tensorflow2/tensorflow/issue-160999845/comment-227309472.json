{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/227309472", "html_url": "https://github.com/tensorflow/tensorflow/issues/2942#issuecomment-227309472", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/2942", "id": 227309472, "node_id": "MDEyOklzc3VlQ29tbWVudDIyNzMwOTQ3Mg==", "user": {"login": "mrry", "id": 192142, "node_id": "MDQ6VXNlcjE5MjE0Mg==", "avatar_url": "https://avatars1.githubusercontent.com/u/192142?v=4", "gravatar_id": "", "url": "https://api.github.com/users/mrry", "html_url": "https://github.com/mrry", "followers_url": "https://api.github.com/users/mrry/followers", "following_url": "https://api.github.com/users/mrry/following{/other_user}", "gists_url": "https://api.github.com/users/mrry/gists{/gist_id}", "starred_url": "https://api.github.com/users/mrry/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/mrry/subscriptions", "organizations_url": "https://api.github.com/users/mrry/orgs", "repos_url": "https://api.github.com/users/mrry/repos", "events_url": "https://api.github.com/users/mrry/events{/privacy}", "received_events_url": "https://api.github.com/users/mrry/received_events", "type": "User", "site_admin": false}, "created_at": "2016-06-21T00:33:09Z", "updated_at": "2016-06-21T00:33:09Z", "author_association": "CONTRIBUTOR", "body_html": "<p>After investigating this, it seems most likely that the cause is heap fragmentation, arising from the creation of a large number of NumPy arrays. The current <code>tf.Session</code> implementation is (inadvertantly) copying the incoming <code>feed_dict</code> values into new NumPy arrays on every step, and I've got a fix for that pending. This leads to a large amount of churn on the heap, and the default <code>malloc()</code> implementation doesn't appear to handle this well.</p>\n<p>Once the fix is in, your example code should not leak, but we would recommend using <a href=\"http://goog-perftools.sourceforge.net/doc/tcmalloc.html\" rel=\"nofollow\"><code>tcmalloc</code></a> for more realistic programs. Running the same code with <code>tcmalloc</code> enabled shows no leak at all with unmodified TensorFlow 0.9. An alternative workaround is to set the <code>malloc()</code> options to be more aggressive about <code>mmap()</code>-ing for large allocations. For example, setting following the environment variable also eliminated the leak for me:</p>\n<pre><code>$ MALLOC_MMAP_THRESHOLD_=100000 python ...\n</code></pre>", "body_text": "After investigating this, it seems most likely that the cause is heap fragmentation, arising from the creation of a large number of NumPy arrays. The current tf.Session implementation is (inadvertantly) copying the incoming feed_dict values into new NumPy arrays on every step, and I've got a fix for that pending. This leads to a large amount of churn on the heap, and the default malloc() implementation doesn't appear to handle this well.\nOnce the fix is in, your example code should not leak, but we would recommend using tcmalloc for more realistic programs. Running the same code with tcmalloc enabled shows no leak at all with unmodified TensorFlow 0.9. An alternative workaround is to set the malloc() options to be more aggressive about mmap()-ing for large allocations. For example, setting following the environment variable also eliminated the leak for me:\n$ MALLOC_MMAP_THRESHOLD_=100000 python ...", "body": "After investigating this, it seems most likely that the cause is heap fragmentation, arising from the creation of a large number of NumPy arrays. The current `tf.Session` implementation is (inadvertantly) copying the incoming `feed_dict` values into new NumPy arrays on every step, and I've got a fix for that pending. This leads to a large amount of churn on the heap, and the default `malloc()` implementation doesn't appear to handle this well.\n\nOnce the fix is in, your example code should not leak, but we would recommend using [`tcmalloc`](http://goog-perftools.sourceforge.net/doc/tcmalloc.html) for more realistic programs. Running the same code with `tcmalloc` enabled shows no leak at all with unmodified TensorFlow 0.9. An alternative workaround is to set the `malloc()` options to be more aggressive about `mmap()`-ing for large allocations. For example, setting following the environment variable also eliminated the leak for me:\n\n```\n$ MALLOC_MMAP_THRESHOLD_=100000 python ...\n```\n"}