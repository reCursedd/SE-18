{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/392264177", "html_url": "https://github.com/tensorflow/tensorflow/issues/19559#issuecomment-392264177", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/19559", "id": 392264177, "node_id": "MDEyOklzc3VlQ29tbWVudDM5MjI2NDE3Nw==", "user": {"login": "tfboyd", "id": 23486130, "node_id": "MDQ6VXNlcjIzNDg2MTMw", "avatar_url": "https://avatars1.githubusercontent.com/u/23486130?v=4", "gravatar_id": "", "url": "https://api.github.com/users/tfboyd", "html_url": "https://github.com/tfboyd", "followers_url": "https://api.github.com/users/tfboyd/followers", "following_url": "https://api.github.com/users/tfboyd/following{/other_user}", "gists_url": "https://api.github.com/users/tfboyd/gists{/gist_id}", "starred_url": "https://api.github.com/users/tfboyd/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/tfboyd/subscriptions", "organizations_url": "https://api.github.com/users/tfboyd/orgs", "repos_url": "https://api.github.com/users/tfboyd/repos", "events_url": "https://api.github.com/users/tfboyd/events{/privacy}", "received_events_url": "https://api.github.com/users/tfboyd/received_events", "type": "User", "site_admin": false}, "created_at": "2018-05-26T14:12:55Z", "updated_at": "2018-05-26T14:12:55Z", "author_association": "MEMBER", "body_html": "<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=12099308\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/ghostplant\">@ghostplant</a></p>\n<p>I know the script well.  I published our original benchmarks and run nightly tests.  Knowing the command-line and your hardware helps me understand the problem.  I do not test Keras and I think Keras multi-gpu places all of the variables on GPU:0, which is often not great but can be \"ok\" with small numbers of GPUs and maybe something is making that slower.  tf_cnn_benchmarks is nice as we can kind of isolate that and put the parameters almost anywhere.  Hardware is good to know as you could have anything from nvlinked V100s to K80s PCIe with no GPU peer-to-peer or two GTX1080tis in a workstation also most likely not peer-to-peer.  You could be using nccl, hierarchical copy, fp16, parameter server = cpu and one of a number of args for tf_cnn_benchmarks.</p>\n<p>My tests show that we are speeding up but <strong>I do not doubt your regression</strong>.  I know many argument combinations are not tracked, which is my fault and a result of pragmatic time use and maybe bad choices. :-)</p>\n<p>There is light at the end of the tunnel.  While it will not help you with Keras, DistributedStrategies (the standard way of doing TensorFlow multi-GPU) will be enabled for Keras models and that will over a simple, flexible, and monitored way to do multi-GPU.</p>\n<p>Send me a little more information and I will run some tests.  I could run some tests now but I fear they would not match your situation and just use up time.</p>", "body_text": "@ghostplant\nI know the script well.  I published our original benchmarks and run nightly tests.  Knowing the command-line and your hardware helps me understand the problem.  I do not test Keras and I think Keras multi-gpu places all of the variables on GPU:0, which is often not great but can be \"ok\" with small numbers of GPUs and maybe something is making that slower.  tf_cnn_benchmarks is nice as we can kind of isolate that and put the parameters almost anywhere.  Hardware is good to know as you could have anything from nvlinked V100s to K80s PCIe with no GPU peer-to-peer or two GTX1080tis in a workstation also most likely not peer-to-peer.  You could be using nccl, hierarchical copy, fp16, parameter server = cpu and one of a number of args for tf_cnn_benchmarks.\nMy tests show that we are speeding up but I do not doubt your regression.  I know many argument combinations are not tracked, which is my fault and a result of pragmatic time use and maybe bad choices. :-)\nThere is light at the end of the tunnel.  While it will not help you with Keras, DistributedStrategies (the standard way of doing TensorFlow multi-GPU) will be enabled for Keras models and that will over a simple, flexible, and monitored way to do multi-GPU.\nSend me a little more information and I will run some tests.  I could run some tests now but I fear they would not match your situation and just use up time.", "body": "@ghostplant \r\n\r\nI know the script well.  I published our original benchmarks and run nightly tests.  Knowing the command-line and your hardware helps me understand the problem.  I do not test Keras and I think Keras multi-gpu places all of the variables on GPU:0, which is often not great but can be \"ok\" with small numbers of GPUs and maybe something is making that slower.  tf_cnn_benchmarks is nice as we can kind of isolate that and put the parameters almost anywhere.  Hardware is good to know as you could have anything from nvlinked V100s to K80s PCIe with no GPU peer-to-peer or two GTX1080tis in a workstation also most likely not peer-to-peer.  You could be using nccl, hierarchical copy, fp16, parameter server = cpu and one of a number of args for tf_cnn_benchmarks.  \r\n\r\nMy tests show that we are speeding up but **I do not doubt your regression**.  I know many argument combinations are not tracked, which is my fault and a result of pragmatic time use and maybe bad choices. :-)\r\n\r\nThere is light at the end of the tunnel.  While it will not help you with Keras, DistributedStrategies (the standard way of doing TensorFlow multi-GPU) will be enabled for Keras models and that will over a simple, flexible, and monitored way to do multi-GPU.\r\n\r\nSend me a little more information and I will run some tests.  I could run some tests now but I fear they would not match your situation and just use up time.  "}