{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/366403766", "html_url": "https://github.com/tensorflow/tensorflow/issues/17076#issuecomment-366403766", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/17076", "id": 366403766, "node_id": "MDEyOklzc3VlQ29tbWVudDM2NjQwMzc2Ng==", "user": {"login": "georgh", "id": 1831252, "node_id": "MDQ6VXNlcjE4MzEyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1831252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgh", "html_url": "https://github.com/georgh", "followers_url": "https://api.github.com/users/georgh/followers", "following_url": "https://api.github.com/users/georgh/following{/other_user}", "gists_url": "https://api.github.com/users/georgh/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgh/subscriptions", "organizations_url": "https://api.github.com/users/georgh/orgs", "repos_url": "https://api.github.com/users/georgh/repos", "events_url": "https://api.github.com/users/georgh/events{/privacy}", "received_events_url": "https://api.github.com/users/georgh/received_events", "type": "User", "site_admin": false}, "created_at": "2018-02-17T01:26:57Z", "updated_at": "2018-02-17T11:03:09Z", "author_association": "NONE", "body_html": "<p>I got it work like this:</p>\n<pre><code>run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\nsess.run(op, feed_dict=fdict, options=run_options)\n</code></pre>\n<p>This will produce messages like this :</p>\n<pre><code>tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: Tile = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, Tile/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from cKR/sub\n\n         [[Node: concat/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8207_concat\", tensor_type=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from cKR/sub\n</code></pre>\n<p>But it seems like - it does not contain all allocation, rendering it a bit pointless :/<br>\nThe error message above is for a 15GB p100 gpu and it says it only allocated 145 MB, but fails on allocating  a tesnor of shape [100000,60,190] -&gt; around 9GB.</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=29663194\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/cy89\">@cy89</a> is there a way to get even more details?</p>\n<p><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/hovercards?user_id=34515418\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/Yagun\">@Yagun</a> for more Information regarding runoptions you may look here:<br>\n<a href=\"https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/protobuf/config.proto\">https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/protobuf/config.proto</a><br>\nBut it is really limited and not a real tutorial.</p>\n<p>I think TF is in a real need of an in deep Tutorial for understanding its core and how to debug in case of errors. Handling OOM on the GPU is quiet a pain without understanding the allocations</p>", "body_text": "I got it work like this:\nrun_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\nsess.run(op, feed_dict=fdict, options=run_options)\n\nThis will produce messages like this :\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n         [[Node: Tile = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, Tile/multiples)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from cKR/sub\n\n         [[Node: concat/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8207_concat\", tensor_type=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  144.96MiB from cKR/sub\n\nBut it seems like - it does not contain all allocation, rendering it a bit pointless :/\nThe error message above is for a 15GB p100 gpu and it says it only allocated 145 MB, but fails on allocating  a tesnor of shape [100000,60,190] -> around 9GB.\n@cy89 is there a way to get even more details?\n@Yagun for more Information regarding runoptions you may look here:\nhttps://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/protobuf/config.proto\nBut it is really limited and not a real tutorial.\nI think TF is in a real need of an in deep Tutorial for understanding its core and how to debug in case of errors. Handling OOM on the GPU is quiet a pain without understanding the allocations", "body": "I got it work like this:\r\n```\r\nrun_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\r\nsess.run(op, feed_dict=fdict, options=run_options)\r\n```\r\nThis will produce messages like this :\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[100000,60,190] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[Node: Tile = Tile[T=DT_DOUBLE, Tmultiples=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](ExpandDims, Tile/multiples)]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from cKR/sub\r\n\r\n         [[Node: concat/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8207_concat\", tensor_type=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\r\n  144.96MiB from cKR/sub\r\n```\r\n\r\nBut it seems like - it does not contain all allocation, rendering it a bit pointless :/\r\nThe error message above is for a 15GB p100 gpu and it says it only allocated 145 MB, but fails on allocating  a tesnor of shape [100000,60,190] -> around 9GB.\r\n\r\n@cy89 is there a way to get even more details? \r\n\r\n@Yagun for more Information regarding runoptions you may look here:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/protobuf/config.proto\r\nBut it is really limited and not a real tutorial.\r\n\r\nI think TF is in a real need of an in deep Tutorial for understanding its core and how to debug in case of errors. Handling OOM on the GPU is quiet a pain without understanding the allocations\r\n\r\n\r\n"}