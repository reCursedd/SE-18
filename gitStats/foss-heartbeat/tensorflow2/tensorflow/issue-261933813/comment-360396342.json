{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/360396342", "html_url": "https://github.com/tensorflow/tensorflow/issues/13433#issuecomment-360396342", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13433", "id": 360396342, "node_id": "MDEyOklzc3VlQ29tbWVudDM2MDM5NjM0Mg==", "user": {"login": "marek-krcal", "id": 26710141, "node_id": "MDQ6VXNlcjI2NzEwMTQx", "avatar_url": "https://avatars0.githubusercontent.com/u/26710141?v=4", "gravatar_id": "", "url": "https://api.github.com/users/marek-krcal", "html_url": "https://github.com/marek-krcal", "followers_url": "https://api.github.com/users/marek-krcal/followers", "following_url": "https://api.github.com/users/marek-krcal/following{/other_user}", "gists_url": "https://api.github.com/users/marek-krcal/gists{/gist_id}", "starred_url": "https://api.github.com/users/marek-krcal/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/marek-krcal/subscriptions", "organizations_url": "https://api.github.com/users/marek-krcal/orgs", "repos_url": "https://api.github.com/users/marek-krcal/repos", "events_url": "https://api.github.com/users/marek-krcal/events{/privacy}", "received_events_url": "https://api.github.com/users/marek-krcal/received_events", "type": "User", "site_admin": false}, "created_at": "2018-01-25T08:31:14Z", "updated_at": "2018-01-25T08:31:14Z", "author_association": "NONE", "body_html": "<p>I don't want to turn this thread into a monologue, but I think I do have one more thing worth a short mention: a simple workaround to my 8GB-limit problem is to make two data variables. I did not try to push the limits but I definitely managed to get beyond the 8GB.  (I also did not try whether I could fit more data by using half precision floats)<br>\nIt is a bit ackward to have the dataset split among two variables - I need additional tf.cond operation at the beginning of my model - but it's not a disaster either.</p>", "body_text": "I don't want to turn this thread into a monologue, but I think I do have one more thing worth a short mention: a simple workaround to my 8GB-limit problem is to make two data variables. I did not try to push the limits but I definitely managed to get beyond the 8GB.  (I also did not try whether I could fit more data by using half precision floats)\nIt is a bit ackward to have the dataset split among two variables - I need additional tf.cond operation at the beginning of my model - but it's not a disaster either.", "body": "I don't want to turn this thread into a monologue, but I think I do have one more thing worth a short mention: a simple workaround to my 8GB-limit problem is to make two data variables. I did not try to push the limits but I definitely managed to get beyond the 8GB.  (I also did not try whether I could fit more data by using half precision floats)\r\nIt is a bit ackward to have the dataset split among two variables - I need additional tf.cond operation at the beginning of my model - but it's not a disaster either."}