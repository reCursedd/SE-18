{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13433", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13433/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13433/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/13433/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/13433", "id": 261933813, "node_id": "MDU6SXNzdWUyNjE5MzM4MTM=", "number": 13433, "title": "Bug: tf.Variable uses always twice the memory (on the CPU)", "user": {"login": "georgh", "id": 1831252, "node_id": "MDQ6VXNlcjE4MzEyNTI=", "avatar_url": "https://avatars2.githubusercontent.com/u/1831252?v=4", "gravatar_id": "", "url": "https://api.github.com/users/georgh", "html_url": "https://github.com/georgh", "followers_url": "https://api.github.com/users/georgh/followers", "following_url": "https://api.github.com/users/georgh/following{/other_user}", "gists_url": "https://api.github.com/users/georgh/gists{/gist_id}", "starred_url": "https://api.github.com/users/georgh/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/georgh/subscriptions", "organizations_url": "https://api.github.com/users/georgh/orgs", "repos_url": "https://api.github.com/users/georgh/repos", "events_url": "https://api.github.com/users/georgh/events{/privacy}", "received_events_url": "https://api.github.com/users/georgh/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": {"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "rmlarsen", "id": 16907534, "node_id": "MDQ6VXNlcjE2OTA3NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/16907534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/rmlarsen", "html_url": "https://github.com/rmlarsen", "followers_url": "https://api.github.com/users/rmlarsen/followers", "following_url": "https://api.github.com/users/rmlarsen/following{/other_user}", "gists_url": "https://api.github.com/users/rmlarsen/gists{/gist_id}", "starred_url": "https://api.github.com/users/rmlarsen/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/rmlarsen/subscriptions", "organizations_url": "https://api.github.com/users/rmlarsen/orgs", "repos_url": "https://api.github.com/users/rmlarsen/repos", "events_url": "https://api.github.com/users/rmlarsen/events{/privacy}", "received_events_url": "https://api.github.com/users/rmlarsen/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 27, "created_at": "2017-10-01T18:00:20Z", "updated_at": "2018-08-07T16:58:57Z", "closed_at": "2018-08-07T16:58:57Z", "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: yes</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Linux Ubuntu 16.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: tested on both</li>\n<li><strong>TensorFlow version (use command below)</strong>: 1.3 for pip / <a class=\"commit-link\" data-hovercard-type=\"commit\" data-hovercard-url=\"https://github.com/tensorflow/tensorflow/commit/0cfb16e025b3d20e8c8aca431fc0887814817c44/hovercard\" href=\"https://github.com/tensorflow/tensorflow/commit/0cfb16e025b3d20e8c8aca431fc0887814817c44\"><tt>0cfb16e</tt></a> for self-compiled</li>\n<li><strong>Python version</strong>: Python 3.4.3 [GCC 4.9.2] on linux</li>\n<li><strong>Bazel version (if compiling from source)</strong>: 0.5.4</li>\n<li><strong>CUDA/cuDNN version</strong>: not used</li>\n<li><strong>GPU model and memory</strong>: not used</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>Every tf.variable occupies always twice the necessary memory:<br>\nOnce for the tf.constant vector that is created for the initializer and once as the persistend storage.<br>\nCode to reproduce:</p>\n<pre><code>import os\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '100' #print all\nimport tensorflow as tf\n\nruns = 1\nN = int(1024 * 1024 * 1.1)\nM = int(1024 / 8)\nprint(\"testing allocation of {:.2f} MB\".format(N*M*8. / 1024 / 1024))\n\n#does not matter which version you use:\nv = tf.Variable(tf.ones([M, N], tf.float64), name=\"var1\")\n#v = tf.get_variable(shape=(M,N), initializer=tf.ones_initializer, dtype=tf.float64, name='var1', trainable=False)\n\ninit = tf.global_variables_initializer()\nfor i in range(runs):\n      print(\"start session\")\n      with tf.Session() as sess:\n            print(\"start init\")\n            sess.run(init)\n</code></pre>\n<p>In my self-compiled version the output contains the following lines:</p>\n<pre><code> tensorflow/core/common_runtime/bfc_allocator.cc:133] Extending allocation by 2.00GiB bytes.\n tensorflow/core/common_runtime/bfc_allocator.cc:137] Total allocated bytes: 4.00GiB\n</code></pre>\n<p>For the pip version, the current allocation is not displayed, but observing htop during the execution or using mprof reveals the same.</p>\n<p>The issue seems to occur because assign does not reuse the memory of tf.ones but instead allocates additional memory. Related lines: <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/assign_op.h#L79-L86\">assign_op.h</a><br>\ncontext-&gt;forward_input returns null in this case, because the memory of tf.ones has a ref count of 2.<br>\n(I dont know why) see <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op_kernel.cc#L455\">op_kernel.cc</a><br>\ninput-&gt;RefCountIsOne() is therefore false.</p>\n<p>I tried to comment out the input-&gt;RefCountIsOne() check, but then it still doesn't work because of the<br>\noutput_attr.IsEqualOrLessRestrictiveThan() check.<br>\nIf you remove this check too, the memory usage finaly drops to the expected value, the memory of tf.ones is reused.<br>\nBut this is not a real solution, because I don't know how this would effect other operations and it seems to break the memory freeing.</p>\n<p>I think this bug is quiet serious, because it affects nearly all computations.<br>\nIs this an already known bug?</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\nTensorFlow installed from (source or binary): tested on both\nTensorFlow version (use command below): 1.3 for pip / 0cfb16e for self-compiled\nPython version: Python 3.4.3 [GCC 4.9.2] on linux\nBazel version (if compiling from source): 0.5.4\nCUDA/cuDNN version: not used\nGPU model and memory: not used\n\nDescribe the problem\nEvery tf.variable occupies always twice the necessary memory:\nOnce for the tf.constant vector that is created for the initializer and once as the persistend storage.\nCode to reproduce:\nimport os\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '100' #print all\nimport tensorflow as tf\n\nruns = 1\nN = int(1024 * 1024 * 1.1)\nM = int(1024 / 8)\nprint(\"testing allocation of {:.2f} MB\".format(N*M*8. / 1024 / 1024))\n\n#does not matter which version you use:\nv = tf.Variable(tf.ones([M, N], tf.float64), name=\"var1\")\n#v = tf.get_variable(shape=(M,N), initializer=tf.ones_initializer, dtype=tf.float64, name='var1', trainable=False)\n\ninit = tf.global_variables_initializer()\nfor i in range(runs):\n      print(\"start session\")\n      with tf.Session() as sess:\n            print(\"start init\")\n            sess.run(init)\n\nIn my self-compiled version the output contains the following lines:\n tensorflow/core/common_runtime/bfc_allocator.cc:133] Extending allocation by 2.00GiB bytes.\n tensorflow/core/common_runtime/bfc_allocator.cc:137] Total allocated bytes: 4.00GiB\n\nFor the pip version, the current allocation is not displayed, but observing htop during the execution or using mprof reveals the same.\nThe issue seems to occur because assign does not reuse the memory of tf.ones but instead allocates additional memory. Related lines: assign_op.h\ncontext->forward_input returns null in this case, because the memory of tf.ones has a ref count of 2.\n(I dont know why) see op_kernel.cc\ninput->RefCountIsOne() is therefore false.\nI tried to comment out the input->RefCountIsOne() check, but then it still doesn't work because of the\noutput_attr.IsEqualOrLessRestrictiveThan() check.\nIf you remove this check too, the memory usage finaly drops to the expected value, the memory of tf.ones is reused.\nBut this is not a real solution, because I don't know how this would effect other operations and it seems to break the memory freeing.\nI think this bug is quiet serious, because it affects nearly all computations.\nIs this an already known bug?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: tested on both\r\n- **TensorFlow version (use command below)**: 1.3 for pip / 0cfb16e025b3d20e8c8aca431fc0887814817c44 for self-compiled\r\n- **Python version**: Python 3.4.3 [GCC 4.9.2] on linux\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**: not used\r\n- **GPU model and memory**: not used\r\n\r\n### Describe the problem\r\nEvery tf.variable occupies always twice the necessary memory: \r\nOnce for the tf.constant vector that is created for the initializer and once as the persistend storage.\r\nCode to reproduce:\r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '100' #print all\r\nimport tensorflow as tf\r\n\r\nruns = 1\r\nN = int(1024 * 1024 * 1.1)\r\nM = int(1024 / 8)\r\nprint(\"testing allocation of {:.2f} MB\".format(N*M*8. / 1024 / 1024))\r\n\r\n#does not matter which version you use:\r\nv = tf.Variable(tf.ones([M, N], tf.float64), name=\"var1\")\r\n#v = tf.get_variable(shape=(M,N), initializer=tf.ones_initializer, dtype=tf.float64, name='var1', trainable=False)\r\n\r\ninit = tf.global_variables_initializer()\r\nfor i in range(runs):\r\n      print(\"start session\")\r\n      with tf.Session() as sess:\r\n            print(\"start init\")\r\n            sess.run(init)\r\n```\r\n\r\nIn my self-compiled version the output contains the following lines:\r\n```\r\n tensorflow/core/common_runtime/bfc_allocator.cc:133] Extending allocation by 2.00GiB bytes.\r\n tensorflow/core/common_runtime/bfc_allocator.cc:137] Total allocated bytes: 4.00GiB\r\n```\r\nFor the pip version, the current allocation is not displayed, but observing htop during the execution or using mprof reveals the same.\r\n\r\nThe issue seems to occur because assign does not reuse the memory of tf.ones but instead allocates additional memory. Related lines: [assign_op.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/assign_op.h#L79-L86)\r\ncontext->forward_input returns null in this case, because the memory of tf.ones has a ref count of 2.\r\n(I dont know why) see [op_kernel.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op_kernel.cc#L455)\r\ninput->RefCountIsOne() is therefore false.\r\n\r\nI tried to comment out the input->RefCountIsOne() check, but then it still doesn't work because of the \r\noutput_attr.IsEqualOrLessRestrictiveThan() check.\r\nIf you remove this check too, the memory usage finaly drops to the expected value, the memory of tf.ones is reused.  \r\nBut this is not a real solution, because I don't know how this would effect other operations and it seems to break the memory freeing.\r\n\r\nI think this bug is quiet serious, because it affects nearly all computations. \r\nIs this an already known bug?\r\n\r\n"}