{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21304", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21304/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21304/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/21304/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/21304", "id": 346559626, "node_id": "MDU6SXNzdWUzNDY1NTk2MjY=", "number": 21304, "title": "Time_Distributed Keras vs TF Keras ", "user": {"login": "lysecret2", "id": 34112996, "node_id": "MDQ6VXNlcjM0MTEyOTk2", "avatar_url": "https://avatars1.githubusercontent.com/u/34112996?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lysecret2", "html_url": "https://github.com/lysecret2", "followers_url": "https://api.github.com/users/lysecret2/followers", "following_url": "https://api.github.com/users/lysecret2/following{/other_user}", "gists_url": "https://api.github.com/users/lysecret2/gists{/gist_id}", "starred_url": "https://api.github.com/users/lysecret2/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lysecret2/subscriptions", "organizations_url": "https://api.github.com/users/lysecret2/orgs", "repos_url": "https://api.github.com/users/lysecret2/repos", "events_url": "https://api.github.com/users/lysecret2/events{/privacy}", "received_events_url": "https://api.github.com/users/lysecret2/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": {"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "bignamehyp", "id": 3474655, "node_id": "MDQ6VXNlcjM0NzQ2NTU=", "avatar_url": "https://avatars2.githubusercontent.com/u/3474655?v=4", "gravatar_id": "", "url": "https://api.github.com/users/bignamehyp", "html_url": "https://github.com/bignamehyp", "followers_url": "https://api.github.com/users/bignamehyp/followers", "following_url": "https://api.github.com/users/bignamehyp/following{/other_user}", "gists_url": "https://api.github.com/users/bignamehyp/gists{/gist_id}", "starred_url": "https://api.github.com/users/bignamehyp/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/bignamehyp/subscriptions", "organizations_url": "https://api.github.com/users/bignamehyp/orgs", "repos_url": "https://api.github.com/users/bignamehyp/repos", "events_url": "https://api.github.com/users/bignamehyp/events{/privacy}", "received_events_url": "https://api.github.com/users/bignamehyp/received_events", "type": "User", "site_admin": false}, {"login": "omalleyt12", "id": 29100818, "node_id": "MDQ6VXNlcjI5MTAwODE4", "avatar_url": "https://avatars3.githubusercontent.com/u/29100818?v=4", "gravatar_id": "", "url": "https://api.github.com/users/omalleyt12", "html_url": "https://github.com/omalleyt12", "followers_url": "https://api.github.com/users/omalleyt12/followers", "following_url": "https://api.github.com/users/omalleyt12/following{/other_user}", "gists_url": "https://api.github.com/users/omalleyt12/gists{/gist_id}", "starred_url": "https://api.github.com/users/omalleyt12/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/omalleyt12/subscriptions", "organizations_url": "https://api.github.com/users/omalleyt12/orgs", "repos_url": "https://api.github.com/users/omalleyt12/repos", "events_url": "https://api.github.com/users/omalleyt12/events{/privacy}", "received_events_url": "https://api.github.com/users/omalleyt12/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 3, "created_at": "2018-08-01T11:27:37Z", "updated_at": "2018-08-06T17:46:24Z", "closed_at": "2018-08-06T17:46:24Z", "author_association": "NONE", "body_html": "<p>Hi,<br>\nthere is a Bug when using the Time_Distributed Layer from tf Keras:</p>\n<pre><code>from tensorflow.python.keras.layers import TimeDistributed,Input,Embedding,LSTM\ninu=Input(shape=(None,None))\nemb=Embedding(input_dim=100,output_dim=100)(inu)\nrnn=TimeDistributed(LSTM(100))(emb)\n\n</code></pre>\n<p>you get the error:</p>\n<p><code>as_list() is not defined on an unknown TensorShape.</code><br>\nIf I use the Time_Distributed from Keras directly like this, there is no error:</p>\n<pre><code>from keras.layers import TimeDistributed,Input,Embedding,LSTM\ninu=Input(shape=(None,None))\nemb=Embedding(input_dim=100,output_dim=100)(inu)\nrnn=TimeDistributed(LSTM(100))(emb)\n</code></pre>\n<p>We can see the difference in how the Time_Distributed gets its shape, which is defined in line 163 in the keras definition <a href=\"https://github.com/keras-team/keras/blob/master/keras/layers/wrappers.py#L114\">Keras</a> they define a \"get_shape_tuple\" function and use that to not have to call the \"as_list\" as in TF Keras in line 164 <a href=\"https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/layers/wrappers.py\">TF Keras</a></p>\n<p>Have I written custom code NO<br>\nOS Platform and Distribution Ubuntu<br>\nTensorFlow installed from Source<br>\nTensorFlow version 1.9<br>\nBazel version NA<br>\nCUDA/cuDNN version 9, 7.1<br>\nGPU model and memory p100<br>\nExact command to reproduce See above<br>\nMobile device NA</p>", "body_text": "Hi,\nthere is a Bug when using the Time_Distributed Layer from tf Keras:\nfrom tensorflow.python.keras.layers import TimeDistributed,Input,Embedding,LSTM\ninu=Input(shape=(None,None))\nemb=Embedding(input_dim=100,output_dim=100)(inu)\nrnn=TimeDistributed(LSTM(100))(emb)\n\n\nyou get the error:\nas_list() is not defined on an unknown TensorShape.\nIf I use the Time_Distributed from Keras directly like this, there is no error:\nfrom keras.layers import TimeDistributed,Input,Embedding,LSTM\ninu=Input(shape=(None,None))\nemb=Embedding(input_dim=100,output_dim=100)(inu)\nrnn=TimeDistributed(LSTM(100))(emb)\n\nWe can see the difference in how the Time_Distributed gets its shape, which is defined in line 163 in the keras definition Keras they define a \"get_shape_tuple\" function and use that to not have to call the \"as_list\" as in TF Keras in line 164 TF Keras\nHave I written custom code NO\nOS Platform and Distribution Ubuntu\nTensorFlow installed from Source\nTensorFlow version 1.9\nBazel version NA\nCUDA/cuDNN version 9, 7.1\nGPU model and memory p100\nExact command to reproduce See above\nMobile device NA", "body": "Hi, \r\nthere is a Bug when using the Time_Distributed Layer from tf Keras:\r\n\r\n\r\n```\r\nfrom tensorflow.python.keras.layers import TimeDistributed,Input,Embedding,LSTM\r\ninu=Input(shape=(None,None))\r\nemb=Embedding(input_dim=100,output_dim=100)(inu)\r\nrnn=TimeDistributed(LSTM(100))(emb)\r\n\r\n```\r\nyou get the error: \r\n\r\n`as_list() is not defined on an unknown TensorShape.`\r\nIf I use the Time_Distributed from Keras directly like this, there is no error: \r\n\r\n```\r\nfrom keras.layers import TimeDistributed,Input,Embedding,LSTM\r\ninu=Input(shape=(None,None))\r\nemb=Embedding(input_dim=100,output_dim=100)(inu)\r\nrnn=TimeDistributed(LSTM(100))(emb)\r\n```\r\nWe can see the difference in how the Time_Distributed gets its shape, which is defined in line 163 in the keras definition [Keras](https://github.com/keras-team/keras/blob/master/keras/layers/wrappers.py#L114) they define a \"get_shape_tuple\" function and use that to not have to call the \"as_list\" as in TF Keras in line 164 [TF Keras](https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/layers/wrappers.py)\r\n\r\n\r\nHave I written custom code NO\r\nOS Platform and Distribution Ubuntu \r\nTensorFlow installed from Source\r\nTensorFlow version 1.9 \r\nBazel version NA \r\nCUDA/cuDNN version 9, 7.1\r\nGPU model and memory p100 \r\nExact command to reproduce See above\r\nMobile device NA"}