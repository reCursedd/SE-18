{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10013", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10013/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10013/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/10013/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/10013", "id": 229772309, "node_id": "MDU6SXNzdWUyMjk3NzIzMDk=", "number": 10013, "title": "GPU resources not released when session is closed", "user": {"login": "ankur2136", "id": 6739498, "node_id": "MDQ6VXNlcjY3Mzk0OTg=", "avatar_url": "https://avatars1.githubusercontent.com/u/6739498?v=4", "gravatar_id": "", "url": "https://api.github.com/users/ankur2136", "html_url": "https://github.com/ankur2136", "followers_url": "https://api.github.com/users/ankur2136/followers", "following_url": "https://api.github.com/users/ankur2136/following{/other_user}", "gists_url": "https://api.github.com/users/ankur2136/gists{/gist_id}", "starred_url": "https://api.github.com/users/ankur2136/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/ankur2136/subscriptions", "organizations_url": "https://api.github.com/users/ankur2136/orgs", "repos_url": "https://api.github.com/users/ankur2136/repos", "events_url": "https://api.github.com/users/ankur2136/events{/privacy}", "received_events_url": "https://api.github.com/users/ankur2136/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 386191887, "node_id": "MDU6TGFiZWwzODYxOTE4ODc=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20response", "name": "stat:awaiting response", "color": "f4b400", "default": false}, {"id": 473184161, "node_id": "MDU6TGFiZWw0NzMxODQxNjE=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/type:support", "name": "type:support", "color": "159b2e", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 2, "created_at": "2017-05-18T18:58:53Z", "updated_at": "2017-09-08T04:55:49Z", "closed_at": "2017-09-08T04:55:49Z", "author_association": "NONE", "body_html": "<p>This is a possible duplicate of <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"144958009\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/1727\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/1727/hovercard\" href=\"https://github.com/tensorflow/tensorflow/issues/1727\">#1727</a>. Posting here as there is no way to re-open or comment on the previous bug.<br>\nThe comments suggests that the updating the driver would most probably fix the issue but its not the case.</p>\n<p><strong>Environment info</strong><br>\nDistributor ID:\tUbuntu<br>\nDescription:\tUbuntu 16.04.2 LTS<br>\nRelease:\t16.04<br>\nCodename:\txenial</p>\n<blockquote>\n<p><code>python3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"</code><br>\n<code>v1.1.0-rc0-61-g1ec6ed5 1.1.0</code></p>\n</blockquote>\n<blockquote>\n<p><code>nvidia-smi</code><br>\n<code>NVIDIA-SMI 375.51                 Driver Version: 375.51</code></p>\n</blockquote>\n<p><strong>Before starting the service</strong><br>\n0     27825    C   /usr/bin/python3                                35MiB</p>\n<p><strong>After deleting the session</strong><br>\nNote that I am creating the session and loading a checkpoint, running the session and then closing it explicitly with <code>session.close()</code>. I am also resetting the graph by calling <code>tf.reset_default_graph()</code> after closing the session.<br>\n0     27825    C   /usr/bin/python3                              1435MiB</p>\n<pre><code>device_t='/gpu:0'\ngraph = tf.Graph()\nsoft_config = tf.ConfigProto(allow_soft_placement=True)\nsoft_config.gpu_options.allow_growth = True . #tried both True and False and doesn't seem to help\nwith graph.as_default(), graph.device(device_t), tf.Session(config=soft_config) as sess:\n    batch_shape = (batch_size,) + img.shape\n    img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n                                     name=\"img_placeholder\")\n    preds = transform.net(img_placeholder)\n    saver = tf.train.Saver()\n    saver.restore(sess, checkpoint_dir)\n\n    content = np.zeros(batch_shape, dtype=np.float32)\n    content[0] = img\n\n    _preds = sess.run(preds, feed_dict={img_placeholder: content})\n    result = crop_img(_preds[0].astype(data_in.dtype))\n    sess.close()   #Explicitly closing the session and deleting does not help as well. \n    del sess\ntf.reset_default_graph()\nreturn result\n</code></pre>\n<p>Here are some of the relevant logs.</p>\n<pre><code>2017-05-18 18:49:16.556719: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-18 18:49:16.556757: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-18 18:49:16.556775: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-18 18:49:16.584028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-05-18 18:49:16.584295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 3.94GiB\nFree memory: 3.87GiB\n2017-05-18 18:49:16.584326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-05-18 18:49:16.584344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-05-18 18:49:16.584368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\n2017-05-18 18:49:16.585190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\n\n\n</code></pre>", "body_text": "This is a possible duplicate of #1727. Posting here as there is no way to re-open or comment on the previous bug.\nThe comments suggests that the updating the driver would most probably fix the issue but its not the case.\nEnvironment info\nDistributor ID:\tUbuntu\nDescription:\tUbuntu 16.04.2 LTS\nRelease:\t16.04\nCodename:\txenial\n\npython3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\nv1.1.0-rc0-61-g1ec6ed5 1.1.0\n\n\nnvidia-smi\nNVIDIA-SMI 375.51                 Driver Version: 375.51\n\nBefore starting the service\n0     27825    C   /usr/bin/python3                                35MiB\nAfter deleting the session\nNote that I am creating the session and loading a checkpoint, running the session and then closing it explicitly with session.close(). I am also resetting the graph by calling tf.reset_default_graph() after closing the session.\n0     27825    C   /usr/bin/python3                              1435MiB\ndevice_t='/gpu:0'\ngraph = tf.Graph()\nsoft_config = tf.ConfigProto(allow_soft_placement=True)\nsoft_config.gpu_options.allow_growth = True . #tried both True and False and doesn't seem to help\nwith graph.as_default(), graph.device(device_t), tf.Session(config=soft_config) as sess:\n    batch_shape = (batch_size,) + img.shape\n    img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n                                     name=\"img_placeholder\")\n    preds = transform.net(img_placeholder)\n    saver = tf.train.Saver()\n    saver.restore(sess, checkpoint_dir)\n\n    content = np.zeros(batch_shape, dtype=np.float32)\n    content[0] = img\n\n    _preds = sess.run(preds, feed_dict={img_placeholder: content})\n    result = crop_img(_preds[0].astype(data_in.dtype))\n    sess.close()   #Explicitly closing the session and deleting does not help as well. \n    del sess\ntf.reset_default_graph()\nreturn result\n\nHere are some of the relevant logs.\n2017-05-18 18:49:16.556719: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-18 18:49:16.556757: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-18 18:49:16.556775: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-18 18:49:16.584028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-05-18 18:49:16.584295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \nname: GRID K520\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\npciBusID 0000:00:03.0\nTotal memory: 3.94GiB\nFree memory: 3.87GiB\n2017-05-18 18:49:16.584326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-05-18 18:49:16.584344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-05-18 18:49:16.584368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\n2017-05-18 18:49:16.585190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)", "body": "This is a possible duplicate of #1727. Posting here as there is no way to re-open or comment on the previous bug. \r\nThe comments suggests that the updating the driver would most probably fix the issue but its not the case. \r\n\r\n**Environment info**\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 16.04.2 LTS\r\nRelease:\t16.04\r\nCodename:\txenial\r\n\r\n>`python3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n   `v1.1.0-rc0-61-g1ec6ed5 1.1.0`\r\n \r\n>`nvidia-smi`\r\n`NVIDIA-SMI 375.51                 Driver Version: 375.51`\r\n\r\n**Before starting the service**\r\n0     27825    C   /usr/bin/python3                                35MiB \r\n\r\n**After deleting the session**\r\nNote that I am creating the session and loading a checkpoint, running the session and then closing it explicitly with `session.close()`. I am also resetting the graph by calling `tf.reset_default_graph()` after closing the session. \r\n0     27825    C   /usr/bin/python3                              1435MiB\r\n\r\n\r\n    device_t='/gpu:0'\r\n    graph = tf.Graph()\r\n    soft_config = tf.ConfigProto(allow_soft_placement=True)\r\n    soft_config.gpu_options.allow_growth = True . #tried both True and False and doesn't seem to help\r\n    with graph.as_default(), graph.device(device_t), tf.Session(config=soft_config) as sess:\r\n        batch_shape = (batch_size,) + img.shape\r\n        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\r\n                                         name=\"img_placeholder\")\r\n        preds = transform.net(img_placeholder)\r\n        saver = tf.train.Saver()\r\n        saver.restore(sess, checkpoint_dir)\r\n\r\n        content = np.zeros(batch_shape, dtype=np.float32)\r\n        content[0] = img\r\n\r\n        _preds = sess.run(preds, feed_dict={img_placeholder: content})\r\n        result = crop_img(_preds[0].astype(data_in.dtype))\r\n        sess.close()   #Explicitly closing the session and deleting does not help as well. \r\n        del sess\r\n    tf.reset_default_graph()\r\n    return result\r\n\r\nHere are some of the relevant logs. \r\n```\r\n2017-05-18 18:49:16.556719: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-18 18:49:16.556757: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-18 18:49:16.556775: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-18 18:49:16.584028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-05-18 18:49:16.584295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \r\nname: GRID K520\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.797\r\npciBusID 0000:00:03.0\r\nTotal memory: 3.94GiB\r\nFree memory: 3.87GiB\r\n2017-05-18 18:49:16.584326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-05-18 18:49:16.584344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-05-18 18:49:16.584368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\r\n2017-05-18 18:49:16.585190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\r\n\r\n\r\n```\r\n"}