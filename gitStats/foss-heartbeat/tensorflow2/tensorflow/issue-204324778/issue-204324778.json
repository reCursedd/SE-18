{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7164", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7164/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7164/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/7164/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/7164", "id": 204324778, "node_id": "MDU6SXNzdWUyMDQzMjQ3Nzg=", "number": 7164, "title": "contrib.batch_norm fails on float16 input", "user": {"login": "kshmelkov", "id": 10819534, "node_id": "MDQ6VXNlcjEwODE5NTM0", "avatar_url": "https://avatars2.githubusercontent.com/u/10819534?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kshmelkov", "html_url": "https://github.com/kshmelkov", "followers_url": "https://api.github.com/users/kshmelkov/followers", "following_url": "https://api.github.com/users/kshmelkov/following{/other_user}", "gists_url": "https://api.github.com/users/kshmelkov/gists{/gist_id}", "starred_url": "https://api.github.com/users/kshmelkov/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kshmelkov/subscriptions", "organizations_url": "https://api.github.com/users/kshmelkov/orgs", "repos_url": "https://api.github.com/users/kshmelkov/repos", "events_url": "https://api.github.com/users/kshmelkov/events{/privacy}", "received_events_url": "https://api.github.com/users/kshmelkov/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2017-01-31T15:08:29Z", "updated_at": "2017-04-09T05:13:17Z", "closed_at": "2017-02-05T06:48:08Z", "author_association": "NONE", "body_html": "<h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</h3>\n<p>I have found a bunch of old issues dated from the initial implementation of float16, but nothing relevant.</p>\n<h3>Environment info</h3>\n<p>Operating System: FC21</p>\n<p>Installed version of CUDA and cuDNN: CUDA8, CuDNN 5.1<br>\n(please attach the output of <code>ls -l /path/to/cuda/lib/libcud*</code>):</p>\n<pre><code>/cuda8_cudnn5_1/lib64/libcudadevrt.a\n/cuda8_cudnn5_1/lib64/libcudart.so -&gt; libcudart.so.8.0\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.44\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0.44\n/cuda8_cudnn5_1/lib64/libcudart_static.a\n/cuda8_cudnn5_1/lib64/libcudnn.so -&gt; libcudnn.so.5\n/cuda8_cudnn5_1/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.1.5\n/cuda8_cudnn5_1/lib64/libcudnn.so.5.1.5\n/cuda8_cudnn5_1/lib64/libcudnn_static.a\n</code></pre>\n<p>If installed from binary pip package, provide:</p>\n<ol>\n<li>A link to the pip package you installed: today nightly build<br>\n<a href=\"https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-0.12.1-cp34-cp34m-linux_x86_64.whl\" rel=\"nofollow\">https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-0.12.1-cp34-cp34m-linux_x86_64.whl</a></li>\n<li>The output from <code>python -c \"import tensorflow; print(tensorflow.__version__)\"</code>.</li>\n</ol>\n<pre><code>&gt;tf.__version__\n'0.12.head'\n&gt;tf.__git_version__\n'0.12.1-2263-g4cc0d1e-dirty'\n</code></pre>\n<h3>If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)</h3>\n<pre><code>p16 = tf.placeholder(tf.float16, (4, 16, 16, 3))\nbn16 = tf.contrib.layers.batch_norm(p16)\n</code></pre>\n<p>It fails with float32 to float16 conversion error deep inside BN op. Traceback is below.</p>\n<h3>What other attempted solutions have you tried?</h3>\n<p>For now working with float32. I tried to track where exactly it fails, but I couldn't. It looks like computed mean value is float32 by default although the variable itself should be <code>inputs.dtype.base_dtype</code> and <code>tf.nn.moments</code> returns <code>float16</code> with corresponding input.</p>\n<h3>Logs or other output that would be helpful</h3>\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-5-e659548f8d6c&gt; in &lt;module&gt;()\n----&gt; 1 bn16 = tf.contrib.layers.batch_norm(p16)\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n    175       current_args = current_scope[key_func].copy()\n    176       current_args.update(kwargs)\n--&gt; 177     return func(*args, **current_args)\n    178   _add_op(func)\n    179   setattr(func_with_args, '_key_op', _key_op(func))\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\n    516           _scope=sc,\n    517           _reuse=reuse)\n--&gt; 518       outputs = layer.apply(inputs, training=is_training)\n    519\n    520       # Add variables to collections.\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\n    301       Output tensor(s).\n    302     \"\"\"\n--&gt; 303     return self.__call__(inputs, **kwargs)\n    304\n    305\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\n    271             self.build(input_shapes)\n    272           self._built = True\n--&gt; 273         outputs = self.call(inputs, **kwargs)\n    274\n    275         # Apply activity regularization.\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\n    191       if not self.updates:\n    192         mean_update = moving_averages.assign_moving_average(\n--&gt; 193             self.moving_mean, mean, self.momentum, zero_debias=False)\n    194         variance_update = moving_averages.assign_moving_average(\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\n     70         update_delta = _zero_debias(variable, value, decay)\n     71       else:\n---&gt; 72         update_delta = (variable - value) * decay\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\n     74\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\n    704     def _run_op(a, *args):\n    705       # pylint: disable=protected-access\n--&gt; 706       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n    707     # Propagate __doc__ to wrapper\n    708     try:\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\n    885     with ops.name_scope(None, op_name, [x, y]) as name:\n    886       if not isinstance(y, sparse_tensor.SparseTensor):\n--&gt; 887         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\n    888       return func(x, y, name=name)\n    889\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\n    649       name=name,\n    650       preferred_dtype=preferred_dtype,\n--&gt; 651       as_ref=False)\n    652\n    653\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\n    714\n    715         if ret is None:\n--&gt; 716           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    717\n    718         if ret is NotImplemented:\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\n    587     raise ValueError(\n    588         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\n--&gt; 589         % (dtype.name, t.dtype.name, str(t)))\n    590   return t\n    591\n\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm/Reshape_1:0\", shape=(3,), dtype=float16)'\n</code></pre>", "body_text": "What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\nI have found a bunch of old issues dated from the initial implementation of float16, but nothing relevant.\nEnvironment info\nOperating System: FC21\nInstalled version of CUDA and cuDNN: CUDA8, CuDNN 5.1\n(please attach the output of ls -l /path/to/cuda/lib/libcud*):\n/cuda8_cudnn5_1/lib64/libcudadevrt.a\n/cuda8_cudnn5_1/lib64/libcudart.so -> libcudart.so.8.0\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0.44\n/cuda8_cudnn5_1/lib64/libcudart_static.a\n/cuda8_cudnn5_1/lib64/libcudnn.so -> libcudnn.so.5\n/cuda8_cudnn5_1/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n/cuda8_cudnn5_1/lib64/libcudnn.so.5.1.5\n/cuda8_cudnn5_1/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n\nA link to the pip package you installed: today nightly build\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-0.12.1-cp34-cp34m-linux_x86_64.whl\nThe output from python -c \"import tensorflow; print(tensorflow.__version__)\".\n\n>tf.__version__\n'0.12.head'\n>tf.__git_version__\n'0.12.1-2263-g4cc0d1e-dirty'\n\nIf possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\np16 = tf.placeholder(tf.float16, (4, 16, 16, 3))\nbn16 = tf.contrib.layers.batch_norm(p16)\n\nIt fails with float32 to float16 conversion error deep inside BN op. Traceback is below.\nWhat other attempted solutions have you tried?\nFor now working with float32. I tried to track where exactly it fails, but I couldn't. It looks like computed mean value is float32 by default although the variable itself should be inputs.dtype.base_dtype and tf.nn.moments returns float16 with corresponding input.\nLogs or other output that would be helpful\nValueError                                Traceback (most recent call last)\n<ipython-input-5-e659548f8d6c> in <module>()\n----> 1 bn16 = tf.contrib.layers.batch_norm(p16)\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\n    175       current_args = current_scope[key_func].copy()\n    176       current_args.update(kwargs)\n--> 177     return func(*args, **current_args)\n    178   _add_op(func)\n    179   setattr(func_with_args, '_key_op', _key_op(func))\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\n    516           _scope=sc,\n    517           _reuse=reuse)\n--> 518       outputs = layer.apply(inputs, training=is_training)\n    519\n    520       # Add variables to collections.\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\n    301       Output tensor(s).\n    302     \"\"\"\n--> 303     return self.__call__(inputs, **kwargs)\n    304\n    305\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\n    271             self.build(input_shapes)\n    272           self._built = True\n--> 273         outputs = self.call(inputs, **kwargs)\n    274\n    275         # Apply activity regularization.\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\n    191       if not self.updates:\n    192         mean_update = moving_averages.assign_moving_average(\n--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)\n    194         variance_update = moving_averages.assign_moving_average(\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\n     70         update_delta = _zero_debias(variable, value, decay)\n     71       else:\n---> 72         update_delta = (variable - value) * decay\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\n     74\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\n    704     def _run_op(a, *args):\n    705       # pylint: disable=protected-access\n--> 706       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n    707     # Propagate __doc__ to wrapper\n    708     try:\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\n    885     with ops.name_scope(None, op_name, [x, y]) as name:\n    886       if not isinstance(y, sparse_tensor.SparseTensor):\n--> 887         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\n    888       return func(x, y, name=name)\n    889\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\n    649       name=name,\n    650       preferred_dtype=preferred_dtype,\n--> 651       as_ref=False)\n    652\n    653\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\n    714\n    715         if ret is None:\n--> 716           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    717\n    718         if ret is NotImplemented:\n\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\n    587     raise ValueError(\n    588         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\n--> 589         % (dtype.name, t.dtype.name, str(t)))\n    590   return t\n    591\n\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm/Reshape_1:0\", shape=(3,), dtype=float16)'", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI have found a bunch of old issues dated from the initial implementation of float16, but nothing relevant.\r\n\r\n### Environment info\r\nOperating System: FC21\r\n\r\nInstalled version of CUDA and cuDNN: CUDA8, CuDNN 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n/cuda8_cudnn5_1/lib64/libcudadevrt.a\r\n/cuda8_cudnn5_1/lib64/libcudart.so -> libcudart.so.8.0\r\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n/cuda8_cudnn5_1/lib64/libcudart.so.8.0.44\r\n/cuda8_cudnn5_1/lib64/libcudart_static.a\r\n/cuda8_cudnn5_1/lib64/libcudnn.so -> libcudnn.so.5\r\n/cuda8_cudnn5_1/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n/cuda8_cudnn5_1/lib64/libcudnn.so.5.1.5\r\n/cuda8_cudnn5_1/lib64/libcudnn_static.a\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: today nightly build\r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-0.12.1-cp34-cp34m-linux_x86_64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\n>tf.__version__\r\n'0.12.head'\r\n>tf.__git_version__\r\n'0.12.1-2263-g4cc0d1e-dirty'\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```\r\np16 = tf.placeholder(tf.float16, (4, 16, 16, 3))\r\nbn16 = tf.contrib.layers.batch_norm(p16)\r\n```\r\n\r\nIt fails with float32 to float16 conversion error deep inside BN op. Traceback is below.\r\n\r\n### What other attempted solutions have you tried?\r\nFor now working with float32. I tried to track where exactly it fails, but I couldn't. It looks like computed mean value is float32 by default although the variable itself should be `inputs.dtype.base_dtype` and `tf.nn.moments` returns `float16` with corresponding input.\r\n\r\n### Logs or other output that would be helpful\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-e659548f8d6c> in <module>()\r\n----> 1 bn16 = tf.contrib.layers.batch_norm(p16)\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    175       current_args = current_scope[key_func].copy()\r\n    176       current_args.update(kwargs)\r\n--> 177     return func(*args, **current_args)\r\n    178   _add_op(func)\r\n    179   setattr(func_with_args, '_key_op', _key_op(func))\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)\r\n    516           _scope=sc,\r\n    517           _reuse=reuse)\r\n--> 518       outputs = layer.apply(inputs, training=is_training)\r\n    519\r\n    520       # Add variables to collections.\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)\r\n    301       Output tensor(s).\r\n    302     \"\"\"\r\n--> 303     return self.__call__(inputs, **kwargs)\r\n    304\r\n    305\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)\r\n    271             self.build(input_shapes)\r\n    272           self._built = True\r\n--> 273         outputs = self.call(inputs, **kwargs)\r\n    274\r\n    275         # Apply activity regularization.\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)\r\n    191       if not self.updates:\r\n    192         mean_update = moving_averages.assign_moving_average(\r\n--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)\r\n    194         variance_update = moving_averages.assign_moving_average(\r\n    195             self.moving_variance, variance, self.momentum, zero_debias=False)\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\r\n     70         update_delta = _zero_debias(variable, value, decay)\r\n     71       else:\r\n---> 72         update_delta = (variable - value) * decay\r\n     73       return state_ops.assign_sub(variable, update_delta, name=scope)\r\n     74\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)\r\n    704     def _run_op(a, *args):\r\n    705       # pylint: disable=protected-access\r\n--> 706       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\r\n    707     # Propagate __doc__ to wrapper\r\n    708     try:\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\r\n    885     with ops.name_scope(None, op_name, [x, y]) as name:\r\n    886       if not isinstance(y, sparse_tensor.SparseTensor):\r\n--> 887         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\r\n    888       return func(x, y, name=name)\r\n    889\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n    649       name=name,\r\n    650       preferred_dtype=preferred_dtype,\r\n--> 651       as_ref=False)\r\n    652\r\n    653\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\r\n    714\r\n    715         if ret is None:\r\n--> 716           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    717\r\n    718         if ret is NotImplemented:\r\n\r\n/home/konstantin/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    587     raise ValueError(\r\n    588         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\r\n--> 589         % (dtype.name, t.dtype.name, str(t)))\r\n    590   return t\r\n    591\r\n\r\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor(\"BatchNorm/Reshape_1:0\", shape=(3,), dtype=float16)'\r\n```"}