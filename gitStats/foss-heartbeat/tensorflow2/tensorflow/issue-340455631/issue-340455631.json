{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20718", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20718/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20718/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20718/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/20718", "id": 340455631, "node_id": "MDU6SXNzdWUzNDA0NTU2MzE=", "number": 20718, "title": "Optimized model is slow on Android ", "user": {"login": "skulhare", "id": 29107055, "node_id": "MDQ6VXNlcjI5MTA3MDU1", "avatar_url": "https://avatars2.githubusercontent.com/u/29107055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skulhare", "html_url": "https://github.com/skulhare", "followers_url": "https://api.github.com/users/skulhare/followers", "following_url": "https://api.github.com/users/skulhare/following{/other_user}", "gists_url": "https://api.github.com/users/skulhare/gists{/gist_id}", "starred_url": "https://api.github.com/users/skulhare/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skulhare/subscriptions", "organizations_url": "https://api.github.com/users/skulhare/orgs", "repos_url": "https://api.github.com/users/skulhare/repos", "events_url": "https://api.github.com/users/skulhare/events{/privacy}", "received_events_url": "https://api.github.com/users/skulhare/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 750616506, "node_id": "MDU6TGFiZWw3NTA2MTY1MDY=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/comp:lite", "name": "comp:lite", "color": "0052cc", "default": false}], "state": "open", "locked": false, "assignee": {"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}, "assignees": [{"login": "achowdhery", "id": 4723042, "node_id": "MDQ6VXNlcjQ3MjMwNDI=", "avatar_url": "https://avatars3.githubusercontent.com/u/4723042?v=4", "gravatar_id": "", "url": "https://api.github.com/users/achowdhery", "html_url": "https://github.com/achowdhery", "followers_url": "https://api.github.com/users/achowdhery/followers", "following_url": "https://api.github.com/users/achowdhery/following{/other_user}", "gists_url": "https://api.github.com/users/achowdhery/gists{/gist_id}", "starred_url": "https://api.github.com/users/achowdhery/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/achowdhery/subscriptions", "organizations_url": "https://api.github.com/users/achowdhery/orgs", "repos_url": "https://api.github.com/users/achowdhery/repos", "events_url": "https://api.github.com/users/achowdhery/events{/privacy}", "received_events_url": "https://api.github.com/users/achowdhery/received_events", "type": "User", "site_admin": false}], "milestone": null, "comments": 10, "created_at": "2018-07-12T01:09:03Z", "updated_at": "2018-11-21T21:33:34Z", "closed_at": null, "author_association": "NONE", "body_html": "<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: No</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Android 7.0</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: Tensorflow Android 1.6 with Java TFInferenceInterface</li>\n<li><strong>Python version</strong>: 3.5</li>\n<li><strong>Bazel version (if compiling from source)</strong>:</li>\n<li><strong>GCC/Compiler version (if compiling from source)</strong>:</li>\n<li><strong>CUDA/cuDNN version</strong>:</li>\n<li><strong>GPU model and memory</strong>:</li>\n<li><strong>Exact command to reproduce</strong>: Please see below.</li>\n</ul>\n<h3>Describe the problem</h3>\n<p>I am using graph transformation tool to optimize SSD model. Here is the command I used to strip the nodes, quantize the weights and for other optimization methods.</p>\n<div class=\"highlight highlight-source-gfm\"><pre>bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/workspace/frozen_inference_graph.pb --out_graph=/workspace/frozen_inference_graph_opti.pb \\\n      --inputs='image_tensor:0' --outputs='detection_boxes:0,detection_scores:0,detection_classes:0,num_detections:0' \\\n          --transforms='strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics)\\\n              fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights'</pre></div>\n<p>The model size changed from 53 MB to 13 MB, new optmization model is working perfectly fine on Ubundu 16.04 and Windows 10 with the following numbers (without the GPU) :</p>\n<h1>On Ubuntu 16.04 &amp; Windows 10 :</h1>\n<p>Before the Optimization :<br>\nInference time = 616 mSec/image<br>\nAfter the optmization :<br>\nInference time =200 mSec /image<br>\nAs you can observe that, there is clear three fold speed boost with the optimized model without compromising the accuracy. However, on android inference time remains same after the optmization.</p>\n<h1>On Android</h1>\n<p>Before the optmization :<br>\nInference time = 900 mSec/image<br>\nAfter the optimization :<br>\nInference time = 890 mSec/image</p>\n<p>The mobile device I am using is Galaxy Tab S2 8.0 with Octa-core processor.<br>\nI have digged most of the issues here but those are either issues with slower model on one OS or some sort of error with optimized model. This is the first time I am seeing this strange behavior when moving to mobile plateform.</p>\n<p>Let me know if you need more information.<br>\nThanks in advance.</p>", "body_text": "System information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 7.0\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): Tensorflow Android 1.6 with Java TFInferenceInterface\nPython version: 3.5\nBazel version (if compiling from source):\nGCC/Compiler version (if compiling from source):\nCUDA/cuDNN version:\nGPU model and memory:\nExact command to reproduce: Please see below.\n\nDescribe the problem\nI am using graph transformation tool to optimize SSD model. Here is the command I used to strip the nodes, quantize the weights and for other optimization methods.\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/workspace/frozen_inference_graph.pb --out_graph=/workspace/frozen_inference_graph_opti.pb \\\n      --inputs='image_tensor:0' --outputs='detection_boxes:0,detection_scores:0,detection_classes:0,num_detections:0' \\\n          --transforms='strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics)\\\n              fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights'\nThe model size changed from 53 MB to 13 MB, new optmization model is working perfectly fine on Ubundu 16.04 and Windows 10 with the following numbers (without the GPU) :\nOn Ubuntu 16.04 & Windows 10 :\nBefore the Optimization :\nInference time = 616 mSec/image\nAfter the optmization :\nInference time =200 mSec /image\nAs you can observe that, there is clear three fold speed boost with the optimized model without compromising the accuracy. However, on android inference time remains same after the optmization.\nOn Android\nBefore the optmization :\nInference time = 900 mSec/image\nAfter the optimization :\nInference time = 890 mSec/image\nThe mobile device I am using is Galaxy Tab S2 8.0 with Octa-core processor.\nI have digged most of the issues here but those are either issues with slower model on one OS or some sort of error with optimized model. This is the first time I am seeing this strange behavior when moving to mobile plateform.\nLet me know if you need more information.\nThanks in advance.", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android 7.0 \r\n- **TensorFlow installed from (source or binary)**: Binary \r\n- **TensorFlow version (use command below)**: Tensorflow Android 1.6 with Java TFInferenceInterface\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: \r\n- **Exact command to reproduce**: Please see below. \r\n\r\n### Describe the problem\r\nI am using graph transformation tool to optimize SSD model. Here is the command I used to strip the nodes, quantize the weights and for other optimization methods. \r\n```markdown\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/workspace/frozen_inference_graph.pb --out_graph=/workspace/frozen_inference_graph_opti.pb \\\r\n      --inputs='image_tensor:0' --outputs='detection_boxes:0,detection_scores:0,detection_classes:0,num_detections:0' \\\r\n          --transforms='strip_unused_nodes(type=float, shape=\"1,299,299,3\") remove_nodes(op=Identity, op=CheckNumerics)\\\r\n              fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights'\r\n```\r\nThe model size changed from 53 MB to 13 MB, new optmization model is working perfectly fine on Ubundu 16.04 and Windows 10 with the following numbers (without the GPU) : \r\n# On Ubuntu 16.04 & Windows 10 : \r\nBefore the Optimization :  \r\nInference time = 616 mSec/image \r\nAfter the optmization : \r\nInference time =200 mSec /image\r\nAs you can observe that, there is clear three fold speed boost with the optimized model without compromising the accuracy. However, on android inference time remains same after the optmization. \r\n# On Android \r\nBefore the optmization : \r\nInference time = 900 mSec/image\r\nAfter the optimization : \r\nInference time = 890 mSec/image \r\n\r\nThe mobile device I am using is Galaxy Tab S2 8.0 with Octa-core processor. \r\nI have digged most of the issues here but those are either issues with slower model on one OS or some sort of error with optimized model. This is the first time I am seeing this strange behavior when moving to mobile plateform.  \r\n\r\n Let me know if you need more information. \r\nThanks in advance. \r\n"}