{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/comments/409355724", "html_url": "https://github.com/tensorflow/tensorflow/issues/20718#issuecomment-409355724", "issue_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/20718", "id": 409355724, "node_id": "MDEyOklzc3VlQ29tbWVudDQwOTM1NTcyNA==", "user": {"login": "skulhare", "id": 29107055, "node_id": "MDQ6VXNlcjI5MTA3MDU1", "avatar_url": "https://avatars2.githubusercontent.com/u/29107055?v=4", "gravatar_id": "", "url": "https://api.github.com/users/skulhare", "html_url": "https://github.com/skulhare", "followers_url": "https://api.github.com/users/skulhare/followers", "following_url": "https://api.github.com/users/skulhare/following{/other_user}", "gists_url": "https://api.github.com/users/skulhare/gists{/gist_id}", "starred_url": "https://api.github.com/users/skulhare/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/skulhare/subscriptions", "organizations_url": "https://api.github.com/users/skulhare/orgs", "repos_url": "https://api.github.com/users/skulhare/repos", "events_url": "https://api.github.com/users/skulhare/events{/privacy}", "received_events_url": "https://api.github.com/users/skulhare/received_events", "type": "User", "site_admin": false}, "created_at": "2018-07-31T20:24:24Z", "updated_at": "2018-07-31T20:24:24Z", "author_association": "NONE", "body_html": "<p>Thanks for getting back on this.<br>\nSure, let me run the profiling, I will post the cases.<br>\nDo you think Tensorflow Lite would be faster in using optimized models?<br>\nI can give a shot to quantized training too but I was trying to take the complete advantage of graph-transformation tool on inference model, just to avoid the re-training again with quantized weights.</p>", "body_text": "Thanks for getting back on this.\nSure, let me run the profiling, I will post the cases.\nDo you think Tensorflow Lite would be faster in using optimized models?\nI can give a shot to quantized training too but I was trying to take the complete advantage of graph-transformation tool on inference model, just to avoid the re-training again with quantized weights.", "body": "Thanks for getting back on this. \r\nSure, let me run the profiling, I will post the cases. \r\nDo you think Tensorflow Lite would be faster in using optimized models? \r\nI can give a shot to quantized training too but I was trying to take the complete advantage of graph-transformation tool on inference model, just to avoid the re-training again with quantized weights. "}