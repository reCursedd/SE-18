{"url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9699", "repository_url": "https://api.github.com/repos/tensorflow/tensorflow", "labels_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9699/labels{/name}", "comments_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9699/comments", "events_url": "https://api.github.com/repos/tensorflow/tensorflow/issues/9699/events", "html_url": "https://github.com/tensorflow/tensorflow/issues/9699", "id": 226661793, "node_id": "MDU6SXNzdWUyMjY2NjE3OTM=", "number": 9699, "title": "RNN: InvalidArgumentError when adding InitialState", "user": {"login": "kevinashaw", "id": 7141343, "node_id": "MDQ6VXNlcjcxNDEzNDM=", "avatar_url": "https://avatars3.githubusercontent.com/u/7141343?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kevinashaw", "html_url": "https://github.com/kevinashaw", "followers_url": "https://api.github.com/users/kevinashaw/followers", "following_url": "https://api.github.com/users/kevinashaw/following{/other_user}", "gists_url": "https://api.github.com/users/kevinashaw/gists{/gist_id}", "starred_url": "https://api.github.com/users/kevinashaw/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kevinashaw/subscriptions", "organizations_url": "https://api.github.com/users/kevinashaw/orgs", "repos_url": "https://api.github.com/users/kevinashaw/repos", "events_url": "https://api.github.com/users/kevinashaw/events{/privacy}", "received_events_url": "https://api.github.com/users/kevinashaw/received_events", "type": "User", "site_admin": false}, "labels": [{"id": 404586594, "node_id": "MDU6TGFiZWw0MDQ1ODY1OTQ=", "url": "https://api.github.com/repos/tensorflow/tensorflow/labels/stat:awaiting%20tensorflower", "name": "stat:awaiting tensorflower", "color": "f4b400", "default": false}], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 14, "created_at": "2017-05-05T18:54:45Z", "updated_at": "2018-09-02T14:54:54Z", "closed_at": "2017-05-07T09:03:37Z", "author_association": "NONE", "body_html": "<p>Please go to Stack Overflow for help and support:</p>\n<h3>System information</h3>\n<ul>\n<li><strong>Have I written custom code (as opposed to using a stock example script provided in TensorFlow)</strong>: Yes.  The current stock examples are pre-TF1.0 and do not run.  I have already posted an issue regarding them. (<a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load issue title\" data-id=\"222509554\" data-permission-text=\"Issue title is private\" data-url=\"https://github.com/tensorflow/tensorflow/issues/9294\" data-hovercard-type=\"issue\" data-hovercard-url=\"/tensorflow/tensorflow/issues/9294/hovercard?comment_id=294944970&amp;comment_type=issue_comment\" href=\"https://github.com/tensorflow/tensorflow/issues/9294#issuecomment-294944970\">#9294 (comment)</a>)</li>\n<li><strong>OS Platform and Distribution (e.g., Linux Ubuntu 16.04)</strong>: Ubuntu 14.04</li>\n<li><strong>TensorFlow installed from (source or binary)</strong>: Binary</li>\n<li><strong>TensorFlow version (use command below)</strong>: TF1.1.0</li>\n<li><strong>Bazel version (if compiling from source)</strong>: n/a</li>\n<li><strong>CUDA/cuDNN version</strong>: 5.1</li>\n<li><strong>GPU model and memory</strong>: p2-xlarge with 12GiB</li>\n<li><strong>Exact command to reproduce</strong>:</li>\n</ul>\n<p>When training a simple two layer RNN, if I do not include the initialstate, the graph trains properly, if I add the initialstate, then I get the following error.<br>\nBrief code (full code below):</p>\n<pre><code>    initial_state = lstm_cells.zero_state(batch_size, tf.float32) \n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\n</code></pre>\n<p>Error message (full message below):</p>\n<pre><code>InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n</code></pre>\n<p>If I print the <code>initial_state</code> variable, I get this:</p>\n<pre><code>(LSTMStateTuple(c=&lt;tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32&gt;, h=&lt;tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32&gt;), LSTMStateTuple(c=&lt;tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32&gt;, h=&lt;tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32&gt;))\n</code></pre>\n<p>If I print the <code>state</code> producted by <code>static_rnn</code> call:</p>\n<pre><code>(LSTMStateTuple(c=&lt;tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32&gt;, h=&lt;tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32&gt;), LSTMStateTuple(c=&lt;tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32&gt;, h=&lt;tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32&gt;))\n</code></pre>\n<p>Here is the full message:</p>\n<pre><code>---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n&lt;ipython-input-15-5e6d1756b352&gt; in &lt;module&gt;()\n     90         Xin   : X_test,\n     91         Ytrue : one_hot(y_test, LabelMax),\n---&gt; 92         keep_prob: 1.0\n     93     }\n     94 )\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    776     try:\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\n--&gt; 778                          run_metadata_ptr)\n    779       if run_metadata:\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    980     if final_fetches or final_targets:\n    981       results = self._do_run(handle, final_targets, final_fetches,\n--&gt; 982                              feed_dict_string, options, run_metadata)\n    983     else:\n    984       results = []\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1030     if handle is None:\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-&gt; 1032                            target_list, options, run_metadata)\n   1033     else:\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n   1050         except KeyError:\n   1051           pass\n-&gt; 1052       raise type(e)(node_def, op, message)\n   1053 \n   1054   def _extend_graph(self):\n\nInvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat', defined at:\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-14-eaca1bbf91d8&gt;\", line 48, in &lt;module&gt;\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\n    (output, state) = call_cell()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in &lt;lambda&gt;\n    call_cell = lambda: cell(input_, state)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 953, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1048, in _linear\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1034, in concat\n    name=name)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 519, in _concat_v2\n    name=name)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n</code></pre>\n<p>Here is the network creation code:</p>\n<pre><code># Clear the graph memory\ntf.reset_default_graph()\n\n# Graph input/output\nXin   = tf.placeholder(tf.float32, [None, n_steps, n_input] , name= \"Xin\")\nYtrue = tf.placeholder(tf.float32, [None, n_classes]        , name= \"Ytrue\")\n\n# Graph weights\nweights={}\nweights['Pre' ] = tf.Variable(tf.random_normal([n_input     , n_hiddenPre ]), name=\"Wght_Pre\") # Hidden layer weights\nweights['LSTM'] = tf.Variable(tf.random_normal([n_hiddenPre , n_hidden    ]), name=\"Wght_LSTM\") # Hidden layer weights\nweights['Post'] = tf.Variable(tf.random_normal([n_hidden    , n_hiddenPost]), name=\"Wght_Post\")\nweights['out' ] = tf.Variable(tf.random_normal([n_hiddenPost, n_classes   ]), name=\"Wght_Out\")\n\nbiases={}\nbiases['Pre' ] = tf.Variable(tf.random_normal([n_hiddenPre ]), name=\"Bias_Pre\")\nbiases['LSTM'] = tf.Variable(tf.random_normal([n_hidden    ]), name=\"Bias_LSTM\")\nbiases['Post'] = tf.Variable(tf.random_normal([n_hiddenPost]), name=\"Bias_Post\")\nbiases['out' ] = tf.Variable(tf.random_normal([n_classes   ]), name=\"Bias_Out\")\n\nXnew = prepareX(Xin)\n\nwith tf.name_scope('DensePre'):\n    Xpre = tf.matmul(Xnew, weights['Pre']) + biases['Pre']\n    keep_prob  = tf.placeholder(tf.float32)\n    Xpre_drop = tf.nn.dropout(Xpre, keep_prob)\n\n    # Linear activation\n    Xnew = tf.matmul(Xpre_drop, weights['LSTM']) + biases['LSTM']\n\nwith tf.name_scope('RNN'): \n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n    Xnew = tf.split(Xnew, n_steps, axis=0) \n    # new shape: n_steps * (batch_size, n_hidden)\n\n    # Can use one or more LSTM layers\n    lstm_cell1  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n    lstm_cell2  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n    lstm_cells  = tf.contrib.rnn.MultiRNNCell([lstm_cell1,lstm_cell2], state_is_tuple=True)\n    #RNN_outputs, state = lstm_cells(Xnew, state=state)  # this code fails, so used line above without state\n    \n    # The following lines are for the bidirectional RNN, but effort was blocked due to an opaque error message\n    #  lstm_cell_back   = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n    #  lstm_cells_back  = tf.contrib.rnn.MultiRNNCell([lstm_cell_back] * 2, state_is_tuple=True)\n\n    # Get LSTM cell output\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) # Not used, but should be!\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\n    #RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32)\n    print(initial_state)\n    print(state)\n\nwith tf.name_scope('DensePost'):\n    Xnew = tf.matmul(RNN_outputs[-1], weights['Post']) + biases['Post']\n    Xnew = tf.nn.dropout(Xnew, keep_prob)\n     \nwith tf.name_scope('DenseOut'):\n    # Linear activation\n    Ypred        = tf.add(tf.matmul(Xnew, weights['out']),biases['out'], name=\"Ypred_raw\")\n    # Compute softmax result\n    YpredSoftMax = tf.nn.softmax(Ypred   , dim =1, name=\"prediction\")\n    YpredIndex   = tf.argmax(YpredSoftMax, axis=1, name=\"predIndex\" )\n# Loss, optimizer and evaluation; Regularization term\nl2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \n# L2 loss prevents this overkill neural network to overfit the data\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Ypred, labels=Ytrue)) + l2 # Softmax loss\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n\ncorrect_pred = tf.equal(tf.argmax(Ypred,1), tf.argmax(Ytrue,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n</code></pre>", "body_text": "Please go to Stack Overflow for help and support:\nSystem information\n\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.  The current stock examples are pre-TF1.0 and do not run.  I have already posted an issue regarding them. (#9294 (comment))\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\nTensorFlow installed from (source or binary): Binary\nTensorFlow version (use command below): TF1.1.0\nBazel version (if compiling from source): n/a\nCUDA/cuDNN version: 5.1\nGPU model and memory: p2-xlarge with 12GiB\nExact command to reproduce:\n\nWhen training a simple two layer RNN, if I do not include the initialstate, the graph trains properly, if I add the initialstate, then I get the following error.\nBrief code (full code below):\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) \n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\n\nError message (full message below):\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nIf I print the initial_state variable, I get this:\n(LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))\n\nIf I print the state producted by static_rnn call:\n(LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>))\n\nHere is the full message:\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-15-5e6d1756b352> in <module>()\n     90         Xin   : X_test,\n     91         Ytrue : one_hot(y_test, LabelMax),\n---> 92         keep_prob: 1.0\n     93     }\n     94 )\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    776     try:\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 778                          run_metadata_ptr)\n    779       if run_metadata:\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    980     if final_fetches or final_targets:\n    981       results = self._do_run(handle, final_targets, final_fetches,\n--> 982                              feed_dict_string, options, run_metadata)\n    983     else:\n    984       results = []\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n   1030     if handle is None:\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n-> 1032                            target_list, options, run_metadata)\n   1033     else:\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n   1050         except KeyError:\n   1051           pass\n-> 1052       raise type(e)(node_def, op, message)\n   1053 \n   1054   def _extend_graph(self):\n\nInvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat', defined at:\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-eaca1bbf91d8>\", line 48, in <module>\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\n    (output, state) = call_cell()\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\n    call_cell = lambda: cell(input_, state)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 953, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1048, in _linear\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1034, in concat\n    name=name)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 519, in _concat_v2\n    name=name)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nHere is the network creation code:\n# Clear the graph memory\ntf.reset_default_graph()\n\n# Graph input/output\nXin   = tf.placeholder(tf.float32, [None, n_steps, n_input] , name= \"Xin\")\nYtrue = tf.placeholder(tf.float32, [None, n_classes]        , name= \"Ytrue\")\n\n# Graph weights\nweights={}\nweights['Pre' ] = tf.Variable(tf.random_normal([n_input     , n_hiddenPre ]), name=\"Wght_Pre\") # Hidden layer weights\nweights['LSTM'] = tf.Variable(tf.random_normal([n_hiddenPre , n_hidden    ]), name=\"Wght_LSTM\") # Hidden layer weights\nweights['Post'] = tf.Variable(tf.random_normal([n_hidden    , n_hiddenPost]), name=\"Wght_Post\")\nweights['out' ] = tf.Variable(tf.random_normal([n_hiddenPost, n_classes   ]), name=\"Wght_Out\")\n\nbiases={}\nbiases['Pre' ] = tf.Variable(tf.random_normal([n_hiddenPre ]), name=\"Bias_Pre\")\nbiases['LSTM'] = tf.Variable(tf.random_normal([n_hidden    ]), name=\"Bias_LSTM\")\nbiases['Post'] = tf.Variable(tf.random_normal([n_hiddenPost]), name=\"Bias_Post\")\nbiases['out' ] = tf.Variable(tf.random_normal([n_classes   ]), name=\"Bias_Out\")\n\nXnew = prepareX(Xin)\n\nwith tf.name_scope('DensePre'):\n    Xpre = tf.matmul(Xnew, weights['Pre']) + biases['Pre']\n    keep_prob  = tf.placeholder(tf.float32)\n    Xpre_drop = tf.nn.dropout(Xpre, keep_prob)\n\n    # Linear activation\n    Xnew = tf.matmul(Xpre_drop, weights['LSTM']) + biases['LSTM']\n\nwith tf.name_scope('RNN'): \n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n    Xnew = tf.split(Xnew, n_steps, axis=0) \n    # new shape: n_steps * (batch_size, n_hidden)\n\n    # Can use one or more LSTM layers\n    lstm_cell1  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n    lstm_cell2  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n    lstm_cells  = tf.contrib.rnn.MultiRNNCell([lstm_cell1,lstm_cell2], state_is_tuple=True)\n    #RNN_outputs, state = lstm_cells(Xnew, state=state)  # this code fails, so used line above without state\n    \n    # The following lines are for the bidirectional RNN, but effort was blocked due to an opaque error message\n    #  lstm_cell_back   = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n    #  lstm_cells_back  = tf.contrib.rnn.MultiRNNCell([lstm_cell_back] * 2, state_is_tuple=True)\n\n    # Get LSTM cell output\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) # Not used, but should be!\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\n    #RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32)\n    print(initial_state)\n    print(state)\n\nwith tf.name_scope('DensePost'):\n    Xnew = tf.matmul(RNN_outputs[-1], weights['Post']) + biases['Post']\n    Xnew = tf.nn.dropout(Xnew, keep_prob)\n     \nwith tf.name_scope('DenseOut'):\n    # Linear activation\n    Ypred        = tf.add(tf.matmul(Xnew, weights['out']),biases['out'], name=\"Ypred_raw\")\n    # Compute softmax result\n    YpredSoftMax = tf.nn.softmax(Ypred   , dim =1, name=\"prediction\")\n    YpredIndex   = tf.argmax(YpredSoftMax, axis=1, name=\"predIndex\" )\n# Loss, optimizer and evaluation; Regularization term\nl2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \n# L2 loss prevents this overkill neural network to overfit the data\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Ypred, labels=Ytrue)) + l2 # Softmax loss\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n\ncorrect_pred = tf.equal(tf.argmax(Ypred,1), tf.argmax(Ytrue,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))", "body": "Please go to Stack Overflow for help and support:\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes.  The current stock examples are pre-TF1.0 and do not run.  I have already posted an issue regarding them. (https://github.com/tensorflow/tensorflow/issues/9294#issuecomment-294944970)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: TF1.1.0\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 5.1\r\n- **GPU model and memory**: p2-xlarge with 12GiB\r\n- **Exact command to reproduce**:\r\n\r\nWhen training a simple two layer RNN, if I do not include the initialstate, the graph trains properly, if I add the initialstate, then I get the following error.  \r\nBrief code (full code below):\r\n```\r\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) \r\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\r\n```\r\nError message (full message below):\r\n```\r\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\r\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\r\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\nIf I print the `initial_state` variable, I get this:\r\n```\r\n(LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))\r\n```\r\nIf I print the `state` producted by `static_rnn` call:\r\n```\r\n(LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>))\r\n```\r\nHere is the full message:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-15-5e6d1756b352> in <module>()\r\n     90         Xin   : X_test,\r\n     91         Ytrue : one_hot(y_test, LabelMax),\r\n---> 92         keep_prob: 1.0\r\n     93     }\r\n     94 )\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\r\n    776     try:\r\n    777       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 778                          run_metadata_ptr)\r\n    779       if run_metadata:\r\n    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    980     if final_fetches or final_targets:\r\n    981       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 982                              feed_dict_string, options, run_metadata)\r\n    983     else:\r\n    984       results = []\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1030     if handle is None:\r\n   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1032                            target_list, options, run_metadata)\r\n   1033     else:\r\n   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\r\n   1050         except KeyError:\r\n   1051           pass\r\n-> 1052       raise type(e)(node_def, op, message)\r\n   1053 \r\n   1054   def _extend_graph(self):\r\n\r\nInvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\r\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\r\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op u'RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat', defined at:\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-14-eaca1bbf91d8>\", line 48, in <module>\r\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 197, in static_rnn\r\n    (output, state) = call_cell()\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\r\n    call_cell = lambda: cell(input_, state)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 953, in __call__\r\n    cur_inp, new_state = cell(cur_inp, cur_state)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 241, in __call__\r\n    concat = _linear([inputs, h], 4 * self._num_units, True)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 1048, in _linear\r\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1034, in concat\r\n    name=name)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 519, in _concat_v2\r\n    name=name)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]\r\n\t [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]\r\n\t [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16414_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n```\r\nHere is the network creation code:\r\n```\r\n# Clear the graph memory\r\ntf.reset_default_graph()\r\n\r\n# Graph input/output\r\nXin   = tf.placeholder(tf.float32, [None, n_steps, n_input] , name= \"Xin\")\r\nYtrue = tf.placeholder(tf.float32, [None, n_classes]        , name= \"Ytrue\")\r\n\r\n# Graph weights\r\nweights={}\r\nweights['Pre' ] = tf.Variable(tf.random_normal([n_input     , n_hiddenPre ]), name=\"Wght_Pre\") # Hidden layer weights\r\nweights['LSTM'] = tf.Variable(tf.random_normal([n_hiddenPre , n_hidden    ]), name=\"Wght_LSTM\") # Hidden layer weights\r\nweights['Post'] = tf.Variable(tf.random_normal([n_hidden    , n_hiddenPost]), name=\"Wght_Post\")\r\nweights['out' ] = tf.Variable(tf.random_normal([n_hiddenPost, n_classes   ]), name=\"Wght_Out\")\r\n\r\nbiases={}\r\nbiases['Pre' ] = tf.Variable(tf.random_normal([n_hiddenPre ]), name=\"Bias_Pre\")\r\nbiases['LSTM'] = tf.Variable(tf.random_normal([n_hidden    ]), name=\"Bias_LSTM\")\r\nbiases['Post'] = tf.Variable(tf.random_normal([n_hiddenPost]), name=\"Bias_Post\")\r\nbiases['out' ] = tf.Variable(tf.random_normal([n_classes   ]), name=\"Bias_Out\")\r\n\r\nXnew = prepareX(Xin)\r\n\r\nwith tf.name_scope('DensePre'):\r\n    Xpre = tf.matmul(Xnew, weights['Pre']) + biases['Pre']\r\n    keep_prob  = tf.placeholder(tf.float32)\r\n    Xpre_drop = tf.nn.dropout(Xpre, keep_prob)\r\n\r\n    # Linear activation\r\n    Xnew = tf.matmul(Xpre_drop, weights['LSTM']) + biases['LSTM']\r\n\r\nwith tf.name_scope('RNN'): \r\n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\r\n    Xnew = tf.split(Xnew, n_steps, axis=0) \r\n    # new shape: n_steps * (batch_size, n_hidden)\r\n\r\n    # Can use one or more LSTM layers\r\n    lstm_cell1  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\r\n    lstm_cell2  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\r\n    lstm_cells  = tf.contrib.rnn.MultiRNNCell([lstm_cell1,lstm_cell2], state_is_tuple=True)\r\n    #RNN_outputs, state = lstm_cells(Xnew, state=state)  # this code fails, so used line above without state\r\n    \r\n    # The following lines are for the bidirectional RNN, but effort was blocked due to an opaque error message\r\n    #  lstm_cell_back   = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\r\n    #  lstm_cells_back  = tf.contrib.rnn.MultiRNNCell([lstm_cell_back] * 2, state_is_tuple=True)\r\n\r\n    # Get LSTM cell output\r\n    initial_state = lstm_cells.zero_state(batch_size, tf.float32) # Not used, but should be!\r\n    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)\r\n    #RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32)\r\n    print(initial_state)\r\n    print(state)\r\n\r\nwith tf.name_scope('DensePost'):\r\n    Xnew = tf.matmul(RNN_outputs[-1], weights['Post']) + biases['Post']\r\n    Xnew = tf.nn.dropout(Xnew, keep_prob)\r\n     \r\nwith tf.name_scope('DenseOut'):\r\n    # Linear activation\r\n    Ypred        = tf.add(tf.matmul(Xnew, weights['out']),biases['out'], name=\"Ypred_raw\")\r\n    # Compute softmax result\r\n    YpredSoftMax = tf.nn.softmax(Ypred   , dim =1, name=\"prediction\")\r\n    YpredIndex   = tf.argmax(YpredSoftMax, axis=1, name=\"predIndex\" )\r\n# Loss, optimizer and evaluation; Regularization term\r\nl2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \r\n# L2 loss prevents this overkill neural network to overfit the data\r\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Ypred, labels=Ytrue)) + l2 # Softmax loss\r\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\r\n\r\ncorrect_pred = tf.equal(tf.argmax(Ypred,1), tf.argmax(Ytrue,1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n```"}